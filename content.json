{"pages":[],"posts":[{"title":"adam","date":"2018-11-07T07:33:45.086Z","path":"wiki/Math/-optimization/adam/","text":"Reference Adam: A Method for Stochastic Optimization","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-optimization","slug":"Math/optimization","permalink":"http://yoursite.com/categories/Math/optimization/"}]},{"title":"weight decay","date":"2018-11-07T07:10:33.328Z","path":"wiki/Math/-optimization/weight-decay/","text":"传统梯度下降法$$\\mathbf{x}{t+1}=\\mathbf{x}{t}-\\alpha \\nabla f_{t}(\\mathbf{x}_t)$$ 缺陷是 weight decayIn the weight decay described by Hanson &amp; Pratt (1988),the weights $\\mathbf{x}$ decay exponentially as$$\\mathbf{x}{t+1}=(1-w) \\mathbf{x}{t}-\\alpha \\nabla f_{t}(\\mathbf{x}_t)$$ where $w$ defines the rate of the weight decay per step and$\\nabla f_{t}(\\mathbf{x}_t)$ is the $t$-th batch gradient to be multiplied by a learning rate $\\alpha$. L2 regularization VS weight decayCommonly, we $$f_{t}^{reg}(\\mathbf{x}{t}) = f{t}(\\mathbf{x}_t)+\\frac{w}{2} {\\left | \\mathbf{x}t \\right |}{2}^{2}$$ Decoupling the Weight Decay from the gradient-based updateReference1.","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-optimization","slug":"Math/optimization","permalink":"http://yoursite.com/categories/Math/optimization/"}]},{"title":"优化方法，汇总","date":"2018-11-07T07:10:08.825Z","path":"wiki/Math/-optimization/summary/","text":"Adaptive gradient methods, such as AdaGrad (Duchiet al., 2011), RMSProp (Tieleman &amp; Hinton, 2012), andAdam (Kingma &amp; Ba, 2014) have become a default methodof choice for training feed-forward and recurrent neuralnetworks. 优化方法 简介 公式 适用场景 其他 Adadelta Adagrad Adam SparseAdam Adamax ASGD 平均SGD LBFGS RMSprop Rprop resilient BP SGD 参考 [pytorch的优化器]http://pytorch.org/docs/master/optim.html keras的优化器 sklearn的优化器 《凸优化》","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-optimization","slug":"Math/optimization","permalink":"http://yoursite.com/categories/Math/optimization/"}]},{"title":"","date":"2018-11-07T03:16:10.880Z","path":"wiki/通信/信号处理/-信号与系统-奥本海姆/平稳信号/","text":"什么是平稳序列？ 一个序列经过预处理被识别为平稳非白噪声序列，那就说明该序列是一个蕴含着相关信息的平稳序列。 什么样的序列不包含信息？白噪声是不包含信息吗？ https://blog.csdn.net/dingming001/article/details/73459494","tags":[],"categories":[{"name":"通信","slug":"通信","permalink":"http://yoursite.com/categories/通信/"},{"name":"信号处理","slug":"通信/信号处理","permalink":"http://yoursite.com/categories/通信/信号处理/"},{"name":"-信号与系统-奥本海姆","slug":"通信/信号处理/信号与系统-奥本海姆","permalink":"http://yoursite.com/categories/通信/信号处理/信号与系统-奥本海姆/"}]},{"title":"","date":"2018-11-06T03:29:18.664Z","path":"wiki/CS/tools/文件管理/-云盘/google云盘/","text":"公司的google suite，每个帐号可存储高达 5TB 文件。 google-doc VS microsoft-office离线、本地同步好弱啊，只能 需要安装插件Google Docs Offline， 将 Google 文档、表格、幻灯片和绘图文件同步到此计算机上，以便您可以在离线状态下进行编辑。系统会将 Google 文档的离线功能扩展程序添加到 Chrome 增量同步？与本地文件夹同步文件的增删以及修改？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"文件管理","slug":"CS/tools/文件管理","permalink":"http://yoursite.com/categories/CS/tools/文件管理/"},{"name":"-云盘","slug":"CS/tools/文件管理/云盘","permalink":"http://yoursite.com/categories/CS/tools/文件管理/云盘/"}]},{"title":"ResNeXt","date":"2018-11-05T08:46:36.669Z","path":"wiki/ML/deep learning/model-basic/CNN/-ResneXt/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"从hexo到hugo","date":"2018-11-05T06:00:13.255Z","path":"wiki/CS/web/blog-framework/go-hugo/hexo-to-hugo/","text":"吐槽 hexo 重量级 node_modules依赖特别大 慢 filter多， OOM:在服务器端生成目前的700多篇文章占用大量内存，很难生成成功1000+ 会造成OOM1FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory 原因: Node.js 的内存限制？一个node进程大概只能使用 1GB 的内存。需要修改启动配置 Go 生成速度极快，几千篇文章的生成只需几秒，而且资源占用极少 吐槽hugo hexo 用 javascript 写的，一堆搞前端的人做主题。 hugo 用 go 写的，一堆搞后端的人做主题。��，一堆搞后端的人做主题。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"go-hugo","slug":"CS/web/blog-framework/go-hugo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/go-hugo/"}]},{"title":"","date":"2018-11-04T05:17:03.388Z","path":"wiki/CS/web/-back-end/node/lib/minimatch/","text":"匹配规则12345* 匹配任意数量的字符，但不匹配/? 匹配单个字符，但不匹配/** 匹配任意数量的字符，包括/，只要它是路径中唯一的一部分&#123;&#125; 允许使用一个逗号分割的列表或者表达式! 在模式的开头用于否定一个匹配模式(即排除与模式匹配的信 息) 关于 /关于 .123minimatch(\"path/.go/src/app.js\", \"**/app.js\") // falseminimatch(\"path/go/src/app.js\", \"**/app.js\") // trueminimatch(\"path/.go/src/app.js\", \"**/app.js\", &#123;dot: true&#125;) // true https://github.com/isaacs/minimatch/issues/30https://github.com/isaacs/minimatch/issues/30","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"node","slug":"CS/web/back-end/node","permalink":"http://yoursite.com/categories/CS/web/back-end/node/"},{"name":"lib","slug":"CS/web/back-end/node/lib","permalink":"http://yoursite.com/categories/CS/web/back-end/node/lib/"}]},{"title":"文件系统 - 概述","date":"2018-11-03T14:27:15.601Z","path":"wiki/CS/OS/-linux/linux kenel/文件系统/src/概述/","text":"Linux 可以很方便地支持别的操作系统的文件系统，比如Windows 的文件系统就被Linux 所支持。Linux 不仅支持多种文件系统，而且还支持这些文件系统相互之间进行访问，这一切都要归功于神奇的虚拟文件系统。 VFS虚拟文件系统又称虚拟文件系统转换（Virual Filesystem Switch ，简称VFS）。说它虚拟，是因为它所有的数据结构都是在运行以后才建立，并在卸载时删除，而在磁盘上并没有存储这些数据结构。 如果只有VFS，系统是无法工作的，因为它的这些数据结构不能凭空而来，只有与实际的文件系统，如Ext2、Minix、MSDOS、VFAT 等相结合，才能开始工作，所以VFS 并不是一个真正的文件系统。与VFS 相对应，我们称Ext2、Minix、MSDOS 等为具体文件系统。 架构 VFS的作用1// include/linux/fs.h 768 790 Windows和Linux文件系统的区别扩展阅读 深入分析Linux内核源码 | 陈莉君-扩展阅读 深入分析Linux内核源码 | 陈莉君-","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"文件系统","slug":"CS/OS/linux/linux-kenel/文件系统","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/"},{"name":"src","slug":"CS/OS/linux/linux-kenel/文件系统/src","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/src/"}]},{"title":"Linux源码  入口","date":"2018-11-02T11:57:19.006Z","path":"wiki/CS/OS/-linux/linux kenel/-入口/","text":"init/main.calds/linux/blob/master/init/main.c)","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"}]},{"title":"","date":"2018-11-02T02:41:06.086Z","path":"wiki/ML/deep learning/model-basic/RNN/-BayesianRNN/","text":"https://github.com/ofirpress/UsingTheOutputEmbedding 三种方式的weight tying？ 利用贝叶斯的方法？ 扩展阅读利用贝叶斯的方法？ 扩展阅读","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"","date":"2018-11-01T08:38:30.240Z","path":"wiki/CS/programing/lan/python/-src-cpython/Objects/dictobjec/","text":"https://github.com/python/cpython/blob/2.7/Objects/dictobject.c- https://github.com/python/cpython/blob/2.7/Objects/dictobject.c","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"-src-cpython","slug":"CS/programing/lan/python/src-cpython","permalink":"http://yoursite.com/categories/CS/programing/lan/python/src-cpython/"},{"name":"Objects","slug":"CS/programing/lan/python/src-cpython/Objects","permalink":"http://yoursite.com/categories/CS/programing/lan/python/src-cpython/Objects/"}]},{"title":"","date":"2018-11-01T04:46:16.745Z","path":"wiki/ML/deep learning/toolbox/tensorflow/low-level-api/-model-and-checkpoint/","text":"deep learning toolbox tensorflow low-level-api","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"low-level-api","slug":"ML/deep-learning/toolbox/tensorflow/low-level-api","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/low-level-api/"}]},{"title":"","date":"2018-11-01T02:56:58.263Z","path":"wiki/CS/programing/lan/python/动态加载/-方法-动态加载/","text":"getattr的方式lan python 动态加载 getattr的方式","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"动态加载","slug":"CS/programing/lan/python/动态加载","permalink":"http://yoursite.com/categories/CS/programing/lan/python/动态加载/"}]},{"title":"","date":"2018-11-01T02:50:18.054Z","path":"wiki/CS/programing/lan/python/-python面向对象/多态/","text":"12345678910class A: # 定义接口(抽象方法)，在子类中实现 def generate_data(self): raise NotImplementedError() # raise NotImplementedError(\"Abstract Method\") # 尼玛，这是占坑？ def hparams(self, defaults, model_hparams): pass","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"-python面向对象","slug":"CS/programing/lan/python/python面向对象","permalink":"http://yoursite.com/categories/CS/programing/lan/python/python面向对象/"}]},{"title":"","date":"2018-11-01T02:50:05.623Z","path":"wiki/CS/programing/lan/python/-python面向对象/封装/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"-python面向对象","slug":"CS/programing/lan/python/python面向对象","permalink":"http://yoursite.com/categories/CS/programing/lan/python/python面向对象/"}]},{"title":"BERT","date":"2018-10-31T02:31:36.250Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/BERT/","text":"本文介绍了一种新的语言表征模型 BERT——来自 Transformer 的双向编码器表征。与最近的语言表征模型不同，BERT 旨在基于所有层的左、右语境来预训练深度双向表征。BERT 是首个在大批句子层面和 token 层面任务中取得当前最优性能的基于微调的表征模型，其性能超越许多使用任务特定架构的系统，刷新了 11 项 NLP 任务的当前最优性能记录。 基于特征的策略 （如 ELMo）使用将预训练表征作为额外特征的任务专用架构。 什么意思？ 微调策略（finetuning） （如生成预训练 Transformer (OpenAI GPT)）引入了任务特定最小参数(pretrain model之外的参数很少)，通过简单地微调预训练参数在下游任务中进行训练。 在之前的研究中，两种策略在预训练期间使用相同的目标函数，利用单向语言模型来学习通用语言表征。 传统方法的局限标准语言模型是单向的(从左到右)，这限制了可以在预训练期间使用的架构类型。 解读单向: RNN、ngram都是单向的。word2vec、ELMo是都是双向吧？双向lstm呢？限制架构类型: pretrain用的从左向右的单向网络，在双向网络transformer上怎样fine tune？比如OpenAI的GPT采用的从左到右的架构，其中每个 token 只能注意Transformer 自注意力层中的先前 token。这种局限很致命 BERTBERT（Bidirectional Encoder Representations from Transformers）改进了基于微调的策略。 BERT 提出一种新的预训练目标——遮蔽语言模型（masked language model，MLM），来克服上文提到的单向局限。MLM 的灵感来自 Cloze 任务（Taylor, 1953）。MLM 随机遮蔽输入中的一些 token，，目标在于仅基于遮蔽词的语境来预测其原始词汇 id。与从左到右的语言模型预训练不同，MLM 目标允许表征融合左右两侧的语境，从而预训练一个深度双向 Transformer。除了 MLM，我们还引入了一个「下一句预测」（next sentence prediction）任务，该任务联合预训练文本对表征。 扩展阅读-","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"RNN的应用","date":"2018-10-30T00:49:25.279Z","path":"wiki/ML/deep learning/model-basic/RNN/-2. RNN-app/","text":"solve sequence learning, sequence translation (seq2seq), which also resulted in amazing results in speech to text comprehension and the raise of Siri, Cortana, Google voice assistant, Alexa. translate images into text, text into images, and captioning video","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"RNN之殇","date":"2018-10-30T00:46:22.899Z","path":"wiki/ML/deep learning/model-basic/RNN/-4. RNN-fall/","text":"attentiion is all your need1. https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"tensorflow高层API -- Estimator","date":"2018-10-29T16:00:00.000Z","path":"wiki/ML/deep learning/toolbox/tensorflow/high-level-api/estimator/estimator/","text":"Estimatortf.estimator是TensorFlow的高层API，对以下方法进行了封装 training: 对应 ModeKeys.TRAIN evaluation: ModeKeys.EVAL predict: ModeKeys.PREDICT export for serving ModeKeys里这几个对应 update: tf要不支持这个模块了 Importing from tensorflow.python.estimator is unsupported and will soon break! Usage有两种使用方式，都需要依赖tf.estimator.Estimator这个类。 pre-made基于Estimator，官方预定义了一些常用的模型，比如DNNClassifier、DNNRegressor、LinearClassifier、BoostedTreesClassifier等。 以下是一个完整实例: 利用DNNClassifier对花萼分类，其核心代码就几行，充分展现了Estimator封装的简洁性 123classifier = tf.estimator.DNNClassifier(features, labels, hidden_units, n_classes) # 实例化estimatorclassifier.train(input_fn_train, steps) # 送入训练数据，开始trainingeval_result = classifier.evaluate(input_fn_test) # 送入test data 官方这几个model也为我们使用Estimator提供了例子 custom官方定义的模型不能够满足我们的需求，那就需要基于Estimator自定义模型 无论是pre-made，还是custom，其核心都是model function。在该方法中需要构建graph，包含training, evaluation, and prediction。 具体实现Estimator的封装，基本思想是让我们只需关心模型和数据，屏蔽硬件(是吗?)。 要实现这种封装，一种思路是抽象类(接口) + 继承 + 覆盖，另一种是完整类 + 传函数。Estimator显然更钟情于第二种方式(why?)。 model_fn 定义模型，即构建graph，主要要包含TRAIN、EVAL、PREDICT对应的op。 自己定义model_fnmodel_fn传给Estimatormodel_fn必须要以Estimator构造函数的方式传递。 pre-made DNNClassifier的实现 12345class DNNClassifier(estimator.Estimator): # 定义Estimator的封装，没必要 def __init__(.. # 重写init方法，仅仅是 def _model_fn(.. # 定义model_fn方法 (required) # 传递model_fn (关键) super(DNNClassifier, self).__init__(model_fn=_model_fn,..) 这仅仅是对Estimator的一个封装，对外直接用DNNClassifier而无视Estimator的存在。 自己的程序，没必要这样封装，屏蔽掉Estimator而定义一个新类，会让其他程序员看的摸不着头脑。 不建议采用继承的方式，还是开放Estimator比较好吧，即后面的custom方式 custom input_fn优势 Estimator对底层隔离，兼容CPU、GPU、TPU、多卡、多机多卡 666 其他几个优点没看懂 Estimator estimator与keras的关系， Datasets for Estimators给Estimator传入数据，通常为train何eval分别定义一个input_fn函数，该函数有三个参数： features：字典或DataFrame类型，包含输入数据的特征，与Feature Columns对应 labels：标签数组 batch_size：batch size 1dataset = dataset.shuffle(1000).repeat().batch(batch_size) repeat 要迭代数据集多个周期,例如，要创建一个将其输入重复 10 个周期的数据集repeat(10),无参表示无限次地重复输入。 shuffle 随机重排输入数据，维持一个固定大小的缓冲区，并从该缓冲区统一地随机选择下一个元素。 batch 每次取多少个数据 FAQ estimator节省了哪些操作？ 模型部分并未节省操作 与硬件底层的隔离，免去了写多机多卡的code estimator能否与low-level API交叉使用？ Estimator如何做多卡？多机并行？如何分配worker和ps？怎样的并行策略？ 另外是怎样封装的？ Estimator是屏蔽硬件吗？我们还是可以在model定义时设置device吧？ 扩展阅读 https://www.tensorflow.org/guide/premade_estimators Estimator源码 实例: pre-made estimator实例 custom estimator实例","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"high-level-api","slug":"ML/deep-learning/toolbox/tensorflow/high-level-api","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/high-level-api/"},{"name":"estimator","slug":"ML/deep-learning/toolbox/tensorflow/high-level-api/estimator","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/high-level-api/estimator/"}]},{"title":"标量、向量、矩阵、张量","date":"2018-10-29T02:02:36.403Z","path":"wiki/Math/交叉领域/-标量-矢量-张量-0维度-n维/","text":"张量: tensor 0阶张量: 无自由指标的量，即标量(Scalar, 即数量) 只有大小，没有方向，可用实数表示的一个量 实际上标量就是实数，标量这个称法只是为了区别与向量的差别 在物理学中，标量是在坐标变换下保持不变的物理量。例如，欧几里得空间中两点间的距离在坐标变换下保持不变，相对论四维时空中时空间隔在坐标变换下保持不变。 实例: 标量的例子包括质量、电荷、体积、时间、速率、温度和某一点的电势。 特别地: 电流具有方向性（由正极流向负极），但由于不符合向量运算，所以不会是向量。 1阶张量: 即向量(vector, 也称矢量) 指一个同时具有大小和方向，且满足平行四边形法则的几何对象。 1维向量 VS 标量 零向量 VS 标量: 始点与终点重合，即大小为0的向量，记为 $\\vec{0}$ 零向量依旧具有方向性，但方向不定。 零向量不等于数量0，它们是两种性质完全不同的对象，即 ${\\vec {0}}\\neq 0$ 实例: 运动学中的位移、速度、加速度，力学中的力、力矩，电磁学中的电流密度、磁矩、电磁波等等 n 维欧几里得空间 Rn上的向量 ${\\vec {v}}=(v_{1},v_{2},\\cdots ,v_{n})$ 特别地: 电流属既有大小、又有正负方向的量，但由于其运算不满足平行四边形法则，公认为其不属于向量 多维的，也是向量？张量呢？ 2阶张量: 有两个自有指标的量，即矩阵(matrix) 实例: 图像 3阶张量:- 4阶张量: [batch_size, channel_number, width_size, height_size] n阶张量: 包括标量、矢量 理解了张量的“阶”的概念，那么就明白了三者之间的关系了。 线性代数专门讨论矢量空间，包括矩阵理论。貌似没太涉及高阶张量- 易混点 维 VS 阶n维: n个自由度n阶: n阶是指数级数据扩充n维是线性数据扩充 n维向量的状态空间，对应n阶张量。 n阶tensor的shape是n维向量 n阶tensor中的一个点，也是n维向量 数据 VS 数据空间(data space)三维向量(数据)的取值空间，是 0维度 VS 0阶1234a = 4 # 0阶张量a = [] # 0维向量a = [[]] # 0维矩阵a = [[[]]] # 0维张量 1维矩阵 VS 1维向量 VS 标量。举个例子: [[5]]、[5]、512 n维与n阶3维向量 VS 3阶张量: 矩阵 VS 二维向量实质: 2阶 VS 2维度 梯度y=f(x)的梯度，算标量还是向量？正负到底算不算方向？ 算1维的向量吧 矩阵- 代数几何可以理解成状态 可以理解成 映射规则、空间变换 物理","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"交叉领域","slug":"Math/交叉领域","permalink":"http://yoursite.com/categories/Math/交叉领域/"}]},{"title":"【信号与系统】第一课","date":"2018-10-27T06:55:26.617Z","path":"wiki/通信/信号处理/-信号与系统-奥本海姆/1/","text":"信号信号，就是一个或多个自变量的函数，一般携带某种信息。 1-D信号声信号 - ，(只有一个自变量)，一维的连续时间信号 声信号也能视为二维信号吗？傅里叶变换后，有幅、频两个。是不是就算2d信号咯？ 2d比如图像brighnetss(x,y) Systems","tags":[],"categories":[{"name":"通信","slug":"通信","permalink":"http://yoursite.com/categories/通信/"},{"name":"信号处理","slug":"通信/信号处理","permalink":"http://yoursite.com/categories/通信/信号处理/"},{"name":"-信号与系统-奥本海姆","slug":"通信/信号处理/信号与系统-奥本海姆","permalink":"http://yoursite.com/categories/通信/信号处理/信号与系统-奥本海姆/"}]},{"title":"","date":"2018-10-26T09:43:26.470Z","path":"wiki/ML/deep learning/model-basic/-NN/NN/","text":"deep learning model-basic ‘-NN’","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"-NN","slug":"ML/deep-learning/model-basic/NN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/NN/"}]},{"title":"","date":"2018-10-26T09:43:11.733Z","path":"wiki/ML/deep learning/model-basic/-NN/BP/","text":"deep learning model-basic ‘-NN’","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"-NN","slug":"ML/deep-learning/model-basic/NN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/NN/"}]},{"title":"","date":"2018-10-25T10:05:09.335Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/-transformer-bad-case/","text":"句子循环因为 原因措施一: 从decoder端处理措施二: 从decoder端处理## 从decoder端处理 措施二: 从decoder端处理##","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"","date":"2018-10-24T10:50:57.345Z","path":"wiki/others/economy/-泡沫/-次贷危机/","text":"3a2a3b2b信用等级 信用低的， 卧槽，听不懂啊 https://www.bilibili.com/video/av19258366/?p=18 华尔街把美国穷人贷款买房的高风险转嫁到全球化的理财产品市场中，这就是固定收益产品的3A游戏。—-卧槽，太贱了，天才都去玩金钱游戏去了。 一旦美国穷人违约不还贷款，整个市场就会像建在沙滩上的宝塔一样顷刻倒塌 几乎全世界都是这个游戏的受害者，麻蛋谁是收益者？ 没有实体经济支撑的资本游戏如同沙上建塔","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-24T10:31:21.354Z","path":"wiki/others/economy/-泡沫/——纳斯达克/","text":"它没有纽交所光辉的历史，但是它有对创新无止境的追求。它赋予资本发掘风险财富的动力，让苹果、微软、英特尔成长为伟大的企业，他就是纳斯达克。 intel创始人，摩尔 纳斯达克就类似创业板，没盈利的也可以上市。 英特尔上市融资八千万美元 纳斯达克的口号，任何公司都可以在这上市。然而开始鱼目混珠，泡沫。大盘很高，互联网泡沫，纳斯达克2000年底，崩盘。指数从5000回落到1000，牛逼啊 纳斯达克对这些企业的成长，有帮助吗？企业融资最直接的方式就是上市，纽交所上市门槛高。 京东亏损，亏的是投资人的钱。 缺钱时，需要上市融资。 有钱时，需要全民股东分担风险。 mask为什么要退市？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-24T04:10:50.126Z","path":"wiki/Math/-计算数学/e的相关计算/","text":"用查表吧？","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-计算数学","slug":"Math/计算数学","permalink":"http://yoursite.com/categories/Math/计算数学/"}]},{"title":"","date":"2018-10-24T04:10:40.129Z","path":"wiki/Math/-计算数学/pie相关的计算/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-计算数学","slug":"Math/计算数学","permalink":"http://yoursite.com/categories/Math/计算数学/"}]},{"title":"","date":"2018-10-24T04:10:24.575Z","path":"wiki/Math/-计算数学/sin的计算/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-计算数学","slug":"Math/计算数学","permalink":"http://yoursite.com/categories/Math/计算数学/"}]},{"title":"微分、导数、偏导、全微分、梯度、切线","date":"2018-10-24T03:48:24.484Z","path":"wiki/Math/-数学分析(微积分)/微分学/微分和导数/","text":"说的真拗口 微分的定义微分(Differentiation) 当一个函数的自变量有微小的改变时，它的因变量一般也会有一个相应的改变。微分的原始思想是想去寻找一种方法，当因变量的改变也很微小时，能够简便而又精确地估计出这个改变量。 在”微小局部”用线性函数代替非线性函数是微积分的基本思想之一。 如果没有线性部分呢？ 导数的定义梯度的定义梯度向量是方向导数最大的地方，也就是曲面上最陡峭的方向，在日常生活中梯度向量用的非常多，因为我们经常会遇到找寻下降最快的路径（梯度向量的反方向）等问题，比如下山最省力气的路径。 切线(平面)的方向法线方向扩展阅读https://www.zybuluo.com/irving512/note/929786","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"微分学","slug":"Math/数学分析-微积分/微分学","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/微分学/"}]},{"title":"","date":"2018-10-23T12:09:18.462Z","path":"wiki/others/economy/-泡沫/-0/","text":"创投，多少还能帮助初创公司，间接创造价值，自身是不创造价值的。 炒股，创造价值吗？ # 工人–&gt;创造价值 企业家 投资家，就是那个杠杆。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T11:24:42.218Z","path":"wiki/others/economy/-泡沫/破碎的梦之队/","text":"设计出量化模型，套利债券 高杠杆的量化投资，通过杠杆率的高低控制收益率 这是在大概率赚小钱，可能小概率赚大钱 黑天鹅事件：无法预测，小概率 几十亿美元的自由资金，翘动了3250亿美元 100倍杠杆。 一次投资的失败，一夜回到解放前。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T11:08:50.129Z","path":"wiki/others/economy/-泡沫/英镑狙击战/","text":"捍卫英镑， 汇率大战 英格兰银行买入20亿英镑，英镑没上升。买入50亿， 似乎全世界都在卖出英镑，买方只有英格兰银行。 为什么叫英镑大势已去？低于下限会怎么样？ 英格兰宣布退出欧盟金融，英镑自由浮动。 犹太人真牛逼，真有钱。英国加入欧洲汇率机制是一个决策失误，索罗斯敏锐发现，英德两国的经济实力悬殊，和如日中天的德国相比，英国的经济实力难以支撑英镑对马克的固定汇率，英镑被明显高估了。 于是他大胆决策，做空英镑挑战英格兰银行，当英镑汇率不断逼近底限时，索罗斯出手了，他几乎是孤注一掷。他用自有资金加信用杠杆，投资总额据说超过一百亿美元。布局完成后，索罗斯开始在各大媒体发表对英镑的评论。他的看法逐渐影响了其他投资基金经理的决策。 英格兰银行面对的不是一个人，不是一家机构，而是主流的价值判断。 他们制定规则是局内人，当然会玩。 评论牛逼啊， 不敢这么玩，加杠杆，血本无归，除非很有自信","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T11:00:37.075Z","path":"wiki/others/economy/-泡沫/门口的野蛮人/","text":"借助杠杆，小鱼吃大鱼 嘲讽，赤裸裸的嘲讽 kkr 华尔街收购之王，也叫门口的野蛮人 垃圾债券，怎么搞？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T10:52:11.363Z","path":"wiki/others/economy/-泡沫/八佰伴倒闭/","text":"上海 八佰伴就是廉价的代名词 八佰伴的海外投资策略，没毛病啊。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T10:51:09.270Z","path":"wiki/others/economy/-泡沫/日本泡沫/","text":"日本日元升值，美元便宜，为什么不去美国买买买？资本外流，日本通货膨胀， 长期低迷的本土经济 VS 日本国民的海外资产不断向本土汇回收入。时至今日，日本海外资产及汇回收入仍高居世界第一。 股市崩盘，房价暴跌","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T10:43:39.676Z","path":"wiki/others/economy/-泡沫/-名画/","text":"名画的价值是否是泡沫？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T10:37:50.307Z","path":"wiki/others/economy/-泡沫/风险的价值/","text":"人的价值是厌恶风险的，而多利奥特的风险投资非常不看好。 财富与风险，就像硬币的两面。成功的，失败的血本无归。 优秀的投资人，像优秀的企业家一样稀缺。 相对纽约，纳斯达克上市较为宽松","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-23T07:17:43.669Z","path":"wiki/CS/web/建站/SSL证书/-ssl证书详解/","text":"123456Issued by: Let&apos;s Encrypt Authority X3Signature Algorithm: SHA-256 with RSA Encryption ( 1.2.840.113549.1.1.11 )Algorithm: RSA Encryption ( 1.2.840.113549.1.1.1 )Public Key: 256 bytes : AB C7 ...65537Signature: 256 bytes : 8E C6 ... 证书类型: RSA、ECC","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"SSL证书","slug":"CS/web/建站/SSL证书","permalink":"http://yoursite.com/categories/CS/web/建站/SSL证书/"}]},{"title":"","date":"2018-10-23T01:05:01.076Z","path":"wiki/CS/tools/绘图工具/-matlab-octave/","text":"大小: Matlab安装包10G，安装后占17G Octave-with-GUI 安装包300M Octave的GUI采用QT Octave开源为什么不放到github1hg clone https://www.octave.org/hg/octave github镜像 https://github.com/NexMirror/Octave 界面版本很难用，mac下字符都不清楚，fonk online tool 官方 https://matlab.mathworks.com/ 要license，fonk http://www.compileonline.com/execute_matlab_online.php 不能上传文件","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"绘图工具","slug":"CS/tools/绘图工具","permalink":"http://yoursite.com/categories/CS/tools/绘图工具/"}]},{"title":"【卷积】1. 卷积定理 & 应用","date":"2018-10-22T13:23:12.437Z","path":"wiki/ML/deep learning/model-basic/CNN/-1. 卷积定理-应用/","text":"什么是卷积卷积方法最早的研究可追溯到 提到的采用CNN只不过是一次尝试而已。发现效果不错。机器学习是在不断使试错中前进的。 卷积定理它将时域和空域上的复杂卷积对应到了频域中的元素间简单的乘积。 这个定理非常强大，在许多科学领域中得到了广泛应用。卷积定理也是快速傅里叶变换算法被称为 20 世纪最重要的算法之一的一个原因。 快速傅里叶变换时域 VS 频域 傅里叶变换包含了关于物体朝向的信息。如果物体被旋转了一个角度，从图像像素上可能很难判断，但从频域上可以很明显地看出来。 卷积的应用卷积在信号处理中的应用卷积在图像处理中的应用常用的卷积子疑问卷积的定义为什么要反褶？一般信号长度远远大于滤波器长度吗？No 许多情况下，信号长度远远大于滤波器长度，滤波器长度M为常数 扩展阅读 《信号与系统》 2.6卷积 3.8卷积定理| 郑君里 《数字信号处理》 《数字图像处理》刚萨雷斯 理解深度学习中的卷积 | Tim Dettmers &amp; 中文翻译 | 码农场","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"卷积的计算","date":"2018-10-22T12:57:44.774Z","path":"wiki/ML/deep learning/model-basic/CNN/-3. 卷积的数值计算/","text":"普通的计算 RAM 是输入图片，Buffer 是 feature map 你可能注意到这里有个正规化因子 m，这里 m 的值为 kernel 的大小 9；这是为了保证输入图像和 feature map 的亮度相同。 并行加速、buffer、精度、BP","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"","date":"2018-10-22T11:19:46.073Z","path":"wiki/others/economy/-泡沫/-美国钢铁公司-摩根/","text":"牛逼啊，第二收购老大，不断的收购达到近乎垄断。 https://www.bilibili.com/video/av19258366/?p=8","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T11:05:36.132Z","path":"wiki/others/economy/-泡沫/-注水的股票/","text":"https://www.bilibili.com/video/av19258366/?p=7 伊利铁路，把美国铁路连城一张网。 大股东一旦控制了，可以滥发股票。像印钞票一样。 华尔街","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T10:59:13.445Z","path":"wiki/others/economy/-泡沫/-期货/","text":"期货的发源 为了减少物价变动，提前规定未来的谷物价格。 保证金交易大大增加了期货市场 期货价格真正反映谷物价格吗？偏离太多呢？ 尼玛 扩展 https://www.bilibili.com/video/av19258366/?p=6 尼玛，越来越复杂，","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T10:40:26.297Z","path":"wiki/others/economy/-泡沫/-汉密尔顿的旋转门-美国/","text":"独立战争使美国背债很多，华盛顿任命汉密尔顿来解决。 统一货币，统一财政，强化国家信用 建国时，各个州的币不同。各州政府发行的，正在渐渐贬值的货币。 旋转门：拆东墙补西墙 将国家信用转化为财富， 信，国只宝也。 –《左传》 扩展阅读","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T06:02:30.335Z","path":"wiki/Math/-数学八卦-数学史-数学家/亚里士多德/","text":"在亚里士多德看来，物质元素除了水、火、气、土之外，还有一种居于天空上层的以太。 以太是什么？真空、暗物质、一种光传播所需要的介质、null 光的传播需要介质吗？真空是介质吗？ 光，无论在“真空”、还是“非真空”状态下，它所依赖的传播介质，都是：暗物质。光把暗物质“激活”为“光”。而，空气、水、玻璃……等，不是“光媒介”而是“消耗光速度”的障碍物。 光的传播不需要介质��的障碍物。 光的传播不需要介质","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学八卦-数学史-数学家","slug":"Math/数学八卦-数学史-数学家","permalink":"http://yoursite.com/categories/Math/数学八卦-数学史-数学家/"}]},{"title":"常用的符号","date":"2018-10-22T05:51:21.649Z","path":"wiki/demo/hexo/-sign/","text":"字符方向指示△ 示例 强调「卷」积 Font Awesomehttps://fontawesome.com/icons 好消息: 采用哪个font？大喇叭的形状 extrul1[&lt;i class=&quot;fa fa-external-link&quot;&gt;link to &lt;/i&gt;](ss) 资本的故事 资本的故事 ### tex#","tags":[],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"","date":"2018-10-22T04:43:41.985Z","path":"wiki/others/economy/-泡沫/-南海骗局/","text":"牛顿亏了10年工资 https://www.bilibili.com/video/av19258366/?p=3","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T04:42:13.225Z","path":"wiki/others/economy/-泡沫/07年中国A股/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T04:41:36.795Z","path":"wiki/others/economy/-泡沫/00年美国互联网泡沫/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T04:41:00.409Z","path":"wiki/others/economy/-泡沫/98年亚洲金融危机/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T04:39:27.596Z","path":"wiki/others/economy/-泡沫/-郁金香泡沫-荷兰/","text":"1929-1933年 郁金香被炒作。 投资市场非理性涨跌。 https://www.bilibili.com/video/av19258366/?p=2","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"-泡沫","slug":"others/economy/泡沫","permalink":"http://yoursite.com/categories/others/economy/泡沫/"}]},{"title":"","date":"2018-10-22T03:05:32.127Z","path":"wiki/demo/hexo/-infinite-scroll/","text":"挺不错 https://github.com/FrontendSophie/hexo-infinite-scroll","tags":[],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"","date":"2018-10-22T01:09:01.455Z","path":"wiki/demo/hexo/-code-hightlight/","text":"tomorrow-themetheme-next默认采用的tomorrow-theme 1234# Code Highlight theme# Available values: normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: normal 相应的code: https://github.com/theme-next/hexo-theme-next/blob/master/source/css/_common/components/highlight/theme.styl highlight-selection不起作用 https://github.com/theme-next/hexo-theme-next/issues/299 网传的配置，是没有作用的。123highlight: enable: false... highlight.jshttps://zihengcat.github.io/2018/03/05/Hexo%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0highlight-js%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/ hexo-prism-pluginJSX syntax (HTML in JS) https://github.com/ele828/hexo-prism-plugin my issuethanks. Actually, css is not the key point.The main issue might be the code block render. In ivan’s pages12345&lt;code class=\"bash\"&gt; &lt;span class=\"bash_symbol\"&gt;$ &lt;/span&gt; &lt;span class=\"built_in\"&gt;yum&lt;/span&gt; install vsftpd&lt;/code&gt; default render123\"hexo-renderer-ejs\": \"^0.3.1\",\"hexo-renderer-marked\": \"^0.3.2\",\"hexo-renderer-stylus\": \"^0.3.3 In the default render, I get the following output12345678&lt;td class=\"code\"&gt; &lt;pre&gt; &lt;span class=\"line\"&gt; $ hexo new &lt;span class=\"string\"&gt;\"My New Post\"&lt;/span&gt; &lt;/span&gt; &lt;/pre&gt;&lt;/td&gt;","tags":[],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"那些荒谬的级数","date":"2018-10-21T10:15:05.768Z","path":"wiki/Math/-数学分析(微积分)/1. 数列极限、函数极限、连续函数/那些荒谬的级数/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"1. 数列极限、函数极限、连续函数","slug":"Math/数学分析-微积分/1-数列极限、函数极限、连续函数","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/1-数列极限、函数极限、连续函数/"}]},{"title":"","date":"2018-10-21T09:21:06.754Z","path":"wiki/Math/-数学分析(微积分)/-解析延拓/黎曼ζ函数/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"-解析延拓","slug":"Math/数学分析-微积分/解析延拓","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/解析延拓/"}]},{"title":"Gamma (Γ) 函数","date":"2018-10-21T09:20:54.849Z","path":"wiki/Math/-数学分析(微积分)/-解析延拓/Γ函数/","text":"$\\Gamma$ 函数，也叫做伽玛函数（Gamma函数），是阶乘函数在实数与复数域上的扩展。如果 $n$为正整数，则$\\Gamma(n) = (n-1)!$对于实数部分为正的复数 $z$，伽玛函数定义为： $\\Gamma (z)=\\int_{0}^{\\infty }{\\frac {t^{z-1}}{\\mathrm {e} ^{t}}}\\,{\\rm {d}}t$ 此定义可以用解析开拓原理，拓展到除去非正整数的整个复数域上。 在概率论中常见此函数，在组合数学中也常见。 扩展阅读","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"-解析延拓","slug":"Math/数学分析-微积分/解析延拓","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/解析延拓/"}]},{"title":"实数的阶乘","date":"2018-10-21T08:12:33.982Z","path":"wiki/Math/数论/-常量/实数的阶乘/","text":"二分之一的阶乘=pie 解析延拓解析延拓的理由，光滑 数学意义上的光滑，是指无穷多阶都可导。 这种满足强迫症的操作就叫 解析延拓 神奇的结论：光滑函数只需要一小段，就能确定整个函数 解析延拓这么牛逼，为什么不去把质数延拓一下？超越函数","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"全体自然数的和等于 -1/12","date":"2018-10-21T08:10:12.946Z","path":"wiki/Math/数论/-常量/全体自然数的和/","text":"数论 ‘-常量’","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"黄金分割","date":"2018-10-21T07:51:41.062Z","path":"wiki/Math/数论/-常量/黄金分割/","text":"我们之前在《琴弦上的数学危机》中讲过，公元前5世纪的毕达哥拉斯学派很有可能在研究五边形的内接五角星时发现了无法公约的数，也就是发现了无理数。而且这个无理数在今天已经非常为人熟知了，它就是黄金分割。 黄金分割最简单的表述，就是将已知线段分割成长短两段，使得原线段与长线段的长度的比值，等于长线段与短线段的长度的比值，有了今天的代数工具，这个结果实在容易计算。 但由于古希腊的数学与几何相当割裂，黄金分割不能计算，被称为“中末比”收录在《几何原本》里。而到文艺复兴，达芬奇有个好朋友，数学家卢卡·帕西奥利（Luca Pacioli，1445 -1517）修士，在整理《几何原本》的时候被带有黄金分割的几何结构深深吸引了，将它誉为“神圣比例”（De divina proportione）。 扩展阅读 黄金分割的妙处 - 混乱博物馆 讲的很好，都听不懂��的很好，都听不懂","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"Real Analysis 实分析","date":"2018-10-21T05:38:34.755Z","path":"wiki/Math/实分析 复分析/实分析/-实分析/","text":"初等微积分，高等微积分，考虑的是函数。要对函数性质分类，引进实数轴上点积。 初等微积分已经学习到，连续性是很重要的性质。 局部限制操作：微分。微分不具有稳定性 global操作：积分。 积分具有稳定性(函数稍微变一下，积分变化不大) 为什么物理一开始偏向与微分的思想？ 微分比积分难？为什么 既然微分难，那么倾向于把微分用积分来表示。 如何微分用积分来代表？如何联系？Integration by parts 跟傅里叶级数什么关系？唯一性(uniquess): 黎曼积分，什么鬼？Lebegus积分什么鬼有比较好的limit性质 积分、微分 都用对函数分类的？热力学 boltzman热力学第一定律：能量不变、第二定律：熵增 boltman确信原子是存在的，化学还有很多虽然用原子的概念，但是他们认为原子只是个概念，是个设计，是个device，是人想象的而已。 其他人不信，他自杀。 布朗运行物理学中很多函数是漂亮的，好看的。 最大的发现是布朗运动，自然现象的函数不一定是好的，也有杂乱无章的。 分析布朗运动，用 我的疑问：是不是宏观上漂亮，微观上都很猥琐、混乱？ 20世纪最重要的数学 probability theory比如通信的传递 基础实数一个实数的集合，如果有上界，就会有最小的上界。如果有下界，就会有最大的下界。 蒙圈 Bolzano weiestrass 什么鬼？卧槽，这俩我都不知道哎 线性代数扩展阅读 讲的很好，大师","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"实分析 复分析","slug":"Math/实分析-复分析","permalink":"http://yoursite.com/categories/Math/实分析-复分析/"},{"name":"实分析","slug":"Math/实分析-复分析/实分析","permalink":"http://yoursite.com/categories/Math/实分析-复分析/实分析/"}]},{"title":"","date":"2018-10-20T16:14:42.698Z","path":"wiki/demo/hexo/-hexo-logo-svg/","text":"挺有意思 https://github.com/bubkoo/logo.svg","tags":[],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"【Hexo插件系列】流程图与时序图","date":"2018-10-20T16:00:00.000Z","path":"wiki/demo/hexo/hexo-chart/","text":"背景有些markdown支持流程图、时序图，比如马克飞象。 实际上，这部分的渲染并非markdown引擎(后端渲染)做的，而是采用的第三方前端渲染引擎。其原理类似公式渲染引擎mathjax。 因此，这种流程图和时序图很容易嵌入到hexo博客中，而且已经有了相关的插件。 流程图 渲染引擎：flowchart.js 相关的hexo插件: hexo-filter-flowchart 时序图:- 渲染引擎: js-sequence-diagrams- 相关的hexo插件: hexo-filter-sequence 提示：想了解更多，请查看流程图语法以及时序图语法。 st=>start: Start e=>end op=>operation: My Operation cond=>condition: Yes or No? st->op->cond cond(yes)->e cond(no)->op{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);Alice->Bob: Hello Bob, how are you? Note right of Bob: Bob thinks Bob-->Alice: I am good thanks!{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"sequence-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"sequence-0-options\").value)); var diagram = Diagram.parse(code); diagram.drawSVG(\"sequence-0\", options);浏览器->Cloudflare: 加密数据 Cloudflare-->web服务器: 明文{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"sequence-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"sequence-1-options\").value)); var diagram = Diagram.parse(code); diagram.drawSVG(\"sequence-1\", options);","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"plugin","slug":"plugin","permalink":"http://yoursite.com/tags/plugin/"},{"name":"流程图","slug":"流程图","permalink":"http://yoursite.com/tags/流程图/"},{"name":"时序图","slug":"时序图","permalink":"http://yoursite.com/tags/时序图/"}],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"","date":"2018-10-20T14:49:23.503Z","path":"wiki/CS/web/blog-framework/-hexo-filter-sequence/","text":"https://github.com/bubkoo/hexo-filter-sequence 挺好","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"}]},{"title":"","date":"2018-10-20T14:20:53.741Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-filter-date-from-git/","text":"web blog-framework nodejs-hexo plugin ‘1’","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-10-19T12:16:03.411Z","path":"wiki/others/历史/-民族/","text":"匈奴 倭寇 汉人 - 发源于西汉吧？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"历史","slug":"others/历史","permalink":"http://yoursite.com/categories/others/历史/"}]},{"title":"","date":"2018-10-19T09:00:48.524Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/CornerNet/","text":"目前大部分的object detection的模型都基于anchor，尤其是one-stage的detector。使用anchor有以下缺点： 通常需要大量的anchor，因为需要判断anchor是否与GT有较大的overlap，所以需要大量的anchor来保证覆盖所有的GT。大量的anchor其实只有少部分和GT相重叠，正样本和负样本的不平衡会影响训练！anchor的使用引入了大量的参数和设计（先验），包括anchor的数量，大小，比例等（虽然这样可以生成较多的multi-scale和multi-ratio的region proposals）。当面临multi-scale architecture的时候会变得非常复杂，因为需要设计每个scale的anchor作者提出了一种全新的将anchor扔掉的detector，将object的检测简化为两个关键点（bounding box的两个端点,corner）的检测。 扩展阅读 https://zhuanlan.zhihu.com/p/41759548","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"【python源码系列】Object对象","date":"2018-10-19T00:37:09.328Z","path":"wiki/CS/programing/lan/python/-src-cpython/Objects/classobject/","text":"背景 &amp; 简介定义12 实现 扩展阅读 PyObject 2.7","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"-src-cpython","slug":"CS/programing/lan/python/src-cpython","permalink":"http://yoursite.com/categories/CS/programing/lan/python/src-cpython/"},{"name":"Objects","slug":"CS/programing/lan/python/src-cpython/Objects","permalink":"http://yoursite.com/categories/CS/programing/lan/python/src-cpython/Objects/"}]},{"title":"VQ-VAE","date":"2018-10-18T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/生成模型/-VQ-VAE/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"生成模型","slug":"ML/deep-learning/model-basic/生成模型","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/生成模型/"}]},{"title":"","date":"2018-10-16T07:00:17.905Z","path":"wiki/machine translation/evaluation/-hard-case/","text":"# 神经机器翻译哪家强？2016 https://www.leiphone.com/news/201610/RjiOWPXVQuhfhiuT.html","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"evaluation","slug":"machine-translation/evaluation","permalink":"http://yoursite.com/categories/machine-translation/evaluation/"}]},{"title":"全卷积 FCN","date":"2018-10-15T12:44:16.766Z","path":"wiki/ML/deep learning/model-basic/CNN/-FCN/","text":"FCN的原理FCN将传统CNN中的全连接层转化成一个个的卷积层。什么叫一个个？ 全连接 VS 全卷积 VS global poolingResnet采用global pooling代替全连接 -https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py#L240 扩展阅读 https://blog.csdn.net/taigw/article/details/51401448 http://simtalk.cn/2016/11/01/Fully-Convolutional-Networks/","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"neural CF","date":"2018-10-15T06:16:17.112Z","path":"wiki/ML/recommender-system/model/-neural CF/","text":"recommender-system model","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"recommender-system","slug":"ML/recommender-system","permalink":"http://yoursite.com/categories/ML/recommender-system/"},{"name":"model","slug":"ML/recommender-system/model","permalink":"http://yoursite.com/categories/ML/recommender-system/model/"}]},{"title":"deep and wide","date":"2018-10-15T06:16:05.260Z","path":"wiki/ML/recommender-system/model/-deep and wide/","text":"recommender-system model","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"recommender-system","slug":"ML/recommender-system","permalink":"http://yoursite.com/categories/ML/recommender-system/"},{"name":"model","slug":"ML/recommender-system/model","permalink":"http://yoursite.com/categories/ML/recommender-system/model/"}]},{"title":"","date":"2018-10-15T05:28:15.111Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-emb_plus/","text":"见 nlp/word2vector","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"","date":"2018-10-15T05:27:58.998Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-emb_transfer/","text":"不同语言的词嵌入具有相似的邻域结构，因为不同国家的人毕竟活在同一个世界中。例如，英语中「cat」和「furry」之间的关系类似于它们在西班牙语中的相应翻译（「gato」和「peludo」）之间的关系，因为这些单词的频率和它们的上下文是相似的","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"加密-解密思想在机器翻译中的应用","date":"2018-10-15T05:04:39.307Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-加密-解密的思想/","text":"ss 需要了解常用的加密算法","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"","date":"2018-10-15T04:33:22.047Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/无监督/Unsupervised PBSMT/","text":"Phrase-Based Statistical Machine Translation (PBSMT)","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"},{"name":"无监督","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水/无监督","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/无监督/"}]},{"title":"","date":"2018-10-15T04:32:00.161Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/无监督/lm/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"},{"name":"无监督","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水/无监督","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/无监督/"}]},{"title":"EMNLP2018最佳论文：Facebook 提升 11BLEU 的无监督机器翻译","date":"2018-10-15T04:29:47.607Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/无监督/unsupervised PBSMT and NMT/","text":"扩展阅读 code: https://github.com/facebookresearch/UnsupervisedMT 雷锋网","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"},{"name":"无监督","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水/无监督","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/无监督/"}]},{"title":"","date":"2018-10-15T03:19:53.586Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-多语种 zero-shot翻译/","text":"“Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation” Zero-Shot 翻译是指在完成语言 A 到语言 B 的翻译训练之后，语言 A 到语言 C 的翻译不需要再经过任何学习。 它能自动把之前的学习成果转化到翻译任意一门语言，即便工程师们从来没有进行过相关训练。 通过 Zero-Shot，谷歌解决了把神经机器翻译系统扩展到全部语言的难题。有了它，一套系统就可以完成所有语言的互翻。从前两种语言之间都需要多个翻译系统的情况，从此成为了历史。这套架构在翻译其他语言时，不需要在底层 GNMT 系统做任何改变。只需在输入语句的开头插入一个输出语种标记，就可以把结果翻译为任意语言。 下面这幅动图对该 Zero-Shot 系统的运作做了示意。 假设谷歌训练该系统做日语英语、韩语英语的互译，图中用蓝色实线来代表。 GNMT 系统就可以分享这四组翻译（日英，英日，韩英，英韩）的参数。这允许它把任意一组语言的翻译经验转到其他语言上去。学习成果转移和多语言翻译的要求，迫使该系统更好地使用建模的能力。 这启发了工程师们设想：我们能否让系统翻译一组它从来没有翻译过的语言？这可以用韩语日语互译的例子来说明。虽然该系统从未处理过韩日互译，但它利用之前的韩英、日英翻译学习成果，能进行水平不错的韩日互译。谷歌把这个过程称为 “zero-shot” 翻译，图中用黄虚线表示。谷歌宣称，这是世界上首例应用在机器翻译上的学习成果转移。 Zero-shot 翻译的成功带来了另外一个重要问题：这个系统是否在学习语言的通用表达（不管是翻译成什么语种，相同含义的语句都被系统使用相似的表达方式）？——类似于“国际语”或者中介语言？工程师们使用了 3D 图像展示系统的内部网络数据，以了解它在处理日、韩、英的任意互译组合时是如何运作的。 上方图片 a 部分（左）展示了这些翻译的几何结构。意义一致的语句用颜色相同的点代表。比方说，英译韩和日译英的两句话如果意思一致，就会是图上颜色相同的两个点。通过这种方式，我们可以很容易地区分不同颜色（含义）的点。b 部分放大了红色区的点，c 部分则对源语言进行区分。在同一组颜色的点里，我们看到含义相同但从属不同语种的句子。这意味着该系统必然对句子的语义进行了编码，而不是记忆一个短语到另一个短语的翻译。谷歌的工程师把这看作是系统中存在中介语言的标志。 谷歌在论文里面展示了更多的分析结果。他们希望这些发现不但对机器学习和机器翻译的研究人员们有用处，也能对语言学家和对单一系统怎么处理多语言学习感兴趣的人有价值。 今日 （美国时间 11 月 22 日），基于 Zero-Shot 的多语言神经机器学习系统正式登陆谷歌翻译。它目前被应用于新增加的 16 个语言组中的 10个，带来更高的翻译质量和简化的系统架构。我们可以期待在不久的将来，该系统会逐步支持更多的谷歌翻译语种。 扩展阅读 https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html - 中文翻译 https://www.leiphone.com/news/201611/14xCi6hNIAqhX0mo.html","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"","date":"2018-10-15T02:59:09.555Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-迁移学习/","text":"迁移学习(Transfer Learning)的方法： 考虑到不同语种间的翻译任务存在一定相关性，通过迁移学习可以将已经学到的知识分享给新模型从而加快模型训练，避免模型训练从零开始。以A和C的翻译任务为例，首先训练A和B之间的NMT模型，之后在训练A和C的翻译模型时，使用A与B的NMT模型参数作为初始值，使用少量A与C的标注平行语料数据进行模型参数的重新训练，得到最终的NMT模型。□B. Zoph , D. Yuret, J. May, and K. Knight，Transfer Learning for Low-Resource Neural Machine Translation , EMNLP 2016.","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"","date":"2018-10-15T02:58:28.871Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-多任务学习/","text":"作者：王砚峰链接：https://www.zhihu.com/question/59955680/answer/175411676来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 多任务学习(Multi-Task Learning)的方法：充分利用不同语种翻译的相关性，采用共享相同的NMT参数同时学习多个翻译任务，以A和C的翻译任务为例，首先建立A与B、A与C共享的一套NMT网络，其中该NMT网络的输入是A，输出有两个，分别是B和C，训练的过程中A与B、A与C的标注平行语料共同更新一套NMT网络的参数，与使用较少的A与C语料单独训练的NMT网络相比，翻译效果有较大提升。此外，谷歌于2016年下半年提出的Zero-Shot翻译方法，基于多语种共享的词汇集，使用单个神经机器翻译（NMT）模型在多种语言之间进行翻译，除了提升训练数据中包含的语种对之间互译的翻译质量之外，很有意义的是，还能完成训练数据中不包含的语言对之间的zero-shot翻译。 □Thang Luong, Quoc Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser, Multi-task Sequence to Sequence Learning，ICLR 2016. □Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda B. Viégas, Martin Wattenberg, Greg Corrado, Macduff Hughes, and Jeffrey Dean. Google’s multilingual neural machine translation system: Enabling zero-shot translation.","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"","date":"2018-10-15T02:50:34.393Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-Pivot language/","text":"以A和C的翻译任务为例，如果A和B、B和C之间的训练语料较多，就可以将B作为枢轴语言，进行语言对之间的桥接，训练A和B、B和C两个NMT的网络，从而完成A和C的互译任务。目前关于枢轴语言的方法主要集中在如何实现两个NMT网络的联合训练上。□Yong Cheng, Qian Yang, Yang Liu, Maosong Sun, and Wei Xu. 2017. Joint Training for Pivot-based Neural Machine Translation. IJCAI 2017 https://www.zhihu.com/question/59955680/answer/175411676 一般针对小语种，比如蒙古语。充分利用大语种丰富的对齐语料来提升小语种机器翻译的能力 TODO ende的语料库，把de转化为zh，得到enzh语料","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"Back Translation(反向翻译)","date":"2018-10-14T09:35:00.782Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/无监督/-back-translation/","text":"要求比较原文和反向译文的差异 反向翻译是将已经译成一种外语的文件反向翻译为原文件语言的过程，通常由独立的第三名译员来完成。反向翻译的目的在于通过第三者将译文反向翻译回原来的语言，以便与原文比较，来判断、提高原译文的可靠性和准确性。反向翻译是一种成本高、效果好的质量控制过程，欧洲的一些客户常常使用这种方法来提高翻译质量。Back Translation is the process of translating a document that has already been translated into a foreign language back to the original language - preferably by an independent translator. Back translation can improve the reliability and validity of research in different languages by requiring that the quality of a translation is verified by an independent translator translating back into the original language. Original and back translated documents can then be compared. #","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"},{"name":"无监督","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水/无监督","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/无监督/"}]},{"title":"","date":"2018-10-14T08:52:40.048Z","path":"wiki/ML/app/nlp/app/分词/监督/-CRF/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"分词","slug":"ML/app/nlp/app/分词","permalink":"http://yoursite.com/categories/ML/app/nlp/app/分词/"},{"name":"监督","slug":"ML/app/nlp/app/分词/监督","permalink":"http://yoursite.com/categories/ML/app/nlp/app/分词/监督/"}]},{"title":"","date":"2018-10-13T11:35:22.660Z","path":"wiki/ML/app/nlp/app/word-vector/-创新/","text":"deep: 不同的层表征不同level的信息 deep cnn/lstm self-attention transformer也能用来学习embedding embeddingembedding plus [count]: count embedding 类似加密破解，就用到了词频统计- count应该是个ranking值吧 segment embedding 比如[Q]、[A]，[src]、[target] [pos]: position embedding 自己学 经验embedding [cls] 类别 [char] char以及中文字形 比如 词性 大小写(首字母大写、全大写、全小写) 实例应用","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"}]},{"title":"","date":"2018-10-13T07:46:54.287Z","path":"wiki/ML/通用/-sequence_modeling/","text":"序列数据 连续时间 语音 离散时间 文本- 方法论 基于学习的方法 无监督学习 监督学习 context很重要上下文很重要，比如以下这句话： “I arrived at the bank after crossing the…” 要知道bank的意思，最后一个词是“road”还是“river”很重要。 RNN优点： - 长依赖: RNN的成功引入， 解决了长距离依赖的问题， 而且引入了上下文和记忆的概念。 LSTM: 相对传统RNN 缺点： 非线性数目： 编码能力弱: 没有attention的RNN，对长序列编码能力较弱 难并行：training阶段RNN很难并行 决策步骤太长: RNN需要一个个地读取bank到river之间的所有单词，才能够确定bank的实际意义。 另外，由于RNN是时序处理，在GPU上不易并行化。 这两点说的太好了，赞，赞。 CNN优点: 易并行：CNN的计算不存在序列依赖问题，training时容易并行化 易优化：CNN的非线性单元的数目固定，容易优化。而RNN的非线性单元随序列长度变化 依赖路径更短: conv在处理dependency问题时，利用卷积的感受野receptive field，通过堆叠卷积层来扩大每个encoder输出位置所覆盖单词的范围，每个单词走的路径大致是$log_{k}n$步，缩短了dependency的长度。 对于距离为n的长依赖，RNN的复杂度是O(n), CNN的复杂度是O(n/k)，k是kernel width gated linear units 缺点：-- self attention 句子中的单词dependency长度最多只有1，减少了信息传输路径 这种attention的方式直接可以挖掘句子内部单词与单词的语义组合关系，将它作为一个语义整体，使得翻译时更好地利用单词组合甚至是短语的信息，更好地decode出语义匹配的目标语言单词 这里的单词组合不仅仅是局部上下文，而是更长的距离的单词组合 缺陷： 获得任意长度word dependency的同时，丢失了位置信息。 解决办法，slef-attention的同时，加入位置依赖的attention positon enhanced self-attention: ss 其他 long-dependency问题：LSTM引以为豪的是long-dependency较好。实际上CNN也可以通过堆叠CNN层来增大感受野，实现long-dependency。 或者dilated convolutions-","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"通用","slug":"ML/通用","permalink":"http://yoursite.com/categories/ML/通用/"}]},{"title":"","date":"2018-10-13T04:53:33.554Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/-universal_transformer/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"一种新的embedding方法 ELMo","date":"2018-10-12T16:00:00.000Z","path":"wiki/ML/app/nlp/app/word-vector/model/-ELMo/-ELMO/","text":"背景word2vec以及glove在nlp任务中都取得了较好的效果。 “Deep contextualized word representations”, NAACL 2018 我们常用的获取embedding方法都是通过训练language model, 将language model中预测的hidden state做为word的表示, 给定N个tokens的序列(t1,t2,…,tn), 前向language model就是通过前k-1个输入序列(t1,t2,…,tk)的hidden表示, 预测第k个位置的token, 反向的language model就是给定后面的序列, 预测之前的, 然后将language model的第k个位置的hidden输出做为word embedding. 之前的做法的缺点是对于每一个单词都有唯一的一个embedding表示, 而对于多义词显然这种做法不符合直觉, 而单词的意思又和上下文相关, ELMo的做法是我们只预训练language model, 而word embedding是通过输入的句子实时输出的, 这样单词的意思就是上下文相关的了, 这样就很大程度上缓解了歧义的发生. 简介ELMO(Embeddings from Language Models) ，来自于语言模型的词向量表示，也是利用了深度上下文单词表征，该模型的好处： （1）能够处理单词用法中的复杂特性（比如句法和语义） （2）这些用法在不同的语言上下文中如何变化（比如为词的多义性建模）。 它首先在大文本语料库上预训练了一个深度双向语言模型（biLM），然后把根据它的内部状态学到的函数作为词向量。 该模型的显著特征： Contextual: The representation for each word depends on the entire context in which it is used. （即词向量不是一成不变的，而是根据上下文而随时变化，这与word2vec或者glove具有很大的区别） Deep: The word representations combine all layers of a deep pre-trained neural network. （采用了较深的网络来实现，如文中采用了双向的LSTM） Character based: ELMo representations are purely character based, allowing the network to use morphological clues to form robust representations for out-of-vocabulary tokens unseen in training. （基于字符的，所以具有更好的鲁棒性） 效果上：ELMo虽然看起来很简单，非常有效。 ELMo: Embeddings from Language Models ELMo用到上文提到的双向的language model, 给定N个tokens (t1, t2,…,tN), language model通过给定前面的k-1个位置的token序列计算第k个token的出现的概率: $$p(t_1, t_2, …, t_N) = \\prod_{k=1}^N p(t_k|t_1, t_2, …, t_{k-1})$$ 后向的计算方法与前向相似: $$p(t_1, t_2, …, t_N) = \\prod_{k=1}^N p(t_k\\vert t_{k+1}, t_{k+2}, …, t_{N})$$ biLM训练过程中的目标就是最大化: 源码疑问 通过char-level(CNN)+biLSTM的结构训练语言模型，最后获得输入层和隐藏层的表示，ELMo再将这些层进行线性组合，但是ELMo最后对每层的权重如何获得呢，是针对不同的任务继续训练以获得各层对应的权重？那么是否可以理解为attention呢？- 扩展阅读 https://allennlp.org/elmo https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md code: https://github.com/allenai/bilm-tf https://blog.csdn.net/sinat_26917383/article/details/81913790 https://cstsunfu.github.io/2018/06/ELMo/ https://zhuanlan.zhihu.com/p/37684922 https://zhuanlan.zhihu.com/p/38254332 带公式","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-ELMo","slug":"ML/app/nlp/app/word-vector/model/ELMo","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/ELMo/"}]},{"title":"ss","date":"2018-10-12T05:34:36.240Z","path":"wiki/others/economy/时代的风口/-所有行业/","text":"站在历史风口思考 从热门专业看风口、价值取向 电气 - 已没落，因为 通信 - 没落 银行 - 没落 - 互联网金融的兴起 # 炒房 软件 -微软 互联网 智能手机 物联网 - 并未没落 大数据 2000年，伴随着Nasdaq的高台跳水，互联网产业的泡沫开始破裂，2001年，911事件爆发，全球的互联网产业达到了冰点。 P2P 投资理财 - 钱多了怎么办？投资理财自然是最好的选择。 自2012年开始，网贷公司迅速增加，2013年，随着余额宝的上线，各类理财宝宝们纷纷涌现，一时间所有的大型互联网企业都推出了自己的宝宝，百宝大战正酣时，收益率的显著下降一下子就让战争失去了悬念 团购网 云计算 人工智能 虚拟货币、区块链 精神层面 美颜 唱吧 斗鱼、抖音 唱吧 喜马拉雅fm 2018科技风口的ABCD 人工智能（Artificial Intelligence)、区块链（Block Chain）、云计算（Cloud）、大数据（Big Data），互联网时代的下半场已经到来。 VR直播、短视频能成为风口 医疗AI 从创业公司看风口 自动驾驶 https://www.zhihu.com/question/52080881 互联网风口捕捉指南之一—— 风口的历史和启示","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"时代的风口","slug":"others/economy/时代的风口","permalink":"http://yoursite.com/categories/others/economy/时代的风口/"}]},{"title":"","date":"2018-10-12T05:32:46.356Z","path":"wiki/others/economy/时代的风口/-科技风口/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"时代的风口","slug":"others/economy/时代的风口","permalink":"http://yoursite.com/categories/others/economy/时代的风口/"}]},{"title":"","date":"2018-10-12T00:20:15.703Z","path":"wiki/ML/trick/optimizer/-optimizer/","text":"optimizer=Adafactor,learning_rate_schedule=rsqrt_decay 这种策略比adam节省内存？ – 来自github","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"},{"name":"optimizer","slug":"ML/trick/optimizer","permalink":"http://yoursite.com/categories/ML/trick/optimizer/"}]},{"title":"从transformer的实现，看深度学习的trick","date":"2018-10-11T01:51:27.691Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/-transformer-trick/","text":"简介tensor2tensor中实现了常用的模型，主要包括transformer等 分解 dropout norm_epsilon moe sampling_method=”argmax”, # “argmax” or “random” use_target_space_embedding conv_first_kernel dropout 在哪dropout，为什么？ dropout的比例？ 123\"dropout\": 0.2\"relu_dropout\": 0.1,\"relu_dropout_broadcast_dims\": \"\", LayerNormLayerNorm(x + Sublayer(x)), residual connectionlayer normalizationresidual之后加的LN share vocabshare the vocabulary between source and target language 对应的参数:1\"shared_embedding\": false 共享词典的 优势: 方便专有名词的直接拷贝，比如人名地名 缺陷: vocab_size较大，会增大softmax的负担。 src和target会混淆。比如英中翻译，可能翻译出来的夹杂英文。 激活函数的选择moe1234567model_dir\": \"./t2t_train/languagemodel_lm1b32k/transformer-transformer_small\",\"moe_hidden_sizes\": \"2048\",\"moe_k\": 2,\"moe_loss_coef\": 0.001,\"moe_num_experts\": 16,\"moe_overhead_eval\": 2.0,\"moe_overhead_train\": 1.0, tie embedding123# Nematus的配置: https://github.com/EdinburghNLP/nematus#network-parameterstie_decoder_embeddings: tie the input embeddings of the decoder with the softmax output embeddingstie_encoder_decoder_embeddings: tie the input embeddings of the encoder and the decoder (first factor only). Source and target vocabulary size must be the same share the weights between softmax and embedding 对应参数:1shared_embedding_and_softmax_weights = True 源码该trick，仅当src和target lr相关12345678910learning_rate\": 0.2,\"learning_rate_constant\": 2.0,\"learning_rate_cosine_cycle_steps\": 250000,\"learning_rate_decay_rate\": 1.0,\"learning_rate_decay_scheme\": \"noam\",\"learning_rate_decay_staircase\": false,\"learning_rate_decay_steps\": 5000,\"learning_rate_minimum\": null,\"learning_rate_schedule\": \"constant*linear_warmup*rsqrt_decay*rsqrt_hidden_size\",\"learning_rate_warmup_steps\": 8000, lr变化曲线 weight相关“weight_decay”: 0.0,“weight_dtype”: “float32”,“weight_noise”: 0.0 optimizer1234567891011121314\"optimizer\": \"Adam\",\"optimizer_adafactor_beta1\": 0.0,\"optimizer_adafactor_beta2\": 0.999,\"optimizer_adafactor_clipping_threshold\": 1.0,\"optimizer_adafactor_decay_type\": \"pow\",\"optimizer_adafactor_factored\": true,\"optimizer_adafactor_memory_exponent\": 0.8,\"optimizer_adafactor_multiply_by_parameter_scale\": true,\"optimizer_adam_beta1\": 0.9,\"optimizer_adam_beta2\": 0.997,\"optimizer_adam_epsilon\": 1e-09,\"optimizer_momentum_momentum\": 0.9,\"optimizer_momentum_nesterov\": false,\"optimizer_multistep_accumulate_steps\": null, bucket12 decode - length penalty - alphaentropy loss - 用于避免重复解码为什么会重复解码？因为length penalty会倾向于长句子。 复杂度作为penalty，input句子和output句子 也可以理解为","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"有一种幸福，叫做黑别人","date":"2018-10-10T11:06:01.132Z","path":"wiki/others/politics/-互黑/","text":"美国圣诞节的流浪汉，能上人民日报。台湾人说大陆喜欢吃香蕉皮。大陆人报导台湾总有美国人抱着台湾妞大马路上瞎撞人。有互联网真好，让交流不再闭塞。 –崔永元 宣传就是统一口径，宣传很吓人 – 崔永元 普世价值 为什么我们都觉得自由、民主、人权都是可以不在乎的呢？ 不让说纳税人，因为你强调纳税人，他会觉得自己是纳税人。 不让说公民，要说人民。 现在中国人没多少记得屈原了，只知道粽子。 爱这个国家最好的方式，就是让他变好，哪怕不被理解。 – 崔永元，牛逼 这个时代，明哲保身- 爱国 小学课本: 我爱北京天安门，伟大领袖毛主席 害怕开启民智，领导人希望被领导的，傻 xiaolinzhang: 我是80后，从亲身感受来看，几十年的民智的闭塞和压制，换来了相对稳定的社会环境，让我们平安度过了资本积累的最早时期。现在我们经济体量上来了，也越来越自信，无论是媒体还是教育，我自己的感觉是越来越开放。这种事本来就应该是循序渐进而不是激进的，企图一夜之间全面改变制度和思想，哪个国家和社会能有这样的承受能力，更何况14亿人口的大国。所以，我觉得，肯一点一滴默默为改良和改革贡献力量的人才是真爱国，我是信息和思想闭塞时代的亲历者，我不后悔也不会去谩骂，因为我知道这是国家发展必须要经历的阵痛，也里边也有我们这代每个人的贡献。 连小时候经常看的日漫都不让播了，还好意思说越来越开放 你太天真了，国内的新闻都是党媒控制的，很多都夸大事实真假难辨，正如崔永元所说的，统一口径 Kyrie CHen: 崔永元 是我見過最幽默風趣的大陸人!!奇才!! 导师制：双向选择。班主任，分配制 #","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"}]},{"title":"","date":"2018-10-10T05:50:26.071Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-shared_words/","text":"目标语言和源语言，两个词典中一般会共享少量词典，或者subword。 关于shared word","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"随机数 与 伪随机数","date":"2018-10-09T12:19:50.356Z","path":"wiki/Math/数论/随机数/-随机数/","text":"扩展阅读","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"随机数","slug":"Math/数论/随机数","permalink":"http://yoursite.com/categories/Math/数论/随机数/"}]},{"title":"light、fast RNN。","date":"2018-10-09T12:12:42.661Z","path":"wiki/ML/deep learning/model-basic/RNN/-lightRNN-summary/","text":"本文重点关注RNN cell的进化史，而非网络架构。 RNN的进化史，从简单到复杂(LSTM)，然后浓缩(SRU、) 类似，先提出一种暴力解法，然后再优化的过程。 LightRNN: Memory and Computation-Efficient Recurrent Neural Networks, NIPS 2016 cudnnLSTM 传统LSTM，8个矩阵，4个bias。cudnnLSTM，额外多了4个bias。用于加速 Quasi-RNN bypass 的思想 借鉴resnet attention的思想 single_point -&gt; moving_average -&gt; attention 并行加速lstm的并行，通常是强制性的。 几套lstm，多卡运行，然后利用tower_grads的方式，更新参数。 小矩阵 类似SVD分解CNN使用纯 CNN 模型超过 RNN 并不是一件容易的事情。QRNN 则可以逐层替代原有的 RNN，使用起来门槛要低很多，而且加速效果有保证 https://blog.csdn.net/JackyTintin/article/details/77945354 QRNN 没有纯 CNN 模型（e.g. WaveNet）那么激进，依然保留了一些循环结构。 keras code: https://github.com/DingKe/nn_playground/tree/master/qrnn GRU SRU（Simple Recurrent Unit）。这实质上是 QRNN window 宽度取1的特殊情况（即使用普通的线性变换）。不同的是，SRU 将 highway 连接作为模型的一部分（QRNNs当然可以加残差或 highway 连接）。 SRU扩展阅读 Optimizing Performance of Recurrent Neural Networks on GPUs, 2016, Nvidiaent Neural Networks on GPUs, 2016, Nvidia","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"学习率","date":"2018-10-08T03:20:27.095Z","path":"wiki/ML/trick/optimizer/-lr/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"},{"name":"optimizer","slug":"ML/trick/optimizer","permalink":"http://yoursite.com/categories/ML/trick/optimizer/"}]},{"title":"","date":"2018-10-07T03:16:27.199Z","path":"wiki/CS/web/-back-end/node/-node-debug/","text":"https://www.cnblogs.com/moonz-wu/archive/2012/01/15/2322120.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"node","slug":"CS/web/back-end/node","permalink":"http://yoursite.com/categories/CS/web/back-end/node/"}]},{"title":"如何阅读hexo源码","date":"2018-10-07T02:56:05.053Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/src/-hexo源码阅读/","text":"console.log如何debug hexo设置断点 调试hexo，实质就是调试nodejs Node.js内置调试工具 1node debug app.js 配合浏览器？V8 Inspector Integration 可以让 DevTools 直接连接 Node.js的Debugger进行调试。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"src","slug":"CS/web/blog-framework/nodejs-hexo/src","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/src/"}]},{"title":"","date":"2018-10-07T02:55:08.840Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/src/-hexo-s/","text":"1hexo s --debug 运行hexo s，先后调用的模块有：123456789101112131415161718192021222324252627282930hexo-generator-archive/index.jshexo-generator-category/index.jshexo-abbrlink/index.jshexo-auto-category/index.jshexo-generator-index/index.jshexo-deployer-git/index.jshexo-generator-tag/index.jshexo-renderer-ejs/index.jshexo-generator-search/index.jshexo-server/index.jshexo-related-popular-posts/index.jshexo-tag-chat/index.jshexo-renderer-kramed/index.jshexo-renderer-stylus/index.jshexo-tag-instagram/index.jshexo-tag-soundcloud/index.jshexo-tag-twitter/index.jshexo-wordcount/index.jsthemes/next/scripts/tags/button.jsthemes/next/scripts/helpers.jsthemes/next/scripts/merge-configs.jsthemes/next/scripts/tags/center-quote.jsthemes/next/scripts/tags/exturl.jsthemes/next/scripts/tags/include-raw.jsthemes/next/scripts/tags/full-image.jsthemes/next/scripts/tags/label.jsthemes/next/scripts/tags/note.jsthemes/next/scripts/tags/group-pictures.jsthemes/next/scripts/tags/tabs.jsthemes/next/scripts/merge.js","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"src","slug":"CS/web/blog-framework/nodejs-hexo/src","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/src/"}]},{"title":"【hexo源码系列】hexo g","date":"2018-10-07T02:55:00.753Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/src/-hexo-g/","text":"首先会加载插件的index.js脚本， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ hexo g --debug04:48:16.759 DEBUG Hexo version: 3.7.104:48:16.761 DEBUG Working directory: ~/workspace/web/blog-dev/04:48:16.846 DEBUG Config loaded: ~/workspace/web/blog-dev/_config.yml04:48:16.864 DEBUG Plugin loaded: hexo-abbrlink # 打印日志 Generate link 767c2456 for post04:48:16.865 DEBUG Plugin loaded: hexo-auto-category # 打印日志 Generated: categories .. for post04:48:16.877 DEBUG Plugin loaded: hexo-deployer-git04:48:16.879 DEBUG Plugin loaded: hexo-generator-archive # Generator: page、post、archive、category04:48:16.880 DEBUG Plugin loaded: hexo-generator-category #04:48:16.882 DEBUG Plugin loaded: hexo-generator-index04:48:16.884 DEBUG Plugin loaded: hexo-generator-search04:48:16.885 DEBUG Plugin loaded: hexo-generator-tag04:48:16.894 DEBUG Plugin loaded: hexo-related-popular-posts04:48:16.896 DEBUG Plugin loaded: hexo-renderer-ejs04:48:16.905 DEBUG Plugin loaded: hexo-renderer-kramed04:48:16.906 DEBUG Plugin loaded: hexo-renderer-stylus04:48:16.949 DEBUG Plugin loaded: hexo-server04:48:16.949 DEBUG Plugin loaded: hexo-tag-chat04:48:16.950 DEBUG Plugin loaded: hexo-tag-soundcloud04:48:16.950 DEBUG Plugin loaded: hexo-tag-instagram04:48:16.951 DEBUG Plugin loaded: hexo-tag-twitter04:48:16.983 DEBUG Plugin loaded: hexo-wordcount04:48:16.990 DEBUG Script loaded: themes/next/scripts/merge-configs.js04:48:16.991 DEBUG Script loaded: themes/next/scripts/helpers.js04:48:16.991 DEBUG Script loaded: themes/next/scripts/tags/button.js04:48:16.992 DEBUG Script loaded: themes/next/scripts/tags/exturl.js04:48:16.992 DEBUG Script loaded: themes/next/scripts/tags/center-quote.js04:48:16.992 DEBUG Script loaded: themes/next/scripts/tags/full-image.js04:48:16.993 DEBUG Script loaded: themes/next/scripts/tags/include-raw.js04:48:16.993 DEBUG Script loaded: themes/next/scripts/tags/label.js04:48:16.994 DEBUG Script loaded: themes/next/scripts/tags/note.js04:48:16.995 DEBUG Script loaded: themes/next/scripts/tags/tabs.js04:48:16.996 DEBUG Script loaded: themes/next/scripts/tags/group-pictures.js04:48:16.999 DEBUG Script loaded: themes/next/scripts/merge.js04:48:17.164 DEBUG Loading database.04:48:17.171 INFO Start processing04:48:17.191 DEBUG Processed: 404.html04:48:17.251 DEBUG Processed: CNAME04:48:17.252 DEBUG Processed: README.md04:48:17.252 DEBUG Processed: robots.txt04:48:17.312 DEBUG Processed: _posts/README.md04:48:17.314 DEBUG Processed: asset/flare.json04:48:17.314 DEBUG Processed: asset/index.html04:48:17.315 DEBUG Processed: asset/math.json04:48:17.316 DEBUG Processed: images/avatar.png04:48:17.318 DEBUG Processed: images/blueprint.png04:48:17.447 DEBUG Processed: images/carbon.png04:48:17.447 DEBUG Processed: images/error-pin.png04:48:17.451 DEBUG Processed: images/error-hanger.png04:48:17.553 DEBUG Processed: images/bg4.png04:48:17.630 DEBUG Processed: _posts/-block-chain/README.md","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"src","slug":"CS/web/blog-framework/nodejs-hexo/src","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/src/"}]},{"title":"非对称加密 - RSA","date":"2018-10-06T16:00:00.000Z","path":"wiki/CS/security/密码学/非对称加密/rsa/","text":"公开密钥密码学加密需要双方共享一个私密的随机数。从未谋面的两人，如何就此共享密钥达成一致，而又不让第三方监听者知道呢？ 离散对数问题我们需要一种运算，正常容易，反向很难。于是我们找到了模运算，也称时钟运算。 比如 $46 \\ \\mathrm {mod} \\ 12 = 10$，正向计算很容易。 下面采用质数， 对于不同的取值$e$，结果是[0,16]之间均匀分布的。 反向是很困难的 $$3^{\\color{red}{29}} \\mathrm {mod} \\ 17 \\xrightarrow[encrypt]{\\color{green}{EASY}} {\\color{blue}12}$$正向加密很容易。 求以上过程的反向，这就很难了。这被称为离散对数问题(discrete logarithm problem) $$3^{\\color{red}?} \\mathrm {mod} \\ 17 \\xleftarrow[decrypt]{\\color{red}{HARD}} {\\color{blue}{12}}$$反向解密却很难。已知12，我们只能采用试错法求出匹配的指数。 反向有多难如果模数很小，比较容易。模数若是长达百位的质数，即便借助地球上最强大的计算机，要遍历所有可能情况也需要上千年时间。 单向函数的强度取决于反向过程所需要的时间。 反向的难度，具体计算一下 迪菲·赫尔曼密钥交换Alice如何向Bob发送信息，而不怕Eve截获信息呢？ 首先Alice和Bob公开地就质模数(prime modulus)和生成元(generator)达成一致，也就是这个例子中的p=17，g=3。 然后Alice选择一个私有数，${\\color{red}{15}}$，加密后是${\\color{blue} 6}$$$3^{\\color{red}{15}} \\mathrm {mod} \\ 17 \\equiv {\\color{blue} 6}$$然后公开将此结果发送给Bob。 Bob选择一个私有数13，计算$$3^{\\color{red}{13}} \\mathrm {mod} \\ 17 \\equiv {\\color{blue} {12}}$$然后公开将此结果发送给Alice。 下面就是关键 Alice经过以下计算，得到共享密钥 (shared secret) ${\\color{Apricot}{10} }$ $${\\color{blue}{12} }^{\\color{red}{15} } \\mathrm {mod} \\ 17 \\equiv {\\color{Apricot}{10} }$$ Bob也计算得到共享密钥，两者计算结果是相同的。 这是因为$$3^{\\color{red}{13 ^{15}} } \\mathrm {mod} \\ 17 \\equiv 3^{\\color{red}{15 ^{13}} } \\mathrm {mod} \\ 17 $$ 两种计算实质是相同的，只是指数的顺序不同而已。没有私有数字 ${\\color{red}{15}}$、${\\color{red}{13}}$，Eve将无法求出结果。Eve会被困在离散对数问题之中，数字足够大时，实践中，她在合理时限内几乎不可能破解。这就解决了交换密钥的问题。这可以同伪随机数生成器结合使用为未曾谋面的人提供通信加密。 Eve将无法求出结果，没太看懂。 这两个私有数字，只要有一个就能解密吗？ 17，3 是怎么达成一致的？传输过程被截获呢？是public的吗？ RSA加密第一步对称加密中，要求通信双方共享密钥。但如果Alice和Bob不能实际见面，则需要额外的通信开销，比如使用迪菲-赫尔曼密钥交换。 另外，如果Alice希望同很多人通信，那么她将需要同每个人交换不同密钥。她必须管理好所有这些密钥，发送数以千计的信息，仅仅为了建立它们。 是否有更简单的额方式？ 1970年，英国数学家James Ellis试图实现公开密钥加密(non-secret encryption)。 加密和解密是互逆操作，Alice可以买一把锁，把钥匙留在手里，然后把打开的锁发给Bob。Bob可以将自己的信息上锁，然后发回给Alice。这里无需交换密钥。 这意味着锁是可以公开的，可以让世界上任何人使用它来发信息。而现在Alice只需要留一把钥匙。 Ellis并未找到相关的数学方法，但他提出了应该怎样做的思路。关键在于将密钥分为两个部分，一部分是加密密钥，一部分是解密密钥。解密密钥用于解密这一逆操作，而加密是通过加密密钥进行的。 RSA加密第二步需要构建一种特殊的单向函数，也叫陷门单向函数(trap door one-way functioin) 这种函数，正向很容易，反向很难，除非你有关于trap door的特殊信息。为此，考虑了模幂运算。 扩展阅读 现代密码学 | 可汗学院 http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"security","slug":"CS/security","permalink":"http://yoursite.com/categories/CS/security/"},{"name":"密码学","slug":"CS/security/密码学","permalink":"http://yoursite.com/categories/CS/security/密码学/"},{"name":"非对称加密","slug":"CS/security/密码学/非对称加密","permalink":"http://yoursite.com/categories/CS/security/密码学/非对称加密/"}]},{"title":"","date":"2018-10-06T11:07:20.840Z","path":"wiki/others/思想 哲学/-意识形态/马克思主义/评价/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"思想 哲学","slug":"others/思想-哲学","permalink":"http://yoursite.com/categories/others/思想-哲学/"},{"name":"-意识形态","slug":"others/思想-哲学/意识形态","permalink":"http://yoursite.com/categories/others/思想-哲学/意识形态/"},{"name":"马克思主义","slug":"others/思想-哲学/意识形态/马克思主义","permalink":"http://yoursite.com/categories/others/思想-哲学/意识形态/马克思主义/"}]},{"title":"","date":"2018-10-06T10:52:25.441Z","path":"wiki/others/-物理学/-光速/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-物理学","slug":"others/物理学","permalink":"http://yoursite.com/categories/others/物理学/"}]},{"title":"【深度学习-RNN系列】SRU","date":"2018-10-05T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/RNN/SRU/","text":"背景RNN、LSTM、GRU都存在一个严重的问题，在 GPU 上实现时，效率不高，主要是由于前后两个时刻 t-1 和 t 的计算存在依赖性。 the sequential dependencies that are central to recurrent architectures limit parallelization potential SRUSRU（Simple Recurrent Unit）则提出更激进的架构，去掉了前后时刻计算的依赖。 input gate和forget gate的合并 (借鉴自GRU) c和h的合并，(并未采用) 对比其他模型 在 GRU 中，大幅简化了 LSTM 结构 SRU进一步 实现细节（trick）SRU实现：增加highway连接和变分dropout 首先，他们在循环层之间增加了highway连接，因为此前的研究已经证明，像highway连接这样的skip connections，在训练深度网络时非常有效；其次，在将RNN正则化时，他们在标准的dropout外，增加了变分dropout，变分dropout在时间步长t与dropout使用相同的mask。 CUDA级的优化源码https://github.com/taolei87/sru/blob/master/sru/sru_functional.py#L128 好复杂，看着头疼 扩展阅读 Training RNNs as Fast as CNNs, pdf","tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"},{"name":"sru","slug":"sru","permalink":"http://yoursite.com/tags/sru/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"","date":"2018-10-05T02:35:54.655Z","path":"wiki/others/-马斯克/","text":"spaceX，绕月飞行，一个舱容纳7人。被日本亿万富翁买下了整个舱， 猎鹰9号火箭 大型猎鹰火箭","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"}]},{"title":"","date":"2018-10-05T02:28:13.255Z","path":"wiki/others/politics/-american/特朗普/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-american","slug":"others/politics/american","permalink":"http://yoursite.com/categories/others/politics/american/"}]},{"title":"","date":"2018-10-05T02:16:52.605Z","path":"wiki/others/economy/-外汇储备/","text":"# 中国的外汇储备中，美元占比太大。要减少美元占比，分摊到其他硬通货上。 为什么要储备很多美元？ 中国与其他国家贸易，很多是以美元结算","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"}]},{"title":"","date":"2018-10-05T02:04:42.327Z","path":"wiki/others/economy/-国营-私营/","text":"国有经济比例越高，经济自由度越低。 有一定道理 第一，世界上只有一次大规模的国企私有化过程，俄罗斯那次，很失败，搞的普京不得不又国有化，不然俄罗斯怕要亡国。第二，私营企业，比如美国那些500强，它们的股东和高官赚很多钱，但是这些钱，美国政府和老百姓没有享受到，香港的经济也是一样的问题，私营企业太大造成贫富差异。 简介优劣 国营: 有钱，举国之力 国营的例子 NASA 私营 spaceX","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"}]},{"title":"","date":"2018-10-04T14:15:26.013Z","path":"wiki/others/-防忽悠系列/凤凰网/","text":"凤凰网凤凰卫视，总部在香港，但也归中宣部管。 谣传，作为部分情报机构","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-防忽悠系列","slug":"others/防忽悠系列","permalink":"http://yoursite.com/categories/others/防忽悠系列/"}]},{"title":"","date":"2018-10-04T10:18:01.603Z","path":"wiki/others/politics/-南斯拉夫/冬奥会/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-南斯拉夫","slug":"others/politics/南斯拉夫","permalink":"http://yoursite.com/categories/others/politics/南斯拉夫/"}]},{"title":"","date":"2018-10-04T06:25:54.311Z","path":"wiki/others/politics/-苏联/苏联解体/","text":"苏共 亡党亡国，前车之鉴。 https://www.youtube.com/watch?v=AriSdJKwsTs 关键环节 强硬派：副总统、 被软禁的戈尔巴樵夫 追求自由的苏联人民 叶利钦 没有开枪 暴力镇压 OR 顺应民意 # 苏联经历了 苏共为何选择与中共不同的道路？ 小平同志666 胡锦涛赵紫阳站在人民一边。 习近平：无一人是男儿 对中国的影响习近平上台以来，中共领导人和官媒一再强调苏联解体是前车之鉴，政治开放可能导致”亡党亡国”。为此焦点对话推出特别节目， 扩展阅读 https://www.youtube.com/watch?v=AriSdJKwsTs","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-苏联","slug":"others/politics/苏联","permalink":"http://yoursite.com/categories/others/politics/苏联/"}]},{"title":"","date":"2018-10-04T05:40:58.425Z","path":"wiki/others/politics/-俄罗斯/普京/","text":"叶利钦为什么会选择普京作为接班人？ 普京上台普京上台后，对经济寡头进行了惩罚，并且把寡头们的能源公司收归国有，这增加了俄罗斯的经济收入，改善了人民的生活水平。 # 普京向军队投入了大量经费，提高了俄罗斯军队的战斗力，使俄罗斯只用短短几年就重新回到了世界强国的行列。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-俄罗斯","slug":"others/politics/俄罗斯","permalink":"http://yoursite.com/categories/others/politics/俄罗斯/"}]},{"title":"叶利钦","date":"2018-10-04T05:40:22.157Z","path":"wiki/others/politics/-俄罗斯/叶利钦/","text":"戈尔巴乔夫提携叶利钦，后来把老领导翘了 简介1931-2007，俄罗斯第一任总统，他也是欧美国家肢解苏联的”代言人” 叶利钦的领导，带给俄罗斯的是战争、饥饿、贫穷、贫穷 与戈尔巴樵夫苏联解体 大部分俄罗斯人都认为叶利钦是俄罗斯的罪人，是他导致了苏联的解体。 解体后 - 与欧美的关系苏联解体后，很多俄罗斯人民认为叶利钦是欧美国家的盟友，欧美国家一定会向俄罗斯进行大量的投资，帮助俄罗斯发展经济。 可是欧美国家却把俄罗斯当成了最大的敌人，苏联解体后美国参与发起了波黑战争和科索沃战争，把俄罗斯在巴尔干半岛的盟友南联盟肢解了，并且把俄罗斯的势力从巴尔干半岛赶了出去。 美国又积极推动北约东扩，挤压了俄罗斯在东欧地区的战略生存空间。 执政叶利钦执政时期腐败无能，在俄罗斯推行寡头政治，把俄罗斯的国有企业和能源公司变成了寡头们的私人财产。 接班人叶利钦深知自己并没有受到俄罗斯民众的肯定，他的同僚对他也不是十分友好。再加上他不想自己走斯大林或赫鲁晓夫的老路，被下一任总统所“清算”。于是他看中了忠诚并懂得感恩的普京。 普京上任后就发布了《关于对停止行使职权的俄罗斯联邦总统及其家庭成员提供保护命令》，这个命令直接保证了叶利钦的晚年高枕无忧，甚至还能享有国家特权。 不过叶利钦也发现了俄罗斯存在的问题，因此培养普京作为他的接班人。 1999年12月叶利钦辞去了俄罗斯总统职务，并且把总统之位交给了普京。 他培养了普京，是俄罗斯在普京的领导下再次强大 民主叶利钦镇压反对派，对合法选出的议会枪击炮打。 贡献扩展阅读 在叶利钦墓前谈叶利钦","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-俄罗斯","slug":"others/politics/俄罗斯","permalink":"http://yoursite.com/categories/others/politics/俄罗斯/"}]},{"title":"阿佛加德罗常数","date":"2018-10-04T05:16:52.882Z","path":"wiki/Math/数论/-常量/阿佛加德罗常数/","text":"数论 ‘-常量’","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"","date":"2018-10-04T05:08:15.614Z","path":"wiki/others/-物理学/炼金术/","text":"世界由少量的元素构成，黄铜和金子只是元素的配比不同，只要更改比例，就能够从黄铜得到金子。 比如中国的金木水火土，柏拉图 - 风火水土","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-物理学","slug":"others/物理学","permalink":"http://yoursite.com/categories/others/物理学/"}]},{"title":"普朗克长度","date":"2018-10-04T03:32:23.720Z","path":"wiki/Math/数论/-常量/普朗克长度/","text":"组成物质的最小单位到底存不存在？ 到目前为止，夸克和轻子就是最基本的粒子了，还没发现它们有更深一层的结构。 不存在，测到一定程度就测不准了 现代物理学，既自然界能观测的都是“物质”单位，不能直观观测到的叫做“能量”，然而量变产生质变，一个“空间单位”中集聚的能量越多,在显微镜的观测中就会“无中生有”凭空产生的一样出现很多最小的“物质”单位，因为人类目前的科技没有办法去观察“量产产生质变”这个能量转成物质单位过程… 目前有一个理论是物质是由种能量波构成的＂弦＂，在最微观，可能根本就没物质。不过既然正反物质能泯灭成纯能量，这种可能性也挺大的。 – 弦理论 最小的可测量单位是普朗克长度，1.6x10^-35米，质子比它大10^22倍。比这个单位还小的地方，是没有意义的，因为这个宇宙里永远也不可能发现它。就是说，在这个宇宙里，不可能发现小于普朗克长度的物质。也不可能知道小于普朗克时间（5.39×10^-44秒）内发生的事情。这是由宇宙本身物理规律决定的，不存在人类技术发展就可以做到。 其他单位必须是普朗克长度的整数倍吗？ 扩展阅读https://www.zhihu.com/question/48616135zhihu.com/question/48616135","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"","date":"2018-10-04T03:19:32.031Z","path":"wiki/Math/-几何/欧式几何/几何原本/","text":"几何原本《几何原本》是古希腊数学家欧几里得所著的一部数学著作，共13卷。这本著作是现代数学的基础，在西方是仅次于《圣经》而流传最广的书籍[1] 欧⼏⾥得（约前330—前275年），古希腊数学家，⼏何学的⿐祖，雅典⼈，柏拉图的学⽣。公元前300年左右，在托勒密王的邀请下，欧⼏⾥得来到亚历⼭⼤，并长期在那⾥⼯作，建⽴了以他为⾸的数学学派。他是⼀位温良憨厚的教育家。他总结了希腊数学成果，写成了⼗三卷的《⼏何原本》，使⼏何学成为⼀门独⽴的学科。他对光学、天⽂学、英语也有研究，主张光的直线性观点。有《数据》《图形分割》《论数学的伪结论》《光学之书》《反射学之书》等著作，对⾃然科学的发展做出了极为重⼤的贡献。 (公设与定义→命題→证明) 背景 定义 公设(假设)，公设的自明的，即无需证明的事实 公理: 公理也是自明的 命题- 详细介绍欧⼏⾥得建⽴了⼈类历史第⼀座宏伟的演绎推理⼤厦，利⽤很少的⾃明公理、定义，推演出四百余个命题，成为⼈类理性的丰碑 《⼏何原本》从少量“⾃明的”定义、公理出发，利⽤逻辑推理的⽅法，推演出整个⼏何体系，选取少量的原始概念和不需证明的命题，作为定义、公设和公理，使它们成为整个体系的出发点和逻辑依据，然后运⽤逻辑推理证明其他命题。 “欧⼏⾥得”成为⼏何学的代名词，并且⼈们把这种体系的⼏何学叫做欧⼏⾥得⼏何学。 《⼏何原本》对世界数学的贡献主要是：确⽴了数学的基本⽅法学。 建⽴了公理演绎体系，即⽤公理、公设和定义的推证⽅法。 将逻辑证明系统地引⼊数学中，确⽴了逻辑学的基本⽅法。 创造了⼏何证明的⽅法：分析法、综合法及归谬法。 本书共分13卷，开始于一系列定义，之后是5条公设、5条公理、119个定义和465个命题，构成历史上第⼀个数学公理体系。 5条公设(基本假设) 两点定一线: 过两点可以作⼀条直线。 线段变直线: 直线可以向两端⽆限延伸。 圆心+半径得到圆: 以定点为圆⼼及定长的线段为半径可以作圆。 直角都相等: 凡直⾓都相等。 平行公设: 同平⾯内⼀条直线和另外两条直线相交，若在直线同侧的两个内⾓之和⼩于180°，则这两条直线经⽆限延长后在这⼀侧⼀定相交。 这就是著名的第五公设 等价于: 过直线外一点，有且只有一条平行线 前四个假设比较简单， 这是5条假设，是不能证明的。但是人们眼中怀疑第五条公理是可以证明的。于是很多科学家希望通过前四个公理以及一些推导过程得到第五公理。持续上千年。 5条公理《几何原本》中的公理亦共有5条： 等于同量的量相等。 等量加等量，其和相等。 等量减等量，其差相等。 能迭合的量一定相等。 整体大于部分。 公理 VS 公设欧几里德是这样区分公理与公设的：第一，公理适合于一切科学，而公设是几何所特有的；第二，公理本身是自明的，公设没有公理那样自明，但也是不加证明而承认其真实性的。时至今日，人们已不在区分公理与公设了，都用公理一词来表明。 罗氏几何俄罗斯，罗巴切夫斯基，把第五公理改了 过直线外一点，有多条平行线 他希望通过更改后的第5公理与前四个公理得到矛盾，这样也能间接证明第五公理。 但是，发现与前四个公理并不矛盾。这说明第五公理是独立的，是不能通过前四个公理进行证明的。他证明了第五公理不可证明，那第五公理本身也是假设。于是他把更改过的第五公理结合前四个公理，得出新的几何。称为罗氏几何。 黎曼几何 过直线外一点没有平行线。比如在球面上是成立的。 爱因斯坦的广义相对论为什么用黎曼几何或罗氏几何呢？因为空间是弯曲的。 例如在地球仪上，欧式几何就是错的。在航海学上就需要用黎曼几何？ 5条公理","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-几何","slug":"Math/几何","permalink":"http://yoursite.com/categories/Math/几何/"},{"name":"欧式几何","slug":"Math/几何/欧式几何","permalink":"http://yoursite.com/categories/Math/几何/欧式几何/"}]},{"title":"e","date":"2018-10-03T16:06:40.058Z","path":"wiki/Math/数论/-常量/e/","text":"$e^{2\\pi i} = 1$ 参考 不可思议的e参考 不可思议的e","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"圆周率pie","date":"2018-10-03T16:06:12.861Z","path":"wiki/Math/数论/-常量/pie/","text":"参考 说不尽的pie","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"-常量","slug":"Math/数论/常量","permalink":"http://yoursite.com/categories/Math/数论/常量/"}]},{"title":"","date":"2018-10-03T15:32:46.263Z","path":"wiki/Math/-数学分析(微积分)/积分学/反常积分/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"积分学","slug":"Math/数学分析-微积分/积分学","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/积分学/"}]},{"title":"","date":"2018-10-03T15:32:35.334Z","path":"wiki/Math/-数学分析(微积分)/积分学/定积分/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"积分学","slug":"Math/数学分析-微积分/积分学","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/积分学/"}]},{"title":"","date":"2018-10-03T15:17:16.385Z","path":"wiki/Math/-数学分析(微积分)/积分学/不定积分/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"积分学","slug":"Math/数学分析-微积分/积分学","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/积分学/"}]},{"title":"","date":"2018-10-03T15:16:42.376Z","path":"wiki/Math/-数学分析(微积分)/积分学/积分/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"积分学","slug":"Math/数学分析-微积分/积分学","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/积分学/"}]},{"title":"哥德巴赫猜想","date":"2018-10-03T08:07:45.860Z","path":"wiki/Math/数论/素数/-哥德巴赫猜想/","text":"数论 素数","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"素数","slug":"Math/数论/素数","permalink":"http://yoursite.com/categories/Math/数论/素数/"}]},{"title":"孪生素数猜想","date":"2018-10-03T08:07:34.724Z","path":"wiki/Math/数论/素数/-孪生素数猜想/","text":"数论 素数","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"素数","slug":"Math/数论/素数","permalink":"http://yoursite.com/categories/Math/数论/素数/"}]},{"title":"黎曼猜想","date":"2018-10-03T08:07:24.272Z","path":"wiki/Math/数论/素数/-黎曼猜想/","text":"RH发端于黎曼在1859年的一篇文章，其历史比费马大定理与哥德巴赫猜想的历史短得多。 全体自然数的和是不是-1/12 调和级数，发散$$\\sum_{k=1}^{\\infty }{\\frac{1}{k}} = 1+{\\frac{1}{2}}+{\\frac{1}{3}}+{\\frac{1}{4}}+\\cdots$${\\frac{1}{4}}+\\cdots$$","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"素数","slug":"Math/数论/素数","permalink":"http://yoursite.com/categories/Math/数论/素数/"}]},{"title":"素数","date":"2018-10-02T08:45:46.919Z","path":"wiki/Math/数论/素数/素数/","text":"简介质数（Prime number），又称素数，指在大于1的自然数中，除了1和该数自身外，无法被其他自然数整除的数（也可定义为只有1与该数本身两个正因数的数）。大于1的自然数若不是素数，则称之为合数（也称为合成数）。 算术基本定理确立了素数于数论里的核心地位：任何大于1的整数均可被表示成一串唯一素数之乘积。 素数的个数古希腊数学家欧几里得于公元前300年前后证明有无限多个素数存在（欧几里得定理）。 不存在最大质数! 已知最大的质数 找素数 即划掉不是素数的，剩下的就是素数。 梅森素数早在2500年前，希腊数学家欧几里德就证明了素数是无限的，并提出少量素数可写成“2的n次方减1(2^n－1)”的形式，这里n也是一个素数。但是目前人类已知的素数很有限，因为数字越大，要发现新的素数就越困难。不过，很多数学家曾对素数问题进行过研究，17世纪的法国教士马丁·梅森就是其中成果较为卓著的一位，因此后人将“2的n次方减1(2^n－1)”形式的素数称为梅森素数。随后，以梅森素数的形式，最大素数的记录被不断刷新。 GIMPS计划1995 年，美国程序设计师乔治·沃特曼整理有关梅森素数的资料，编制了一个梅森素数计算程序，并将其放置在因特网上供数学爱好者使用，这就是分布式计算因特网梅森素数大搜索（GIMPS）项目。目前有6万多名志愿者、超过20万台计算机参与这项计划。该计划采取分布式计算方式，利用大量普通计算机的闲置时间，获得相当于超级计算机的运算能力，第 37、38 和 39 个梅森素数都是用这种方法找到的。美国一家基金会还专门设立了 10 万美元的奖金，鼓励第一个找到超过千万位素数的人。 专门搜寻巨大质数的GIMPS计划再发现长达千万个位的质数，为甚麽会有些人对寻找大质数如此有兴趣？ 2016, Dr. Curtis Cooper发现了第49个梅森素数和已知最大的素数：$2^74,207,281-1, 共有22,338,618位. 2017年12月26日，互联网梅森素数大搜索（GIMPS）项目宣布发现第 50 个梅森素数和已知最大的素数：2^77,232,917-1，共有 23,249,425 位。该素数已被多人使用不同的硬件和软件完成验证。发现者是 GIMPS 志愿者 Jonathan Pace，他住在田纳西州的 Germantown，是一位电机工程师，他有资格获得 3000 美元的研究发现奖。GIMPS 是一个分布式计算项目，至今已有 20 年历史，它利用志愿者的空闲 CPU 创建了一个遍布全球的超级计算机，它的 prime95 软件此前发现了英特尔处理器的一个漏洞。 最大素数 | 维基百科- 大家利用梅森素数刷新最大素数记录，是否验证了两个梅森素数之间的所有数？ Prime Number Checker素数的分布统计规律 数学家们之前认为素数是随机分布的。比如某一个位是1的素数，那么它的下一个素数以1结尾和以3结尾、以7结尾、以9结尾的概率都应大致相等。 如果素数与素数之间没有相互作用，那么素数分布就应该是之前我们所想的那样。”桑德拉说，“但事实上，一些有趣的事发生了。”发生了什么？原来桑德拉他们发现，尽管素数分别以这四个数字结尾的总几率大致相同，但它们出现的顺序却有所“偏好”。比如个位为7的素数，它后面更容易跟着一个个位为9、3或者1的素数，而不是个位也为7的素数。据《量子杂志》（Quanta Magazine）3月13日的报道，在前10亿个素数中，以9结尾的素数之后跟着以1结尾的素数的比例比跟着以9结尾的素数的比例高了65%。 当素数趋于无穷时，这样的“偏好”会慢慢消失，分布更趋向于随机。但不可否认的是，“偏好”还是存在的。更重要的是，这些素数对尾数的偏好还很不一致。比如在前1亿个素数中，有750万个以3结尾的素数之后紧跟的是以9结尾的素数，有600万个以3结尾的素数之后紧跟的是以1结尾的素数，而只有440万个以3结尾的素数之后紧跟的是以3结尾的素数。 乌岚螺旋乌岚螺旋，又称素数螺旋，是一个简单的展示出素数的一定明显规律的结构，同时它也指出一些二次多项式有着大量生成素数（富素数）的特性。 乌岚是写下了一个正方形的数组来构造了这个螺旋数组，从1开始且开始按照这个螺旋规律： 他然后圈起了所有的素数（如下图）： 令他吃惊的是这堆圈起来的数字趋向于与对角线排成一行。在200×200的乌岚素数表当中（上图），其中对角线都是清晰可见且完成整一个表，而且水平线和垂直线都是有证明显著突出素数的样子。 为什么喜欢这种画法？其他画法呢？- 映射的思想 一维空间不可分，于是映射到二维空间。即乌岚螺旋仅仅将数据映射到二维空间而已。找不到规律也很正常。too naive 乌岚螺旋等价于哪种映射？- 映射到更高维空间呢？ 乌岚螺旋的变种https://en.wikipedia.org/wiki/Ulam_spiral 空间变换局限于数空间，是否存在某个空间(类似频域)，使得 整数 VS 实数只有整数具有质数、合数性质吗？ 小数呢？ 机器学习用学习的方法呢？ 分类input: valueoutput: boolean(是否是质数) 这样构造一个二分类器？ 回归聚类关于素数的猜想猜想一M=2×3×5×7×11×13×……×N+1,1~N为连续质数，用从1到N之间的任何一个质数去除M，总是余1！ 那么这个M是质数还是合数呢？ M=2×3×5×7×11×13+1=30031=59×509, 所以M不一定是质数。 其他猜想 费马猜想： 所有具$2^{2^n} + 1$形式的数均为素数（称之为费马数） 欧拉发现，下一个费马数$2^{32} + 1$即为合数 梅森发现有的素数具$2^{p} − 1$的形式，其中p为素数。为纪念他的贡献，此类素数后来被称为梅森素数。 黎曼猜想。 黎曼通过研究发现， 素数分布的绝大部分猜想都取决于黎曼zeta函数ζ（s）的零点位置。他猜测那些非平凡零点都落在复平面中实部为1/2的直线上， 这就是被誉为千禧年世界七大数学难题之一的黎曼猜想， 是解析数论的重要课题。 孪生素数猜想 存在无穷多对相差2的素数 如果p和p+2都是素数， 那么就称他们为孪生素数。一个重要的问题就是：是否存在无限多对孪生素数？美国华人张益唐对这个问题的解决迈出了重要一步，他证明了有无穷多对差小于七千万的素数。之后大家不断改进他的证明，现在这个七千万已经缩小到246. 3,5 5,7 11,13 17,19… 哥德巴赫猜想（Goldbach Conjecture) 偶数哥德巴赫猜想：任一大于2的偶数可表示成两个素数之和 (“1+1”) 奇数哥德巴赫猜想：任一大于5的奇数都可以表示为三个素数之和 “a+b”：每个大偶数N都可表为A+B，其中A和B的素因子个数分别不超过a和b。显然，哥德巴赫猜想就可以写成”1+1”。 证明： 陈景润证明了 “1 + 2 ”，即任何大于6的偶数都是一个素数加上两个素数的积 哥德巴赫猜想（每个大于2的偶数可表示成两个素数之和 素数的应用这个现实，又表明M一定是质数。 公钥加密利用了难以将大数分解成其素因数之类的性质 几个公开金钥加密算法，如RSA与迪菲－赫尔曼金钥交换，都是以大素数为其基础（如512位元的素数常被用于RSA里，而1024位元的素数则一般被迪菲-赫尔曼金钥交换所采用）。RSA依靠计算出两个（大）素数的相乘会比找出相乘后的数的两个素因数容易出许多这个假设。迪菲－赫尔曼金钥交换依靠存在模幂次的有效算法，但相反运算的离散对数仍被认为是个困难的问题此一事实。 参考 https://www.thepaper.cn/newsDetail_forward_1446862","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"数论","slug":"Math/数论","permalink":"http://yoursite.com/categories/Math/数论/"},{"name":"素数","slug":"Math/数论/素数","permalink":"http://yoursite.com/categories/Math/数论/素数/"}]},{"title":"费马","date":"2018-10-02T08:36:49.844Z","path":"wiki/Math/-数学八卦-数学史-数学家/费马/","text":"马是17世纪的法国律师这个法国律师特别喜欢数学他经常会在图书馆里看书当他看到有意思的地 有一些自己的想法之后他就会把自己的想法写在书的空白处而且写上一句话这个定理我已经证明完毕了 但是书的空白太小了我就不写了 费马大定理被一批又一批的数学家前仆后继地进行研究时间持续了300年在300年间 世界上第一流的数学家几乎都参与了这个问题证明比如说欧拉 高斯 刘维尔 柯西等等一些人这个定理无数次被人们宣布已经证明完毕了但是又无数次被宣布证明过程是有问题的 最后被世界上第一流的数学家英国人怀尔斯所证明 费马猜想: 2^2^n + 1 一定是质数 50年后，欧拉计算了n=5，不是质数。 费马大定理n = 3n &gt; 3后面又猜想，n=6，n=7 之后是不是都不是质数？目前一直没被证明。 费马大定理n=3 x^3 欧拉证明了 n=3无整数解 300年 1995年证明了费马大定理。","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学八卦-数学史-数学家","slug":"Math/数学八卦-数学史-数学家","permalink":"http://yoursite.com/categories/Math/数学八卦-数学史-数学家/"}]},{"title":"第三次数学危机 - 罗素 - 理发师悖论","date":"2018-10-02T08:05:06.223Z","path":"wiki/Math/-数学八卦-数学史-数学家/第三次数学危机/","text":"罗素: 理发师悖论 问题: 我给且仅给自己不刮胡子的人刮胡子。那么到底该不该给自己刮胡子? 为了诘难康托尔：集合论 定义， A={x|x不属于A}本身只有一个条件，没有任何矛盾，是推理推出了矛盾。 集合理论永久的瑕疵，现在人们还没有完美解决。 到目前仍然无解。 全能的上帝能造出自己也举不起的石头网友评论: Ken Li: 这个问题是『假命题』 ，假命题是没有答案的，比如说，一个单身汉如何要跟他的妻子搞好关系？，单身汉的定义就已经把『有妻子』排除在外，所以假命题的意思就是，问题本身就不成立，既然问题本身不成立，那么问题就不会有答案。『全能的上帝』这一定义就已经把『自己舉不起來石头』排除在外了，所以就是假命题，没有答案。 Bowen Qiu: @Ken Li 如果按照这个逻辑，那么“不属于A”这个条件也是已经把A排除在外了，自然A里面就不会有这些元素了，所以这个悖论也是个假命题。 Lyuxun Yang: 视频里的问题是只定义了A={x|x不属于A}，本身只有一个条件，没有任何矛盾，是推理推出了矛盾。你的问题中说上帝既全知全能，又存在他举不起的石头，这两个条件本身就矛盾，还问能不能举起就没有任何意义了。就好比我定义x同时满足x&gt;0和x&lt;0这两个条件，还问你x是不是奇数，这有意义吗？ Enjie Guo: A中的x是属于A的，这个是默认条件，又新加条件x不属于A，这两个条件是相悖的，比较同意Ken Li说的假命题。 郭芝融: @Enjie Guo 這樣跟你說好了，如果有一個B集合，B中的x都滿足x不等於x，如果你覺得x=x是默認條件，又新加條件x不等於x，所以是假命題的話，我告訴你，其實B存在，而且是空集合，但是羅素悖論的集合A不管是不是空集合都會有矛盾 Enjie Guo: @郭芝融 我不觉得x=x是默认条件，我觉得x属于b是默认条件。 在计算机里这是recursive definition, 无法编译通过 网友的智慧 可不可以发明一个量子数学啥的，这样就是即属于又不属于，处于一种纠缠态的概念 模糊数学？ 應該是不行 你說的量子既屬於又不屬於是基於機率分佈的概念，但是機率論的理論基礎正好就是集合論 问题续 这个问题应该算是解决了，ZFC集合公理系统里剔除了集合包含自身的情况。并且在集合论里提出了类的概念，任何一个集合必然包含在另一个集合内，而类不然。所以不存在包含所有集合的集合，但是存在包含所有集合的类 参考 https://www.youtube.com/watch?v=GWTVAYQytJ8","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学八卦-数学史-数学家","slug":"Math/数学八卦-数学史-数学家","permalink":"http://yoursite.com/categories/Math/数学八卦-数学史-数学家/"}]},{"title":"","date":"2018-10-02T07:56:53.525Z","path":"wiki/Math/-数学八卦-数学史-数学家/第二次数学危机/","text":"阿基里斯追乌龟。 可以给小孩说说，挺不错。 骗人的。 无穷小到底是不是0. 颠覆了微积分。后面对无穷小做了精确的定义。 # https://www.youtube.com/watch?v=S5z7xYfGNXs","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学八卦-数学史-数学家","slug":"Math/数学八卦-数学史-数学家","permalink":"http://yoursite.com/categories/Math/数学八卦-数学史-数学家/"}]},{"title":"","date":"2018-10-02T07:51:58.427Z","path":"wiki/Math/-数学八卦-数学史-数学家/第一次数学危机/","text":"第一次数学危机毕达哥拉斯 万物皆数 - 整数 要么是整数，要么是整数的比。 有理数 整数- 0.806…. = 806/999 勾股定理问题来了 勾股定理的 1，1 根号2，不是有理数。 希伯索斯被绑在石头上，扔到大海。","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学八卦-数学史-数学家","slug":"Math/数学八卦-数学史-数学家","permalink":"http://yoursite.com/categories/Math/数学八卦-数学史-数学家/"}]},{"title":"","date":"2018-10-02T02:45:25.448Z","path":"wiki/Math/-数学分析(微积分)/葛立恒数/","text":"https://www.youtube.com/watch?v=eSYN2UN3SXM tree(3)比葛立恒数更大","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"}]},{"title":"","date":"2018-10-02T02:45:11.192Z","path":"wiki/Math/-数学分析(微积分)/高德纳箭头/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"}]},{"title":"","date":"2018-10-02T02:39:46.266Z","path":"wiki/Math/-数学分析(微积分)/1. 数列极限、函数极限、连续函数/综述/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-数学分析(微积分)","slug":"Math/数学分析-微积分","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/"},{"name":"1. 数列极限、函数极限、连续函数","slug":"Math/数学分析-微积分/1-数列极限、函数极限、连续函数","permalink":"http://yoursite.com/categories/Math/数学分析-微积分/1-数列极限、函数极限、连续函数/"}]},{"title":"","date":"2018-10-02T01:35:33.206Z","path":"wiki/Math/-希尔伯特的旅店/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"}]},{"title":"ngram发展现状","date":"2018-10-01T07:52:21.257Z","path":"wiki/-language_model/-model/ngram进展/","text":"count-based LM","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"}]},{"title":"factored language models","date":"2018-10-01T06:07:29.951Z","path":"wiki/-language_model/-model/flm/","text":"proposed by Bilmes andKirchhoff [4],","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"}]},{"title":"","date":"2018-10-01T03:12:28.983Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/应用/-nnlm的查询/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"},{"name":"应用","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/应用","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/应用/"}]},{"title":"","date":"2018-09-30T04:52:53.864Z","path":"wiki/-audio/前端信号处理/扰动/","text":"数据扰动：2000小时音量扰动(+-)，2000小时音速扰动(1000拉长或1000缩短 0.1，不能扰动太多，调整语速)， 变速：波形叠加，OLA 在时域上扰动，后面再提特征。是简单的拉伸或者拉高吗？不是，重要的是平滑。平滑就差值呗？不是，貌似比较高级。 time scaleA Review of Time-Scale Modification of Music Signals","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"浮点数的定点化","date":"2018-09-30T01:10:36.050Z","path":"wiki/ML/quantize/-定点化/","text":"背景知识 浮点 定点 float、double、intdouble、int","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"quantize","slug":"ML/quantize","permalink":"http://yoursite.com/categories/ML/quantize/"}]},{"title":"","date":"2018-09-30T00:21:21.559Z","path":"wiki/machine translation/-patent/","text":"双语混合词典back translation无监督半监督","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"}]},{"title":"专利","date":"2018-09-30T00:19:50.312Z","path":"wiki/-language_model/-patent/","text":"cnntransformer + cnn (局部约束)subword","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"}]},{"title":"","date":"2018-09-29T14:16:37.883Z","path":"wiki/CS/programing/lan/-对象/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"面向对象编程","date":"2018-09-29T12:24:33.231Z","path":"wiki/CS/programing/编程思想 - 设计模式/-面向对象/","text":"面向对象的三个基本特征是：封装、继承、多态。 要符合人们习惯的思维方法，便于分解大型的复杂多变的问题。由于对象对应于现实世界中的实体，因而可以很自然地按照现实世界中处理实体的方法来处理对象，软件开发者可以很方便地与问题提出者进行沟通和交流。 易于软件的维护和功能的增减。对象的封装性及对象之间的松散组合，都给软件的修改和维护带来了方便。 可重用性好。重复使用一个类（类是对象的定义，对象是类的实例化），可以比较方便地构造出软件系统，加上继承的方式，极大地提高了软件开发的效率。4、与可视化技术相结合，改善了工作界面。随着基于图形界面操作系统的流行，面向对象的程序设计方法也将深入人心。它与可视化技术相结合，使人机界面进入GUI时代。 聚合关系是一种松散的关联关系，目标元素可有可无。 组合关系是一种强关联，它有一个重要的特性：部分在某一时刻仅仅只能属于一个整体。 降低程序的耦合度 扩展阅读 大话设计模式 - 程杰 大话设计模式 - 吴强","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"编程思想 - 设计模式","slug":"CS/programing/编程思想-设计模式","permalink":"http://yoursite.com/categories/CS/programing/编程思想-设计模式/"}]},{"title":"","date":"2018-09-29T12:24:23.172Z","path":"wiki/CS/programing/编程思想 - 设计模式/-面向过程/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"编程思想 - 设计模式","slug":"CS/programing/编程思想-设计模式","permalink":"http://yoursite.com/categories/CS/programing/编程思想-设计模式/"}]},{"title":"java数组","date":"2018-09-29T12:14:14.686Z","path":"wiki/CS/programing/lan/java/-java数组/","text":"源码在哪？ Java提供Null指针检测数组便捷检测异常出口字节代码校验。 《大话设计模式》","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"}]},{"title":"fastText 压缩 量化","date":"2018-09-29T12:00:19.863Z","path":"wiki/ML/app/nlp/app/word-vector/model/-fastText/fastText.zip/","text":"https://www.jianshu.com/p/9ea0d69dd55e","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-fastText","slug":"ML/app/nlp/app/word-vector/model/fastText","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/fastText/"}]},{"title":"","date":"2018-09-29T09:17:40.320Z","path":"wiki/ML/deep learning/-quantize/","text":"见ML/quantize","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"}]},{"title":"","date":"2018-09-29T06:20:00.521Z","path":"wiki/-audio/ASR/-TODO/","text":"语音识别：增加类内损失项，联合 CE/CTC 损失项和类内损失项训练声学模型；","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"}]},{"title":"关于C程序的编译和链接","date":"2018-09-29T02:50:39.943Z","path":"wiki/CS/tools/build/-make/c的编译和链接/","text":"一般来说，无论是C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下也就是 .obj 文件，UNIX下是 .o 文件，即 Object File，这个动作叫做编译（compile）。然后再把大量的 Object File合成执行文件，这个动作叫作链接（link）。 编译时，编译器需要的是语法的正确，函数与变量的声明的正确。对于后者，通常是你需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件都应该对应于一个中间目标文件（O文件或是 OBJ文件）。 链接时，主要是链接函数和全局变量，所以，我们可以使用这些中间目标文件（O文件或是OBJ文件）来链接我们的应用程序。链接器并不管函数所在的源文件，只管函数的中间目标文件（Object File），在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File)，也就是 .lib 文件，在UNIX下，是Archive File，也就是 .a 文件。 总结一下，源文件首先会生成中间目标文件，再由中间目标文件生成执行文件。在编译时，编译器只检测程序语法，和函数、变量是否被声明。如果函数未被声明，编译器会给出一个警告，但可以生成Object File。而在链接程序时，链接器会在所有的Object File中找寻函数的实现，如果找不到，那到就会报链接错误码（Linker Error），在VC下，这种错误一般是：Link 2001错误，意思说是说，链接器未能找到函数的实现。你需要指定函数的Object File. 扩展阅读 http://wiki.ubuntu.org.cn/%E8%B7%9F%E6%88%91%E4%B8%80%E8%B5%B7%E5%86%99Makefile:%E6%A6%82%E8%BF%B0 程序员的基本素养 程序构建","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-make","slug":"CS/tools/build/make","permalink":"http://yoursite.com/categories/CS/tools/build/make/"}]},{"title":"","date":"2018-09-29T01:58:16.534Z","path":"wiki/ML/app/nlp/trick/-trick-数值计算/","text":"见ML","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"}]},{"title":"","date":"2018-09-28T08:32:26.175Z","path":"wiki/machine translation/evaluation/-lepor/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"evaluation","slug":"machine-translation/evaluation","permalink":"http://yoursite.com/categories/machine-translation/evaluation/"}]},{"title":"","date":"2018-09-28T08:32:16.846Z","path":"wiki/machine translation/evaluation/-meteor/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"evaluation","slug":"machine-translation/evaluation","permalink":"http://yoursite.com/categories/machine-translation/evaluation/"}]},{"title":"","date":"2018-09-28T08:31:05.197Z","path":"wiki/machine translation/evaluation/-word-error-rate/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"evaluation","slug":"machine-translation/evaluation","permalink":"http://yoursite.com/categories/machine-translation/evaluation/"}]},{"title":"","date":"2018-09-28T08:30:50.115Z","path":"wiki/machine translation/evaluation/-nist/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"evaluation","slug":"machine-translation/evaluation","permalink":"http://yoursite.com/categories/machine-translation/evaluation/"}]},{"title":"tie embedding","date":"2018-09-28T07:52:23.089Z","path":"wiki/ML/app/nlp/trick/trick-lm/-tie-embedding/","text":"Using the Output Embedding to Improve Language Models, 2016","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-lm","slug":"ML/app/nlp/trick/trick-lm","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-lm/"}]},{"title":"cnnlm","date":"2018-09-28T07:50:42.048Z","path":"wiki/-language_model/-model/nnlm/cnnlm/","text":"","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"},{"name":"nnlm","slug":"language-model/model/nnlm","permalink":"http://yoursite.com/categories/language-model/model/nnlm/"}]},{"title":"","date":"2018-09-28T07:43:31.009Z","path":"wiki/machine translation/-4. trick/","text":"见 nlp目录","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"}]},{"title":"trick","date":"2018-09-28T07:41:38.082Z","path":"wiki/-language_model/-trick/","text":"见 nlp目录","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"}]},{"title":"","date":"2018-09-28T04:46:08.596Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/点估计/-贝叶斯点估计/","text":"贝叶斯点估计，就是MAP吧？？ 扩展阅读 贝叶斯点估计 | 知乎专栏","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"},{"name":"点估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计/点估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/点估计/"}]},{"title":"","date":"2018-09-28T04:32:28.466Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/点估计/-MAP/","text":"th ‘-概率论与数理统计’ 统计推断 1 参数估计 点估计","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"},{"name":"点估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计/点估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/点估计/"}]},{"title":"","date":"2018-09-28T02:43:56.257Z","path":"wiki/ML/ml 传统方法/降维/-t-SNE/","text":"tensorflow的word embedding可视化，默认集成了tsne 参考http://www.datakit.cn/blog/2017/02/05/t_sne_full.html","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"降维","slug":"ML/ml-传统方法/降维","permalink":"http://yoursite.com/categories/ML/ml-传统方法/降维/"}]},{"title":"","date":"2018-09-28T02:14:57.688Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/区间估计/-贝叶斯区间估计/","text":"起点是未知随机变量$\\Theata$的先验分布$p_{\\Theta}$或者$f_{\\Theta}$ 得到观测向量$X$的$\\p_{X|\\Theta}$或者$f_{\\Theta}$ 一旦$X$的一个特定量$x$观测到后，运用贝叶斯法则计算$\\Theta$的后验分布 贝叶斯估计是点估计，还是区间估计？ 扩展阅读 贝叶斯区间估计","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"},{"name":"区间估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计/区间估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/区间估计/"}]},{"title":"NLP中的平滑方法","date":"2018-09-27T07:09:56.091Z","path":"wiki/ML/app/nlp/trick/trick-lm/-smooth/","text":"背景MLE我们来看一个概率模型，也就是 p(e)在 event space E 下的概率分布，模型很可能会用最大似然估计(MLE)，如下$$P_{MLE}={c(x) \\over \\sum_ec(e)}$$ 然而，由于观测数据不充足，很多事件 x 并没有在训练数据中出现，也就是 c(x)=0，PMLE=0，这是有问题的，没有在训练数据中出现的数据，并不代表不会在测试数据中出现，如果没有考虑到数据稀疏性，你的模型就太简单了！ 没有观测样本，怎样来预测呢？ 为什么要平滑？因为根据链式法则，联合概率是分概率的乘积。如果单个概率为0，会导致整体概率=0。所以必须要平滑。 NLP中哪些任务要平滑语言模型: ngram, nnlm机器翻译: ## Data sparsity 是 smoothing 的最大原因。Chen &amp; Goodman 在1998 年提到过，几乎所有数据稀疏的场景下，smoothing 都可以帮助提高 performance，而数据稀疏性几乎是所有统计模型(statistical modeling)都会遇到的问题。而如果你有足够多的训练数据，所有的 parameters 都可以在没有 smoothing 的情况下被准确的估计，那么你总是可以扩展模型，如原来是 bigram，没有数据稀疏，完全可以扩展到 trigram 来提高 performance，如果还没有出现稀疏，就再往高层推，当 parameters 越来越多的时候，数据稀疏再次成为了问题，这时候，用合适的平滑方法可以得到更准确的模型。实际上，无论有多少的数据，平滑几乎总是可以以很小的代价来提高 performance。 平滑方法 Additive smoothing Add-one smoothing- Good-Turing estimate Jelinek-Mercer smoothing (interpolation) Katz smoothing (backoff) Witten-Bell smoothing Absolute discounting Kneser-Ney smoothing Additive smoothing - 贝叶斯估计MLE estimate: $$P_{MLE}(w_i|w_{i-1})={c(w_{i-1}w_i) \\over c(w_{i-1})}$$ Additive smoothing: $$P_{Add-1}(w_i|w_{i-1})={c(w_{i-1}w_i)+\\delta \\over c(w_{i-1})+\\delta V}$$ 通常取值 $0 \\lt \\delta \\le 1$。 $\\delta=0$时就是极大似然估计。通常取$\\delta=1$，这时成为拉普拉斯平滑 （Laplace smoothing)，即假设每个词多出现了一次。 用极大似然估计可能会出现索要估计的概率值为0的情况。这时会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。 这样等价于拉普拉斯先验的贝叶斯估计。还是dir(delta)先验？ 参考 《统计学习方法 | 李航》 4.2.3 贝叶斯估计 - Katz smoothing (backoff)为什么叫backoff Katz backoff是一个经典的语言平滑模型，我们知道一般来说低阶模型出现的频率更高（低阶的元组包含在高阶元组中，阶数越高越稀疏），从而更加可靠，于是乎，未出现的高阶元组可以利用高阶元组中包含的低阶元组对其进行平滑。总之，高阶模型可靠时候便使用高阶模型，否则使用低阶模型。 差值(Interpolation) vs. 回退(backoff)扩展阅读 NLP 笔记 - 平滑方法(Smoothing)小结%E5%B0%8F%E7%BB%93/)","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-lm","slug":"ML/app/nlp/trick/trick-lm","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-lm/"}]},{"title":"python 命名空间、权限","date":"2018-09-26T03:16:31.463Z","path":"wiki/CS/programing/lan/-命名空间-模块-权限/","text":"测试12345678910111213141516171819class Test: def __init__(self): self._a = 1 self.__b = 2 # 内部会被重命名为_Test__b self.__c__ = 3 def print(self): print(self._a) print(self.__b) print(self.__c__) print('\\n')t = Test()t.print()t._a = 5t._Test__b = 6t.__c__ = 7t.print() ss public private需求 私有变量 私有方法 私有类 实现 - pythonPython中的成员函数和成员变量都是公开的(public),在python中没有类似public,private等关键词来修饰成员函数和成员变量。 在python中定义私有变量只需要在变量名或函数名前加上 ”__“两个下划线，那么这个函数或变量就是私有的了。在内部，python使用一种 name mangling 技术，将 __membername替换成 _classname__membername，也就是说，类的内部定义中, 私有变量: 实例._类名__变量名 私有方法: 实例._类名__方法名() 私有类: ssdfsd xx: 公有变量 _xx: 表示保护成员（属性或者方法），只有类对象和子类对象自己能访问到这些变量。 以单下划线开头的变量和函数被默认当作内部函数 使用from module improt *时不会被获取，但是使用import module可以获取 什么鬼设计 xx_: 在解析时并没有特别的含义，但通常用于和 Python 关键词区分开来，比如如果我们需要一个变量叫做 class，但 class 是 Python 的关键词，就可以以单下划线结尾写作 class_ __xxx: 表示私有成员 表示名字改编 (Name Mangling)，即如果有一 Test 类里有一成员 __x，那么 dir(Test) 时会看到 _Test__x 而非 __x。这是为了避免该成员的名称与子类中的名称冲突。但要注意这要求该名称末尾没有下划线。 __xxx__: 表示这是一个特殊成员 是一些 Python 的“魔术”对象，如类成员的 __init__、__del__、__add__、__getitem__、__call__ 等，以及全局的 __file__、__name__ 等。 Python 官方推荐永远不要将这样的命名方式应用于自己的变量或函数，而是按照文档说明来使用。 _: 作被丢弃的名称 实现 - Java实现 - C/C++扩展阅读 https://www.zhihu.com/question/19754941 https://segmentfault.com/a/1190000002611411","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"tensorflow中的动态维度","date":"2018-09-26T01:23:58.972Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-动态维度/","text":"123456789101112131415import tensorflow as tfsess = tf.Session()q = tf.placeholder(tf.float32, shape=(None, 1024))# 采用未知维度(None)，初始化tensordim_none = tf.shape(a)[0]p = tf.zeros([dim_none], tf.float32)# 采用未知维度(None)，初始化variablev = tf.Variable(tf.ones([dim_none,5])) # 这里会报错# runrand_array = np.random.rand(10, 1024)p_value = sess.run(p, feed_dict=&#123;q: rand_array&#125;)p_value.shape # (10, 1024)","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"切片操作 分片赋值","date":"2018-09-25T23:40:06.800Z","path":"wiki/CS/programing/lan/-切片操作/","text":"简介什么是切片赋值？ pythonpython为什么要设计分片赋值 Java C呢？tensorflowtensorflow中的tensor是一个整体，切片不能赋值。 示例123456import tensorflow as tfsess = tf.Session()a = [1,3,2,4,0,5]mask = tf.less(b,2)index = tf.squeeze() 如何实现切片赋值？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"NLU","date":"2018-09-25T01:52:50.692Z","path":"wiki/ML/app/nlp/app/-0 NLU/-NLU/","text":"Natural language understanding comprises a wide range of diverse tasks such 有监督任务 textual entailment, natural language inference, question answering semantic similarity document classification. 无监督任务 Improving Language Understanding by Generative Pre-Training。先无监督训练语言模型，再对每个task做fine tune。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"-0 NLU","slug":"ML/app/nlp/app/0-NLU","permalink":"http://yoursite.com/categories/ML/app/nlp/app/0-NLU/"}]},{"title":"","date":"2018-09-23T14:38:20.601Z","path":"wiki/others/politics/-苏联/2. 赫鲁晓夫/","text":"1954年访华 &lt;中苏大论战&gt; 赫鲁晓夫，全面否定斯大林。 毛泽东评价斯大林，37开，功大于过","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-苏联","slug":"others/politics/苏联","permalink":"http://yoursite.com/categories/others/politics/苏联/"}]},{"title":"","date":"2018-09-23T14:38:07.538Z","path":"wiki/others/politics/-苏联/1. 斯大林/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-苏联","slug":"others/politics/苏联","permalink":"http://yoursite.com/categories/others/politics/苏联/"}]},{"title":"","date":"2018-09-23T13:10:03.646Z","path":"wiki/others/politics/-苏联/戈尔巴乔夫/","text":"简介仁慈政治，不予人民开枪。 诺贝尔和平奖 与叶利钦冷战一手好牌，打得这么烂。 评价欧美眼中的戈尔巴乔夫共产主义的叛徒掘墓人 ## 戈尔巴乔夫是苏联的罪人，因为对敌人仁慈导致了苏联解体 不過蘇聯就是人類的毒瘤，所以戈氏功在全人類！ 苏联解体对中国、美国和欧洲都是好事 苏联垮台最大的受益者是中国 苏联前总统戈尔巴乔夫携孙女拍摄的必胜客披萨广告 https://www.bilibili.com/video/av7339398/ 戈尔巴樵夫: 有些人总是把摧毁苏联的责任全部推在我身上，但这不是事实。我尽力保存苏联到最后。是叶利钦在任总统的时候摧毁苏联的。 ，是叶利钦摧毁苏联的。 ##戈尔巴乔夫后的俄罗斯经济崩溃，国家经济被寡头和资本家窃取，百姓很多冬天付不起暖气费冻死。戈尔巴乔夫后来还继续选过总统，得了多少票？如果俄国人真喜欢他，他就后来怎么没被选为总统？ 扩展阅读 Gorbachev: The Great Dissident","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-苏联","slug":"others/politics/苏联","permalink":"http://yoursite.com/categories/others/politics/苏联/"}]},{"title":"苏联化","date":"2018-09-23T11:45:19.828Z","path":"wiki/others/politics/china/-苏联化/","text":"原子弹、工厂、炼钢都学苏联。电影也学苏联，凋敝 83年春晚，84年-99年， 陈佩斯的离开### 把春晚说成癌细胞，除了老陈也没谁了！异化出来的优秀细胞，吸收所有营养，破坏了市场秩序，造成很多人梦想、追求它。就要两级分化,不是因为高技术，是因为政府行为办艺术，超大艺术。中国文化的衰败就从这儿开始。明朝有一台晚会留下来的吗?不平等竞争 我谈不上支持，反正我没权利反对 站着活着的人，脱离春晚那个大粪坑，干净活着 体制内的限制，相声的发挥空间。2013郭德纲上春晚，不好笑。 谁能迎合它们后来的标准，谁就胜出了。（陈佩斯胜出，因为政府允许人民笑了。后面政府不需要这个了，能说别别的） 别看是个助理，你不敢惹，都是以爷自居。 你有更好的东西，它们永远给你关着门，理由让你苦笑不得。这样不就是限制艺人的发展吗 陈佩斯 - 大道戏剧院 - 《阳台》《托》- 干好10分钟的活，一年有饭吃。在生产上叫做不平等竞争，要杜绝这个。 政府行为半艺术 早就想走了，中和不了，双方很僵，变不了体质，就别抬杠，所以选择逃跑。 需要大量的实践活动，需要时间。因为有自己要做的事。认为自己没有一个完整的东西，需要梳理， 陈佩斯承包荒山，网传种石榴树","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"","date":"2018-09-23T11:33:20.795Z","path":"wiki/others/politics/china/人物/-江泽民/","text":"为什么6 4 美国人很关心，10年文革也没见这么关心？关于独裁 &amp;&amp; 民主华莱士: you will be the last dictator in the world?江: 什么是独裁？华: 举个例子，中国没有新闻自由，freedom of people，freedom of press。你们在怕什么？江: 不管哪个国家，哪个党，都有出版物来宣传自身的意识形态。中国是中共领导的多党制体系。我们有新闻自由华: n你封锁了互联网网站，BBC、washton news。你怕人们从网上看到什么？江: 某些政治新闻，我们希望限制对中国发展不利的新闻。 江: 我是独裁者吗？华: 美国有句话，走起来像鸭子，叫起来像鸭子，那就是鸭子。独裁者就是指强力禁止新闻自由、宗教自由，或民营经济的自由。江: 你这是天方夜谭，中国根据法律，党只会提议，一切都需要经过全国人大通过 华: 天安门前，一个青年挡在tank前，这就是独裁 A: 为民主而民主 不过是这些人的傲慢罢了。A: 民主是奢侈品，只有发达的社会才是可以使用的 A: 辛亏那时候没有让步妥协。就好像李光耀说的，经济发展，社会和谐，中产阶级扩大稳定是因，民主是果。西方民主在上个世纪的成功也是基于几百年殖民掠夺，经济飞速发展带来的果。美国民主最辉煌的时代也是其国力和经济实力最强大的时候，当任何一个民主国家经济衰退的时候，民主的弱点就暴露出来了，结果就是保护主义，民粹主义的抬头，希特勒就是很好的一个例子。 A: 現在中國大陸已經到了可以開始民主的階段了， 中國大陸已經世界第二大經濟體， 但國富民窮。 如果共產黨的勢力再壯大， 那麼中國將要再次重蹈蘇聯的覆轍。 希望中共識得大體， 著手開始民主改革， 開放黨禁。 這才是現在中國的工作核心 ## 华: 你从来没在中国的武装部队服役过，一个从来没有在不对服役的人，你是军委主席，一直严厉控制军队江: 我确实没在部队服役过，因为我是一个知识分子，华: 美国，知识分子也在部队服役江: 我任军委主席十一年了，我对管理军队有自信 华: 两年前，你规定军队不允许经商，为什么？因为那会腐蚀军队，历史教导我们任何从商的军队最终走向腐败 华: 你过去是一个学生示威者，在上海。在国民党时代，we want freedom，we want democracy。那些在天安门广场上的人也这样呼吁的， 宗教华: 你迫害了法轮功，你虐待、逮捕、杀害法轮功信徒，为什么？江: 你信法轮功吗？华: 我了解不够 (故意回避)江: 李洪志 自称是释迦摩尼转世，也是基督耶稣的化身，你信吗？他说世界末日将要来临，地球将会爆炸。他说我和李鹏总理致电给他来推迟地球爆炸的日子，大概几十年吧。法轮功让很多人受害，我们认为法轮功是邪教 些人2002年将会卸任，会卸任三个title中的哪个？ ## A: 中国那么好，请问最“爱国“的红二代，官二代为什么要移民，而且还是移民到万恶的西方国家，他们不是天天教育我们西方很烂很坏，中国很好很强大吗？还是中国其实就是一坨屎！是给人民吃的！党的后代要到西方吃有营养的，","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"ASR 评价指标","date":"2018-09-21T09:56:39.820Z","path":"wiki/-audio/ASR/metric/","text":"CER (Character Error Rate) WER (Word Error Rate)","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"}]},{"title":"d-softmax *","date":"2018-09-21T05:10:36.067Z","path":"wiki/-language_model/-model/nnlm/trick/d-softmax-star/","text":"Efficient softmax approximation for GPUs, 2016","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"},{"name":"nnlm","slug":"language-model/model/nnlm","permalink":"http://yoursite.com/categories/language-model/model/nnlm/"},{"name":"trick","slug":"language-model/model/nnlm/trick","permalink":"http://yoursite.com/categories/language-model/model/nnlm/trick/"}]},{"title":"d-softmax","date":"2018-09-21T05:10:27.810Z","path":"wiki/-language_model/-model/nnlm/trick/d-softmax/","text":"Strategies for Training Large Vocabulary Neural Language Models 2015","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"},{"name":"nnlm","slug":"language-model/model/nnlm","permalink":"http://yoursite.com/categories/language-model/model/nnlm/"},{"name":"trick","slug":"language-model/model/nnlm/trick","permalink":"http://yoursite.com/categories/language-model/model/nnlm/trick/"}]},{"title":"","date":"2018-09-20T02:27:09.634Z","path":"wiki/-audio/ASR/声学模型/NIN/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"CLDNN","date":"2018-09-20T02:26:37.445Z","path":"wiki/-audio/ASR/声学模型/CLDNN/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"","date":"2018-09-20T01:36:18.659Z","path":"wiki/CS/programing/lan/java/关键字/-Synthetic/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"关键字","slug":"CS/programing/lan/java/关键字","permalink":"http://yoursite.com/categories/CS/programing/lan/java/关键字/"}]},{"title":"IO对比","date":"2018-09-20T01:07:46.908Z","path":"wiki/CS/programing/lan/-IO/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"神经网络的模型复杂度（时间复杂度、空间复杂度）","date":"2018-09-19T09:17:12.202Z","path":"wiki/ML/deep learning/-复杂度/","text":"存储量：模型所占的存储 + 一个batch的训练数据占用的存储。类似空间复杂度 计算量: 计算量的单位是flop，也就是一个乘法和加法，例如计算两个n维向量的内积一共就需要n个flops。类似时间复杂度 所以通过这两个维度就可以大致估计模型训练所耗费的资源了。 常见模型的计算量见 https://juejin.im/post/5ae283c4f265da0b886d2323 算力GPU的算力挖矿算力扩展阅读- 常见模型的网络结构 以及运算量 https://cwlacewe.github.io/netscope/quickstart.html","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"}]},{"title":"传值、传引用、传参","date":"2018-09-19T07:05:54.640Z","path":"wiki/CS/programing/lan/-PassByValue/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"string","date":"2018-09-19T07:01:37.944Z","path":"wiki/CS/programing/lan/-string/","text":"Java C/C++python","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"解析解","date":"2018-09-19T02:26:12.066Z","path":"wiki/Math/-代数/-解析解/","text":"背景知识 解析表达式 有限次常见运算 解析解解析解，又称为闭式解，是可以用解析表达式来表达的解。 在数学上，如果一个方程或者方程组存在的某些解，是由有限次常见运算的组合给出的形式，则称该方程存在解析解。二次方程的根就是一个解析解的典型例子。在低年级数学的教学当中，解析解也被称为公式解。 当解析解不存在时，比如五次以及更高次的代数方程，则该方程只能用数值分析的方法求解近似值。大多数偏微分方程，尤其是非线性偏微分方程，都只有数值解。 解析表达式的准确含义依赖于何种运算称为常见运算或常见函数。传统上，只有初等函数被看作常见函数（由于初等函数的运算总是获得初等函数，因此初等函数的运算集合具有闭包性质，所以又称此种解为闭式解），无穷级数、序列的极限、连分数等都不被看作常见函数。按这种定义，许多累积分布函数无法写成解析表达式。但如果把特殊函数，比如误差函数或gamma函数也看作常见函数，则累积分布函数可以写成解析表达式。 在计算机应用中，这些特殊函数因为大多有现成的数值法实现，它们通常被看作常见运算或常见函数。实际上，在计算机的计算过程中，多数基本函数都是用数值法计算的，所以所谓的基本函数和特殊函数对计算机而言并无区别。 非解析解非解析解的弊端","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-代数","slug":"Math/代数","permalink":"http://yoursite.com/categories/Math/代数/"}]},{"title":"","date":"2018-09-18T07:51:35.351Z","path":"wiki/CS/-distributed-system/Consensus一致性/Paxos/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-distributed-system","slug":"CS/distributed-system","permalink":"http://yoursite.com/categories/CS/distributed-system/"},{"name":"Consensus一致性","slug":"CS/distributed-system/Consensus一致性","permalink":"http://yoursite.com/categories/CS/distributed-system/Consensus一致性/"}]},{"title":"raft算法","date":"2018-09-18T07:47:05.389Z","path":"wiki/CS/-distributed-system/Consensus一致性/raft/","text":"Paxos和Raft都是为了实现Consensus一致性这个目标，这个过程如同选举一样，参选者需要说服大多数选民(服务器)投票给他，一旦选定后就跟随其操作。 Paxos和Raft的区别在于选举的具体过程不同。在Raft中，任何时候一个服务器可以扮演下面角色之一： Leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader. Follower: 类似选民，完全被动 Candidate候选人: 类似Proposer律师，可以被选为一个新的领导人。 Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性： 强领导者：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。 领导选举：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。 关系调整：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法中，两种不同的配置都要求的大多数机器会重叠。这就使得集群在成员变换的时候依然可以继续工作。 Raft的优势 更简单，更容易理解 Paxos算法的问题在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。 不幸的是，Paxos 有两个明显的缺点。 问题一：难以理解Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。 我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。 问题二：Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。 扩展阅读 raft paper: In Search of an Understandable Consensus Algorithm 翻译 raft demo: http://thesecretlivesofdata.com/raft/ raft demo: https://raft.github.io/","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-distributed-system","slug":"CS/distributed-system","permalink":"http://yoursite.com/categories/CS/distributed-system/"},{"name":"Consensus一致性","slug":"CS/distributed-system/Consensus一致性","permalink":"http://yoursite.com/categories/CS/distributed-system/Consensus一致性/"}]},{"title":"","date":"2018-09-18T06:19:54.995Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/Insertion sort/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"","date":"2018-09-18T06:13:04.373Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/mergesort/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"","date":"2018-09-18T06:12:33.538Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/priority-queue/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"快排","date":"2018-09-18T06:12:19.099Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/quicksort/","text":"探索分⽽治之（divide and conquer，D&amp;C）——⼀种著名的递归式问题解决⽅法。 只能解决⼀种问题的算法毕竟⽤处有限，⽽D&amp;C提供了解决问题的思路。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"","date":"2018-09-18T03:39:11.747Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash-table/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"}]},{"title":"","date":"2018-09-18T03:38:18.856Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/balanced-search-trees/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"}]},{"title":"","date":"2018-09-18T03:38:06.391Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/symbol-tables/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"}]},{"title":"","date":"2018-09-18T03:37:54.086Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/binary-search-trees/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"}]},{"title":"二分查找","date":"2018-09-18T03:37:34.029Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/binary-search/","text":"仅当列表是有序的时候，⼆分查找才管⽤。例如电话簿中的名字是按字母顺序排序的。 如果名字不是按顺序排列的，结果将 ⼆分查找。使⽤它可节省多少时间呢？ 简单查找逐个地检查数字，如果列表包含100个数字，最多需要猜100次。如果列表包含40亿个数字，最多需要猜40亿次。换⾔之，最多需要猜测的次数与列表长度相同，这被称为线性时间（linear time）。⼆分查找则不同。如果列表包含100个元素，最多要猜7次；如果列表包含40亿个数字，最多需猜32次。厉害吧？⼆分查找的运⾏时间为对数时间（或log时间）。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"}]},{"title":"高斯 多维高斯 混合高斯GMM","date":"2018-09-17T01:44:37.515Z","path":"wiki/Math/-概率论与数理统计/-gaussian/","text":"高斯若随机变量X服从一个数学期望为$\\mu$，标准方差为$\\delta^2$的高斯分布，记为: $N\\sim(\\mu,\\delta^2)$。则概率密度函数： 正太分布的期望值$\\mu$决定了其位置，标准方差$\\delta^2$决定了其幅度。标准正太分布是$\\mu = 0$，$\\delta = 1$。如下图所示： 多维高斯多维单高斯是如何由一维单高斯发展而来的呢？首先我们一维正太分布单高斯可以表示如下：布单高斯可以表示如下：","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"}]},{"title":"递归","date":"2018-09-15T16:00:00.000Z","path":"wiki/CS/programing/algorithm-数据结构与算法/递归/","text":"递归递归是⼀种优雅的问题解决⽅法，是一种分⽽治之(divide and conquer，D&amp;C)的⽅法。递归，就是函数调⽤⾃⼰。 递归的核心思想 就是：把问题分解成规模更小，但和原问题有着相同解法的问题。 ## 编写递归函数时，必须告诉它何时停⽌递归。正因为如此，每个递归函数都有两部分： 基线条件（base case）: 函数调⽤⾃⼰的条件 递归条件（recursive case）: 函数不再调⽤⾃⼰的条件，从⽽避免形成⽆限循环。 其中有一个基础的编程概念 - 调⽤栈（call stack）。调⽤栈不仅对编程来说很重要，使⽤递归时也必须理解这个概念 示例 - 求阶乘 压栈: x==1之前，压了三个函数栈，但一个都没调用结束 出栈: x==1后，从栈顶开始出栈 使⽤栈虽然很⽅便，但是也要付出代价：存储详尽的信息可能占⽤⼤量的内存。每个函数调⽤都要占⽤⼀定的内存，如果栈很⾼，就意味着计算机存储了⼤量函数调⽤的信息。在这种情况下，你有两种选择。 重新编写代码，转⽽使⽤循环。 使⽤尾递归。这是⼀个⾼级递归主题，不在本书的讨论范围内。另外，并⾮所有的语⾔都⽀持尾递归。 练习 假设你编写了⼀个递归函数，但不⼩⼼导致它没完没了地运⾏。正如你看到的，对于每次函数调⽤，计算机都将为其在栈中分配内存。递归函数没完没了地运⾏时，将给栈带来什么影响？ #### ⼩结 递归指的是调⽤⾃⼰的函数。 每个递归函数都有两个条件：基线条件和递归条件。 栈有两种操作：压⼊和弹出。 所有函数调⽤都进⼊调⽤栈。 调⽤栈可能很长，这将占⽤⼤量的内存 递归转循环递归转尾递归比如维特比算法+ 有些简单的递归问题，可以不借助堆栈结构而改成循环的非递归问题。 递归的应用维特比算法见 。。 快排见 。。 RNN、LSTM递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。 扩展阅读 为什么说递归效率低？ | 知乎 漫谈递归转非递归 | cnblog","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"}]},{"title":"control flow","date":"2018-09-15T16:00:00.000Z","path":"wiki/CS/programing/lan/-control-flow/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"python c java 的变量、堆、栈","date":"2018-09-15T16:00:00.000Z","path":"wiki/CS/programing/lan/variable/","text":"背景知识 栈: 是向低地址扩展的数据结构，是一块连续的内存区域。 栈顶的地址和栈的最大容量是系统预先规定好的，在 WINDOWS 下，栈的大小是 2M （也有的说是 1M ，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示 overflow 。因此，能从栈获得的空间较小。 由系统自动分配，速度较快。但程序员是无法控制的 堆：是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。 堆是由 new 分配的内存，一般速度比较慢，而且容易产生内存碎片 , 不过用起来最方便 。 变量 二进制存储，数值在内存中的表示- many languages have “variables”计算机内存就像是很多盒子的集合体，每个盒子都有地址。在很多语言中，给变量赋值可以理解成把value放入盒子，比如： int a = 1; a = 2; 只是替换了盒子里的内容。 int b = a; C - 面向过程 运行时，首先系统为整个函数栈预分配空间(一块连续的内存区域)，栈上存储该函数的局部变量。即变量a对应固定的盒子(地址)。 执行 int a = 1 即把数值1放入a对应的盒子 执行 a = 2 替换了a盒子里的内容 C++ - 半面向对象Java 不完全 面向对象 Java中的原始类型 primitive type，与C语言类似，变量对应盒子 运行 int a = 1，存储在栈中 运行 a = 2， class，与python类似，变量 运行 Integer b = 1，存储在栈中还是堆中？貌似有个Integer池，预分配好的。 运行 Integer c = 1000，会new 一个Integer Object，并存储在堆中 疑问 java不预分配函数栈空间吗？ java中为什么是frames和objects？为什么不是stack heap？ java中的原始类型，与class类型 python - 面向对象python has “names” python中一切皆对象，a=1，a是PyIntObject的对象，存储在堆中 python has “names”，指的是python的变量都是代号(盒子中存的是地址，而不是value)。 a=2，是把a指向了对象2 疑问 python中是frame的概念，不是stack。why？ javascript扩展阅读 code like a pythonista: idiomatic python http://pythontutor.com","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"","date":"2018-09-15T13:59:45.220Z","path":"wiki/-audio/声纹识别/GMM+SVM/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-15T13:59:33.251Z","path":"wiki/-audio/声纹识别/ivector+PLDA/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-15T13:59:17.025Z","path":"wiki/-audio/前端信号处理/特征/BNF/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"},{"name":"特征","slug":"audio/前端信号处理/特征","permalink":"http://yoursite.com/categories/audio/前端信号处理/特征/"}]},{"title":"","date":"2018-09-15T13:58:02.888Z","path":"wiki/-audio/声纹识别/ivevtor-plda/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-15T13:56:33.663Z","path":"wiki/-audio/声纹识别/Supervised-UBM i-vector/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-15T13:56:18.731Z","path":"wiki/-audio/声纹识别/GMM-UBM i-vector/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-15T13:56:03.868Z","path":"wiki/-audio/声纹识别/JFA/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-15T13:54:20.672Z","path":"wiki/-audio/前端信号处理/特征/PLP/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"},{"name":"特征","slug":"audio/前端信号处理/特征","permalink":"http://yoursite.com/categories/audio/前端信号处理/特征/"}]},{"title":"","date":"2018-09-15T13:50:45.167Z","path":"wiki/-audio/前端信号处理/特征/FBank/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"},{"name":"特征","slug":"audio/前端信号处理/特征","permalink":"http://yoursite.com/categories/audio/前端信号处理/特征/"}]},{"title":"","date":"2018-09-14T08:56:37.069Z","path":"wiki/-audio/声纹识别/deep speaker/","text":"fft之后的特征，直接end-to-end deep speaker，每帧一个网络，","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-14T08:56:03.084Z","path":"wiki/-audio/声纹识别/d-vector/","text":"D-vector (谷歌2014年提的）","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-14T08:19:16.325Z","path":"wiki/-audio/声纹识别/GMM-UBM/","text":"注册只有几十秒特征，GMM来拟合很难，所以提出来GMM-UBM。 UBM是用一大堆人的。是一个大的GMM， 声纹识别，M会取很大。ASR中一般采用 8，16。因为UBM是要建模所有人的，ASR只是mixture mu是mfccmix=39256 只用均值就够了，sigma， log(gmm)-log(ubm)进行打分。没考虑，，，所以用svm。 s=","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-09-03T04:26:20.134Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-工业化/并行-多机多卡/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-工业化","slug":"ML/deep-learning/toolbox/tensorflow/工业化","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/工业化/"}]},{"title":"","date":"2018-09-03T02:21:38.259Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-工业化/并行-多卡-多进程-horovod/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-工业化","slug":"ML/deep-learning/toolbox/tensorflow/工业化","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/工业化/"}]},{"title":"tensorflow的多GPU并行","date":"2018-09-03T02:21:23.369Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-工业化/并行-多卡-单进程/","text":"A single host with one CPU; A single host with multiple GPUs; Multiple hosts with CPU or multiple GPUs; 见multi-gpu项目 TF gpu基本操作、参数简单计算实例二: cifar10 数据并行处理、梯度并行计算 梯度合成 loss合成1. average_gradients，不同GPU计算梯度合成。 核心代码 123456789101112131415161718192021222324252627for i in xrange(FLAGS.num_gpus): with tf.device('/gpu:%d' % i): with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope: # 为每个GPU分配不同batch的数据 image_batch, label_batch = batch_queue.dequeue() # Calculate the loss for one tower of the CIFAR model. This function # constructs the entire CIFAR model but shares the variables across # all towers. loss = tower_loss(scope, image_batch, label_batch) # Reuse variables for the next tower. tf.get_variable_scope().reuse_variables() # Retain the summaries from the final tower. summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope) # Calculate the gradients for the batch of data on this CIFAR tower. grads = opt.compute_gradients(loss) # Keep track of the gradients across all towers. tower_grads.append(grads)# 多个GPU的并行，# We must calculate the mean of each gradient. Note that this is the# synchronization point across all towers.# 同步是怎样做的？grads = average_gradients(tower_grads) 疑问，什么时候进行的同步？ 实例三: tensor2tensor的多卡并行https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/devices.py#L61 数据分配、计算资源分配参考 tensorflow multi-gpu |官方教程 - 中文翻译 cifar10 tutorial https://www.jianshu.com/p/c6745aaac2f1","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-工业化","slug":"ML/deep-learning/toolbox/tensorflow/工业化","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/工业化/"}]},{"title":"","date":"2018-09-03T02:19:19.575Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-工业化/tf-分布式-集群/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-工业化","slug":"ML/deep-learning/toolbox/tensorflow/工业化","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/工业化/"}]},{"title":"比特币 - 交易池","date":"2018-09-01T13:35:21.846Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-txmempool/","text":"我们知道当交易被广播并且被矿工接收到时，矿工就会把交易加入到本地的交易池当中，每个矿工又会对自己的交易池设置相应的限制，来保证交易数量不会过多，矿工在打包交易到区块中时，也会根据一定的优先顺序来选择交易，从而让自己能获得尽量多的交易费。 对于交易池主要介绍两个结构CTxMemPoolEntry和CTxMemPool，第一个是交易池中每一个元素的基本结构，第二个是整个交易池包含的所有信息。 CTxMemPoolEntryCTxMemPoolEntry存储交易和该交易的所有子孙交易，当一个新的entry添加到mempool中时，我们更新它的所有子孙状态和祖先状态 txmempool.h 123456789101112131415161718192021222324class CTxMemPoolEntry&#123;private: CTransactionRef tx; // 交易引用 CAmount nFee; // Cached to avoid expensive parent-transaction lookups size_t nTxWeight; // avoid recomputing tx weight (also used for GetTxSize()) size_t nUsageSize; // total memory usage int64_t nTime; // Local time when entering the mempool unsigned int entryHeight; // Chain height when entering the mempool bool spendsCoinbase; // 前一个交易是否是CoinBase int64_t sigOpCost; // Total sigop cost int64_t feeDelta; // 调整交易的优先级 LockPoints lockPoints; // 交易最后的所在区块高度和打包的时间 // 子节点交易信息，如果我们移除一个交易，必须同时移除它的所有后续交易 uint64_t nCountWithDescendants; // 子孙交易的数量 uint64_t nSizeWithDescendants; CAmount nModFeesWithDescendants; // 费用和，包括当前交易 // Analogous statistics for ancestor transactions uint64_t nCountWithAncestors; uint64_t nSizeWithAncestors; CAmount nModFeesWithAncestors; int64_t nSigOpCostWithAncestors; CTxMemPool交易内存池，保存所有在当前主链上有效的交易。当交易在网络上广播之后，就会被加进交易池。 但并不是所有的交易都会被加入，例如交易费太小的，或者“双花”的交易或者非标准交易。内存池中通过一个boost::multi_index类型的变量mapTx来排序所有交易，按照下面四个标准： -交易hash-交易费（包括所有子孙交易）-在mempool中的时间-挖矿分数 为了保证交易费的正确性，当新交易被加进mempool时，我们必须更新该交易的所有祖先交易信息，而这个操作可能会导致处理速度变慢，所以必须对更需祖先的数量进行限制。 1234567891011121314class CTxMemPool&#123;private: uint32_t nCheckFrequency GUARDED_BY(cs); // 表示在2^32时间内检查的次数 unsigned int nTransactionsUpdated; //!&lt; Used by getblocktemplate to trigger CreateNewBlock() invocation CBlockPolicyEstimator* minerPolicyEstimator; uint64_t totalTxSize; // 所有mempool中交易的虚拟大小，不包括见证数据 uint64_t cachedInnerUsage; // map中元素使用的动态内存大小之和 mutable int64_t lastRollingFeeUpdate; mutable bool blockSinceLastRollingFeeBump; mutable double rollingMinimumFeeRate; // 进入pool需要的最小费用，指数级下降&#125; 交易移除123456789101112/** Reason why a transaction was removed from the mempool, * this is passed to the notification signal. */enum class MemPoolRemovalReason &#123; UNKNOWN = 0, //! Manually removed or unknown reason EXPIRY, //! Expired from mempool SIZELIMIT, //! Removed in size limiting REORG, //! Removed for reorganization BLOCK, //! Removed for block CONFLICT, //! Removed for conflict with in-block transaction REPLACED //! Removed for replacement&#125;; 疑问权重比较低的交易，存储在本地内存交易池中(Local Memory Tx Pool), 这种尚未被加入block chain的，就没被分布式账本记录？容易被篡改？为什么叫内存池？只在局部节点？不在 参考 https://blog.csdn.net/pure_lady/article/details/77776716","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"","date":"2018-09-01T13:25:48.152Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-挖矿原理-概述/","text":"每个比特币客户端节点自加入比特币网络开始，无时不刻不在做着创造新区块的操作； 而创造新区块的过程，即是打包每一笔“比特币交易”的过程；","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"区块链“分叉”的产生“ & ”BestChain选择准则","date":"2018-09-01T13:08:03.057Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-分叉/","text":"“分叉”现象的产生非人为“分叉”的产生原因所谓“挖矿”，是计算一个HASH值&lt;=TargetHash的过程； 而符合计算规则的结果Hash有很多个，所以会出现同时好多个“矿工”同一时段（考虑到网络延迟）宣布“挖矿”成功； 所以，同一区块高度会出现多个区块的时候，由此就产生了区块链的Fork,也就是“分叉”现象。（插一句，这就是为什么中本聪要规定均值10分钟产生一个区块，为的就是降低碰撞的频次，减少fork次数）； 人为“分叉”的产生原因这种人为分叉，要从区块链的共识机制说起。 区块链是由点对点的去中心化节点共同维护的，区块链的有序运转靠的就是大家的共识； 即对于哪些交易是可以接受的、哪些节点具有记账权等关键事宜，有一套公认的标准。 这套标准是部署在区块链底层协议中自动化执行的。 当不同节点运行的底层标准（即客户端软件版本不一致）不一致的时候，人为分叉自然而然就产生了。 PS：为什么会出现不同的客户端软件版本不一致呢？主要原因有以下几种 利益原因：不同的矿工因为利益关系，矿工个体本身有选择性的接受或者不接受新的升级版本 不接受新版本，挖到的新矿就在某个分支上。如果算力过硬，该分支有可能取代其他分支，作为主链。 时延原因：不可能所有的客户端在同一时刻同时升级，即使所有节点都同意升级并立刻升级，也会有时延 区块链网络节点可自由动态加入或者离线，离线的那部分节点会感知不到升级，等再次入局升级的时候，这中间会有一段时间。 “分叉”之后，最佳链（bestChain）的选择准则？那么，要保证区块链的MainChain唯一性，当出现多处分叉的时候，该用什么准则去选择最佳链（select the bestChain as mainChain）呢？ 如果不同分支的区块高度不同，那么选择最长区块高度的分支为MainChain（在POW共识机制下，最长工作量代表着最权威的说服力）； 如果高度一致，则选择难度系数最大的分支为MainChain（在POW共识机制下，difficulty越大，则说明该区块被创造所需要的工作量越大，则权威说服力越大）； 区块高度如果相同，并且难度系数也一样，那么选择接受时间最早的那个分支为MainChain； 若所有的评判系数均相同，则等待各自某分支的区块高度+1之后，重新重复上述1~3步骤选择出一个BestChain。 软分叉 VS 硬分叉比特币网络正常运行出现的“分叉”，是非人为干扰的系统“自分叉”，系统的筛选逻辑可解决该种分叉； 所以，也会存在人为“分叉”，人为“分叉”分为：软分叉和硬分叉； 硬分叉指的是改变了比特币底层协议，使得之前被验证无效的区块变得有效，而为了保持兼容性，会强制要求所有节点都更新协议版本至最新。（一句话就是：凡是霸王手段耍流氓式的要求所有节点必须升级，否则运行机制不兼容影响新生成区块和交易验证的分叉都是硬分叉） 软分叉指的是虽然改变了比特币底层协议，但是只会使之前被验证有效的区块变的无效，而且即使节点不升级（虽然官方WIKI是这么描述的，但是是有具体的实施机制的，下文中会详细说明，暂不提），也不会影响新生成区块和交易被验证接受。软分叉是“向后兼容”的。 参考 https://www.jianshu.com/p/ec7ee2bb1697","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"","date":"2018-09-01T12:47:13.350Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-hash-挖矿成功/","text":"通俗地讲，“挖矿”即生成新区块的本质是：做一系列的哈希运算，当运算得到的哈希值符合目标规则，即为挖矿成功（其实，就是寻找符合条件的Nonce参数的过程，下文会详细解释，此处记住这个概念即可）。 也就是比较俩数值的大小，target目标值（固定）与哈希计算值（矿工每次计算算出来的值），这两个值的计算公式是什么呢？ 如下图，为区块头（header）结构，结合着图示，介绍下挖矿的原理。 这里直介绍两个关键信息： 1）难度系数：difficulty参数，顾名思义用来调节生成区块的难度的。该值决定了target的大小， 公式为：target=2**（256-Difficulty） 中本聪希望生成每个区块需要耗时10分钟，但是实际情况往往多变，生成区块（算出target）的时间有可能远小于十分钟（difficulty偏下）或者远大于十分钟（difficulty偏大）； 那么在每2016【2016=14（day）24（hour）60（min）/10(min）】个区块生成完毕之后，系统要自动调节difficulty参数大小； 调整公式为：New Difficulty= Old Difficulty*（最新的2016区块实际耗时/ 20160 minutes）.即：最新2016个区块花费时长与20160分钟（20160分钟是2016个区块期望的产出时间）比较所得。 2）随机数：Nonce参数，也可以理解为POW工作量证明的计数器； 该字段是最重要的一个字段，因为其实“挖矿”的过程就是寻找符合条件的Nonce值的过程；我们知道“挖矿”是做一些列的哈希计算的过程，该过程为：对区块头和nonce进行哈希运算【sha256(str(header)+str(nonce))】；如果本次所得的哈希值&lt;=target，则“挖矿”成功；反之，Nonce+1，重复上述过程； PS： 1）Nonce叫“随机数”的原因是因为原则上每次计算当前Nonce值可以随机产生。但是，实际情况下：什么方式最容易计算出目标值呢？穷举法；所以每次计算Nonce从0开始；计算Hash值是否&lt;=targetHash; 如果本次所得的哈希值&lt;=target，则“挖矿”成功；反之，Nonce+1，重复计算过程； 2）为什么说“挖矿”这么难呢？（上文中说的target值符合特定的规则：十六进制的以连续0开头，且连续的0越多越能符合命中规则） 打个比方：当前target值为连续20个0开头的十六进制数字； 一个不透明的口袋里有俩形状一模一样的乒乓球，一个红色（1），一个蓝色（0）；每次抓阄抓到蓝色则标记位0，红色标记位1，那么如果矿工想要“挖矿”成功，意味着：至少连续20次抓阄均抓到篮球。是不是瞬间觉得很难呢？ 如果连续2016个区块的生成时间小于期望的20160分钟，系统会自动调节Difficulty系数，比如调节Difficulty系数之后，target变成了连续21个0开头的十六进制数字，此时，矿工想要挖矿成功，则需要连续21次抓到篮球，生成时间就会相对变长。是不是更难了呢？ 如果连续2016个区块的生成时间大于期望的20160分钟，则调低难度系数。 参考 https://www.jianshu.com/p/07274c3de3e6","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"","date":"2018-09-01T11:49:46.297Z","path":"wiki/CS/programing/lan/java/-java8/","text":"Java 8 引入了新的语言特性——默认方法（Default Methods）。 默认方法允许您添加新的功能到现有库的接口中，并能确保与采用旧版本接口编写的代码的二进制兼容性。 为什么要有默认方法简单说，就是接口可以有实现方法，而且不需要实现类去实现其方法。只需在方法名前面加个default关键字即可。 为什么要有这个特性？首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类，目前的java 8之前的集合框架没有foreach方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。 参考https://my.oschina.net/benhaile/blog/176007","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"}]},{"title":"【比特币源码】交易 transaction","date":"2018-09-01T09:40:53.227Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/primitive/transaction/","text":"名词 术语 交易: 简单地说，交易指把⽐特币从⼀个地址转到另⼀个地址。更准确地说，⼀笔“交易”指⼀个经过签名运算的，表达价值转移的数据结构。每⼀笔“交易”都经过⽐特币⽹络传输，由矿⼯节点收集并封包⾄区块中，永久保存在区块链某处。 交易验证: 被验证成功的交易放入本地内存交易池中（Local Memory Tx Pool，交易池是存储在本地内存中，并不是存储在硬盘里，因此不同节点的两池内容可能有很大差别。原则是，要保证任何在本地内存交易池中的交易均是未确认的。 交易确认: 当⼀项交易被区块收录时，我们可以说它有⼀次确认。矿⼯们在此区块之后每再产⽣⼀个区块，此项交易的确认数就再加⼀。当确认数达到六及以上时，通常认为这笔交易⽐较安全并难以逆转。 确认数+1什么意思？ 交易权重: 挨个打包进入到区块体中；优先处理权重最高的交易；偶尔会出现提示：”当前网路交易拥堵，建议提高交易费用”。正是因为按照优先级处理，所以在网络交易拥堵的时候，有可能造成低优先级的交易“永远”不会被打包。交易的权重大小取决于三个因素：1）交易创建时间越早；2）交易UTXO大小越大；3）交易费用越高，则权重越大。 ⼯作量证明: ⼯作量证明指通过有效计算得到的⼀⼩块数据。具体到⽐特币，矿⼯必须要在满⾜全⽹⽬标难度的情况下求解SHA256算法 难度: 整个⽹络会通过调整“难度”这个变量来控制⽣成⼯作量证明所需要的计算⼒。难度怎样调整的，见。。 难度⽬标: 使整个⽹络的计算⼒⼤致每10分钟产⽣⼀个区块所需要的难度数值即为难度⽬标。 难度调整: 整个⽹络每产⽣2,106个区块后会根据之前2,106个区块的算⼒进⾏难度调整。 ss⽐特币交易是⽐特币系统中最重要的部分。根据⽐特币系统的设计原理，系统中任何其他的部分都是为了确保⽐特币交易可以被⽣成、能在⽐特币⽹络中得以传播和通过验证，并最终添加⼊全球⽐特币交易总账簿（⽐特币区块链）。⽐特币交易的本质是数据结构，这些数据结构中含有⽐特币交易参与者价值转移的相关信息。⽐特币区块链是全球复式记账总账簿，每个⽐特币交易都是在⽐特币区块链上的⼀个公开记录。 比特币“交易打包”底层原理“挖矿”与“交易打包”前文我们说到，所谓“挖矿”，就是生成一个最新“区块”的过程，“矿工”在该过程中，是为了获取比特币的奖励（经济驱动）； 这部分奖励分为两部分：比特币网络系统的CoinBase奖励 和 所打包的所有交易的交易费（交易费的作用下文会介绍）； 那么，交易打包的过程和底层原理是什么呢？下文我们将图文展示整个交易打包的细节； “交易打包”过程？每个比特币客户端节点自加入比特币网络开始，无时不刻不在做着创造新区块的操作； 而创造新区块的过程，即是打包每一笔“比特币交易”的过程； 下图是站在“比特币客户端节点”的角度，来描述一次区块生成过程中的交易打包过程。 源码primitives/transaction.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** The basic transaction that is broadcasted on the network and contained in * blocks. A transaction can contain multiple inputs and outputs. */class CTransaction&#123;public: // 以下变量采用常量，为了避免无意的改动 const std::vector&lt;CTxIn&gt; vin; const std::vector&lt;CTxOut&gt; vout; const int32_t nVersion; const uint32_t nLockTime; // ...&#125;;class COutPoint&#123;public: uint256 hash; uint32_t n; // ...&#125;/** An input of a transaction. It contains the location of the previous * transaction's output that it claims and a signature that matches the * output's public key. */class CTxIn&#123;public: COutPoint prevout; CScript scriptSig; uint32_t nSequence; CScriptWitness scriptWitness; //! Only serialized through CTransaction static const uint32_t SEQUENCE_FINAL = 0xffffffff; static const uint32_t SEQUENCE_LOCKTIME_DISABLE_FLAG = (1 &lt;&lt; 31); static const uint32_t SEQUENCE_LOCKTIME_TYPE_FLAG = (1 &lt;&lt; 22); static const uint32_t SEQUENCE_LOCKTIME_MASK = 0x0000ffff; static const int SEQUENCE_LOCKTIME_GRANULARITY = 9;&#125;/** An output of a transaction. It contains the public key that the next input * must be able to sign with to claim it. */class CTxOut&#123;public: CAmount nValue; CScript scriptPubKey&#125;// 可变交易是干嘛用的？交易还能撤销？更改？回退？struct CMutableTransaction&#123; std::vector&lt;CTxIn&gt; vin; std::vector&lt;CTxOut&gt; vout; int32_t nVersion; uint32_t nLockTime;&#125; 12345678910111213┌─────────────────────────────────────────────┐│Tx: 12af...e85d │├─────────────────────┬───────────────────────┤│TxIn │TxOut │├─────────────┬───────┼──────┬────────────────┤│prev hash │index │btc │pkScript │├─────────────┼───────┼──────┼────────────────┤│0000...0000 │ffff │12.5 │OP_DUP c58a... │├─────────────┼───────┼──────┼────────────────┤│2016...a3c5 │3 │0.15 │OP_DUP a1b2... │├─────────────┼───────┼──────┼────────────────┤│2015...b6d8 │1 │0.08 │OP_DUP c3d4... │└─────────────┴───────┴──────┴────────────────┘ 除了第一笔交易是矿工的挖矿所得外，每一笔交易都拥有一个或多个输入（TxIn），以及一个或多个输出（TxOut）。 第一笔矿工挖矿的收入交易通常被称为Coinbase，它没有输入，所以TxIn的Hash总是被标记为00000000...0000其他的交易，任何一个TxIn都会唯一追溯到区块链上在本区块之前的某个交易Hash，以及索引。 通过交易Hash和索引（从0开始），即可唯一确定一个未花费的交易输出——UTXO（Unspent Transaction Output）。这样，每一个Tx Input都和之前的某个Tx Output关联了起来。 交易的输出和输⼊⽐特币交易的基本单位是未经使⽤的⼀个交易输出，简称UTX。UTXO是不能再分割、被所有者锁住或记录于区块链中的并被整个⽹络识别成货币单位的⼀定量的⽐特币货币 扩展阅读 《精通比特币》 深入理解比特币交易的脚本 比特币“交易打包”底层原理与区块链“分叉”","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"},{"name":"primitive","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/primitive","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/primitive/"}]},{"title":"挖矿与作弊","date":"2018-09-01T07:12:56.703Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-作弊/","text":"据说算力超过51%以上就可以作弊。 意思就是所有比特币都归属一个人呗？","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"挖矿与共识","date":"2018-09-01T07:11:21.114Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-挖矿与共识/","text":"挖矿是增加⽐特币货币供应的⼀个过程。挖矿同时还保护着⽐特币系统的安全，防⽌欺诈交易，避免“双重⽀付”，“双重⽀付”是指多次花费同⼀笔⽐特币。矿⼯们通过为⽐特币⽹络提供算⼒来换取获得⽐特币奖励的机会。 “挖矿”的原理，就是计算一个HASH值&lt;=TargetHash的过程； FAQ比特币“挖矿”的平均时间为何规定成“10分钟”？10 分钟是系统找到一个有效的交易链块所需要的平均时间（这个时间不是固定的）； 基于运气这个时间实际上会稍长或稍短，比如突然间网络中，算力急速增加，那么生成新区块的时间就会变短；这个平均时长”力图逼近10分钟”，当然，这个出块速度是系统每生成2016个块之后自动调整的，通过调整难度系数difficulty（前序文章中有讲过），大致参考源代码： 123static const int64 nTargetTimespan = 14 * 24 * 60 * 60; //目标时间窗口长度：两周static const int64 nTargetSpacing = 10 * 60; // block频率，每10分钟一块static const int64 nInterval = nTargetTimespan / nTargetSpacing; // 每两周的产量2016，也是调节周期 10分钟—&gt;1分钟会如何？1）间隔太短，易导致较多孤块的出现，不安全，不利于交易确认，还浪费资源； 原因是：每一个“矿工”都需要时刻确认自己是否在主链上，那么就需要矿工之间时刻交流，交流受网速影响（在网络情况不良时，间隔时间越短，这个网络不良的影响对最终的结果影响越大），当有“矿工”生成新的区块，发现它们不在主链上，也就是孤块，只能丢弃，造成浪费。 2）如果出块间隔太短，侧面的也就说明，出块的难度太低； 当出块的频率变高的时候，块与块之间的碰撞频率也就变高，碰撞次数越高，主链被fork（分叉）的概率就越大，fork越多，链结构就会变成树结构。而且每当出现分叉的时候，系统需要花费性能去选出bestChain（bestChain被当做Main链，被各节点认可）； PS：fork即为分叉，分叉分为软分叉和硬分叉，关于分叉和bestChain的选择相关知识点会在本系列的其他文章中讲述。 参考 https://www.jianshu.com/p/07274c3de3e6","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"【比特币源码】block","date":"2018-09-01T04:03:02.799Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/primitive/-block/","text":"背景 术语 区块:⼀个区块就是若⼲交易数据的集合，它会被标记上时间戳和之前⼀个区块的独特标记。区块头经过哈希运算后会⽣成⼀份⼯作量证明，从⽽验证区块中的交易。有效的区块经过全⽹络的共识后会被追加到主区块链中。 区块链:区块链是⼀串通过验证的区块，当中的每⼀个区块都与上⼀个相连，⼀直连到创世区块。 区块头 - CBlockHeaderheader只有80字节的数据， block.h 123456789class CBlockHeader&#123; int32_t nVersion; uint256 hashPrevBlock; // 上一个区块的Hash，区块哈希链就是比特币账本不可篡改的基础 uint256 hashMerkleRoot; // Merkle树根的Hash，根据本区块中的交易计算得来的 uint32_t nTime; // 该区块产生的近似时间 (精确到秒) uint32_t nBits; // 该区块工作量证明算法的难度目标 uint32_t nNonce; // 用于验证 pow，当解决了pow时，广播该区块，并加入区块链&#125; header不包括当前区块的Hash。当前区块的Hash，是GetHash这个函数算出来的，但算出来后在本地肯定有缓存供下个区块生成或者是到来较验用，下个区块如何包含进去的你就需要去了解下挖矿的过程了。 区块 - CBlockblock.h 区块由一个包含元数据的区块头和紧跟其后的构成区块主体的一长串交易组成 123456789class CBlock : public CBlockHeader&#123;public: // network and disk std::vector&lt;CTransactionRef&gt; vtx; // 交易，一个区块包含至少一笔交易。这些Transaction的Hash通过Merkle Tree计算出所有交易的Merkle Hash，并被包含至区块Hash中，从而实现交易的不可修改。 // memory only mutable bool fChecked;&#125;; 当前区块的hash值存在哪里 区块哈希值实际上并不包含在区块的数据结构里，不管是该区块在网络上传输时，抑或是它作为区块链的一部分被存储在某节点的永久性存储设备上时。相反，区块哈希值是当该区块从网络被接收时由每个节点计算出来的。区块的哈希值可能会作为区块元数据的一部分被存储在一个独立的数据库表中，以便于索引和更快地从磁盘检索区块。 尼玛，说的什么？看不懂 BlockLocator12345struct CBlockLocator&#123; std::vector&lt;uint256&gt; vHave; ...&#125; 疑问","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"},{"name":"primitive","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/primitive","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/primitive/"}]},{"title":"","date":"2018-09-01T04:01:56.784Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/-CBlockIndex/","text":"","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"}]},{"title":"","date":"2018-09-01T04:01:05.360Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-CWallet/","text":"","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"dev","date":"2018-09-01T03:51:15.095Z","path":"wiki/CS/OS/-linux/linux kenel/文件系统/系统文件/dev/","text":"12345678910111213$ ls /devptys1ptys2..tty...disk0...null tty控制终端(/dev/tty) 如果当前进程有控制终端(Controlling Terminal)的话，那么/dev/tty就是当前进程的控制终端的设备特殊文件。可以使用命令”ps –ax”来查看进程与哪个控制终端相连。对于你登录的shell，/dev/tty就是你使用的终端，设备号是(5,0)。使用命令”tty”可以查看它 具体对应哪个实际终端设备。/dev/tty有些类似于到实际所使用终端设备的一个联接。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"文件系统","slug":"CS/OS/linux/linux-kenel/文件系统","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/"},{"name":"系统文件","slug":"CS/OS/linux/linux-kenel/文件系统/系统文件","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/系统文件/"}]},{"title":"","date":"2018-09-01T03:40:26.999Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-coins/","text":"# https://github.com/bitcoin/bitcoin/blob/0.17/src/coins.cpp","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"","date":"2018-09-01T03:39:00.512Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-chain/","text":"https://github.com/bitcoin/bitcoin/blob/0.17/src/chain.cpp","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"","date":"2018-09-01T03:36:56.633Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-validation/","text":"","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"比特币中的计算量证明","date":"2018-09-01T03:36:22.314Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-pow/","text":"⽐特币系统的信任是建⽴在计算的基础上的。交易被包在⼀起放进区块中时需要极⼤的计算量来证明，但只需少量计算就能验证它们已被证明。挖矿在⽐特币系统中起着两个作⽤： ▷ 挖矿在构建区块时会创造新的⽐特币，和⼀个中央银⾏印发新的纸币很类似。每个区块创造的⽐特币数量是固定的，随时间会渐渐减少。▷ 挖矿创建信任。挖矿确保只有在包含交易的区块上贡献了⾜够的计算量后，这些交易才被确认。区块越多，花费的计算量越⼤，意味着更多的信任。 比特币使用两次 hash 来计算：SHA256(SHA256(Block_Header))","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"","date":"2018-09-01T03:29:19.577Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/-CChain/","text":"CChain是内存链 内存链就是我们把从硬盘上的数据读取到内存是并封装成cchain这种结构，方便处理数据。所以叫内存链。 # https://www.jianshu.com/p/33af9cf6a9e8","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"},{"name":"基本的数据结构","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/基本的数据结构/"}]},{"title":"","date":"2018-09-01T03:25:34.627Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/-确认钱包数据库的完整性/","text":"https://www.jianshu.com/p/93e20b9e6345","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"}]},{"title":"","date":"2018-09-01T03:17:24.843Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/-入口/","text":"main函数入口 bitcoind.cpp123456789int main(int argc, char* argv[])&#123; SetupEnvironment(); // Connect bitcoind signal handlers noui_connect(); return (AppInit(argc, argv) ? EXIT_SUCCESS : EXIT_FAILURE);&#125; https://www.jianshu.com/p/4a5b0c0f9984","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"}]},{"title":"","date":"2018-09-01T02:54:00.689Z","path":"wiki/block-chain/虚拟货币/币种/-以太币-ETH/RLP编码/","text":"","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"-以太币-ETH","slug":"block-chain/虚拟货币/币种/以太币-ETH","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/以太币-ETH/"}]},{"title":"GPU - 硬件架构","date":"2018-08-31T16:00:00.000Z","path":"wiki/电子/芯片/芯片类型/GPU/-GPU/","text":"GPU 架构(microarchitecture), 表示GPU在芯片设计层面上的不同处理方式，包括的内容有计算单元(SIMD)的个数、有无L1,L2缓存、是否有双精度支持等。按时间顺序依次是Tesla, Fermi, Kepler， Maxwell, Pascal, Volta。 显卡系列：根据使用场景的不同，分成GeForce, Quadro, Tesla。 GeForce用于家庭和个人电脑，包括游戏和娱乐等; Quadro用于工业渲染、艺术设计，工作站等场合。 Tesla用于科学计算，深度学习加速等场景。当然这三者的使用场景并没有严格的边界，想GeForce 系列的GTX 1080也可以用来做深度学习实验。 芯片型号，例如GT200、GK210、GM104、GF104， K80, M40等。其中第二个字母表示架构，如K40 中的K表示是Kepler架构,P100中的P表示Pascal架构。 针对GeForce系列，还有2系列，3系列，200系列，400系列等分类，像GeForce GTX 1080 就是10系列。 疑问：为什么GPU的升级是按架构的。CPU的升级也是按架构升级的，还是多架构同时迭代更新？ 注意区分 Tesla GPU架构和Tesla系列。前者已经用的不是很多了，而后者是最近才出的针对深度学习的系列，使用很多，像我们实验室用的K20,K80都是这个系列。 最近新出了一款 TiTan X, 主要要和GeForce GTX Tian X 区分 参考 https://vra.github.io/2016/12/18/nvidia-gpu-names/ GPU架构细节 CPU和GPU的浮点数计算能力差距较大，是因为GPU是专门为密集型计算、并行计算设计的，常用于图形渲染。GPU的设计架构会把更多的晶体管用于数据处理，而不是数据缓存和控制流。 GPU会将数据映射到多线程并行处理。 the memory access latency can be hidden with calculations instead of big data caches. FAQCPU为什么需要这么多cache和control？GPU不用cache，数据读写比较慢吧？是不涉及到频繁用cache？不需要对一些数据复用吗？GPU的绿色点都是ALU？边上的黄色和红色是control和cache？","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"芯片类型","slug":"电子/芯片/芯片类型","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/"},{"name":"GPU","slug":"电子/芯片/芯片类型/GPU","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/GPU/"}]},{"title":"python 动态加载模块、类、函数","date":"2018-08-31T04:50:04.882Z","path":"wiki/CS/programing/lan/python/动态加载/-类和模块的动态加载/","text":"背景在Java中我们可以通过反射来根据类名创建类实例,那么在Python我们怎么实现类似功能呢？ importlib (或者低版本中的import)- 简介方式一1234if data=='a': import loader_a as loaderelse: import load_b as loader 方式二12345678import importlibdef class_for_name(module_name, class_name): # load the module, will raise ImportError if module cannot be loaded m = importlib.import_module(module_name) # get the class, will raise AttributeError if class cannot be found c = getattr(m, class_name) return c 更优雅的方式动态加载模块：方式1：系统函数import()方式2：imp, importlib 模块方式3：exec 函数 动态加载类和函数首先，使用加载模块，使用内置函数提供的反射方法getattr()，依次按照层级获取模块-&gt;类\\全局方法-&gt;类对象\\类方法。 ## Java的方式参考https://blog.csdn.net/shijichao2/article/details/51165576","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"动态加载","slug":"CS/programing/lan/python/动态加载","permalink":"http://yoursite.com/categories/CS/programing/lan/python/动态加载/"}]},{"title":"python的重写（Override）与重载(Overload)","date":"2018-08-30T11:54:12.878Z","path":"wiki/CS/programing/lan/python/-python面向对象/-override-VS-overload/","text":"overload: 函数重载override: 重写，也就是覆盖 函数重载重载Overload表示同一个类中可以有多个名称相同的方法，但这些方法的参数列表各不相同（即参数个数或类型不同）。 12345678def f(a ,b): return a+ bdef f(a,b,c): return a+b+cprint(f(2,4))print(f(2,3,4)) 会报错 为什么 Python 不支持函数重载？函数重写重写Override表示子类中的方法可以与父类中的某个方法的名称和参数完全相同，通过子类创建的实例对象调用这个方法时，将调用子类中的定义方法，这相当于把父类中定义的那个完全相同的方法给覆盖了，这也是面向对象编程的多态性的一种表现。 函数重载主要是为了解决两个问题。1。可变参数类型。2。可变参数个数。数。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"-python面向对象","slug":"CS/programing/lan/python/python面向对象","permalink":"http://yoursite.com/categories/CS/programing/lan/python/python面向对象/"}]},{"title":"tensorflow的softmax实现","date":"2018-08-30T08:03:03.308Z","path":"wiki/ML/trick/-加速-softmax-tf/","text":"第一个参数logits：就是神经网络最后一层的输出，如果有batch的话，它的大小就是[batchsize，num_classes]，num_classes就是分类的数量。单样本的话，大小就是num_classes第二个参数labels：实际的标签，它的shape同上 第一步是先对网络最后一层的输出做一个softmax，这一步通常是求取输出属于某一类的概率，对于单样本而言，输出就是一个num_classes大小的向量（[Y1，Y2,Y3…]其中Y1，Y2，Y3…分别代表了是属于该类的概率），多样本的话就是输出[batchsize，num_classes]大小的矩阵softmax的公式是： 第二步是softmax的输出向量[Y1，Y2,Y3…]和样本的实际标签做一个交叉熵cross_entropy，公式如下： 12345678910111213141516171819202122232425262728293031323334# -*- coding: utf-8 -*-# https://blog.csdn.net/m0_37041325/article/details/77040060import tensorflow as tf# our NN's output （尚未经过softmax）logits = tf.constant([[0.9, 2.1, 3.0], [0.9, 2.1, 3.0], [0.9, 2.1, 3.0]])# true label# 注意这里标签必须是浮点数,不然在后面计算tf.multiply时就会因为类型不匹配tf_log的float32数据类型而出错y_ = tf.constant([[0, 0, 1.0], [0, 0, 1.0], [0, 0, 1.0]])# 方式一：自己算cross entropyy = tf.nn.softmax(logits)tf_log = tf.log(y)pixel_wise_mult = tf.multiply(y_, tf_log)cross_entropy = -tf.reduce_sum(pixel_wise_mult)# 方式二：用组合版 softmax_cross_entropy (TF进行了内部优化)cross_entropy2_step1 = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)cross_entropy2_step2 = tf.reduce_sum(cross_entropy2_step1) # dont forget tf.reduce_sum()!!with tf.Session() as sess: y_value, tf_log_value, pixel_wise_mult_value, cross_entropy_value = sess.run( [y, tf_log, pixel_wise_mult, cross_entropy]) cross_entropy2_step1_value, cross_entropy2_step2_value = sess.run([cross_entropy2_step1, cross_entropy2_step2]) print(\"==== 方式一 ====\\n\") print(\"step1:softmax result=\\n%s\\n\" % (y_value)) print(\"step2:tf_log_result result=\\n%s\\n\" % (tf_log_value)) print(\"step3:pixel_mult=\\n%s\\n\" % (pixel_wise_mult_value)) print(\"step4:cross_entropy result=\\n%s\\n\" % (cross_entropy_value)) print(\"==== 方式二 ====\\n\") print(\"Function(softmax_cross_entropy_with_logits) result=\\n%s\\n\" % (cross_entropy2_step1_value)) print(\"Function(tf.reduce_sum) result=\\n%s\\n\" % (cross_entropy2_step2_value))","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-08-30T01:24:12.281Z","path":"wiki/ML/deep learning/model-basic/RNN/-lightRNN-SRNN/","text":"海交通大学的Zeping Yu 和Gongshen Liu，在论文“Sliced Recurrent Neural Networks”中，提出了全新架构“切片循环神经网络”（SRNN）。SRNN可以通过将序列分割成多个子序列来实现并行化。SRNN能通过多个层获得高级信息，而不需要额外的参数。 https://github.com/zepingyu0512/srnn SRNN和标准RNN之间的区别在于SRNN将输入序列切分为许多最小子序列，并利用每个子序列上的循环单元。通过这种方式，子序列可以很容易地并行化。�式，子序列可以很容易地并行化。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"cuDNN LSTM","date":"2018-08-30T01:10:04.712Z","path":"wiki/ML/deep learning/model-basic/RNN/-lightRNN-cuDNN-LSTM/","text":"Optimizing performance of recurrent neural networks on gpus","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"","date":"2018-08-30T00:38:59.401Z","path":"wiki/ML/deep learning/model-basic/RNN/-lightRNN-QuasiRNN/","text":"Quasi-RNN的核心是在 k-gram CNN（文本卷积）的基础上使用 adaptive gating。在讨论k-gram卷积的时候，通常不会使用k=1既 window size 1作为运行参数。这点在包括Q-RNN本身的许多论文中都有体现 [1,2,3,4,5]。 SRU中的矩阵变换虽然可以看做 k=1的情况，但这跟声称“所有前馈神经网络（fast forward network）都是 k=1 卷积” 或者 “VGG net 和 GoogLeNet 是 AlexNet 改成3*3卷积然后加深度”没有本质差别。3卷积然后加深度”没有本质差别。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"word2vec源码分析","date":"2018-08-29T01:35:45.618Z","path":"wiki/ML/app/nlp/app/word-vector/model/word2vec/-word2vec-code/","text":"重点对比A probabilistic model for semantic word vectors 参考 word2vec源码 word2vec源码+注释 word2vec - tensorflow版","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"word2vec","slug":"ML/app/nlp/app/word-vector/model/word2vec","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/word2vec/"}]},{"title":"","date":"2018-08-28T14:17:32.529Z","path":"wiki/ML/app/nlp/app/-text-vector/-fastText/","text":"见 word-vector","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"-text-vector","slug":"ML/app/nlp/app/text-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-vector/"}]},{"title":"","date":"2018-08-28T11:42:05.194Z","path":"wiki/ML/app/nlp/app/word-vector/model/-fastText/fastText-code/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-fastText","slug":"ML/app/nlp/app/word-vector/model/fastText","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/fastText/"}]},{"title":"fastText","date":"2018-08-28T11:41:04.623Z","path":"wiki/ML/app/nlp/app/word-vector/model/-fastText/fastText/","text":"简介从另一个角度来说，fastText可以看作是用window_size=1的卷积 + average pooling的CNN [3]对句子进行建模。 核心 - 创新点1 在word2vec的基础上, 把Ngrams也当做词训练word2vec模型, 最终每个词的vector将由这个词的Ngrams得出. 这个改进能提升模型对morphology的效果, 即”字面上”相似的词语distance也会小一些. 疑问 ngram的vector跟word vector什么关系？加和？ trickhierarchical softmax类别数较多时，通过构建一个霍夫曼编码树来加速softmax layer的计算，和之前word2vec中的trick相同N-gram features只用unigram的话会丢掉word order信息，所以通过加入N-gram features进行补充用hashing来减少N-gram的存储 缺陷The movie is not very good , but i still like it .The movie is very good , but i still do not like it .I do not like it , but the movie is still very good .其中第1、3句整体极性是positive，但第2句整体极性就是negative。如果只是通过简单的取平均来作为sentence representation进行分类的话，可能就会很难学出词序对句子语义的影响。 总结对简单的任务来说，用简单的网络结构进行处理基本就够了，但是对比较复杂的任务，还是依然需要更复杂的网络结构来学习sentence representation的。 在合适的任务上应当使用合适的方法，像文本分类这样的任务，如果是长文本，即使用BOW也能做很不错的效果。 用了deep的结构之后，效果没有提升的原因是很多的，比如 数据量不够，过拟合严重 数据标记质量有限，本身的标记中就有一定的噪音。 疑问fastText训练embedding，跟word2vec的区别是什么？ 会考虑subword所有subword都会考虑吗，那样会词典特别大哎？整体的向量和局部向量的关系？近似是之和，还是=和？ 参考 FastText.zip: Compressing text classification models Bag of Tricks for Efficient Text Classification Enriching Word Vectors with Subword Information DAN: Deep Unordered Composition Rivals Syntactic Methods for Text Classification DAN这种东西。。居然在SST数据下和最高的差距还不是很大呐。 简化的dan，加上word2vec中使用的hierarchical softmax, 再加ngrams特征，就是一篇文章 Natural Language Processing (Almost) from Scratch 如何评价Word2Vec作者提出的fastText算法？ | 知乎","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-fastText","slug":"ML/app/nlp/app/word-vector/model/fastText","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/fastText/"}]},{"title":"","date":"2018-08-28T09:45:43.482Z","path":"wiki/ML/ml 传统方法/supervised/广义线性模型/-poisson模型/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"广义线性模型","slug":"ML/ml-传统方法/supervised/广义线性模型","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/广义线性模型/"}]},{"title":"逻辑斯谛回归与最⼤熵模型","date":"2018-08-28T07:52:59.790Z","path":"wiki/ML/ml 传统方法/supervised/广义线性模型/对数线性模型/lr/","text":"逻辑斯谛回归（logistic regression）是统计学习中的经典分类⽅法。最⼤熵是概率模型学习的⼀个准则，将其推⼴到分类问题得到最⼤熵模型（maximum entropy model）。逻辑斯谛回归模型与最⼤熵模型都属于对数线性模型。 逻辑斯蒂分布，logit转换⾸先介绍逻辑斯谛分布（logistic distribution） 定义6.1（逻辑斯谛分布） 设X是连续随机变量，X服从逻辑斯谛分布是指X具有下列分布函数和密度函数： 逻辑斯谛分布的密度函数f(x)和分布函数F(x)的图形如图6.1所⽰。分布函数属于逻辑斯谛函数，其图形是⼀条S形曲线（sigmoid curve） 参考李航","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"广义线性模型","slug":"ML/ml-传统方法/supervised/广义线性模型","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/广义线性模型/"},{"name":"对数线性模型","slug":"ML/ml-传统方法/supervised/广义线性模型/对数线性模型","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/广义线性模型/对数线性模型/"}]},{"title":"概率论的起源、发展、应用","date":"2018-08-28T01:00:10.695Z","path":"wiki/Math/-概率论与数理统计/-概率/","text":"概率论源于游戏和赌博。 概率论的起源简史 概率论的发展概率论的应用��发展 概率论的应用","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"}]},{"title":"中国餐馆过程","date":"2018-08-27T06:28:21.680Z","path":"wiki/ML/PGM/nonparametric/-Chinese restaurant processes/","text":"Dirichlet Process (2018) 中国餐馆过程… 扩展阅读 https://www.cs.princeton.edu/courses/archive/fall11/cos597C/","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"nonparametric","slug":"ML/PGM/nonparametric","permalink":"http://yoursite.com/categories/ML/PGM/nonparametric/"}]},{"title":"","date":"2018-08-27T06:23:19.731Z","path":"wiki/ML/PGM/LDA/-lda基础/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"LDA","slug":"ML/PGM/LDA","permalink":"http://yoursite.com/categories/ML/PGM/LDA/"}]},{"title":"","date":"2018-08-27T05:44:37.473Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/点估计/-矩估计/","text":"th ‘-概率论与数理统计’ 统计推断 1 参数估计 点估计","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"},{"name":"点估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计/点估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/点估计/"}]},{"title":"数学体系架构","date":"2018-08-25T16:00:00.000Z","path":"wiki/Math/summary/","text":"简介 var myChart = echarts.init(document.getElementById('mathchart')); myChart.showLoading(); var data1 = { \"name\": \"数学\", \"children\": [ { \"name\": \"代数\", \"children\": [ {\"name\": \"表示论\", \"value\": 1616}, {\"name\": \"调换代数\", \"value\": 1027}, {\"name\": \"同调代数\", \"value\": 3891}, {\"name\": \"李代数\", \"value\": 891}, {\"name\": \"代数数论\", \"value\": 2893}, { \"name\": \"其他\", \"children\": [ {\"name\": \"add\", \"value\": 593}, {\"name\": \"and\", \"value\": 330} ] } ] }, { \"name\": \"几何\", \"children\": [ {\"name\": \"代数几何\", \"value\": 2105}, {\"name\": \"微分几何\", \"value\": 1316}, {\"name\": \"黎曼几何\", \"value\": 3151}, {\"name\": \"代数拓扑\", \"value\": 3770} ] }, { \"name\": \"分析\", \"children\": [ {\"name\": \"泛函分析\", \"value\": 2105}, {\"name\": \"调和分析\", \"value\": 1316}, {\"name\": \"数学物理\", \"value\": 3151}, {\"name\": \"动力系统\", \"value\": 3770}, {\"name\": \"偏微分方程\", \"value\": 3151}, {\"name\": \"变分\", \"value\": 3151} ] } ] }; myChart.hideLoading(); myChart.setOption(option = { tooltip: { trigger: 'item', triggerOn: 'mousemove' }, legend: { top: '2%', left: '3%', orient: 'vertical', data: [{ name: 'tree1', icon: 'rectangle' } , { name: 'tree2', icon: 'rectangle' }], borderColor: '#c23531' }, series:[ { type: 'tree', name: 'tree1', data: [data1], top: '5%', left: '7%', bottom: '2%', right: '60%', symbolSize: 7, label: { normal: { position: 'left', verticalAlign: 'middle', align: 'right' } }, leaves: { label: { normal: { position: 'right', verticalAlign: 'middle', align: 'left' } } }, expandAndCollapse: true, animationDuration: 550, animationDurationUpdate: 750 } ] }); var myChart = echarts.init(document.getElementById(‘mathchart2’)); myChart.showLoading(); var data = { “name”: “数学”, “children”: [{ “name”: “数论”, “children”: [{ “name”: “初等数论” }, { “name”: “解析数论” }, { “name”: “代数数论” }, { “name”: “超越数论” }, { “name”: “概率数论” }, { “name”: “计算数论” }, { “name”: “其他” } ] }, { “name”: “代数学”, “children”: [{ “name”: “线性代数” }, { “name”: “群论” }, { “name”: “域论”, “value”: 1041 }, { “name”: “李群”, “value”: 5176 }, { “name”: “李代数”, “value”: 449 }, { “name”: “Kac-Moody代数”, “value”: 5593 }, { “name”: “环论”, “value”: 5534 }, { “name”: “同调代数”, “value”: 9201 }, { “name”: “微分代数”, “value”: 19975 }, { “name”: “其他”, “value”: 1116 } ] }, { “name”: “几何学”, “children”: [{ “name”: “几何学基础” }, { “name”: “欧式几何”, “value”: 1759 }, { “name”: “非欧几何”, “value”: 2165 }, { “name”: “球面几何”, “value”: 586 }, { “name”: “向量和张量分析”, “value”: 3331 }, { “name”: “仿射几何”, “value”: 772 }, { “name”: “射影几何”, “value”: 3322 }, { “name”: “微分几何”, “value”: 3322 }, { “name”: “计算几何”, “value”: 3322 }, { “name”: “分数维几何”, “value”: 3322 }, { “name”: “其他”, “value”: 3322 } ] }, { “name”: “拓扑学”, “children”: [{ “name”: “点集拓扑学”, “value”: 1103110 }, { “name”: “代数拓扑学”, “value”: 1732 }, { “name”: “几何拓扑学”, “value”: 3623 }, { “name”: “奇点理论”, “value”: 10066 }, { “name”: “微分拓扑学”, “value”: 10066 } ] }, { “name”: “数学分析”, “children”: [{ “name”: “微分学”, “value”: 4116 }, { “name”: “积分学”, “value”: 4116 }, { “name”: “级数论”, “value”: 4116 }, { “name”: “泛函分析”, “children”: [{ “name”: “线性算子理论”, “value”: 1082 }, { “name”: “变分法”, “value”: 1336 }, { “name”: “拓扑线性空间”, “value”: 319 }, { “name”: “希尔伯特空间”, “value”: 10498 }, { “name”: “函数空间”, “value”: 2822 }, { “name”: “算子代数”, “value”: 9983 }, { “name”: “广义函数论”, “value”: 2213 }, { “name”: “非线性泛函分析”, “value”: 1681 } ] } ] }, { “name”: “计算数学”, “children”: [{ “name”: “常微分方程数值解”, “value”: 1082 }, { “name”: “偏微分方程数值解”, “value”: 1336 }, { “name”: “积分变换与积分方程数值方法”, “value”: 319 }, { “name”: “数值计算”, “value”: 10498 }, { “name”: “优化计算方法”, “value”: 2822 }, { “name”: “数值逼近与计算几何”, “value”: 9983 }, { “name”: “小波分析与傅立叶分析的数值方法”, “value”: 2213 } ] }, { “name”: “概率论”, “children”: [{ “name”: “几何概率”, “value”: 1616 }, { “name”: “概率分布”, “value”: 1027 }, { “name”: “极限理论”, “value”: 3891 }, { “name”: “随机过程”, “value”: 891 }, { “name”: “马尔科夫过程”, “value”: 2893 }, { “name”: “随机分析”, “value”: 5103 }, { “name”: “鞅论”, “value”: 3677 }, { “name”: “应用概率论”, “value”: 781 } ] }, { “name”: “数理统计学”, “children”: [{ “name”: “抽样理论”, “value”: 2105 }, { “name”: “假设检验”, “value”: 1316 }, { “name”: “非参数统计”, “value”: 3151 }, { “name”: “方差分析”, “value”: 3770 }, { “name”: “相关回归分析”, “value”: 2435 }, { “name”: “统计推断”, “value”: 4839 }, { “name”: “贝叶斯统计”, “value”: 1756 }, { “name”: “试验设计”, “value”: 4268 }, { “name”: “多元分析”, “value”: 1821 }, { “name”: “时间序列分析”, “value”: 5833 } ] } ] }; myChart.hideLoading(); echarts.util.each(data.children, function(datum, index) { index % 2 === 0 &amp;&amp; (datum.collapsed = true); }); myChart.setOption(option = { tooltip: { trigger: ‘item’, triggerOn: ‘mousemove’ }, series: [{ type: ‘tree’, data: [data], top: ‘1%’, left: ‘7%’, bottom: ‘1%’, right: ‘20%’, symbolSize: 7, label: { normal: { position: ‘left’, verticalAlign: ‘middle’, align: ‘right’, fontSize: 9 } }, leaves: { label: { normal: { position: ‘right’, verticalAlign: ‘middle’, align: ‘left’ } } }, expandAndCollapse: true, animationDuration: 550, animationDurationUpdate: 750 }] }); 维基百科这样分 代数（初等 线性 多重线性 抽象） 分析/微积分学 几何 (离散 代数 解析 微分 有限) 概念 &amp; 分支现代数学大致分5大方向。粗糙来讲，可以分代数(数论)、几何(拓扑)、分析(微积分)，三大方向 代数 algebra: 代数是数学的一个分支，是研究数、数量、关系、结构与代数方程（组）的通用解法及其性质的数学分支。代数的研究对象不仅是数字，而是各种抽象化的结构。常见的代数结构类型有群、环、域、模、线性空间等。 线性代数是代数学的一个分支，主要处理线性关系问题。线性关系意即数学对象之间的关系是以一次形式来表达的。例如，在解析几何里，平面上直线的方程是二元一次方程；空间平面的方程是三元一次方程，而空间直线视为两个平面相交，由两个三元一次方程所组成的方程组来表示。含有n个未知量的一次方程称为线性方程。 几何: 分析(mathematical analysis)：数学分析区别于其他非数学类学生的高等数学内容，是分析学中最古老、最基本的分支，一般指以微积分学、无穷级数和解析函数等的一般理论为主要内容，并包括它们的理论基础（实数、函数、测度和极限的基本理论）的一个较为完整的数学学科。 集值分析集值函数的分析及应用。凸分析是有关凸集合及凸函数的研究。 代数几何， 根基欧几里得用公里推 几何，欧氏几何公理 等 代数，根基公理就是运算定律(交换律、结合律、分配律) 分类-分支数学分析与高数的区别？https://www.zhihu.com/question/19745167 相同点：两门课基本都是研究微积分学 区别高数重计算、应用，数分重证明 reading list普林斯顿微积分读本 扩展阅读 学科分类 数学包含的学科 | 百度百科","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"}]},{"title":"概率论与数理统计","date":"2018-08-25T16:00:00.000Z","path":"wiki/Math/-概率论与数理统计/summary/","text":"名词解释 概率论部分主要是讲：大千世界中，数据的分布呈现出来的形状 (分布函数，密度函数..)。 数理统计部分则是在讲：建立在各种分布的前提下，我们如何用少量的样本数据来推断总体的一些性质; 或者推断两个样本是否来自一个总体; 等等…- 统计学（statistics）是应用数学的一个分支，主要通过利用概率论建立数学模型，收集所观察系统的数据，进行量化的分析、总结，并进而进行推断和预测，为相关决策提供依据和参考。统计学主要分为描述统计学和推断统计学。 统计推断，或者叫做推断统计学（statistical inference）是指统计学中研究如何根据样本数据去推断总体数量特征的方法。统计推断主要可以分为两大类：一类是参数估计问题；另一类是假设检验问题。 统计学习（statistical learning）关注的是最小化预测的误差。是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科，也称为统计机器学习（statistical machine learning）。统计学习是概率论，统计学，信息论，计算理论，最优化理论及计算机科学等多个领域的交叉学科。statistical learning 讲的是 在machine learning 学科下, 利用统计学知识和数值型数据 来进行机器 学习 (或叫 优化). machine learning 除了 statistical learning 以外，还有其他 learning 的方法. 样本估计 statistics 统计学是基础. statistical inference 是学统计的目的,即根据样本数据,对总体进行统计推断(假设检验 或 预测). 这两个概念都可以算属于统计学学科. [统计学] 里，用的最多的就是回归模型，而回归模型里参数的求解，主要是通过[最小二乘（OLS）]和[最大似然估计（MLE）] 来求解。OLS 和 MLE 其实是一个 [数值优化 (Optimization)] 的问题。而 [数值优化] 就和机器学习联系起来了。 关系 &amp; 架构 [概率论] 是 [数理统计] 的理论基础；学[数理统计] 就等于在学习如何进行 [统计推断]； [概率论]+[数理统计] = [统计学]； 学习[统计学] 的目的 就是进行[统计推断]。 从概念和内容上，三者的关系是：statistics &lt; statistical inference &lt; statistical learning 总结统计推断统计学习 扔硬币 1000000次的人是不是傻？ 大数定律是必然的吗？ 抛硬币实验的意义是什么？ 参考https://www.zhihu.com/question/23687389 概率导论 第二版 - 翻译真差劲，错别字多。 ss","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"}]},{"title":"贝叶斯学派 VS 频率学派","date":"2018-08-25T16:00:00.000Z","path":"wiki/Math/-概率论与数理统计/贝叶斯 VS 频率/","text":"简介在统计领域，有两种突出但对立的思想学派：贝叶斯学派（Bayesian）和频率学派（Frequentist，也称经典学派）。他们之间最重要的区别就是如何看待未知模型或者变量，即对参数的理解不同。 频率学派: 认为未知参数$\\theta$是确定的(非随机)，而取值未知；是未知常数，而不是随机变量。 贝叶斯学派: 将未知参数$\\theta$看做已知分布的随机变量(先验分布) 频率学派从「自然」角度出发，试图直接为事件本身建模，即事件A在独立重复试验中发生的频率趋于极限p，那么这个极限就是该事件的概率。举例而言，想要计算抛掷一枚硬币时正面朝上的概率，我们需要不断地抛掷硬币，当抛掷次数趋向无穷时正面朝上的频率即为正面朝上的概率。 然而，贝叶斯学派并不从试图刻画事件本身，而从「观察者」角度出发。贝叶斯学派并不试图说「事件本身是随机的」，或者「世界的本体带有某种随机性」，这套理论根本不言说关于「世界本体」的东西，而只是从「观察者知识不完备」这一出发点开始，构造一套在贝叶斯概率论的框架下可以对不确定知识做出推断的方法。频率学派下说的「随机事件」在贝叶斯学派看来，并不是「事件本身具有某种客观的随机性」，而是「观察者不知道事件的结果」而已，只是「观察者」知识状态中尚未包含这一事件的结果。但是在这种情况下，观察者又试图通过已经观察到的「证据」来推断这一事件的结果，因此只能靠猜。贝叶斯概率论就想构建一套比较完备的框架用来描述最能服务于理性推断这一目的的「猜的过程」。因此，在贝叶斯框架下，同一件事情对于知情者而言就是「确定事件」，对于不知情者而言就是「随机事件」，随机性并不源于事件本身是否发生，而只是描述观察者对该事件的知识状态。 总的来说，贝叶斯概率论为人的知识（knowledge）建模来定义「概率」这个概念。频率学派试图描述的是「事物本体」，而贝叶斯学派试图描述的是观察者知识状态在新的观测发生后如何更新。 贝叶斯方法主要是想将统计领域拉回到「概率」的王国里，使得每个问题都只有唯一的答案。特别地，当人们欲对未知模型进行推断时，贝叶斯方法将该模型看成是随机地从已知的一类模型中选出来的。处理方法是引入一个随机变量$\\Theta$来刻画该模型，然后构造一个先验概率分布$p_{\\Theta}{\\theta}$。在已知数据x的情况下，人们原则上使用贝叶斯公式来推导后验概率分布$p_{\\Theta | x}{\\theta | x}$。这样就抓住了x能提供关于$\\theta$的所有信息。 相反，经典统计方法将未知参数$\\theta$视为常数，但是未知就需要估计。然后经典统计的目标就是提出参数$\\theta$的估计方法，且保证具有一些性质。经典方法处理的不是一个概率模型，而是有多个待选的概率模型，每个标记为$\\theta$的一个可能值。比如矩估计和MLE会得到不同的参数$\\theta$，这些就是不同的模型。 例子我们通过下面的例子，简短地回顾两个学派争论的观点。 估计电子的质量假设我们要通过噪声实验的手段来测量一个物理常数，比如电子的质量。经典统计学家认为电子的质量尽管未知，但也只是一个常数，所以不能把它看成随机变量。而贝叶斯统计学家却给它一个先验分布，来反映人们对电子质量的已有知识。比如，如果我们已经从历史实验中获知电子质量的大概范围，则可以将先验分布集中在那个范围中。 我觉得贝叶斯靠谱啊，贝叶斯考虑了历史性、全局性（历史实验中电子质量的分布，或者人的先验知识），以及参数的相关性（体现在先验分布的协方差）。而频率学派讲究让数据说话，在数据中挖掘信息。只局限于单个样本（或所有观测样本），孤立的看问题。 投硬币以最简单的扔硬币游戏为例，一枚硬币扔了五次，有一次是正面。用最大似然估计，就是以这五次结果为依据，判断这枚硬币每次落地时正面朝上的概率（期望值）是多少时，最有可能得到四次反面一次正面的结果。不难计算得到期望概率0.2。 如果你的先验知识告诉你，这枚硬币是均匀的，正面朝上的概率一般是0.5。这时候就需要在先验概率0.5和最大似然估计0.2之间取个折中值，这个折中值称为后验概率。 剩下的问题就是先验知识和最大似然估计结果各应起多大作用了。如果你对制币工艺非常有信心，觉得先验知识的可靠程度最起码相当于做过一千次虚拟试验，那么后验概率是(0.2 5 + 0.5 1000)/(5 + 1000) = 0.4985，如果你对制币局技术信心不足，觉得先验知识的可靠程度也就相当于做过五次试验，那么后验概率是(0.2 5 + 0.5 5)/(5 + 5) = 0.35. 这种在先验概率和最大似然结果之间做折中的方法称为后验估计方法。这是用贝耶斯观点对最大后验方法的阐述，其实也可以用用经典统计学派的偏差方差的折中来解释。 例如：小明先验地相信一枚硬币是均匀的，可能是出于认为均匀硬币最常见这种信念。 之后观察者开始新的观测或实验（小明开始不断地抛硬币，发现抛了100次后，居然只有20次是正面朝上）。经过中间的独立重复试验，观察者获得了一些新的观测结果，这些新的观测将以含有不确定性的逻辑推断的方式影响观察者原有的信念（小明开始怀疑这枚硬币究竟是不是均匀的，甚至开始断定硬币并不均匀） 小明开始怀疑这枚硬币究竟是不是均匀的体现在哪？贝叶斯并涉及超参的更新吧 投篮我定点投篮, 投5次, 次次投中, 问：我的投篮技术如何？再比如科比投篮, 投100次, 次次投中, 问：科比投篮技术如何？如果我们使用经典方法：矩法估计、极大似然估计, 得到的结果是我和科比投蓝准确率都是100%, 即我和科比技术一样, 都是百投百中。 参考: http://www.datakit.cn/blog/2014/10/30/bayes_estimation.html MLE VS 贝叶斯估计《统计机器学习 | 李航》4.2.3 学派大战两个学派的争论已经持续一个世纪了，经常争论的是哲学思想。在两派的争论过程中，每派都构造一些例子来说明对方学派的方法有时得到不合理的，或者不吸引人的结论。 经典学派统计学家经常返回这种挑选一个特定先验的随意性。贝叶斯统计学家反驳说，任何统计推断往往隐含着一些先验。进一步地，在某些例子中，先验分布如果是某个特殊选定的分布，经典方法实质上是与贝叶斯方法等价的。通过将所有的假设都以先验的形式放在一起，贝叶斯统计学家主张将这些假设公开的，并认为它们是经得起推敲的。 最后，从实际的角度考虑。在许多情况下，贝叶斯方法在计算方面很棘手，比如需要计算多维的积分。另一方面，随着快速计算逐渐为人们所用，贝叶斯统计学派的大量最新研究成果就集中在如何使贝叶斯方法具有可行性上。 争论结果 我是贝叶斯学派的支持者（an outspoken partisan on the Bayesian side） – 《概率沉思录》大量实践证明，贝叶斯方法是优于频率方法的。当然你可以在哲学上进行争论，但我们的论点现在是通过引用事实而不是宣扬哲学或意识形态立场。 – 《概率沉思录》probability theory as extended logic. 概率论作为逻辑的补充 summary学界一般认为，Bayesian 视角的优势在于能解释一些传统统计不能解释的问题，而劣势在于先验这个概念太主观；而现在真正让Bayesian 起飞的，是十多二十年前它和MCMC结合以后方法。 实例一般的统计推断，也有对应的Bayesian 推断；有一般的假设检验，也有对应的Bayesian 检验 PLSA VS LDA PLSA中认为，一个文档的主题分布是常数 LDA认为，一个文档的主题分布是服从dirichlet分布的随机变量 高斯的参数估计- 贝叶斯方法先验，一般是 先验分布的选择如果先验选择某分布的共轭，那么后验就一定会和先验的分布类型一样，而类型一样的优势在于，极大化简运算。这就是为什么LDA中会选择 Dirichlet 和 Multinomial，因为前者是后者的共轭先验。GMM之所以要从Bayesian 考虑，是因为将数据的来源视为未知变量，从而再从条件概率考虑并用EM算法求解。 经典方法传统的“频率主义者”只使用抽样分布，这在许多特别简单、理想化的情况下是起作用的; 然而，这些简化是概率论中最特殊情况，因为他们基于这样的预设：一个“随机实验”具有独立重复性。这在实际问题中很少遇到的。 疑问贝叶斯方法的先验分布形式是否太局限？形式是比较局限，一般用常见的简单分布。但是作为参数的先验，简单的分布基本够用了。 如果觉得不够用，可以采用对简单分布的变换，构造复杂分布。 参数theta确是一个常数，而且假设经典方法能够准确学习该参数的情况下。再用贝叶斯方法是不是多此一举，徒增误差(不确定性)？贝叶斯方法 与过拟合通常，最参数w加高斯先验，其后验分布等价于L2正则。加拉普拉斯先验，等价于L1正则(Lasso)。这样起到了架构风险最小的作用，有助于减小模型的过拟合。 Bayesian 和防止过拟合没有本质联系，Frequency 实用（潜台词Bayesian 没那么实用）与否也未必是两者的区别。就拿Bayesian Lasso 来说，其结果是后验分布的 mode——而 mode 并非总是0——所以确实没有 Lasso 的变量选择能力（没看懂），但如果多考虑一步，比如 估计出的Bayesian 区间是否含0等等从而进行取舍，依然可以实现将估计压缩到0的目标。— 没看懂 这两个学派跟波粒二象性的关系？波 - 概率粒 - 常数 参考 概率沉思录 - 前言 概率导论 - 第8章 贝叶斯学派与频率学派有何不同？ | 知乎 贝叶斯概率、贝叶斯推断以及模型之间的关系？ | 知乎 MLE，MAP，EM 和 point estimation 之间的关系是怎样的？ | 知乎","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"}]},{"title":"参数估计","date":"2018-08-25T16:00:00.000Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/参数估计/","text":"名词解释 参数估计 参数估计参数估计有点估计(point estimation)和区间估计(interval estimation)两种。 点估计是依据样本估计总体分布中所含的未知参数或未知参数的函数。通常它们是总体的某个特征值，如数学期望、方差和相关系数等。点估计问题就是要构造一个只依赖于样本的量，作为未知参数或未知参数的函数的估计值。例如，设一批产品的废品率为θ。为估计θ，从这批产品中随机地抽出n个作检查，以X记其中的废品个数，用X/n估计θ，这就是一个点估计。 点估计: 一般就是要找概率密度曲线上值最大的那个点 区间估计: 则要寻找该曲线上满足某种条件的一个曲线段 点估计设总体X的分布函数的形式已知，但它的一个或多个参数未知，借助于总体X的一个样本估计总体未知参数的值的问题成为参数的点估计问题。 点估计常用的方法有： 矩估计法。用样本矩估计总体矩，如用样本均值估计总体均值。 最大似然估计(MLE)。于1912年由英国统计学家R.A.费希尔提出，用来求一个样本集的相关概率密度函数的参数。 最大后验估计(MAP): 是点估计，是因为Max，要的是一个点而不是区间。但是又属于贝叶斯估计吧？ 最小二乘法。主要用于线性统计模型中的参数估计问题。 贝叶斯估计法。基于贝叶斯学派(见贝叶斯统计)的观点而提出的估计法。 最小二乘法，跟其他三种什么关系？是并列关系吗？ 贝叶斯估计是区间估计吧？ 为什么说正态分布的矩估计跟极大似然估计相等呢？在矩估计中，我们的一阶原点矩就是期望，二阶中心距就是方差。也就是说，样本均值（一阶样本原点矩）就可以直接作为模型的均值。方差亦然。而通过极大似然的方法，让似然函数导数为0直接求解，最终会发现模型参数的均值就是一阶样本原点矩，方差亦然。 能够出现这样的情况，只是恰好因为正态分布的一个有趣的性质：模型的参数（均值和方差）直接就是样本矩（一阶样本原点矩和二阶样本中心距） 疑问与 EM算法，梯度下降法，关系。 区间估计区间估计是依据抽取的样本，根据一定的正确度与精确度的要求，构造出适当的区间，作为总体分布的未知参数或参数的函数的真值所在范围的估计。例如人们常说的有百分之多少的把握保证某值在某个范围内，即是区间估计的最简单的应用。 求置信区间常用的三种方法： 利用已知的抽样分布。 利用区间估计与假设检验的联系。（请参考几种常见的参数估计） 利用大样本理论。 贝叶斯区间估计呢？ 疑问： 区间估计一般用不着吧？ 参数估计的效果评估可以用来估计未知参数的估计量很多，于是产生了怎样选择一个优良估计量的问题。首先必须对优良性定出准则，这种准则是不唯一的，可以根据实际问题和理论研究的方便进行选择。优良性准则有两大类：一类是小样本准则，即在样本大小固定时的优良性准则；另一类是大样本准则，即在样本大小趋于无穷时的优良性准则。最重要的小样本优良性准则是无偏性及与此相关的一致最小方差无偏估计，其次有容许性准则，最小化最大准则，最优同变准则等。大样本优良性准则有相合性、最优渐近正态估计和渐近有效估计等。 无偏估计 VS 有偏估计","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"}]},{"title":"","date":"2018-08-25T04:01:08.064Z","path":"wiki/Math/-概率论与数理统计/-parameter estimation/","text":"参数估计（parameter estimation），统计推断的一种。根据从总体中抽取的随机样书．来估计总体分布中未知参数的过程。从估计形式看，区分为点估计与区间估计：从构造估计量的方法讲，有矩法估计、最小二乘估计、似然估计、贝叶斯估计等。��似然估计、贝叶斯估计等。","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"}]},{"title":"LDA的","date":"2018-08-25T03:40:29.312Z","path":"wiki/ML/PGM/LDA/-lda-gibbs/","text":"code https://code.google.com/archive/p/lsa-lda/ http://gibbslda.sourceforge.net/ java https://github.com/yangliuy/LDAGibbsSampling","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"LDA","slug":"ML/PGM/LDA","permalink":"http://yoursite.com/categories/ML/PGM/LDA/"}]},{"title":"","date":"2018-08-25T03:40:14.570Z","path":"wiki/ML/PGM/LDA/-lda-variational/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"LDA","slug":"ML/PGM/LDA","permalink":"http://yoursite.com/categories/ML/PGM/LDA/"}]},{"title":"时隔多年，回顾LDA","date":"2018-08-25T03:38:14.696Z","path":"wiki/ML/PGM/LDA/-lda/","text":"一定要回顾一下LDA，变分、gibbs都忘记了。 LDA算是自己PGM的入门paper。后面渐渐NN走上神坛，PGM的一系列渐渐遗忘。 LDA应该算是PGM的代表作品之一。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"LDA","slug":"ML/PGM/LDA","permalink":"http://yoursite.com/categories/ML/PGM/LDA/"}]},{"title":"","date":"2018-08-25T03:21:21.227Z","path":"wiki/ML/PGM/-bayesian-inference/variational-inference/","text":"基础知识概率 VS 贝叶斯 exact inference VS variational inference -- variational approximation Variational Bayesian","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"-bayesian-inference","slug":"ML/PGM/bayesian-inference","permalink":"http://yoursite.com/categories/ML/PGM/bayesian-inference/"}]},{"title":"分布式哈希算法","date":"2018-08-24T11:15:53.978Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-分布式哈希/","text":"普通的Hash方式在介绍分布式哈希算法之前，先了解下普通的Hash是如何实现的。JDK中的java.util.HashMap类就实现了一个哈希表，它的特点有：①创建哈希表(HashMap)需要先指定大小，即默认创建一个能够存储多少个元素的哈希表，它的默认大小为16。 ②当不断地向HashMap中添加元素时，HashMap越来越满，当添加的元素达到了装载因子乘以表长时，就需要扩容了。扩容时，原来已经映射到哈希表中的某个位置(桶)的元素需要重新再哈希，然后再把原来的数据复制到新的哈希表中。 因此，这是普通哈希的一个不足：扩容可能会影响到所有元素的移动。这也是为什么：为了减少扩容时元素的移动，总是将哈希表扩容成原来大小的两倍的原因。因为，有数学证明，扩容成两倍大小，使得再哈希的元素个数最少。 示例分布式哈希","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"一致性哈希","date":"2018-08-24T09:40:23.796Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-一致性哈希/","text":"基础知识 热点(Hot spot)问题: 分布式哈希: 一致性 简介一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对$K/n$个关键字重新映射，其中$K$是关键字的数量，$n$是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 历史一致哈希是1997年由MIT的Karger提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot) 问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性哈希算法(Consistent Hashing)是分布式系统中常用的算法。比如，一个分布式的存储系统，要将数据存储到具体的节点上，如果采用普通的hash方法，将数据映射到具体的节点上，如key%N，key是数据的key，N是机器节点数，如果有一个机器加入或退出这个集群，则所有的数据映射都无效了，如果是持久化存储则要做数据迁移，如果是分布式缓存，则其他缓存就失效了。 因此，引入了一致性哈希算法： 把数据用hash函数（如MD5），映射到一个很大的空间里，如图所示。数据的存储时，先得到一个hash值，对应到这个环中的每个位置，如k1对应到了图中所示的位置，然后沿顺时针找到一个机器节点B，将k1存储到B这个节点中。 如果B节点宕机了，则B上的数据就会落到C节点上，如下图所示： 这样，只会影响C节点，对其他的节点A，D的数据不会造成影响。然而，这又会造成一个“雪崩”的情况，即C节点由于承担了B节点的数据，所以C节点的负载会变高，C节点很容易也宕机，这样依次下去，这样造成整个集群都挂了。 为此，引入了“虚拟节点”的概念：即把想象在这个环上有很多“虚拟节点”，数据的存储是沿着环的顺时针方向找一个虚拟节点，每个虚拟节点都会关联到一个真实节点，如下图所使用： 图中的A1、A2、B1、B2、C1、C2、D1、D2都是虚拟节点，机器A负载存储A1、A2的数据，机器B负载存储B1、B2的数据，机器C负载存储C1、C2的数据。由于这些虚拟节点数量很多，均匀分布，因此不会造成“雪崩”现象。 加虚拟节点解决数据均衡的问题1.使用虚拟节点后，但是当我增加物理节点后，环中的虚拟节点是否要增加，如果把他应用在mysql上，数据迁移是否会很困难？ 2.在使用虚拟节点时，比如5个物理节点，每个物理节点虚拟出1024个虚节点，按道理hash环有5120个节点，但是使用kemata哈希虚拟环时，有些节点key的哈希结果相同，导致hash环中少于5120个节点？、 有一个问题，如果使用虚拟节点，某台机器每次宕机再恢复后都需要迁移数据。这样是否反而更麻烦了。 实现参考思考题 一致性哈希只是分布式场景下的应用吗？单机能用吗？单机怎样实现哈希的一致性？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"MurmurHash算法","date":"2018-08-24T09:11:54.891Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-MurmurHash3/","text":"MurmurHash is a non-cryptographic hash function suitable for general hash-based lookup.The name comes from two basic operations, multiply (MU) and rotate (R), used in its inner loop. Unlike cryptographic hash functions, it is not specifically designed to be difficult to reverse by an adversary, making it unsuitable for cryptographic purposes. MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。已经被应用到很多开源项目如Redis，Memcached，Cassandra，HBase，Lucene等。与其它流行的哈希函数相比，对于规律性较强的key，MurmurHash的随机分布特征表现更良好。 优缺点 速度快，比安全散列算法快几十倍； 变化足够激烈，相似的字符串如“abc”和“abd”能够均匀散落在哈希环上； 不保证安全性（缺点）","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"高斯混合模型","date":"2018-08-24T06:26:22.443Z","path":"wiki/ML/PGM/-GMM/","text":"这是密度估计？还是概率估计？ 什么是高斯混合模型（Gaussian Mixture Model） 高斯混合模型（Gaussian Mixture Model）通常简称GMM，是一种业界广泛使用的聚类算法，该方法使用了高斯分布作为参数模型，并使用了期望最大（Expectation Maximization，简称EM）算法进行训练。 本文对该方法的原理进行了通俗易懂的讲解，期望读者能够更直观地理解方法原理。文本的最后还分析了高斯混合模型了另一种常见聚类算法K-means的关系，实际上在特定约束条件下，K-means算法可以被看作是高斯混合模型（GMM）的一种特殊形式（达观数据 陈运文）。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"}]},{"title":"","date":"2018-08-24T03:17:25.328Z","path":"wiki/-audio/声纹识别/xvector/","text":"更看重在短语的融合？ 先训练ubm，再训T矩阵。 每个句子一个vector。d-vector是每一帧一个vector。 tdnn xvector更适合短时","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"Python collections中的Counter","date":"2018-08-23T16:00:00.000Z","path":"wiki/CS/programing/lan/python/标准库/collection/-counter/","text":"Counter是dict的子类，是一个简单的计数器 12345from collections import Counterc = Counter()for ch in 'programming': c[ch] = c[ch] + 1c # Counter(&#123;'g': 2, 'm': 2, 'r': 2, 'a': 1, 'i': 1, 'o': 1, 'n': 1, 'p': 1&#125;) counter有多高效？counter为什么这么高效？ 速度测评以下计数，发现并未对速度做优化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/env python# -*- coding: utf-8 -*-from time import timeimport tensorflow as tffrom collections import Counterdef _read_words(filename): with tf.gfile.GFile(filename, &quot;r&quot;) as f: return f.read().decode(&quot;utf-8&quot;).replace(&quot;\\n&quot;, &quot;&lt;eos&gt;&quot;).split()# 计数 + 排序def _build_vocab(filename): data = _read_words(filename) start = time() # 利用counter，计数+排序。counter并不快 counter = Counter(data) count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0])) # 自己计数 # word_cnt = count(data) # count_pairs = sorted(word_cnt.items(), key=lambda x: (-x[1], x[0])) stop = time() print(&quot;Stop: &quot; + str(stop)) print(str(stop - start) + &quot;秒&quot;) words, _ = list(zip(*count_pairs)) word_to_id = dict(zip(words, range(len(words)))) return word_to_iddef count(data): word_cnt = &#123;&#125; for w in data: if w in word_cnt: word_cnt[w] += 1 else: word_cnt[w] = 1 return word_cntword_to_id = _build_vocab(&quot;ptb_data/ptb.train.txt&quot;)print(word_to_id[&quot;no&quot;])","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"标准库","slug":"CS/programing/lan/python/标准库","permalink":"http://yoursite.com/categories/CS/programing/lan/python/标准库/"},{"name":"collection","slug":"CS/programing/lan/python/标准库/collection","permalink":"http://yoursite.com/categories/CS/programing/lan/python/标准库/collection/"}]},{"title":"python 的 counter 源码","date":"2018-08-23T16:00:00.000Z","path":"wiki/CS/programing/lan/python/标准库/collection/-counter源码/","text":"参考https://blog.csdn.net/Shiroh_ms08/article/details/52653385","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"标准库","slug":"CS/programing/lan/python/标准库","permalink":"http://yoursite.com/categories/CS/programing/lan/python/标准库/"},{"name":"collection","slug":"CS/programing/lan/python/标准库/collection","permalink":"http://yoursite.com/categories/CS/programing/lan/python/标准库/collection/"}]},{"title":"","date":"2018-08-23T03:20:05.393Z","path":"wiki/CS/programing/lan/C++/-虚函数/","text":"概念 定义一个函数为虚函数，不代表函数为不被实现的函数。 定义他为虚函数是为了允许用基类的指针来调用子类的这个函数。 定义一个函数为纯虚函数，才代表函数没有被实现。 定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。 C++多态(polymorphism)是通过虚函数来实现的。 # 虚函数只能借助于指针或者引用来达到多态的效果。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"C++","slug":"CS/programing/lan/C","permalink":"http://yoursite.com/categories/CS/programing/lan/C/"}]},{"title":"","date":"2018-08-23T01:48:13.975Z","path":"wiki/ML/trick/-标准化/","text":"正则化 VS 标准化regularization 与 normalization 区别？ “standardization 一般是指将数据正态化，使平均值1方差为0. ” normalization和standardization是差不多的，都是把数据进行前处理，从而使数值都落入到统一的数值范围，从而在建模过程中，各个特征量没差别对待。normalization一般是把数据限定在需要的范围，比如一般都是【0，1】，从而消除了数据量纲对建模的影响。standardization 一般是指将数据正态化，使平均值0方差为1. 因此normalization和standardization 是针对数据而言的，消除一些数值差异带来的特种重要性偏见。经过归一化的数据，能加快训练速度，促进算法的收敛。 而regularization是在cost function里面加惩罚项，增加建模的模糊性，从而把捕捉到的趋势从局部细微趋势，调整到整体大概趋势。虽然一定程度上的放宽了建模要求，但是能有效防止over-fitting的问题(如图，来源于网上)，增加模型准确性。因此，regularization是针对模型而言。 机器学习中的一个核心问题是设计不仅在训练数据上表现好，并且能在新输入上泛化好的算法。在机器学习中，许多策略显式地被设计来减少测试误差（可能会以增大训练误差为代价）。这些策略被统称为正则化。 正则化：对学习算法的修改——旨在减少泛化误差而不是训练误差 扩展阅读 《深度学习 - 第七章》 机器学习里的黑色艺术：normalization, standardization, regularization","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"softmax的困扰、改进","date":"2018-08-22T16:00:00.000Z","path":"wiki/ML/trick/加速-softmax/","text":"简介数学上的softmax在数学，尤其是概率论和相关领域中，Softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量 ${\\displaystyle \\mathbf {z} }$“压缩”到另一个K维实向量 ${\\displaystyle \\sigma (\\mathbf {z} )}$ 中，使得每一个元素的范围都在 ${\\displaystyle (0,1)}$ 之间，并且所有元素的和为1。该函数的形式通常按下面的式子给出： $${\\displaystyle \\sigma (\\mathbf {z} ){j}={\\frac {e^{z{j}}}{\\sum {k=1}^{K}e^{z{k}}}}} \\quad j = 1, …, K.$$ softmax的应用Softmax函数实际上是有限项离散概率分布的梯度对数归一化。因此，Softmax函数在包括 多项逻辑回归，多项线性判别分析，朴素贝叶斯分类器和人工神经网络等的多种基于概率的多分类问题方法中都有着广泛应用。特别地，在多项逻辑回归和线性判别分析中，函数的输入是从K个不同的线性函数得到的结果，而样本向量 x 属于第 j 个分类的概率为： $${\\displaystyle P(y=j\\mid \\mathbf {x} )={\\frac {e^{\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{j}}}{\\sum _{k=1}^{K}e^{\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{k}}}}}$$ 这可以被视作K个线性函数${\\displaystyle \\mathbf {x} \\mapsto \\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{1},\\ldots ,\\mathbf {x} \\mapsto \\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{K}}$Softmax函数的复合（ \\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} \\mathbf {x} \\mathbf {w} ）。 loss functionsoftmax loss是我们最熟悉的loss之一了，分类任务中使用它，分割任务中依然使用它。softmax loss实际上是由softmax和cross-entropy loss组合而成，两者放一起数值计算更加稳定。这里我们将其数学推导一起回顾一遍。 令z是softmax层的输入，f(z)是softmax的输出，则 softmax的瓶颈softmax需要计算每个类别的score，并且归一化为概率p。当类别特别多（比如大词表）的情况下，计算量超大。 参数量=计算量=n*V 复杂度O(n^2) 对于大词表V softmax的瓶颈常见于语言模型的巨量词汇、 优化汇总对损失函数的近似方法 HSM: Hierarchical Softmax: 用两层的树((Goodman, 2001a; Mikolovet al., 2011c)，或者更深层的结构（） NCE: 重要性采样 class-based softmax: adaptive softmax: 对class-based softmax的改进，针对GPU的加速 其他 Large-Margin Softmax Loss weighted softmax loss soft softmax loss angular softmax loss L2-constrained softmax loss additive margin softmax loss 基于采样的近似方法 基于 其他 简单的trick [batch_size, seq_length, hidden_size] * [hidden_size, vocab_size] 这样的操作，可以reshape成 [batch_size seq_length, hidden_size] [hidden_size, vocab_size] 的操作。即真个sequence一起算softmax。 但是有些decode中，上一时刻的output作为下一时刻的输入，就没办法这样算了。 对loss-function的优化/近似（Loss function approximation） HSM: hierarchical softmax 树结构是一般基于frequency binning或者word similarities hierarchical softmax是很多层二分类，在GPU上效率并不高。假如，浅层的多分类，每层没必要是两个类。单层矩阵运算更容易用GPU加速层数少了，在GPU上速度提升了，(当然如果是cpu，速度会更慢) 基于采样的优化/近似 (Sampling based approximation)importance sampling 不同的采样策略： unigram bigram power-raised distribution of the unigram Self-normalized approachesclass based softmaxClasses for fast maximum entropy training. Joshua Goodman, 2001 We assign each word in thevocabulary to a unique class. 比如，猫、狗属于动物类，周二、周三属于工作日。 FAQ 类之间有没有word overlap？没有，这样能减小计算量。(HS的二叉树也) 有没有大类小类？多层类？没有 class与word的对应关系是怎样得到的？ 由用户自定义，自定义的方法有： 按语义分类：猫、狗属于动物类，周二、周三属于工作日。 按词频分类：首先词频排序，然后分块作为class adaptive softmaxFacebook 人工智能研究（FAIR）设计出一种新式的 softmax 函数逼近，专用于 GPUs，帮助其在语言模型的基础上通过巨量词汇来有效训练神经网络。 这种方法叫做自适应 softmax（adaptive softmax），利用不平衡词分布形成簇（cluster），这种簇能明确地减少对计算复杂度的期望，从而规避对词汇量的线性依赖。这种方法通过利用流行架构的特殊性和矩阵-矩阵向量运算（matrix-matrix vector operations）进一步减少了训练和测试时的计算成本。这使得它特别适合于 GPU，而以往的方法，如分层 softmax，NCE 和重要性采样，都是为标准的 CPU 设计的。 有点类似HS和重要性采样吧？词频高的 FAQ adaptive softmax为什么能加速？ 为什么要这样分cluster？ 核心NCEnegative sampling。这种只针对training吧？inference怎样sampling呢？ (CPU上会更低效) FAQ关于名称 softmax直接来看是一个归一化方法，loss的形式和是不是概率是不是softmax形式是没有必然联系的。当然它们现在的形式都是可以从entropy延伸出来，但是换一个新的loss，softmax也可以照用，或者不用softmax归一化，这个loss也一样可以继续用于优化。我觉得还是叫entropy loss比较好。 全称是softmax cross entropy loss，但这个实在是太长了 没什么全称的吧，好多地方都叫得不一样，就叫entropy loss最好了，既简洁又准确，这个loss就是entropy的形式 这个损失函数的核心是softmax函数，用softmax得到概率才能用cross entropy，得到概率的方式也有很多，比如sigmoid后l1归一化。 caffe里除了softmax cross entropy，还有sigmoid cross entropy。 参考 维基百科写的很好，很多篇幅摘自维基百科 efficient softmax approximation for GPUs 综述归纳的很好 一文道尽softmax loss及其变种 漫谈词向量之基于Softmax与Sampling的方法 | 待看","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"为什么Python比C++慢很多？","date":"2018-08-22T16:00:00.000Z","path":"wiki/CS/programing/lan/python/-python VS C/","text":"12345678910111213141516171819202122232425# include &lt;cstdio&gt;int n = 15 ;int cnt ;void Dfs ( int row, int shu, int pie, int na ) &#123;int ave = ((1 &lt;&lt; n) - 1) &amp; ~(shu | pie | na) ;while ( ave ) &#123;int p = ave &amp; -ave ;ave ^= p ;if ( row == n )++ cnt ;elseDfs ( row + 1, shu | p, (pie | p) &gt;&gt; 1, (na | p) &lt;&lt; 1 ) ;&#125;&#125;int main ( ) &#123;Dfs ( 1, 0, 0, 0 ) ;printf ( \"%d\\n\", cnt ) ;&#125;","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"}]},{"title":"python collection","date":"2018-08-22T16:00:00.000Z","path":"wiki/CS/programing/lan/python/标准库/collection/summary/","text":"collections — High-performance container datatypes¶ collections是Python内建的一个集合模块，在2.4版本开始被引入，该模块实现了专用容器数据类型来替代python的通用内置容器：dict（字典），list（列表）， set（集合）和tuple（元组）。 容器 中文名 简介 引入版本 namedtuple() 命名元组 使用工厂方法创建带有命名的字段的元组的子类 2.6 deque 双向队列 类似列表的容器，能够快速响应在任何一端进行pop 2.4 Counter 计数器 字典子类，为可以进行哈希的对象计数 2.7 OrderedDict 有序字典 字典子类，记录了字典的添加次序 2.7 defaultdict 字典 字典子类，调用一个工厂方法来提供缺失的值 2.5 除了具体的容器类，collections模块还提供了abstract_base_classes来测试一个类是否体用了一个特定的接口，例如，这是可哈希的还是一个映射。 在2.4版本中新加入，。 中文翻译：https://blog.csdn.net/Shiroh_ms08/article/details/52653385 扩展阅读 collections官方文档 源码 Lib/collections.py Lib/_abcoll.py [java的collection架构]","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"标准库","slug":"CS/programing/lan/python/标准库","permalink":"http://yoursite.com/categories/CS/programing/lan/python/标准库/"},{"name":"collection","slug":"CS/programing/lan/python/标准库/collection","permalink":"http://yoursite.com/categories/CS/programing/lan/python/标准库/collection/"}]},{"title":"","date":"2018-08-22T03:22:17.452Z","path":"wiki/ML/deep learning/toolbox/-静态图-动态图/bucket/","text":"为什么需要bucketbucket就是一种编码思想，bucket的存在是为了减小计算量,从而可以减少模型的训练时间。当然，使用dynamic_rnn或rnn这两个接口也可以减少运算时间。bucket是用在使用在cell(input,state)这种古老的方法上的。 每一个bucket都是一个固定的computation graph； 其次，每一个sequence的pad都不是很多，对于计算资源的浪费很小 再次，这样的实现很简单，就是一个给长度聚类，对于framework的要求很低 对train set:要对sequence的长度聚类，确保如何分配bucket。 数据依旧要填充到最大长度 对每个bucket都要建立一个模型，但是模型都是共享变量的 对每个模型都要都要计算loss，保存到list中 训练的时候，最小化对应bucket的loss 源码 https://github.com/tensorflow/tensorflow/blob/27711108b5fce2e1692f9440631a183b3808fa01/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py#L1118 Update最新版本的 tensorflow 不需要使用 bucketing了，直接用 dynamic rnn 就好，它会根据每个batch自动计算最好的输出，不过要更定每个example的 sequence length。当然，现在有人可以做到自动计算 sequence length 了，可参考 tensorlayer.layers这个方法也用在google 最新开源的 image captioning 例子里了。 dynamic rnn是如何解决效率问题的？有了dynamic rnn, buket也仍然有用，因为后续logits loss计算的时候batch length小仍然会减少计算量。“One reason is that seq2seq was created before dynamic rnn was available. The other is that, even with dynamic rnn, it still helps for speed if your batches are organized by bucket” dynamic rnn并不会提升效率.The parameter sequence_length is optional and is used to copy-through state and zero-out outputs when past a batch element’s sequence length. So it’s more for correctness than performance. 参考 tensorflow中的seq2seq例子为什么需要bucket？","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-静态图-动态图","slug":"ML/deep-learning/toolbox/静态图-动态图","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/静态图-动态图/"}]},{"title":"静态图如何","date":"2018-08-22T03:07:47.961Z","path":"wiki/ML/deep learning/toolbox/-静态图-动态图/静态图-模拟动态图/","text":"参考 tensorflow中的seq2seq例子为什么需要bucket？ | 知乎","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-静态图-动态图","slug":"ML/deep-learning/toolbox/静态图-动态图","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/静态图-动态图/"}]},{"title":"","date":"2018-08-22T00:53:15.457Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/Faster R‑CNN/","text":"Faster R‑CNN是首个利用CNN来完成proposals的预测的，之后的很多目标检测网络都是借助了Faster R‑CNN的思想。而Faster R‑CNN系列的网络都可以分成2个部分：1.Fully Convolutional subnetwork before RoI Layer2.RoI‑wise subnetwork Position‑sensitive RoI pooling位置敏感RoI池化操作了（Position‑sensitive RoI pooling）","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"","date":"2018-08-21T01:01:48.808Z","path":"wiki/CS/programing/lan/python/装饰器/-装饰器/","text":"@classmethod, @staticmethod, @property？ 这些都是装饰器（decorator）。装饰器是一种特殊的函数，要么接受函数作为输入参数，并返回一个函数，要么接受一个类作为输入参数，并返回一个类。@标记是语法糖（syntactic sugar），可以让你以简单易读得方式装饰目标对象。 装饰器跟工厂模式有关系吗？参考tensor2tensor中的装饰器","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"装饰器","slug":"CS/programing/lan/python/装饰器","permalink":"http://yoursite.com/categories/CS/programing/lan/python/装饰器/"}]},{"title":"python多线程","date":"2018-08-20T13:55:09.737Z","path":"wiki/CS/programing/lan/python/-多线程/","text":"Python和多线程（multi-threading）。这是个好主意码？ Python并不支持真正意义上的多线程。Python中提供了多线程包，但是如果你想通过多线程提高代码的速度，使用多线程包并不是个好主意。Python中有一个被称为Global Interpreter Lock（GIL）的东西，它会确保任何时候你的多个线程中，只有一个被执行。线程的执行速度非常之快，会让你误以为线程是并行执行的，但是实际上都是轮流执行。经过GIL这一道关卡处理，会增加执行的开销。这意味着，如果你想提高代码的运行速度，使用threading包并不是一个很好的方法。 不过还是有很多理由促使我们使用threading包的。如果你想同时执行一些任务，而且不考虑效率问题，那么使用这个包是完全没问题的，而且也很方便。但是大部分情况下，并不是这么一回事，你会希望把多线程的部分外包给操作系统完成（通过开启多个进程），或者是某些调用你的Python代码的外部程序（例如Spark或Hadoop），又或者是你的Python代码调用的其他代码（例如，你可以在Python中调用C函数，用于处理开销较大的多线程工作）。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"}]},{"title":"","date":"2018-08-20T07:55:04.374Z","path":"wiki/ML/deep learning/next/-very-large/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"next","slug":"ML/deep-learning/next","permalink":"http://yoursite.com/categories/ML/deep-learning/next/"}]},{"title":"BP","date":"2018-08-20T07:45:53.261Z","path":"wiki/ML/deep learning/优化-学习-训练/-BP-in-cnn/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"优化-学习-训练","slug":"ML/deep-learning/优化-学习-训练","permalink":"http://yoursite.com/categories/ML/deep-learning/优化-学习-训练/"}]},{"title":"BP算法","date":"2018-08-20T07:45:39.161Z","path":"wiki/ML/deep learning/优化-学习-训练/-BP/","text":"扩展阅读 Backpropagation, Intuitions | CS231n","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"优化-学习-训练","slug":"ML/deep-learning/优化-学习-训练","permalink":"http://yoursite.com/categories/ML/deep-learning/优化-学习-训练/"}]},{"title":"【卷积】1. 卷积的由来","date":"2018-08-20T07:34:07.556Z","path":"wiki/ML/deep learning/model-basic/CNN/-0-conv/","text":"参考 BP in CNN","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"resnet及其变种","date":"2018-08-20T06:42:43.571Z","path":"wiki/ML/deep learning/model-basic/CNN/-resnet_next/","text":"Resnet 前From shallow to deep skip connection和identity skip connection什么区别？ 后Resnet时代参考 kaiming He","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"【机器翻译】- 机器翻译 发展史","date":"2018-08-20T02:54:34.085Z","path":"wiki/machine translation/-0. related-work survey/summary/","text":"机器翻译历史 直接转换法 从源语言句子的表层出发，将单词、短语或句子直接置换成目标语言译文，必要时进行简单的词序调整。对原文句子的分析仅满足于特定译文生成的需要。这类翻译系统一般针对某一个特定的语言对，将分析与生成、语言数据、文法和规则与程序等都融合在一起。例如：I like Mary. –&gt; Me(I) gusta(like) Maria(Mary).X like Y –&gt; Y X gusta 基于规则的机器翻译(Rule-based) 对源语言和目标语言均进行适当描述、把翻译机制与语法分开、用规则描述语法的实现思想 1954年 Georgetown 大学在 IBM 协助下，用IBM-701计算机实现了世界上第一个 MT 系统，实现俄译英翻译，1954年1月该系统在纽约公开演示。系统只有250条俄语词汇，6 条语法规则，可以翻译简单的俄语句子。 统计机器翻译 SMT(-2016)： 1990年，IBM 提出统计机器翻译模型，机器翻译研究进入了一个空前辉煌的繁荣时期。 神经机器翻译 NMT(2016-): 优点：翻译更加顺畅；不需要去存储短语表，而是有着一个小规模的词汇表，这大大减小了计算的复杂度。 缺点：为了能够控制计算的复杂度，有着一个固定大小的词汇表，通常会将词汇表限制在 30k 到 80k 之间，这就导致了其在翻译未登录词时有着严重的不足 主流架构 基于规则的机器翻译 统计机器翻译 SMT： 神经机器翻译 NMT 优点：翻译更加顺畅；不需要去存储短语表，而是有着一个小规模的词汇表，这大大减小了计算的复杂度。 缺点：为了能够控制计算的复杂度，有着一个固定大小的词汇表，通常会将词汇表限制在 30k 到 80k 之间，这就导致了其在翻译未登录词时有着严重的不足。 ## SMT时代 - 1978年欧共体启动多语言机器翻译计划； 11.1.2 机器翻译的产生与发展 - 1982 ~ 1986，日本在提出第五代机的同时，研究日英双向机器翻译系统 Mu 和亚洲多语言机器翻译（日语、汉语、印尼语、马来西亚语、泰国语）； - 1990年，IBM 提出统计机器翻译模型，机器翻译研究进入了一个空前辉煌的繁荣时期。 NMT时代 2005年，Google基于统计方法的翻译系统全面超过基于规则方法的SysTran翻译系统。基于规则方法固守的最后一个堡垒被拔掉了。 2016 GNMT facebook FAIR在上个月刚祭出state of the art的convseq2seq 谷歌全attention机器翻译模型Transformer, WMT en-de和en-fr都刷到了新的state of the art，而且这次不用RNN，不用CNN，只有attention","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-0. related-work survey","slug":"machine-translation/0-related-work-survey","permalink":"http://yoursite.com/categories/machine-translation/0-related-work-survey/"}]},{"title":"【机器翻译】- 统计机器翻译 SMT","date":"2018-08-20T02:46:10.447Z","path":"wiki/machine translation/-0. related-work survey/smt/","text":"我们首先要了解一下基于短语的系统的工作原理。基于短语的方法是目前比较成熟的统计机器翻译技术，它的主要思想是以短语作为翻译的基本单元。给定一个源语言句子，其翻译过程如下：a． 对源语言句子进行短语划分；b． 根据翻译模型翻译每个短语；c． 对短语进行重排序。","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-0. related-work survey","slug":"machine-translation/0-related-work-survey","permalink":"http://yoursite.com/categories/machine-translation/0-related-work-survey/"}]},{"title":"","date":"2018-08-20T01:31:47.337Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/SPPNets/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"RCNN","date":"2018-08-20T01:31:12.338Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/RCNN/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"","date":"2018-08-20T01:30:45.306Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/Mask RCNN/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"","date":"2018-08-20T01:28:41.886Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/FPN/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"","date":"2018-08-20T01:28:20.301Z","path":"wiki/ML/app/vision/app/Object Recognition/-object-detection/DensePose-RCNN/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"-object-detection","slug":"ML/app/vision/app/Object-Recognition/object-detection","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/object-detection/"}]},{"title":"","date":"2018-08-18T16:42:45.347Z","path":"wiki/ML/app/vision/dataset/-coco/","text":"coco数据下载 detection数据caption数据keypoints数据","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"dataset","slug":"ML/app/vision/dataset","permalink":"http://yoursite.com/categories/ML/app/vision/dataset/"}]},{"title":"Eigen2","date":"2018-08-18T07:54:07.045Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/0. 矩阵计算/-Eigen/Eigen2/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"0. 矩阵计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/"},{"name":"-Eigen","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/Eigen","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/Eigen/"}]},{"title":"","date":"2018-08-18T07:53:48.642Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/0. 矩阵计算/-Eigen/Eigen3/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"0. 矩阵计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/"},{"name":"-Eigen","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/Eigen","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/Eigen/"}]},{"title":"矩阵计算库，汇总","date":"2018-08-18T07:44:13.570Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/0. 矩阵计算/-summary/","text":"对于机器学习的很多问题来说，计算的瓶颈往往在于大规模以及频繁的矩阵运算，主要在于以下两方面： (Dense/Sparse) Matrix – Vector product (Dense/Sparse) Matrix – Dense Matrix product 这篇文章的主要目的就是比较几个常见的BLAS库的矩阵运算性能，分别是 LAPACK (Linear Algebra Package) LAPACK is built on top of the BLAS; 是基于BLAS的更高层的线性代数库，用于做矩阵分解(LU, LLt, QR, SVD, Schur, etc)，计算特征值、奇异值、解线性系统等。LAPACK的编译不依赖BLAS，可以依赖 EIGEN: 是一个线性算术的C++模板库。功能强大、快速、优雅以及支持多平台，可以使用该库来方便处理一些矩阵的操作，达到类似matlab那样的快捷。 需要定义 EIGEN_NO_DEBUG 阻止运行时assertion。编译单线程版本需要开启 -DEIGEN_DONT_PARALLELIZE. 在试验中，我们采用 EIGEN 原生 BLAS 实现。 ntel MKL: 英特尔数学核心函数库是一套经过高度优化和广泛线程化的数学例程，专为需要极致性能的科学、工程及金融等领域的应用而设计。它可以为当前及下一代英特尔处理器提供性能优化，包括更出色地与 Microsoft Visual Studio、Eclipse和XCode相集成。英特尔 MKL 支持完全集成英特尔兼容性 OpenMP 运行时库，以实现更出色的 Windows/Linux 跨平台兼容性。在试验中的多线程版本需要链接到 mkl_gnu_thread，而不是 mkl_intel_thread，单线程版本需要链接到 mkl_sequential_thread。 OpenBLAS: 是一个高性能多核 BLAS 库，是 GotoBLAS2 1.13 BSD 版本的衍生版。OpenBLAS 的编译依赖系统环境，并且没有原生单线程版本，在实验这哦那个，通过设置 OMP_NUM_THREADS=1 来模拟单线程版本，可能会带来一点点的性能下降 常用的组合 ATLAS+LAPACK 效果对比https://stackoverflow.com/questions/7596612/benchmarking-python-vs-c-using-blas-and-numpy","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"0. 矩阵计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/"}]},{"title":"numpy","date":"2018-08-18T06:59:53.760Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/1. 科学计算/numpy/","text":"简介NumPy是Python语言的一个扩充程序库。支持高阶大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库 NumPy参考CPython(一个使用字节码的解释器)，而在这个Python实现解释器上所写的数学算法代码通常远比编译过的相同代码要来得慢。为了解决这个难题，NumPy引入了多维数组以及可以直接有效率地操作多维数组的函数与运算符。因此在NumPy上只要能被表示为针对数组或矩阵运算的算法，其运行效率几乎都可以与编译过的等效C语言代码一样快。[1] numpy的依赖独立安装NumPy这个Python包本身不需依赖任何第三方库就能完成编译和安装使用，只不过其计算性能会受到影响。 在编译NumPy时通常会依赖一些经过特别优化的第三方科学计算库。 高性能NumPy包通常会依赖LAPACK和ATLAS库lapack和atlas是科学计算领域的两个针对线性代数运算的经过特别优化的非常强大的工具库， 这两个库对于安装NumPy包来说并不是强制依赖的。 查看 numpy的配置本机mac上 1234567891011121314151617181920212223242526272829303132333435363738&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; np.show_config()blas_mkl_info: NOT AVAILABLEblis_info: NOT AVAILABLEopenblas_info: NOT AVAILABLEatlas_3_10_blas_threads_info: NOT AVAILABLEatlas_3_10_blas_info: NOT AVAILABLEatlas_blas_threads_info: NOT AVAILABLEatlas_blas_info: NOT AVAILABLEblas_opt_info: extra_compile_args = ['-msse3', '-I/System/Library/Frameworks/vecLib.framework/Headers'] extra_link_args = ['-Wl,-framework', '-Wl,Accelerate'] define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)]lapack_mkl_info: NOT AVAILABLEopenblas_lapack_info: NOT AVAILABLEopenblas_clapack_info: NOT AVAILABLEatlas_3_10_threads_info: NOT AVAILABLEatlas_3_10_info: NOT AVAILABLEatlas_threads_info: NOT AVAILABLEatlas_info: NOT AVAILABLElapack_opt_info: extra_compile_args = ['-msse3'] extra_link_args = ['-Wl,-framework', '-Wl,Accelerate'] define_macros = [('NO_ATLAS_INFO', 3), ('HAVE_CBLAS', None)] P100 GPU服务器ubuntu123456789101112131415161718192021222324252627&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; np.__config__.show()mkl_info: libraries = ['mkl_rt', 'pthread'] library_dirs = ['/home/song.xu01/anaconda3/lib'] define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)] include_dirs = ['/home/song.xu01/anaconda3/include']blas_mkl_info: libraries = ['mkl_rt', 'pthread'] library_dirs = ['/home/song.xu01/anaconda3/lib'] define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)] include_dirs = ['/home/song.xu01/anaconda3/include']blas_opt_info: libraries = ['mkl_rt', 'pthread'] library_dirs = ['/home/song.xu01/anaconda3/lib'] define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)] include_dirs = ['/home/song.xu01/anaconda3/include']lapack_mkl_info: libraries = ['mkl_rt', 'pthread'] library_dirs = ['/home/song.xu01/anaconda3/lib'] define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)] include_dirs = ['/home/song.xu01/anaconda3/include']lapack_opt_info: libraries = ['mkl_rt', 'pthread'] library_dirs = ['/home/song.xu01/anaconda3/lib'] define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)] include_dirs = ['/home/song.xu01/anaconda3/include'] 该服务器的全局python12345678910111213141516171819202122232425262728&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; np.__config__.show()lapack_opt_info: libraries = ['openblas', 'openblas'] library_dirs = ['/usr/local/lib'] define_macros = [('HAVE_CBLAS', None)] language = cblas_opt_info: libraries = ['openblas', 'openblas'] library_dirs = ['/usr/local/lib'] define_macros = [('HAVE_CBLAS', None)] language = copenblas_info: libraries = ['openblas', 'openblas'] library_dirs = ['/usr/local/lib'] define_macros = [('HAVE_CBLAS', None)] language = cblis_info: NOT AVAILABLEopenblas_lapack_info: libraries = ['openblas', 'openblas'] library_dirs = ['/usr/local/lib'] define_macros = [('HAVE_CBLAS', None)] language = clapack_mkl_info: NOT AVAILABLEblas_mkl_info: NOT AVAILABLE 安装numpy的过程，也会显示 扩展阅读 如何获得NumPy的最佳性能","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"1. 科学计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/1-科学计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/1-科学计算/"}]},{"title":"","date":"2018-08-18T04:01:22.509Z","path":"wiki/CS/programing/lan/-装饰器-注解/","text":"疑问 Annotation与Decorator的字面意思是什么？区别？ Python装饰器是否与Java注释相同,或者与Aspects？ Angular2 注解与装饰器的区别？ TypeScript 所支持的装饰器只是函数调用的语法糖； 扩展阅读https://www.zhihu.com/question/68257128","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"","date":"2018-08-16T07:33:47.709Z","path":"wiki/-audio/TTS/model/HMM/","text":"1）先从label提取70多种特征（5因子，声调，前后信息等等），再又HMM提取一个粗糙的时长模型定位字的大致范围。2） 对语音提取频谱特征和基频特征3） 声学训练对齐，HHM状态为语言特征序列，单高斯为频谱特征4 ）参数生成过程为 ：已知模型参数a,求P(O|a)，频谱参数。具体地，phone经过决策树查询聚类的均值和方差，然后求P(O|a)。","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"TTS","slug":"audio/TTS","permalink":"http://yoursite.com/categories/audio/TTS/"},{"name":"model","slug":"audio/TTS/model","permalink":"http://yoursite.com/categories/audio/TTS/model/"}]},{"title":"","date":"2018-08-16T02:47:33.990Z","path":"wiki/ML/竞赛/kaggle/入门/-泰坦尼克号幸存预测/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"竞赛","slug":"ML/竞赛","permalink":"http://yoursite.com/categories/ML/竞赛/"},{"name":"kaggle","slug":"ML/竞赛/kaggle","permalink":"http://yoursite.com/categories/ML/竞赛/kaggle/"},{"name":"入门","slug":"ML/竞赛/kaggle/入门","permalink":"http://yoursite.com/categories/ML/竞赛/kaggle/入门/"}]},{"title":"常用的html版式","date":"2018-08-16T00:19:18.687Z","path":"wiki/demo/hexo/-style/","text":"字体图片样式 ![]， 缺陷，不方便自定义size和title 排版 12![convs2s的batch training过程](/images/raw/NN - convseq2seq - architecture.png)这种样式只加了alt属性，并未加title属性 背景切换图片大小多张图片","tags":[],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"","date":"2018-08-16T00:05:44.853Z","path":"wiki/ML/ml 传统方法/supervised/SVM/-Soft Margin SVM/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"SVM","slug":"ML/ml-传统方法/supervised/SVM","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/SVM/"}]},{"title":"","date":"2018-08-15T23:51:34.646Z","path":"wiki/ML/ml 传统方法/supervised/SVM/-核函数-RBF/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"SVM","slug":"ML/ml-传统方法/supervised/SVM","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/SVM/"}]},{"title":"","date":"2018-08-15T14:24:43.321Z","path":"wiki/ML/ml 传统方法/supervised/SVM/-SVR/","text":"参考 http://shomy.top/2017/03/09/support-vector-regression/","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"SVM","slug":"ML/ml-传统方法/supervised/SVM","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/SVM/"}]},{"title":"yield return","date":"2018-08-15T08:44:55.300Z","path":"wiki/CS/programing/lan/python/-迭代器-生成器-yield/","text":"python在 yield 从字面上理解有“退位，屈服”的意思，转一下弯就理解成“权限转移”，也就是将控制权交给别人，在这里就是把集合里满足条件（如果没有过滤条件，就是全体）的个体的操作转移给另一个对象。 第一种方法，是把结果集全部加载到内存中再遍历； 第二种方法，客户端每调用一次，yield return就返回一个值给客户端，是”按需供给”。 yield与装饰器、yield并发切换(非io) 其他语言中的yieldjava - yieldThread.yield( )使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。cpu会从众多的可执行态里选择，也就是说，当前也就是刚刚的那个线程还是有可能会被再次执行到的，并不是说一定会执行其他线程而该线程在下一次中不会执行到了。 Java线程中有一个Thread.yield( )方法，很多人翻译成线程让步。顾名思义，就是说当一个线程使用了这个方法之后，它就会把自己CPU执行的时间让掉，让自己或者其它的线程运行。 使当前线程（即调用该方法的线程）暂停执行一段时间，让其他线程有机会继续执行，但它并不释放对象锁。 该方法与sleep()类似，只是不能由用户指定暂停多长时间，并且yield（）方法只能让同优先级的线程有执行的机会。 CC#中的yield关键字的用法经常是 yield return nodejs","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"}]},{"title":"互信息和左右熵的新词发现","date":"2018-08-14T13:26:00.597Z","path":"wiki/ML/app/nlp/app/新词发现/-左右熵的新词发现/","text":"是由Matrix67牛人提出来的，实现的方式也有很多人解决了。我只是写个最简单的介绍和实现方式给自己做做笔记罢。该算法最主要是基于互信息和左右熵的计算规则，而这两个概念都是出自信息论的范畴，其一者称内部凝和度，其二者称外部自由度或者边界自由度。 第一是最小互信息，因为互信息越大说明相关度越大，将n-gram分好的词计算互信息，如果低于阈值，则说明不能成词。 第二是最小熵值，因为熵也是越大说明周边词越丰富，计算其左熵和右熵的最小值，如果最小值低于阈值，则说明不能成词。 第三个是最少出现次数，为什么有这个数呢？假设前后两个词是完全相关的，出现400次，总共8000词，那么互信息=log((400/8000)/(400/8000)(400/8000))，约掉之后剩下log(8000/400)。但是一个词如果从头到尾出现了一次，但是并不是单词，则互信息为=log((1/8000)/(1/8000)(1/8000))=log(8000/1)，那么它的互信息会更大。取最少出现次数也会出现问题，就是一些低频率的词不能发现。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"新词发现","slug":"ML/app/nlp/app/新词发现","permalink":"http://yoursite.com/categories/ML/app/nlp/app/新词发现/"}]},{"title":"【Linux网络编程】原始套接字","date":"2018-08-14T05:37:52.683Z","path":"wiki/CS/network/网络编程-socket编程/-raw_socket/","text":"通常情况下程序员接所接触到的套接字（Socket）为两类： 流式套接字（SOCK_STREAM）：一种面向连接的 Socket，针对于面向连接的TCP 服务应用； 数据报式套接字（SOCK_DGRAM）：一种无连接的 Socket，对应于无连接的 UDP 服务应用。 从用户的角度来看，SOCK_STREAM、SOCK_DGRAM 这两类套接字似乎的确涵盖了 TCP/IP 应用的全部，因为基于 TCP/IP 的应用，从协议栈的层次上讲，在传输层的确只可能建立于 TCP 或 UDP 协议之上，而 SOCK_STREAM、SOCK_DGRAM 又分别对应于 TCP 和 UDP，所以几乎所有的应用都可以用这两类套接字实现。 但是，当我们面对如下问题时，SOCK_STREAM、SOCK_DGRAM 将显得这样无助： 怎样发送一个自定义的 IP 包？ 怎样发送一个 ICMP 协议包？ 怎样分析所有经过网络的包，而不管这样包是否是发给自己的？ 怎样伪装本地的 IP 地址？ 这使得我们必须面对另外一个深刻的主题——原始套接字（SOCK_RAW）。原始套接字广泛应用于高级网络编程，也是一种广泛的黑客手段。著名的网络sniffer（一种基于被动侦听原理的网络分析方式）、拒绝服务攻击（DOS）、IP 欺骗等都可以通过原始套接字实现。 原始套接字（SOCK_RAW）可以用来自行组装数据包，可以接收本机网卡上所有的数据帧（数据包），对于监听网络流量和分析网络数据很有作用。 原始套接字是基于 IP 数据包的编程（SOCK_PACKET 是基于数据链路层的编程）。另外，必须在管理员权限下才能使用原始套接字。 原始套接字（SOCK_RAW）与标准套接字（SOCK_STREAM、SOCK_DGRAM）的区别在于原始套接字直接置“根”于操作系统网络核心（Network Core），而 SOCK_STREAM、SOCK_DGRAM 则“悬浮”于 TCP 和 UDP 协议的外围。 转载自 https://blog.csdn.net/tennysonsky/article/details/44655077写的太好了，no comments","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络编程-socket编程","slug":"CS/network/网络编程-socket编程","permalink":"http://yoursite.com/categories/CS/network/网络编程-socket编程/"}]},{"title":"","date":"2018-08-12T07:16:33.262Z","path":"wiki/ML/deep learning/model-basic/CNN/-LeNet/","text":"参考 参数量: https://zhuanlan.zhihu.com/p/40791280","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"","date":"2018-08-11T16:58:04.649Z","path":"wiki/ML/deep learning/-trick/","text":"见 ML/_trick","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"}]},{"title":"超参","date":"2018-08-11T16:54:52.307Z","path":"wiki/ML/trick/-调参-超参选择/","text":"超参 - 汇总 batch size，见.. 步长 多机多卡 - 见deep-learning/优化 - 分布式集群 难点• 超参数范围广泛： 随着模型复杂度的提升，模型中可供调节的超参数数量及数值范围也在增多。例如，在CIFAR-10数据集上训练的ResNet模型有16个可调的超参数[8]，当多数超参数的取值为连续域的情况下，如此少量的超参数仍然可能造成组合爆炸。因此，最近也出现了以谷歌的Vizier为代表的系统，采用优化的搜索及学习算法为模型自动适配合适的超参数值的集合。 如何选择合适的超参此外，由于超参较多，而每一个超参分布范围较广，使得超参调优的耗时较长，特别是针对ImageNet这种超大数据集的情况。前文提过，CIFAR-10数据集上训练的ResNet模型就有16个超参。 随着项目进展，团队还引入了很多新的关键技术，如后面将会提到的LARS算法、分层同步算法、梯度融合策略，Batch Norm替换等都会增加模型超参数量，如何在可接受的时间内寻找到较优解，是机智团队面临的第三个重大挑战。 参数步长由粗到细调优参数值先以较大步长进行划分，可以减少参数组合数量，当确定大的最优范围之后再逐渐细化调整，例如在调整学习速率时，采取较大步长测试发现：学习率lr较大时，收敛速度前期快、后期平缓，lr较小时，前期平缓、后期较快，根据这个规律继续做细微调整，最终得到多个不同区间的最佳学习速率； 低精度调参在低精度训练过程中，遇到的最大的一个问题就是精度丢失的问题，通过分析相关数据，放大低精度表示边缘数值，保证参数的有效性是回归高精度计算的重要方法； 初始化数据的调参随着网络层数的增多，由于激活函数的非线性，初始化参数使得模型变得不容易收敛，可以像VGGNet那样通过首先训练一个浅层的网络，再通过浅层网络的参数递进初始化深层网络参数，也可以根据输入输出通道数的范围来初始化初始值，一般以输入通道数较为常见；对于全连接网络层则采用高斯分布即可；对于shortcut的batch norm，参数gamma初始化为零。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-08-11T16:30:28.055Z","path":"wiki/ML/trick/-过拟合-参数量/","text":"模型参数• 参数量大： 深度神经网络由于层次很多，参数量往往很大。ResNet-50有2500万参数量，AlexNet有6200万的参数量，而VGG-16参数量则达到1.38亿，有的语言模型参数量甚至超过10个亿[5]。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"分布式集群","date":"2018-08-11T16:00:00.000Z","path":"wiki/ML/deep learning/加速 分布式集群/-集群/","text":"为了弥补性能的差距，一些研究人员已经把工作重点放在探索如何有效利用大规模并行处理器训练深度神经网络上面。 大多数扩展ImageNet训练的成功方法，都使用了同步随机梯度下降（SGD）。但是，为了扩展同步SGD，必须增加每次迭代中使用的批量的大小。 多机多卡扩展性差深度训练通常采用数据并行模式，数据并行模式将样本分配给不同的GPU进行训练。相比模型并行，数据并行简单且可扩展，成为目前主流的分布式训练方式。 分布式训练数据并行模式下，经典的部署方式是独立的参数服务器（Parameter Server）来做训练过程中梯度的收集、分发和更新工作，每一次迭代所有的GPU都要与PS多次通信来获取、更新参数；当节点超过一定数量时，PS的带宽以及处理能力将成为整个系统的瓶颈。 AI训练系统和传统后台系统之间的一个最主要区别是，传统后台系统可以通过增加节点的方式来分担访问请求，节点之间没有强相关的关系；而AI训练系统在训练模型时需要参与训练的所有节点都不断的与模型参数服务器交换和更新数据。 所以如何在架构部署和算法层面减少对带宽需求，控制多机扩展中参数传输对训练速度的影响，使AI训练集群性能可线性扩展，是AI面临的另一项挑战。 疑问: 通常参数服务器是CPU还是GPU？ 官方示例cifar10_multi_gpu中，采用CPU作为参数服务器进行收集(average_gradients)、分发、更新参数(apply_gradients) 超大规模GPU集群（1024+GPUs）线性扩展能力参数更新去中心化数据并行训练方式下，每一次迭代都需要做梯度规约，以TensorFlow为代表的经典分布式训练部署方式中，中心化的参数服务器（Parameter Server）承担了梯度的收集、平均和分发工作，这样的部署方式下PS的访问带宽容易成为瓶颈，严重影响可扩展性，机智团队最初应对方法是引入HPC领域常用的去中心化的Allreduce方式，然而目前流行的NCCL2或baidu-allreduce中的Allreduce采用的基于环形拓扑的通信方式，在超大规模GPU集群场景下数据通信会有很大的延时开销。 机智团队进一步将Allreduce算法进行了改进，并成功的部署在1024+GPUs的异构集群中，达到了理想的扩展效率。 利用分层同步和梯度分段融合优化Ring Allreduce好复杂，后面再看… 扩展阅读-4分钟训练ImageNet！腾讯创纪录 | 机器之心","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"加速 分布式集群","slug":"ML/deep-learning/加速-分布式集群","permalink":"http://yoursite.com/categories/ML/deep-learning/加速-分布式集群/"}]},{"title":"深入研究 矩阵乘法优化","date":"2018-08-11T09:32:55.788Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/0. 矩阵计算/-矩阵乘法-高性能-实现原理/","text":"gemm指的是普通矩阵乘法（General Matrix Multiplication）而gemv指的是普通矩阵向量乘法（General Matrix Vector） BLAS关于矩阵乘法的API sgemm 加速策略关于硬件单核2048大小的双精度矩阵乘法大概4s，机器为XP系统，I3,2.1Ghz，三级缓存3M。 扩展 how-to-optimize-gemm | github","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"0. 矩阵计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/"}]},{"title":"","date":"2018-08-11T09:00:56.417Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/2. dnn库/-卷积操作/","text":"充分利用局部性 空间局部性 访问周围的数据 减少随机访问 时间局部性 重复使用 扩展阅读 computer system: a programemr’s perspective 2003","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"2. dnn库","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/2-dnn库","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/2-dnn库/"}]},{"title":"BLAS","date":"2018-08-11T08:27:52.344Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/0. 矩阵计算/BLAS/","text":"什么是BLASBLAS是 Basic Linear Algebra Subprograms （基本线性代数子程序）的首字母缩写，主要用来做基础的矩阵计算，或者是向量计算。它分为三级： BLAS 1级，主要是向量与向量的计算 BLAS 2级，主要是矩阵和向量的计算 BLAS 3级，主要是矩阵和矩阵的计算，最典型的是A矩阵*B矩阵，得到一个C矩阵。 为什么BLAS是一个非常重要的库或者接口，是因为它是很多科学计算的核心之一。每年做超级计算机的排行榜，都要做LINPACK测试，该测试很多部分就是做BLAS 3级矩阵和矩阵的计算。此外，还有很多科学和工程的模拟，在转换后都变成了一种矩阵上的操作。如果你把矩阵优化的特别好的话，对整个应用的提升，都是非常有帮助的。 广泛用于LAPACK 疑问: 有没有tensor计算？tensor计算要转化成以上三个级别的计算吗？没有。numpy支持高阶矩阵(多维数组)计算。 注意subprograms这个词，表示线性代数库的子项目 BLAS与深度学习经过测试，发现Alexnet大部分的时间花费在卷积层（Conv Layer），另外不少时间花在了全连接层（FC layer）。 卷基层目前通用的实现是展成矩阵，变成矩阵与矩阵的乘法，就是BLAS 3级。 全连接层一般是变成一个矩阵和向量的乘法，也落成了BLAS操作。 也就是说，基于矩阵类学习的深度学习，有90%或者更多的时间是通过BLAS来操作的。当然，随着新的算法出现，卷积层对3*3的卷积核有专门的算法，或者用FFT类类算法也可以做，但是在通用上，展矩阵来做也非常广泛。 疑问: cuda也兼容BLAS接口吗？还是自己独立的接口？ BLAS实现BLAS只是定义了接口，但是具体的实现其实有很多种。从商业的角度来讲，存在很多商业版本。基本上为了搭配自己的硬件，对其做了更优的优化。常见的商业版本有 Intel MKL AMD ACML NVIDIA CUBLAS IBM ESSL 开源 GotoBLAS:（2010年中止开发） ATLAS: 美国一所学校开发 OpenBLAS: 基于GotoBLAS BLIS: 基于GotoBLAS扩展出来的一个项目","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"0. 矩阵计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/"}]},{"title":"矩阵乘法","date":"2018-08-11T02:48:56.413Z","path":"wiki/CS/parallel computing-高性能计算/线性代数-blas-lapack-numpy/0. 矩阵计算/-矩阵计算/","text":"矩阵分解gemmgemm指的是普通矩阵乘法（General Matrix Multiplication） gemvgemv指的是普通矩阵向量乘法（General Matrix Vector） 共享内存 参考：https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"线性代数-blas-lapack-numpy","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/"},{"name":"0. 矩阵计算","slug":"CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/线性代数-blas-lapack-numpy/0-矩阵计算/"}]},{"title":"cuda编程模型","date":"2018-08-10T16:00:00.000Z","path":"wiki/CS/parallel computing-高性能计算/-cuda/cuda编程模型/","text":"基础unified memory architectureaccessible from cpu and GPU 编程模型KernelsCUDA C通过允许程序员定义C函数(称为内核)来扩展C，当调用时，由N个不同的CUDA线程并行执行N次，而不是像常规的C函数那样只执行一次。 kernel function用global关键字标记，这样的函数能够在GPU上并行计算。 使用global声明说明符定义内核，并使用新的&lt;&lt;&lt;…执行配置语法(参见C语言扩展)。执行内核的每个线程都有一个惟一的线程ID，该ID可以通过内置的threadIdx变量在内核中访问。 以下是两个N维向量的加法，$ C = A + B $: 传统写法：1// todo cuda编程1234567891011121314// 首先定义内核函数 (采用__global__关键字)__global__ void VecAdd(float* A, float* B, float* C)&#123; int i = threadIdx.x; C[i] = A[i] + B[i];&#125;int main()&#123; ... // Kernel invocation with N threads VecAdd&lt;&lt;&lt;1, N&gt;&gt;&gt;(A, B, C); ...&#125; 这里，N个线程同时计算VecAdd，进行元素加和。 疑问：并行度设置为1呢，设置为其他数值呢？ 效果对比： 源码下载： 线程层次结构在cuda中，线程ID（threadIdx)是一个三维向量，因此可用一维、二维或三维线程索引来标识线程，从而形成一维、二维或三维线程块(thread block)。这方便我们进行向量、矩阵或卷的计算。 线程的索引及其线程ID以一种简单的方式相互关联: 一维块，线程的索引 = 线程ID 大小是$(D_x, D_y)$的二维块，索引为$(x, y)$的线程对应的线程ID是$(x + y Dx)$ 大小是$(Dx, Dy, Dz)$的三维块，索引为$(x, y, z)$的线程对应的线程ID是$(x + y Dx + z Dx Dy)$ 例如，下面的代码将大小为$N \\times N$的两个矩阵相加，$C = A + B$ : 123456789101112131415161718// Kernel definition__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])&#123; int i = threadIdx.x; // i,j 对应矩阵的两个维度 int j = threadIdx.y; C[i][j] = A[i][j] + B[i][j];&#125;int main()&#123; ... // Kernel invocation with one block of N * N * 1 threads int numBlocks = 1; // 为什么numBlocks=1？ dim3 threadsPerBlock(N, N); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); // 这里采用 ...&#125; FAQ内核是函数？是的，kernel is function，能够并行的function。 ## 扩展阅读 cuda programming-model cuda-samples","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"-cuda","slug":"CS/parallel-computing-高性能计算/cuda","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/cuda/"}]},{"title":"","date":"2018-08-10T13:29:02.762Z","path":"wiki/电子/芯片/-芯片架构/基础/","text":"词汇流处理器，Stream ProcessorSMXStreaming Multiprocessors CUDA执行模型是SIMT（单指令多线程），G80会在物理上把若干个（G80是8个）流处理器组合到一起，共享缓存，形成一个SM单元（Stream Multiprocessor）。因为单个SM里的所有流处理器共享缓存，所以CUDA模型里，会把多个Thread打包成一个Block，让Block内的线程在同一个SM里跑（实际执行粒度是Wrap，Block内的Threads不是同时跑的，但是线程切换开销极低，这个和CPU不同，因为显卡的寄存器数量巨大，可以理解为拥有很多个超线程的CPU，对超线程技术有了解很好理解，因为Intel的超线程技术就是分时调用Decoder但每个线程独享寄存器），Block内的线程间可以数据同步，不同Block间线程则不行。YouTube上有个视频很形象的把这种模型类比成OpenMP+MPI。 control 控制单元DMAGPUDirect allows you to DMA directly to GPU host memory.","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"","date":"2018-08-10T13:16:19.613Z","path":"wiki/电子/芯片/-芯片架构/架构汇总/","text":"","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"","date":"2018-08-10T13:15:31.884Z","path":"wiki/电子/芯片/-芯片架构/Pascal架构/","text":"from Maxwell to Pascal","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"","date":"2018-08-10T13:14:55.877Z","path":"wiki/电子/芯片/-芯片架构/Volta架构/","text":"","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"麦克斯韦架构 (Maxwell)","date":"2018-08-10T13:14:42.964Z","path":"wiki/电子/芯片/-芯片架构/Maxwell架构/","text":"Maxwell GPU的主要目标是提高性能-功耗比 Maxwell可以算Kepler的改进版架构。两个架构最明显的变化是在SMX单元和GPC单元上。Maxwell的SMM（之前叫SMX）单元从之前Kepler的包含192个CUDA Core下降到128个，但发射器从之前的每SMX一个变为了每SMM四个，目的是降低每个SMM单元的运算压力提升效率。增加了两个寄存器，然后L1缓存翻倍，GPC单元的L2缓存增加到了2M。 扩展阅读https://www.zhihu.com/question/23208778/answer/23922535","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"Fermi架构","date":"2018-08-10T12:52:48.871Z","path":"wiki/电子/芯片/-芯片架构/Fermi架构/","text":"扩展阅读 Fermi架构白皮书","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"开普勒架构","date":"2018-08-10T12:52:33.703Z","path":"wiki/电子/芯片/-芯片架构/Kepler架构/","text":"开普勒架构产品nvidia - 开普勒GPUSMX - 流式多处理器 这一创新的新型流式多处理器设计让应用到处理核心上的空间比例远高于控制逻辑单元上所应用的空间比例，从而可实现更高的处理性能和效率。 Kepler GK110 GPU由 71 亿个晶体管组成，是创造的一个工程奇迹。 Kepler 设计的初衷就是利用卓越的电源效率达到计算性能的最大化。该架构的创新之处在于使混合计算大大简化，适用于更广泛的应用，更容易获得。 Dynamic Parallelism - 动态创建工作 新的 Dynamic Parallelism 功能，使 Kepler GK110 GPU 能通过应用不返回主机 CPU 的数据而动态创建新线程。这能使多个程序有效地直接在 GPU 上运行，因为内核现在有能力独立承担所需的额外工作量。 任何内核可以启动另一个内核，并创建处理额外的工作所需的必要流程、事件和依赖，而无需主机 CPU的介入。这种简化的编程模式更易于创建、优化和维护。 扩展阅读 Nvidia - KEPLER架构白皮书 Nvidia - KEPLER架构","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"多GPU并行计算","date":"2018-08-10T12:45:20.397Z","path":"wiki/CS/parallel computing-高性能计算/-cuda/多GPU/","text":"单机多卡常用的tower loss的方式。 多机多卡Q: 业内有哪些成熟的GPU集群的解决方案？A: 哪方面需求？训练、运维、部署、调度、负载均衡？ Q: 主要是部署、调度和负载均衡吧A: docker+kubernetes+prometheus 我: 震惊，集群还分这么多种？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"-cuda","slug":"CS/parallel-computing-高性能计算/cuda","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/cuda/"}]},{"title":"cuda并行编程","date":"2018-08-10T12:44:59.997Z","path":"wiki/CS/parallel computing-高性能计算/-cuda/cuda简介/","text":"cudacuda全程 Compute Unified Device Architecture. 2009年nvidia引入tesla架构，创造了cuda。 cuda是专门为Nvidia GPU的提供的C/C++ API，是GPU计算资源的高层抽象(兼容不同架构、不同版本GPU)。 它的核心是三个关键的抽象—— 线程组的层次结构(hierarchy of thread groups): 共享内存(shared memories): 障碍同步(barrier synchronization): 它们只是作为最小的语言扩展集公开给程序员。 这些抽象提供细粒度数据并行性和线程并行性，嵌套在粗粒度数据并行性和任务并行性中。 扩展阅读 cuda c programming guide GPU Programming with CUDA | Youtube","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"-cuda","slug":"CS/parallel-computing-高性能计算/cuda","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/cuda/"}]},{"title":"","date":"2018-08-10T12:32:45.753Z","path":"wiki/电子/芯片/芯片类型/CPU/-CPU/","text":"FAQ控制流","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"芯片类型","slug":"电子/芯片/芯片类型","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/"},{"name":"CPU","slug":"电子/芯片/芯片类型/CPU","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/CPU/"}]},{"title":"","date":"2018-08-10T11:41:04.411Z","path":"wiki/others/通信/-调幅/","text":"调幅广播（535~1605kHZ为广播频段），AM调制，假定载波639KHZ（《中国之声》北京、天津AM调幅），那么1/4波长约为117.3m，即天线长约117.3m。 新闻中的中波电台发射塔，最高的发射塔高度达165米 所以确实需要很大的发射天线。作为发射电台，功率要大，效率要高，所以只能这么大个子了。 接收端则要求便携，效率不是首先要考虑的问题。一般用磁棒天线利用磁棒的高磁导率来缩小天线尺寸，所以10cm甚至更短的磁棒就够用了 FAQ调幅广播频率这么低也能发射，什么原理？如果天线太短，则说明发射极频率过高，反射厉害，信号也不稳定，不容易找到目标 低频的载频是可以发射的，只不过天线要长一些，功率要高些而已。 频率越高天线越短，反之越长，有公式 经验上，天线是四分之一的波长，例如GSM波长33cm，所以手机一般也就大于8cm长。 准确地说，天线是四分之一的电波长。如果导体在介电常数为n的介质中，则尺寸可以缩为原有的1/n。比如现在的2.4GHz陶瓷天线，可以做到只有大概一粒大米那么大 6M是妥妥的HF了…短波电台都是这个频率量级的，而中波电台现在都还很常见","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"通信","slug":"others/通信","permalink":"http://yoursite.com/categories/others/通信/"}]},{"title":"","date":"2018-08-10T11:40:33.854Z","path":"wiki/others/通信/-调频/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"通信","slug":"others/通信","permalink":"http://yoursite.com/categories/others/通信/"}]},{"title":"","date":"2018-08-10T11:36:26.424Z","path":"wiki/hardware/-嵌入式设备/对讲机/-通信/","text":"见 others","tags":[],"categories":[{"name":"hardware","slug":"hardware","permalink":"http://yoursite.com/categories/hardware/"},{"name":"-嵌入式设备","slug":"hardware/嵌入式设备","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/"},{"name":"对讲机","slug":"hardware/嵌入式设备/对讲机","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/对讲机/"}]},{"title":"","date":"2018-08-10T11:35:35.891Z","path":"wiki/others/通信/-对讲机通信/","text":"原理简单的讲，将声音加载到高频载波上发射过去，接收到后解码听到语音 协议 、 语音路由分类每个地区的协议不同，涉及计到国家安全。2G 对讲机三大协议：CDMA。频分多路。是否是标准化协议？每个地区的协议不同，涉及计到国家安全。和2G类似 语音路由是指对讲机在各种环境（是否在通话， 连接，断连各种附件）下，扬声能够正确的选择扬声器播放语音，麦克风发送语音。语音路由模块是对讲机的传统模块。 通常对讲机采用的TDD模式，同一时刻只能一个人说话。 为什么？ 单工模式对讲机一般是单工模式，一般没有全双工的，手机是全工模式。你按住，对方就不能说话了。dual-radio采用双工模式。连个车载对讲机的连接方式改变？在一个工作模式下。两个对讲机的同步，完全一致。没有主从。同步，是通过线连接的。自己设计通信协议。 双工模式频分双工(FDD)和时分双工(TDD)是两种不同的双工方式TDD用时间来分离接收和发送信道。在TDD方式的移动通信系统中，接收和发送使用同一频率载波的不同时隙作为信道的承载，其单方向的资源在时间上是不连续的，时间资源在两个方向上进行了分配。某个时间段由基站发送信号给移动台，另外的时间由移动台发送信号给基站，基站和移动台之间必须协同一致才能顺利工作。 全双工 FAQ怎么提高对讲机的通信距离？１，提高发射功率 对于手持机而言，发射功率一般可在0.5~5W之间选择；车载台可在10W~40W之间选择。如果使用低功率通讯有明显噪音而影响通信时，则换用较高发射功率，即可提高通讯质量和延长一定的通讯距离。理论上发射功率提高一倍，通讯距离大约可扩大至原距离的1.4倍。但如果发射功率无目的的随意加大也会带来耗电量增加，电磁辐射及干扰增加等负面影响。 2，尽量架高天线 大功率对讲机的优点大功率对讲机绕射能力强，通信越好。 为什么？ 对讲机在飞机上可以开机吗？相对于手机U/V频段的对讲机对航空安全影响特别大，航空通信频率基本上接近V频段的对讲机频率，而且对讲机的发射功率也很大，如果在飞机上使用对讲机，会干扰飞机通讯或者飞行，从而有可能造成事故。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"通信","slug":"others/通信","permalink":"http://yoursite.com/categories/others/通信/"}]},{"title":"对讲机软件","date":"2018-08-10T11:19:51.985Z","path":"wiki/hardware/-嵌入式设备/对讲机/软件/","text":"通讯录、未接来电等的结构为什么采用链表？链表的好处、插入、删除方便。查询会采用顺序查找。 通讯录、未接来电等的存储地址是否交叉？不交叉，独立地址空间。 比如老版本的手机，通讯录只能存200条。SIM卡通讯录只能存固定条数。 新版手机呢？地址空间是否会交叉？ 通讯录、未接来电等的是怎样存储的？以文件的形式存在flash上。不同的通讯录用偏移量表示。 面临的挑战：插入和删除会造成大量数据的移位，较多写操作。 解决办法是：在内存中插入和删除，然后统一写入flash上 貌似这个办法写操作更多吧？？ 之前没有缓存机制，整个链表在内存中构建好。用户从中间删除。 存储占用空间是否是固定的？如果是固定的为什么不采用数组的方式存储？加载对讲机开机时会加载。 每个链表有自己的id。比如通讯录链表的id=1，未接来电的id=3。如果内存中找不到该id，就会重新加载。","tags":[],"categories":[{"name":"hardware","slug":"hardware","permalink":"http://yoursite.com/categories/hardware/"},{"name":"-嵌入式设备","slug":"hardware/嵌入式设备","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/"},{"name":"对讲机","slug":"hardware/嵌入式设备/对讲机","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/对讲机/"}]},{"title":"对讲机 - 产品简介","date":"2018-08-10T11:18:40.054Z","path":"wiki/hardware/-嵌入式设备/对讲机/汇总/","text":"背景种类 无基站： -talk-around模式，直联。最基本的。根据功率，比如5W 2-3公里。。 带基站：警车、出租车。 车载 repeat模式： 漫游模式： 使用模式group call，别人就打不出来了。老大有priority call，能把别人挤下去。为什么不采用双工？技术无关。最早是模拟化协议，现在是数字化协议。全双工也可以做。用户习惯： 全双工复杂度高在哪？ 大厂商 摩托罗拉 FAQ对讲机为什么不采用FDD模式？ FAQ##","tags":[],"categories":[{"name":"hardware","slug":"hardware","permalink":"http://yoursite.com/categories/hardware/"},{"name":"-嵌入式设备","slug":"hardware/嵌入式设备","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/"},{"name":"对讲机","slug":"hardware/嵌入式设备/对讲机","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/对讲机/"}]},{"title":"Network In Network","date":"2018-08-10T10:04:22.236Z","path":"wiki/ML/deep learning/model-basic/CNN/-NIN/","text":"Network In Network 是发表于2014年ICLR的一篇paper。这篇文章采用较少参数就取得了Alexnet的效果，Alexnet参数大小为230M，而Network In Network仅为29M，这篇paper主要两大亮点： 1*1卷积的意义：","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"","date":"2018-08-10T09:00:43.732Z","path":"wiki/hardware/-嵌入式设备/arm/","text":"","tags":[],"categories":[{"name":"hardware","slug":"hardware","permalink":"http://yoursite.com/categories/hardware/"},{"name":"-嵌入式设备","slug":"hardware/嵌入式设备","permalink":"http://yoursite.com/categories/hardware/嵌入式设备/"}]},{"title":"bazel简介","date":"2018-08-09T11:35:26.610Z","path":"wiki/CS/tools/build/-bazel/-bazel简介/","text":"简介什么是Bazel？Bazel是一种用于软件自动化构建和测试的工具 为什么要用Bazel？Bazel是一个类似于Make的编译工具，是Google为其内部软件开发的特点量身定制的工具，如今Google使用它来构建内部大多数的软件。Google认为直接用Makefile构建软件速度太慢，结果不可靠，所以构建了一个新的工具叫做Bazel，Bazel的规则层级更高。 Bazel的核心理念是： 把一个项目分成若干个packages，在每个packages目录下需要放一个构建文件，包括这个包的信息。一个package中除了规则文件外，其余的文件，目录以及子packages都叫“targets”。 packages里要写明依赖关系，Bazel会知道哪些需要重新编译（只会编译修改后的包，及那些依赖于修改包的包） 判断一个变化是否是包内部的变化。举例，在一个库中新增了一个helper函数，对于那些依赖于这个库的包，我们无需去重建，这就是内部变化；而要是改变了这个库的一个方法名称，这时候就要重建那些包了。 怎样用Bazel？ bazel编译C++ 入门 | 英文原文 bazel编译C++ 入门 | 翻译 bazel构建函数大全 bazel构建函数 123# target: BUILD文件中的每一条编译指令被称为一个target，它指向一系列的源文件和依赖，一个target也可以指向别的target。- cc_binary: Binary rules- cc_library: Library rules Bazel是怎样工作的？bazel的作用 将tensorflow的C++ api编译成可执行文件，示例 https://www.tensorflow.org/api_guides/cc/guide 将tensorflow的python api编译成可执行文件 将tensorflow的python api编译成.so 123456789# 从github下载tensorflow源代码git clone --recursive https://github.com/tensorflow/tensorflow## 进入根目录后编译# 编译生成.so文件, 编译C++ API的库 (建议)bazel build //tensorflow:libtensorflow_cc.so# 也可以选择,编译C API的库bazel build //tensorflow:libtensorflow.so 扩展阅读 FAQ | Bazel []-https://zhuanlan.zhihu.com/p/27286391","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"tensorflow 架构","date":"2018-08-08T06:28:51.859Z","path":"wiki/ML/deep learning/toolbox/tensorflow/architecture/","text":"Tensorflow是一个跨平台库。C API之上兼容很多不同的编程语言。 Client: Defines the computation as a dataflow graph. Initiates graph execution using a session. Distributed Master Prunes a specific subgraph from the graph, as defined by the arguments to Session.run(). Partitions the subgraph into multiple pieces that run in different processes and devices. Distributes the graph pieces to worker services. Initiates graph piece execution by worker services. Worker Services (one for each task) Schedule the execution of graph operations using kernel implementations appropriate to the available hardware (CPUs, GPUs, etc). Send and receive operation results to and from other worker services. Kernel Implementations Perform the computation for individual graph operations. 各个模块- layers module provides a high-level API that makes it easy to construct a neural network High Level APIs Eager Execution, which is the easiest way to use tensorflow. Estimators, which introduces a high-level TensorFlow API that greatly simplifies ML programming. Importing Data, which explains how to set up data pipelines to read data sets into your TensorFlow program. 参考 TensorFlow Architecture | 官方 programmers guide | 官方","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"【trick】数值计算","date":"2018-08-08T03:12:41.434Z","path":"wiki/ML/app/nlp/trick/trick-数值计算/-定点化/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-数值计算","slug":"ML/app/nlp/trick/trick-数值计算","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-数值计算/"}]},{"title":"chain model","date":"2018-08-08T02:37:23.689Z","path":"wiki/-audio/ASR/声学模型/chain-model/","text":"chain类似马尔科夫，TDNN虽然体现了context，但是前后马尔科夫性。用了bi-gram的phone。 1 chain model相对tdnn变化？1）准则方面：由帧级别的准则变为一个片段或一段语音的准则2）数据方面：由于低帧率原因，加入了一些扩充数据的方法3）网络结构方面：可以跨层连接 2 chain model前端的变化？HMM tri-phone聚类后变为bi-phone，并且HMM状态之间可以跳跃转移而不是相邻之间，以用来适应后面网络结构的变化。 #","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"","date":"2018-08-07T14:31:54.755Z","path":"wiki/-audio/TTS/model/wavenet/","text":"2016年Google发布的Wavenet语音合成系统。 Wavenet的系统架构非常有意思，融合了dilated CNN，残差网络，CTC，LSTM中的门，1*1卷积核等经典结构： CTC可以说是现在端到端语音识别系统的标配，它解决了文本序列和神经网络模型输出的一对多映射问题，因此可以搭建端到端系统。 11卷积核的研究最早见于14年的论文Network In Network，后来谷歌在Inception的模型中发扬光大。它的作用是整合多通道信息进行非线性变换，并且可以进行通道升降维（卷积核都有升降维的左右，但11卷积核的优点是参数更少），因此在神经网络模型中可以跳跃链接（见Residual部分，匹配相连层的通道数）。 残差神经网络结构的核心是将之前的输入跳跃连接到n层后的输出，可以解决深层网络的梯度弥撒问题；Wavenet模型采用分block策略，每个block的输入和输出相加，然后再作为下一个block的输入，每层包含128。 经典的门结构见于LSTM模型，可以对输入信息进行有效选择，应用在长距离（长时）有效信息相关性的架构中，比如自然语言处理。 dilated CNN模型可以增加卷积核的感受野，利用更长距离的上下文信息： 程序实现中，采用的策略有： Xavier权值初始化策略； 每次epoch的数据随机打乱策略； Batch Normalization策略； 因为硬件资源GPU的限制，目前只实现了3个block，每个block包含五层dilated卷积层； 采用Adam参数学习策略。 扩展阅读 用Wavenet做中文语音识别 | 知乎","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"TTS","slug":"audio/TTS","permalink":"http://yoursite.com/categories/audio/TTS/"},{"name":"model","slug":"audio/TTS/model","permalink":"http://yoursite.com/categories/audio/TTS/model/"}]},{"title":"","date":"2018-08-07T14:24:13.610Z","path":"wiki/-audio/ASR/声学模型/综述/","text":"目前主流的语音识别系统普遍采用基于深度神经网络和隐马尔可夫（Deep Neural Networks-Hidden Markov Model，DNN-HMM）的声学模型，其模型结构如图 1所示。声学模型的输入是传统的语音波形经过加窗、分帧，然后提取出来的频谱特征，如 PLP， MFCC 和 FBK等。而模型的输出一般采用不同粒度的声学建模单元，例如单音素 (mono-phone)、单音素状态、绑定的音素状态 (tri-phonestate) 等。从输入到输出之间可以采用不同的神经网络结构，将输入的声学特征映射得到不同输出建模单元的后验概率，然后再结合HMM进行解码得到最终的识别结果。 最早采用的网络结构是前馈全连接神经网路（Feedforward Fully-connected Neural Networks, FNN）。FNN实现固定输入到固定输出的一对一映射，其存在的缺陷是没法有效利用语音信号内在的长时相关性信息。一种改进的方案是采用基于长短时记忆单元（Long-Short Term Memory，LSTM）的循环神经网络（Recurrent Neural Networks，RNN）。LSTM-RNN通过隐层的循环反馈连接，可以将历史信息存储在隐层的节点中，从而可以有效地利用语音信号的长时相关性。","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"【语言模型】- 综述","date":"2018-08-07T14:18:53.435Z","path":"wiki/-language_model/-model/nnlm/related-work/","text":"基础RNN CNN的发展lstmcudnn-lstmsru softmax的发展语言模型发展（增量介绍） Class-Based n-gram Models of Natural Language(1992), Peter F. Brown et al. [pdf] An estimate for an upper bound for the entropy of English (1992), [pdf] 神经概率语言模型的第一篇论文，使用了WordNet作为先验知识； An empirical study of smoothing techniques for language modeling(1996), Stanley F. Chen et al. [pdf] A Neural Probabilistic Language Model(2000), Yoshua Bengio et al. [pdf] A new statistical approach to Chinese Pinyin input(2000), Zheng Chen et al. [pdf] A Neural Probabilistic Language Model(2003), Yoshua Bengio et al. [pdf] Hierarchical probabilistic neural network language model(2005) [pdf] 在【2】的基础上将词汇分层得到的，优化了算法的时间复杂度； Discriminative n-gram language modeling(2007), Brian Roark et al. [pdf] Three new graphical models for statistical language modelling (2007) Hinton et al. [pdf] A scalable hierarchical distributed language model(2009) Hinton et al. [pdf] 在【9】的基础上将词汇分层得到 Neural Network Language Model for Chinese Pinyin Input Method Engine(2015), S Chen et al. [pdf] Efficient Training and Evaluation of Recurrent Neural Network Language Models for Automatic Speech Recognition(2016), Xie Chen et al. [pdf] Exploring the limits of language modeling(2016), R Jozefowicz et al. [pdf] On the State of the Art of Evaluation in Neural Language Models(2016), G Melis et al. [pdf] ngram分类汇总按照粒度 char-based model subword-based model - no OOV rate, smaller model size and better speed. Subword Language Modeling with Neural Networks. word-based model phrase-based model 加速 - softmax对损失函数的近似方法 采用NCE和HS加速softmax的计算 https://github.com/yandex/faster-rnnlm NCE HS class-based softmax adaptive-softmax [pdf] code-tf code-pytorch 加速 - rnn cell vanila rnn lstm gru qusi-rnn sru nnlm经典/传统 rnnlm code pdf 正则化约束subword - lmchar - lm- faster-rnnlm lm应用 asr，kaldi mikolov- 模型融合rescore策略其他trick oov的penalty- 参考 https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers#language-modelling https://people.csail.mit.edu/regina/6881/ http://www.fit.vutbr.cz/~imikolov/rnnlm/","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"},{"name":"nnlm","slug":"language-model/model/nnlm","permalink":"http://yoursite.com/categories/language-model/model/nnlm/"}]},{"title":"","date":"2018-08-07T14:02:44.658Z","path":"wiki/-audio/ASR/声学模型/BLSTM/","text":"latendy controlled 的 BLSTM必须要等到一句话说完了才开始去做解码，得到结果，就造成说完这句话后要等很久才能拿到结果，这当然是坏处，但为什么大家还是那么着迷呢，因为好处是精度特别高，准确程度高。 我们做的工作就是能够把识别的延迟降下来，使得它能够在边说话就边解码，而不是像以前一样，要等到这句话结束后才能够进行解码，达到一个既快又好的效果。 参考： 15 年的时候，阿里 latendy controlled 的 BLSTM 模型，叫 LC-BLSTM 模型 Low frame rate latendy controlled 的 BLSTM原来语音识别的帧率大约是 100 帧每秒，每秒钟要计算100个 frame，运算量不容忽视，所以我们去年有一个方法叫 Low frame rate，把 100 帧每秒的速率，降到三分之一，相当于同样是 1 秒钟的语音，处理起来只需要原来运算量的三分之一了。同时保证了跟以前一样甚至更好的精度。","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"声学模型","date":"2018-08-07T13:56:01.835Z","path":"wiki/-audio/ASR/声学模型/papers/","text":"语音识别有一个重要的模型叫声学模型，就是来模拟a,o,e,b,p,m,f 是怎么发音的，这个也是提高语音识别准确率的重要手段。 research BLSTM 模型很慢 2014 - Deep Speech | 百度 2015 - Deep Speech 2 | 百度 CLDNN:NIN: 第一个前沿问题是如何构建更有效的序列到序列(Sequence-to-Sequence)直接转换的模型，目前最佳的解决方案是把 CTC 与Attention 结合起来，CTC有持续信息，可根据后面的语音信号生成词，这有助于Attention生成更好的表达，两者结合比CTC、Attention各自训练效果更好，所以是一个1+1大于2的结果。 当前主流LSTM、CNN并未占工程主流。没有超过Kaldi最有模型TDNN+chain。（不靠谱的回答）","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"","date":"2018-08-07T11:56:49.862Z","path":"wiki/ML/deep learning/model-basic/-TDNN/","text":"见ASR目录","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"NPM 与Yarn","date":"2018-08-07T01:23:18.308Z","path":"wiki/CS/web/-back-end/node/-包管理工具/","text":"Yarn 是 Facebook, Google, Exponent 和 Tilde 开发的一款新的 JavaScript 包管理工具。它的目的是解决这些团队使用 npm 面临的少数问题，即： 安装的时候无法保证速度/一致性 安全问题，因为 npm 安装时允许运行代码 npmnpm是Node.js的包管理工具（package manager）。为啥我们需要一个包管理工具呢？因为我们在Node.js上开发时，会用到很多别人写的JavaScript代码。如果我们要使用别人写的某个包，每次都根据名称搜索一下官方网站，下载代码，解压，再使用，非常繁琐。于是一个集中管理的工具应运而生：大家都把自己开发的模块打包后放到npm官网上，如果要使用，直接通过npm安装就可以直接用，不用管代码存在哪，应该从哪下载。 更重要的是，如果我们要使用模块A，而模块A又依赖于模块B，模块B又依赖于模块X和模块Y，npm可以根据依赖关系，把所有依赖的包都下载下来并管理起来。否则，靠我们自己手动管理，肯定既麻烦又容易出错。 npm已经在Node.js安装的时候顺带装好了 对比其他包管理器 npm在不使用-g参数时，默认把package安装在当前目录的node_modules下，不会污染系统环境。 pip虽然可以指定安装目录，但是如果要换目录安装，你还需要更新配置文件（麻烦）。python的包安装要不污染环境，需要其它的工具实现。这样也有优势，可以共享，不占用磁盘空间。 对于pip的使用，可以在virtualenv建立的虚拟环境下安装包，不会污染环境 package.json的写起来比setup.py爽…… npm和nodejs的关系npm是nodejs的包管理工具，npm随nodejs一同安装 (从 Node.js 0.6.3 开始，npm 集成到了 Node.js 的安装包里面) 两者的关系相当于 pip -&gt; python 或 gem -&gt; ruby 或maven 和 Java 之间的关系 npm与npx如果你把NPM升级到最新版本，npm@5.2.0，可能会发现，它会安装一个新的包npx。 npx是一个工具，旨在提高从npm注册表使用软件包的体验 ，npm使得它非常容易地安装和管理托管在注册表上的依赖项，npx使得使用CLI工具和其他托管在注册表。它大大简化了一些事情，到目前为止，如何安装npx： Yarn vs npm: 功能差异扩展阅读 Yarn vs npm: 你需要知道的一切","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"node","slug":"CS/web/back-end/node","permalink":"http://yoursite.com/categories/CS/web/back-end/node/"}]},{"title":"TDNN时延神经网络","date":"2018-08-06T16:00:00.000Z","path":"wiki/-audio/ASR/声学模型/TDNN/","text":"CNN是受语音信号处理中时延神经网络（TDNN）影响而发明的。 1989年本篇的大部分内容都来自关于TDNN原始文献【1】的理解和整理。该文写与1989年，在识别”B”, “D”, “G”三个浊音中得到98.5%的准确率，高于HMM的93.7%。是CNN的先驱。 简介时延神经网络(Time delay neural network, TDNN)是一种多层神经网络，主要用来 区分平移不变的特征 在每一层建模上下文信息 using a 3 layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces. 模型设计思想 要有多层，而且每层的units之间要有充分的交互1. 输入特征拼起来。前后10帧。另外一个思路：把DNN每一层之间建立一个联系，下一层的输入，不仅由上一层当前时刻输出，还把上一层前后输出都考虑。采用拼接的方式，增加了模型复杂度，可以拆分成两个矩阵。类似LSTM。 模型架构 TDNN 的 units 独立于时间位移（i.e. sequence position）识别特征，通常用于组建一个更大的模式识别系统。例如，将连续的音频转换为分类号的音素（phoneme）标签 stream 来做语音识别。 一个输入信号用延迟的复制s增强（augmented）作为其他输入，神经网络是时移不变的，因为它没有内部状态。 相关进展TDNN+chain-model。。 16年，povey在kaldi的nnet3中增加chain-model。 FAQDNN网络可以用1维卷积实现吗？把输入序列当成16通道1xn的图片即可。 扩展阅读 TDNN - wiki TDNN时延神经网络 | CSDN 图1没看懂，","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"【深度学习-RNN系列】RNN的变种 以及提高RNN训练速度的多种方法","date":"2018-08-06T11:08:53.000Z","path":"wiki/ML/deep learning/model-basic/RNN/summary/","text":"最受欢迎的两个循环单元是长短期记忆（LSTM）和门控循环单元（GRU），两者都可以将先前的记忆存储在隐藏状态，并使用门控机制来确定应该在何种程度将先前的记忆应与当前的输入结合。但是，由于其循环的结构，RNN不能并行计算。因此，训练RNN需要花费大量时间，这限制了学术研究和工业应用。 为了解决这个问题，一些学者尝试在NLP领域使用卷积神经网络（CNN）来代替RNN。但是，CNN无法获得序列的顺序信息，而顺序信息在NLP任务中非常重要。 线性激活函数 简介 瓶颈 训练速度 模型收敛 (梯度消失、弥散) 针对LSTM结构的加速策略 合并input gate和forget gate：GRU、SRU 合并cell state和hidden state: GRU、 分割成多个子序列来实现并行化 SRNN。它在不改变循环单元的情况下，能够比标准RNN快得多- 针对模型收敛的优化 LSTM shortcut TODSRU+slice。有必要吗？貌似没必要了。SRU中计算","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"数学史","date":"2018-08-05T01:32:27.539Z","path":"wiki/Math/-数学史/","text":"时间轴ß 公元前580年 毕达哥拉斯 这个学派企图⽤数来解释⼀切，不仅仅认为万物都包含数，⽽且说万物都是数。 发现勾股定理(毕达哥拉斯定理) 把算数和⼏何图形结合起来 正多面体最多有5种 4，6，8，12，20 ⾸创地圆说，认为⽇、⽉、五星都是球体 希波战争后，雅典的巧辩学派提出了几何作图的三大问题(只使用没有刻度的尺规)： 三等分任意角 倍立方 - 求作一个立方体，使其体积等于一直立方体的两倍 化方为圆 - 求作一个正方形，使其面积等于已知圆 欧几里得 公元前427-347 柏拉图， 圆锥曲线、抛物线、椭圆、双曲线 亚里士多德 （柏拉图学生） 原⼦论学派 以德谟克⾥特为代表的原⼦论学派认为，线段、⾯积和⽴体是由许多不可再分的原⼦所构成。计算⾯积和体积，等于将这些原⼦集合起来。这种不甚严格的推理⽅法却是古代数学家发现新结果的重要线索。(挺有道理的啊，极限、采样就是这种思想吧)- 17世纪出现的解析⼏何学、微积分学 毕达哥拉斯毕达哥拉斯学派试图用数来解释一切","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"}]},{"title":"","date":"2018-08-04T03:43:04.381Z","path":"wiki/Math/-疑问/","text":"0.9999…和1相等吗？为什么？ 整数和偶数都是无限的，数量一样多吗？有什么深层次的意义？","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"}]},{"title":"python3","date":"2018-08-04T02:48:18.575Z","path":"wiki/CS/programing/lan/python/python3/-python3/","text":"python3buhui zhixing daduoshu zhendui python2解释器所写的旧代码。 在过去的数年里，python稳定性得以保持的主要原因之一就是，核心开发团队保持python后向兼容性的坚定决心(python2能正常运行python1.5.2的软件)。然而，创造者Guido van Rossum、Andrew Kuchling以及其他用户发现了某些“粘性”缺陷（存在于不同版本之间的问题）。需要发行一个包含重大变化的版本以确保该语言的明显进步。2008年发行的python3.0版本，标志着故意打破后向兼容性原则的python解释器第一次发布。 python3有哪些变化 print变成了print() 字符串默认转换为Unicode编码 增加了一个单类（single class）类型 更新了异常的语法 更新了整数 迭代无处不在 print变成了print()为什么要将其从一条语句变化成一个内置函数（BIF）呢？因为 将print作为声明会在很多方面受到限制。 print作为语句将闲置对它的改进。而作为print()，就可以添加新的关键字参数，能够利用关键字参数覆写某些标准行为，并且也可以根据需求来替代print() TODO：加入更多例子 字符串默认转换为Unicode编码","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"python3","slug":"CS/programing/lan/python/python3","permalink":"http://yoursite.com/categories/CS/programing/lan/python/python3/"}]},{"title":"深度前馈序列记忆网络（DFSMN）","date":"2018-08-01T16:00:00.000Z","path":"wiki/-audio/ASR/声学模型/DFSMN/","text":"近日，阿里巴巴达摩院机器智能实验室开源了新一代语音识别模型DFSMN，将全球语音识别准确率纪录提高至96.04%（这一数据测试基于世界最大的免费语音识别数据库LibriSpeech）。对比目前业界使用最为广泛的LSTM模型，DFSMN模型训练速度更快、识别准确率更高。 阿里巴巴（科大的一位博士）张世良搞 阿里巴巴达摩院机器智能技术实验室语音识别团队于即日推出了新一代语音识别模型——DFSMN，与此同时团队已将这一模型开源。 深度前馈序列记忆网络（DFSMN） 使用基于 BLSTM 的统计参数语音合成系统作为基线系统，采用广泛使用的跳跃连接技术，在执行反向传播算法时，梯度可以绕过非线性变换。而官方介绍，对比目前业界使用最为广泛的 LSTM 模型，训练速度更快、识别准确率更高。采用全新 DFSMN 模型的智能音响或智能家居设备，相比前代技术深度学习训练速度提到了 3 倍，语音识别速度提高了 2 倍。 模型DFSMN≈TDNN+ResNet 就是一个普通的全链接模型+残差记忆模块参数特别难调 扩展阅读 code | github 阿里开源自研语音识别模型DFSMN | 知乎专栏","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"","date":"2018-08-01T15:48:55.372Z","path":"wiki/docker/advanced/-容器管理/","text":"ss 扩展阅读http://wudaijun.com/2018/03/docker-container-ops/","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-08-01T09:46:53.140Z","path":"wiki/CS/tools/build/-bazel/-trouble-shooting/","text":"可能出现的问题OOM：最好先增加下 swap 的空间： 123456# 生成swap镜像文件sudo dd if=/dev/zero of=/mnt/1024Mb.swap bs=1M count=1024# 对该镜像文件格式化sudo mkswap /mnt/1024Mb.swap# 挂载该镜像文件sudo swapon /mnt/1024Mb.swap 使用free -m 即可查看到swap空间已经增加成功","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"","date":"2018-08-01T09:30:09.335Z","path":"wiki/CS/tools/build/-bazel/-bazel-building-java-project/","text":"扩展阅读https://docs.bazel.build/versions/master/tutorial/java.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"","date":"2018-08-01T09:25:49.587Z","path":"wiki/CS/tools/build/-bazel/-how-bazel-works/","text":"bazel的作用 将tensorflow的C++ api编译成可执行文件，示例 https://www.tensorflow.org/api_guides/cc/guide 将tensorflow的python api编译成可执行文件 将tensorflow的python api编译成.so 123456789# 从github下载tensorflow源代码git clone --recursive https://github.com/tensorflow/tensorflow## 进入根目录后编译# 编译生成.so文件, 编译C++ API的库 (建议)bazel build //tensorflow:libtensorflow_cc.so# 也可以选择,编译C API的库bazel build //tensorflow:libtensorflow.so","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"【bazel系列】tensorflow的java编程","date":"2018-08-01T09:23:10.123Z","path":"wiki/CS/tools/build/-bazel/-tensorflow-with-java/","text":"tensorflow有jar包。 FAQ","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"","date":"2018-08-01T08:31:33.359Z","path":"wiki/ML/app/nlp/-多音字/","text":"特征工程方法输入一句话，把每个字拼音标出来，涉及到多音字。用分类器做预测。两个改进：1. 特征优化、筛选。 2. 训练语料增加数据。窗口大小是5，前后各一个词。 线性分类，对简单的多音字。作为、为什么。交叉熵效果不太好，就用SVM。没读多少相关paper。前后的拼音不重要，词性重要。没有加语义特征？没句法分析的结构。 其他方法","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"}]},{"title":"","date":"2018-08-01T05:24:22.637Z","path":"wiki/-audio/ASR/-语音唤醒/","text":"简介一般VAD + 小模型ASR 挑战低功耗","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"}]},{"title":"","date":"2018-08-01T05:16:26.819Z","path":"wiki/CS/web/front-end/-前端工具/","text":"https://codepen.io/ CSS/Canvas/SVG 动画的灵感 Explore Pens on CodePen 分享代码片段, Github Gist JS Fiddle JS Bin CodePen 跟jsbin差不多，好像上面的代码大多数是CSS相关的 HackerRank. 这个严格说是个比赛／面试环境，实时性不错，其它跟jsfiddle大同小异。我司电面御用。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"}]},{"title":"","date":"2018-08-01T05:13:51.497Z","path":"wiki/CS/web/front-end/html5/-canvas/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"html5","slug":"CS/web/front-end/html5","permalink":"http://yoursite.com/categories/CS/web/front-end/html5/"}]},{"title":"【bazel系列】从源码安装tensorflow","date":"2018-07-31T16:00:00.000Z","path":"wiki/CS/tools/build/-bazel/-tensorflow-bazel-编译成whl/","text":"为什么要通过源码安装tensorflow？ 特定平台没有安装包，比如arm 对特定平台加速，(比如AVX指令集) 定制化 （OPENCL） 1234&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; tf.Session()2018-08-05 09:38:38.966050: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA# AVX是x86指令集的扩展，用于线性代数计算的加速(例如矩阵乘法、卷积等) 如果没有GPU，只在CPU上运行tensorflow的代码，那么最好从源码编译tensorflow，利用AVX、AVX2、FMA等进行优化。 有些tensorflow operation会在CPU上运行，不在GPU上运行。 Placing input pipeline operations on the CPU can significantly improve performance. Utilizing the CPU for the input pipeline frees the GPU to focus on training.1. 下载tensorflow源码1234# git clone http://10.31.39.11/xusong/tensorflow.gitgit clone https://github.com/tensorflow/tensorflow.gitcd tensorflowgit checkout r1.8 启动Docker环境12345NAME=xusong_tf_bazel2 # 命名你的容器nvidia-docker run -it \\ --name $NAME \\ -v `pwd`:/root/tensorflow1.8.0 \\ tensorflow/tensorflow:1.8.0-devel-gpu /bin/bash 编译tensorflow123456cd tensorflow1.8.0./configure # 全部采用默认配置# 把tensorflow源码编译成whl文件，编译后保存在/tmp/tensorflow_pkg目录下bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package#bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg 成功后，会编译成一个.whl文件。 安装tensorflow1pip install /tmp/tensorflow_pkg/tensorflow-1.9.0-py2-none-any.whl 验证1234import tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello)) 原理核心主要在以下命令：1bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/pip_package","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"【bazel系列】tensorflow的自动化构建","date":"2018-07-31T16:00:00.000Z","path":"wiki/CS/tools/build/-bazel/tensorflow-bazel-summary/","text":"bazel的作用 将tensorflow的C++ api编译成可执行文件，示例 https://www.tensorflow.org/api_guides/cc/guide 将tensorflow的python api编译成可执行文件 将tensorflow的python api编译成.so 下载tensorflow源码12# 从github下载tensorflow源代码git clone --recursive https://github.com/tensorflow/tensorflow 启动Docker环境12345NAME=xusong_tf_bazel # 命名你的容器nvidia-docker run -it \\ --name $NAME \\ -v `pwd`:/root/tensorflow1.8.0 \\ bitspeech/tensorflow:1.8.0-gpu-bazel /bin/bash 编译tensorflow123456## 进入根目录后编译# 编译生成.so文件, 编译C++ API的库 (建议)bazel build //tensorflow:libtensorflow_cc.so# 也可以选择,编译C API的库bazel build //tensorflow:libtensorflow.so 1. 首先跑通 https://github.com/tensorflow/models/tree/master/research/lm_1b 按教程编译 2.编译LM模型 BUILD文件配置示例文件 -https://github.com/tensorflow/models/blob/master/research/lm_1b/ https://github.com/tensorflow/tensorflow/blob/master/tools/bazel.rc 扩展阅读编译成安装包whl Bazel编译tensorflow源码为安装包whl | 官网 Bazel编译tensorflow Serving | 官网 编译成动态链接库so 或 dll Bazel编译tensorflow项目为动态链接库so | 官网 编译成可执行文件 Bazel编译tensorflow的C++代码为可执行文件 | 官网 Bazel编译语言模型为可执行文件 | 官网 其他 Tensorflow源码安装时bazel行为解析","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"build","slug":"CS/tools/build","permalink":"http://yoursite.com/categories/CS/tools/build/"},{"name":"-bazel","slug":"CS/tools/build/bazel","permalink":"http://yoursite.com/categories/CS/tools/build/bazel/"}]},{"title":"Sequence Modeling With CTC","date":"2018-07-31T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/RNN/-CTC/","text":"关于blank节点一般CTC需要与RNN或DNN结合使用。DNN与CTC模型在输出层引入一个“blank(空白)”节点,将两个发音单元之间混淆或不确定的区域映射到“blank”节点（传统“固定对齐边界”的方法将该“模糊”区域“强制”分类为左边标签、右边标签或者短停顿，存在天然的缺陷），这样，将传统的“轨迹”建模转化为“差异性”建模，使得模型更加关注一个发音单元与其它发音单元之间的“差异性”，缓减了传统模型需要完整地描述该发音单元全部信息的建模负担，可以参考 [1] 工具包 baidu-warpctc mxnet + baidu-warpctc https://zhuanlan.zhihu.com/p/21344595 疑问tesseract是否采用的CTC方法 CTC是否适用seq2seq问题。背景CTC解决的问题是，输入序列和输出序列数目不同的问题。seq2seq(翻译模型)也是这样的。 解答CTC适用于存在一一对应关系、主要利用局部context信息的问题，比如语音识别、OCR等。seq2seq则更适用于需要利用全局的context信息的场合，比如翻译，因为经常从局部context得不到足够的信息。 CTC要解决的是sequence labeling的问题。 seq2seq解决的是序列到序列的广义上的翻译问题，看起来是可以解决ctc的问题，但是由于其往往需要把整个输入压成一个fixd-length vector，会导致丢失很多的信息，同时其并没有输入输出的强制对应关系，对于语音识别或者OCR这种任务来说，约束力太弱了，因此虽然这个框架可以执行ctc的任务，但是效果应该不会很好。 https://www.zhihu.com/question/49043625 我的注释这个问题实质上是在问seq2seq和sequence labeling的区别。前者对生成的序列不需要顺序保持(例如机器翻译)，后者是需要顺序保持(例如NER、OCR、语音识别)。 如果用CTC处理翻译模型，基本就是逐字翻译的效果了。貌似还不是这样，CTC是sequence labeling的问题，有序label，顺序不能变。 首先要区分seq2seq和sequence labeling这两个问题。seq2seq解决的是序列到序列的广义上的翻译问题， lstm+attention解决seq2seq问题， 参考paper &amp; blog Sequence Modeling With CTC | Distill Supervised Sequence Labelling with Recurrent Neural Networks | Alex Graves 语音识别中的CTC方法的基本原理？ | 知乎 fds code","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"","date":"2018-07-31T12:59:49.323Z","path":"wiki/-audio/前端信号处理/语谱图/","text":"语谱图 基频 图1虚框框住的部分就是一条横条纹，整个谱图中有非常多的这种横条纹。图2虚框框住的部分，在小图中清晰的显示出了一条一条的“竖线”，被框住的有27条竖线。 从窄带语谱图和宽带语谱图看基音频率和共振峰参考https://blog.csdn.net/lzrtutu/article/details/78882715","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"语音信号处理中基频提取算法","date":"2018-07-31T12:40:51.206Z","path":"wiki/-audio/前端信号处理/基频提取算法/","text":"当语音是一个干净的语音时，大部分的基频提取算法的结果都很好，但是当语音中混有较强的噪声，或者语音是多个语音的混合，从而同时含有多个基频的时候，很多现在的技术都表现得不好。 参考 《语音信号处理中基频提取算法综述》","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-31T12:37:07.152Z","path":"wiki/-audio/前端信号处理/低音增强/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-31T12:36:58.888Z","path":"wiki/-audio/前端信号处理/立体声增强/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"MFCC 梅尔频率倒频谱系数(MFCCs)","date":"2018-07-31T12:36:16.908Z","path":"wiki/-audio/前端信号处理/特征/MFCC/","text":"倒频谱倒频谱（cepstrum），顾名思义，就是将频谱（spectrum）的英文前四个字母反过来写。倒频谱是为了某些时候，为了计算方便，将原来信号的频谱先转成类似分贝的单位，再作逆傅里叶变换，把它视为一种新的信号做处理。倒频谱有复数倒频谱，及实数倒频谱。 倒频谱被定义在1963的论文（Bogert等）。 复数倒频谱与实数倒频谱梅尔频率倒频谱梅尔频率倒频谱是倒频谱的一种应用，梅尔频率倒频谱常应用在声音信号处理，对于声音信号处理比倒频谱更接近人耳对声音的分析特性，而梅尔频率倒频谱与倒频谱的差别在于: 梅尔频率倒频谱的频带分析是根据人耳听觉特性所设计，人耳对于频率的分辨能力，是由频率的”比值”决定，也就是说，人耳对200赫兹和300赫兹之间的差别与2000赫兹和3000赫兹之间的差别是相同的。 梅尔频率倒频谱是针对信号的能量取对数，而倒频谱是针对信号原始在频谱上的值取对数。 梅尔频率倒频谱是使用离散余弦变换，倒频谱是用离散傅里叶变换。 梅尔频率倒频谱系数足够描述语音的特征。","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"},{"name":"特征","slug":"audio/前端信号处理/特征","permalink":"http://yoursite.com/categories/audio/前端信号处理/特征/"}]},{"title":"","date":"2018-07-31T12:32:26.250Z","path":"wiki/-audio/前端信号处理/共振峰/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-31T08:07:38.343Z","path":"wiki/machine translation/2. 主流model-研究现状/1. SMT/-交互式机器翻译/","text":"对齐概率：P(1|0) P(2|0) P()。 英文30-60之间。 方向围边 P(E_9 E_11 E_12 | E_10.) 一般集中到周围。 address翻译成地址，也有演讲的意思。P(地址|address) 繁衍概率模型：P(次数| address)只翻译成一次。还有多大概率被翻译。between要被翻译2词。已经翻译了一次还被 语言模型：矩阵。","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"1. SMT","slug":"machine-translation/2-主流model-研究现状/1-SMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/1-SMT/"}]},{"title":"","date":"2018-07-31T05:36:26.786Z","path":"wiki/docker/advanced/-troubleshooting/","text":"扩展阅读 https://docs.docker.com/docker-for-mac/troubleshoot/","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-07-31T05:24:38.243Z","path":"wiki/CS/web/front-end/js/-异步编程/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"js","slug":"CS/web/front-end/js","permalink":"http://yoursite.com/categories/CS/web/front-end/js/"}]},{"title":"","date":"2018-07-31T05:14:04.115Z","path":"wiki/CS/web/front-end/css/-笔记/","text":"选择器内外边距 扩展阅读 http://wudaijun.com/2017/01/css-notes/","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"css","slug":"CS/web/front-end/css","permalink":"http://yoursite.com/categories/CS/web/front-end/css/"}]},{"title":"","date":"2018-07-31T05:13:44.631Z","path":"wiki/CS/web/front-end/css/-常用的css样式/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"css","slug":"CS/web/front-end/css","permalink":"http://yoursite.com/categories/CS/web/front-end/css/"}]},{"title":"","date":"2018-07-31T05:03:19.931Z","path":"wiki/CS/programing/编程思想 - 设计模式/-函数式编程/","text":"扩展阅读http://wudaijun.com/2018/05/understand-functional-programing/","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"编程思想 - 设计模式","slug":"CS/programing/编程思想-设计模式","permalink":"http://yoursite.com/categories/CS/programing/编程思想-设计模式/"}]},{"title":"docker 网络模式","date":"2018-07-31T04:53:20.840Z","path":"wiki/docker/advanced/-网络/","text":"","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-07-31T04:51:59.873Z","path":"wiki/docker/advanced/-集群/","text":"","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-07-31T04:47:30.289Z","path":"wiki/docker/advanced/-docker-compose/","text":"","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-07-31T03:48:55.163Z","path":"wiki/docker/advanced/-docker-machine/","text":"通常我们使用的Docker都是直接在物理机上安装Docker Engine，docker-machine是一个在虚拟机上安装Docker Engine的工具","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-07-31T02:22:30.249Z","path":"wiki/docker/tutorial/-docker与VM/","text":"容器 VS 虚拟机 轻量级：硬盘空间: ubuntu 16.4的docker镜像只有114M，系统镜像iso则需要1.5G。 运行时: 多个容器共享主机的内核，VM会消耗更多资源 启动快：虚拟机等完整系统，冗余步骤多：比如用户登录 Stackable: You can stack services vertically and on-the-fly. Hypervisor是一种运行在物理服务器和操作系统之间的中间软件层,可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）。 虚拟化的级别越偏底层，速度越慢，用户越难察觉到虚拟化的存在。 虚拟化的级别越偏上层，速度越快，用户越容易感知。 JVM 程序虚拟机：Java虚拟机（JVM） 系统虚拟机：VPC，v-Box，VMware Server。。KVM、Xen、OpenVZ。需要一个完整的操作系统，所以体积会比较大，如果想优化速度就必须要精简操作系统了， VMware ESX Server 裸机安装 那么 Docker 的实质是什么？在我看来就是个针对 PAAS 平台的自动化运维工具而已。 虚拟机启动太慢，额外开销太高，性能由于多了一层会下降。 KVM：KVM并没有选择从底层开始新写一个Hypervisor，而是选择了基于Linux Kernel，通过加载新的模块从而使Linux Kernel本身变成一个Hypervisor","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"【机器翻译】SliceNet","date":"2018-07-29T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/-SliceNet/","text":"架构 # 本文提出了一种新的卷积seq2seq结构（SliceNet）。模型采取了堆叠深度可分离卷积层以及残差连接的方法 分组卷积（grouped convolutions or “sub-separable convolutions”) 超可分卷积（super-separable convolutions） 过滤膨胀（filter dilation）与更大的卷积窗之间的权衡之后选择不使用filter dilation方法，通过卷积的分离操作，取得了更佳效果。 可分离卷积与分组卷积超可分卷积过滤膨胀和卷积窗大小权衡code tensor2tensor 扩展阅读 Depthwise Separable Convolutions for Neural Machine Translation","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"【机器翻译】CNN系列 - ByteNet","date":"2018-07-29T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/-ByteNet/","text":"","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"自然语言理解","date":"2018-07-29T16:00:00.000Z","path":"wiki/ML/app/nlp/框架-综述/自然语言理解/","text":"自然语言理解定义什么是NLU？怎样才算理解了语言？ 自然语言理解，也就是人或机器理解人类语言，有两种不同定义：一种基于表征，另一种基于行为。基于表征（representation），就是系统根据输入的语言产生相应的内部表征，这个过程也称为语义接地（semantic grounding）。比如，有人说「哈利波特」，在大脑里联系到哈利波特的概念就意味着理解了对方的语言。基于行为，就是系统根据输入的语言采取相应的动作。比如，有人说「给我拿一杯茶」，机器人按照命令做了，就认为它理解了人的语言。这两个定义在一定程度上互为补充，前者从语义角度，后者从语用角度界定这个问题。 扩展阅读李航","tags":[{"name":"nlp","slug":"nlp","permalink":"http://yoursite.com/tags/nlp/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"框架-综述","slug":"ML/app/nlp/框架-综述","permalink":"http://yoursite.com/categories/ML/app/nlp/框架-综述/"}]},{"title":"LDA线性判别分析","date":"2018-07-28T06:33:43.046Z","path":"wiki/ML/ml 传统方法/降维/-LDA/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"降维","slug":"ML/ml-传统方法/降维","permalink":"http://yoursite.com/categories/ML/ml-传统方法/降维/"}]},{"title":"","date":"2018-07-27T14:19:25.754Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-强化学习/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"","date":"2018-07-27T13:04:56.656Z","path":"wiki/CS/network/网络协议-OSI七层模型/6. 第二层 链路层/-wifi暴力破解/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"6. 第二层 链路层","slug":"CS/network/网络协议-OSI七层模型/6-第二层-链路层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/6-第二层-链路层/"}]},{"title":"","date":"2018-07-27T12:36:39.130Z","path":"wiki/CS/network/网络协议-OSI七层模型/6. 第二层 链路层/-wifi连接/","text":"无线连接的握手。 广播：发起侦测请求。FPA(手机，笔记本网卡等)发送广播请求。周围的信号源AP收到广播请求后，返回自己的mac，ssid(查看多少热点，侦测)。FPA收到response后，就知道有多少工作站(wifi信号) join request: FPA端 第二次握手，join网络。把信息放到报文。(AP返回的join response，包含sequence_num，有没有加密，加密算法是什么） FPA主动发，包含wifi密码，目的mac，wifi接到信息后会校验。 建立连接。 WiFi 的四次握手是干什么的？WiFi 身份认证的一个过程，如果没有你的设备没有通过他的身份验证就不能加入他的局域网当中。 WiFi 的四次握手跟破解 WiFi 有什么关系？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"6. 第二层 链路层","slug":"CS/network/网络协议-OSI七层模型/6-第二层-链路层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/6-第二层-链路层/"}]},{"title":"char based","date":"2018-07-27T08:46:36.439Z","path":"wiki/-language_model/-model/nnlm/char/","text":"疑问： 英文的char比较少，训练模型会不会表达性不够？ char级别的 词性+位置","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"},{"name":"nnlm","slug":"language-model/model/nnlm","permalink":"http://yoursite.com/categories/language-model/model/nnlm/"}]},{"title":"","date":"2018-07-27T03:49:19.792Z","path":"wiki/machine translation/-TODO/","text":"首先了解高层api training过程再走一遍细节。因为很多依赖高层api eager走一遍decode，不依赖graph eager走一遍training，不依赖graph 解码过程 bleu原理 各个模型(convseq2seq)分工跑一下源码 transformer其他任务 定点化","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"}]},{"title":"","date":"2018-07-27T03:23:47.733Z","path":"wiki/-audio/疑问/","text":"书君syllable cldnn是什么？目前syllable decoder尚未ready CLDNN = CNN + LSTM + DNN。根据以往经验是CNN+DNN 优于 DNN（Tara N. Sainath 13年有两篇CNN+DNN ASR的文章），Deep LSTM ≈ CNN + DNN，所以CLDNN也算是一个“自然”的探索。 CNN 相比 DNN 存在计算量过大的问题，所以太深的 CNN 在要求实时解码的ASR场景并不实用；CLDNN = 2 layer CNN + 1 layer LSTM + 2 layer DNN 计算量并不算太大，做到实时解码并不难，业界有些公司上线过 CLDNN 的 ASR 系统。 https://www.zhihu.com/question/59375524 NIN language modelcudnn model是什么？ #","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"}]},{"title":"","date":"2018-07-27T03:17:05.284Z","path":"wiki/-audio/dataset/制作数据/","text":"视频，切音频。 为什么不用纯音频，","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"dataset","slug":"audio/dataset","permalink":"http://yoursite.com/categories/audio/dataset/"}]},{"title":"","date":"2018-07-27T03:16:02.688Z","path":"wiki/-audio/声纹识别/ivector/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"声纹识别","slug":"audio/声纹识别","permalink":"http://yoursite.com/categories/audio/声纹识别/"}]},{"title":"","date":"2018-07-27T03:03:23.436Z","path":"wiki/-audio/前端信号处理/波束成型 Beamforming/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-27T03:03:12.644Z","path":"wiki/-audio/前端信号处理/声源定位 DOA/","text":"必须要用麦克风阵列。 https://blog.csdn.net/qq_23660243/article/details/78689295 https://zhuanlan.zhihu.com/p/22512377 麦克风阵列能干什么？1.语音增强（Speech Enhancement）2.声源定位（Source Localization）3.去混响（Dereverberation）4.声源信号提取（分离）","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-27T03:03:04.523Z","path":"wiki/-audio/前端信号处理/噪声抑制 NS/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-27T03:02:53.248Z","path":"wiki/-audio/前端信号处理/回声消除 AEC/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-27T03:01:38.186Z","path":"wiki/-audio/前端信号处理/硬件/","text":"单麦双麦","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"前端信号处理","slug":"audio/前端信号处理","permalink":"http://yoursite.com/categories/audio/前端信号处理/"}]},{"title":"","date":"2018-07-26T16:35:57.514Z","path":"wiki/ML/trick/-数值计算/smooth/","text":"https://mp.weixin.qq.com/s?__biz=MzIzMjU1NTg3Ng==&amp;mid=2247483900&amp;idx=1&amp;sn=8bfb01b13608b2f85e0d9db06c515000&amp;chksm=e89255f7dfe5dce154365521674072078ff8ed5d0fd75f37b0009414a4bc734156fbcf074683&amp;scene=21#wechat_redirect","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"},{"name":"-数值计算","slug":"ML/trick/数值计算","permalink":"http://yoursite.com/categories/ML/trick/数值计算/"}]},{"title":"","date":"2018-07-26T16:15:17.832Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-辅助翻译 交互式翻译/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"基于短语的翻译","date":"2018-07-26T11:38:44.174Z","path":"wiki/machine translation/2. 主流model-研究现状/1. SMT/-PBMT/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"1. SMT","slug":"machine-translation/2-主流model-研究现状/1-SMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/1-SMT/"}]},{"title":"","date":"2018-07-26T09:55:16.414Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/半监督/","text":"from future import absolute_importfrom future import divisionfrom future import print_functionimport numpy as npimport tensorflow as tfimport osimport loader as loaderfrom eval import eval FLAGS.dataset = “sogou”FLAGS.tf_checkpoint_dirFLAGS.tf_checkpoint_dir = “model/“FLAGS.model = “model.ckpt-44”FLAGS.dict = “dict.sogou.100000” batch_size = 64interval=[4000,20000,40000,100004]cluster_num = len(interval) - 1 def get_head_label(targetY): head_labels = np.reshape(targetY, [-1]) for i in range(cluster_num): mask = np.logical_and(np.greater_equal(targetY, interval[i]), np.less(targetY, interval[i + 1])) head_labels = np.where(mask, [interval[0] + i] * head_labels.shape[0], head_labels) return head_labels e = eval()result = e.loader.get_batch(batch_size)all_names = []all_losses = []all_scores = []while result: inputX_test, targetY_test, seqlen, names = result val = e.eval(inputX_test,targetY_test,seqlen) losses ,scores = e.get_loss(val,seqlen) all_names.extend(names) all_losses.extend(losses[:len(names)]) all_scores.extend(scores[:len(names)]) result = e.loader.get_batch(batch_size) #print(&apos;the loss is &apos;) #for sent , loss in zip(inputX_test,losses): # print(unicode(e.vocab.decode(sent),encoding=&apos;utf8&apos;).encode(&apos;utf8&apos;)) # print(loss) with open(‘lm-sencond.txt’,’w’) as file: for name,loss in zip(all_names,all_losses): file.write(name+’ ‘+str(loss)+’\\n’)with open(‘lm-second-score.txt’,’w’) as file: for name,score in zip(all_names,all_scores): file.write(name+’ ‘+str(score)+’\\n’)","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"【机器翻译】工业届发展史","date":"2018-07-26T09:23:41.539Z","path":"wiki/machine translation/竞赛 & 业界/-业界/","text":"2006年，谷歌开始提供机器翻译服务，采用基于短语的机器翻译。 百度翻译腾讯翻译https://ai.qq.com/product/nlptrans.shtml#text 腾讯机器翻译（Tencent Machine Translation）基于腾讯领先的底层算法、丰富的中文知识图谱和先进的NLP引擎能力，结合了神经网络机器翻译和统计机器翻译的优点，对源语言文本进行深入理解，使翻译效果更为准确，同时支持语音翻译、图片翻译、语种识别等多种场景，大大减轻传统文本翻译的读写成本，翻译更轻松。 讯飞翻译搜狗翻译","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"竞赛 & 业界","slug":"machine-translation/竞赛-业界","permalink":"http://yoursite.com/categories/machine-translation/竞赛-业界/"}]},{"title":"","date":"2018-07-26T08:21:07.658Z","path":"wiki/ML/trick/-数值计算/上溢和下溢-log/","text":"log用log级别 防止underflow 乘法变成加法，加速计算 上溢乘法中如果数字相乘过大会导致溢出的问题，从而导致数据的丢失. log sum问题定点化(对比浮点)浮点运算变成定点运算： 减小模型大小 加快计算速度 降低功耗 随着计算性能提升，速度优势没那么大。手机端也重视精度，因此采用GPU、TPU。 常用的方法","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"},{"name":"-数值计算","slug":"ML/trick/数值计算","permalink":"http://yoursite.com/categories/ML/trick/数值计算/"}]},{"title":"从最大似然到EM算法浅解","date":"2018-07-26T07:45:28.044Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/点估计/-EM/","text":"要由简入深先介绍没有隐变量，MLE或者MAP就能够解决。 简单复杂模型很复杂，似然函数虽然貌似可以写出来，但是要给指数级的项目求和，或者似然函数根本写不出来。 这样的模型就不能简单最大化似然了之了。 虽然不能直接写出模型的似然函数，要是给模型加上几个隐变量，那么给定参数下，数据与隐变量的联合分布倒是很容易算，要是知道隐变量的值，针对参数最大化似然函数也很容易。 唯一的问题是，他们既不知道隐变量的值，也不知道参数的值。这时就可以用到 EM 算法了，这个两步的算法很好地解决了这个两不知的问题，也即：第一步，给定参数，对隐变量做期望，算出包括隐变量的似然函数；第二步，对这个似然函数最大化，update 参数。因为这个模型可以让似然函数递增，如果似然函数是凹函数，那就一定会收敛到最大值，如果似然函数有多个极值，则要随机化初始参数值，算很多次，选择似然最大的参数。 EM对初始值的敏感。 HMM， 首先平均初始化(硬平均策略,比如kaldi 音频里的平均切分)。GMM先验概率， # EM方法是在有缺失值时进行估计的一种方法，这是一个迭代方法，每个迭代有求期望(E)和最大化(M)两个步骤。其中M可以是MLE或者MAP。 EM算法（Expectation-maximization)，期望最大化算法。在统计中被用于寻找，依赖于不可观察的隐性变量的概率模型中，参数的最大似然估计。 最大期望（EM）算法是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐性变量。最大期望算法经常用在机器学习和计算机视觉的数据聚类（Data Clustering）领域。最大期望算法经过两个步骤交替进行计算， 计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值； 最大化（M），最大化在E步上求得的最大似然(MLE)值来计算参数的值。（或者MAP） M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行。 简版：猜（E-step）,反思（M-step）,重复； 注意，你猜的时候，要尽可能的猜遍所有情况，然后求期望（Expected）；就是你不能仅仅猜一个个例，而是要猜出来整个宇宙；2. 为什么要猜，因为反思的时候，知道全部的东西比较好。（就是P(X,Z)要比P(X)好优化一些。Z是hidden states） 示例无缺失值 - MLE或者MAP一枚硬币扔了五次，有一次是正面。 用最大似然估计，就是以这五次结果为依据，判断这枚硬币每次落地时正面朝上的概率（期望值）是多少时，最有可能得到四次反面一次正面的结果。不难计算得到期望概率0.2。 有缺失值 - EM 迭代假设投了五次硬币，记录到结果中有两正一反，还有两次的数据没有记录下来。 需要注意，为缺失值赋值可以有两种策略，一种是按某种概率赋随机值，采用这种方法得到所谓hard EM，另一种用概率的期望值来为缺失变量赋值，这是通常所谓的EM。 另外，上例中，为两个缺失记录赋随机值，以期望为0.8的0-1分布为他们赋值，还是以期望为0.2的0-1分布为他们赋值，得到的结果会不同。而赋值方法的这种差别，实际上体现了不同的先验信息。所以即便在M步骤中采用MLE，EM方法也融入了非常多的先验信息。 扔硬币 - 多个变量LDA上面的例子中只有一个随机变量，而LDA中则有多个随机变量，考虑的是某些随机变量完全没有观测值的情况（也就是Latent变量），由于模型非常复杂，LDA最初提出时采用了变分方法得到一个简单的模型，EM被应用在简化后的模型上。从学习角度说，以PLSA为例来理解EM会更容易一点。另外，kmeans聚类方法实际上是典型的hard EM，而soft kmeans则是通常的EM 扩展阅读 Bishop的 PRML 从最大似然到EM算法浅解 | CSDN 通俗易懂地解释EM算法 | 知乎 adrew ng的视频 gaussian mixture引出EM factor analysis讲到EM 《统计学习方法》| 李航 MLE, MAP, EM关系 | 知乎","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"},{"name":"点估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计/点估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/点估计/"}]},{"title":"","date":"2018-07-26T07:45:03.457Z","path":"wiki/Math/-概率论与数理统计/统计推断/1 参数估计/点估计/-MLE/","text":"极大似然估计为什么不叫最大似然估计？参数估计 点估计 极大似然估计为什么不叫最大似然估计？","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"},{"name":"统计推断","slug":"Math/概率论与数理统计/统计推断","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/"},{"name":"1 参数估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/"},{"name":"点估计","slug":"Math/概率论与数理统计/统计推断/1-参数估计/点估计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/统计推断/1-参数估计/点估计/"}]},{"title":"dilated gated CNN","date":"2018-07-26T06:00:20.865Z","path":"wiki/ML/deep learning/model-basic/CNN/-Dilate-GatedCNN/","text":"参考 https://zhuanlan.zhihu.com/p/35988797","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"Gated Convolutional Networks","date":"2018-07-26T05:30:48.545Z","path":"wiki/ML/deep learning/model-basic/CNN/-GatedCNN/","text":"Language Modeling with Gated Convolutional Networks. 这也是第一次将门限控制引入到CNN中的文章 提出一种新的门控机制 缓解梯度传播，降低梯度弥散等现象 相比LSTM，模型更加简单，收敛速度更快","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"","date":"2018-07-26T05:12:37.841Z","path":"wiki/docker/tutorial/-存在的问题/","text":"隔离性不够 存在很多安全漏洞 docker软件本身存在很多不稳定 docker daemon进程与容器之间的耦合 存储的可靠性 参考https://www.zhihu.com/question/31805655","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"","date":"2018-07-26T05:12:37.841Z","path":"wiki/docker/tutorial/-漫谈虚拟化/","text":"","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"","date":"2018-07-26T05:12:37.841Z","path":"wiki/docker/tutorial/-源/","text":"怎么修改拉取源从指定的国内仓库拉取镜像？由于docker hub下载速度很慢，一个70M的镜像，要下载很久， 123456789101112mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://rgr5cdlp.mirror.aliyuncs.com&quot;], &quot;runtimes&quot;: &#123; &quot;nvidia&quot;: &#123; &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;, &quot;runtimeArgs&quot;: [] &#125; &#125;&#125;EOF ss 12systemctl daemon-reloadsystemctl restart docker","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"swarms","date":"2018-07-26T05:12:37.840Z","path":"wiki/docker/advanced/-swarms/","text":"Docker Swarm是docker原生的集群管理工具，之前是个独立的项目，于 Docker 1.12 被整合到 Docker Engine 中,作为swarm model存在，因此Docker Swarm实际上有两种：独立的swarm和整合后swarm model。官方显然推荐后者，本文也使用swarm model。相较于kubernetes，Mesos等工具，swarm最大的优势是轻量，原生和易于配置。它使得原本单主机的应用可以方便地部署到集群中。 使用它，用户可以将多个 Docker 主机封装为单个大型的虚拟 Docker 主机，快速打造一套容器云平台。","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"advanced","slug":"docker/advanced","permalink":"http://yoursite.com/categories/docker/advanced/"}]},{"title":"","date":"2018-07-26T05:12:37.840Z","path":"wiki/docker/tutorial/-services/","text":"12$ docker imagesCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running 启动docker服务 1systemctl start docker mac上没有systemctl这个命令 监听的端口","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"","date":"2018-07-26T05:12:37.840Z","path":"wiki/docker/tutorial/-registry/","text":"参考 https://blog.csdn.net/M2l0ZgSsVc7r69eFdTj/article/details/78538819 docker build -f tensor2tensor-1.6.6 . -t bitspeech/tensor2tensor:1.6.6 自动化构建除了在本地创建镜像然后使用push命令将其推送到Docker Hub之外，我们还可以使用Docker Hub提供的自动化构建技术在服务端直接构建镜像。通过在Docker Hub连接一个包含Dockerfile文件的Git Hub或Bit Bucket的仓库， Docker Hub的构建集群服务器就会自动构建镜像。通过这种方式构建出来的镜像会被标记为Automated Build，也可以称为受信构建（Trusted Build）。","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"","date":"2018-07-26T05:12:37.839Z","path":"wiki/docker/tutorial/-help/","text":"help1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283$ docker --helpUsage: docker COMMANDA self-sufficient runtime for containersOptions: --config string Location of client config files (default \"/Users/bitmain/.docker\") -D, --debug Enable debug mode -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/Users/bitmain/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/Users/bitmain/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/Users/bitmain/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quitManagement Commands: checkpoint Manage checkpoints config Manage Docker configs container Manage containers # docker container ls 命令等价于 docker ps image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumesCommands: attach Attach local standard input, output, and error streams to a running container # 常用 build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container deploy Deploy a new stack or update an existing stack diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server exec Run a command in a running container # docker exec -it container_id bash 进入指定的容器 export Export a container's filesystem as a tar archive history Show the history of an image images List images # 等价于 docker image ls import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers # 等价于 docker container ls pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers # 镜像运行后，是容器层。用docker ps查看容器 rmi Remove one or more images # 镜像是静态文件 run Run a command in a new container # 会运行一个新容器 save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers # 容器stop后，仍然存在。 tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE # top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codesRun 'docker COMMAND --help' for more information on a command.","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"","date":"2018-07-26T05:12:37.838Z","path":"wiki/docker/tutorial/-architecture/","text":"启动关闭dockersystemctl start docker.service 重新启动容器 systemctl start docker.service","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"位置信息","date":"2018-07-25T16:00:00.000Z","path":"wiki/ML/trick/-position/","text":"简介 绝对位置信息： 句首 句尾 做法：直接把位置编号当做特征 相对位置信息(relative)： 上下文信息(context)： 好像前两者都不重要，重要的是context信息。句首、句尾可以通过符号的LM来学习。 平移不变性: 位置移动 ss-google 周期性：与平移不变性很像 人工特征naive 方法直接把位置编号 [1，2，3，…n]作为一个维度。 缺陷：这样体现的是绝对位置信息。期望这种encoding具有平移不变性 常用方法google提出的position encoding。推荐系统中的时序信息： FM中采用 last movie rated 学习特征position embedding通常采用position embedding + word embedding，比如：ConvSeq2Seq，Transformer，等 优势: 简单，易与word_embedding融合 缺陷: 貌似没有考虑relative position 疑问： 是否能够学习到relative position 两个embedding的融合为什么要采用加法，串起来呢？ position matrix ?人工特征 + 学习特征可以显式的加入位置信息，[1，2，3，…n]作为一个维度，能够体现位置的连续性，进而体现relative position。 但是绝对位置 1 2 3 不太靠谱，我们需要的仅仅是一个 扩展阅读 Convolutional Sequence to Sequence Learning | facebook Attention is All Your Need | Google","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"维度尺寸设计 - 综述","date":"2018-07-25T11:34:28.010Z","path":"wiki/ML/trick/-维度尺寸设计-综述/","text":"实例分析lexNetResNet 整体架构一直在升维，没有升维的地方采用了residual connection 单个block结构：降维(11small_size) + 卷积(33small_size) + 升维(11large_size)。 NINGoogLeNetTransformer先升维再降维 PCA映射过程是一个“先升维再降维”的过程 SVM的核函数，低维空间不可分，先映射到高维空间 ResNet的 inception网络中的1*1卷积 先降维再升维1×1 layers reducing and then increasing (restoring) dimensions, leaving the 3×3 layer a bottleneck with smaller input/output dimensions. 1*1 kernel可用于降维，可用于升维。 NIN中用于降维 12 input conv[?*100*100*128] * [1*1*128*32] bottleneck设计","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"【北大公开课】人工智能与金融服务 漆远","date":"2018-07-25T11:34:28.010Z","path":"wiki/others/economy/AI-金融/-漆远-北大公开课/","text":"漆远蚂蚁金服副总裁、首席数据科学家、国家千人计划特聘专家 漆远教授在2005年获得MIT博士学位，并在计算机与人工智能实验室进行博士后研究工作。他于2007年加入普渡大学并在2013年成为普渡大学计算机科学系和统计系的终身（副）教授。14年回国来到阿里。北大客座教授。JMLR执行编辑，ICML领域主席。 报告题目：人工智能与金融服务报告时间：2018-03-06","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"AI-金融","slug":"others/economy/AI-金融","permalink":"http://yoursite.com/categories/others/economy/AI-金融/"}]},{"title":"维度尺寸设计 - 卷积","date":"2018-07-25T11:34:28.009Z","path":"wiki/ML/trick/-维度尺寸设计-卷积/","text":"# 卷积维度设计 常见的卷积## 1×1卷积1×1的卷积层（可能）引起人们的重视是在NIN的结构中 1×1卷积核，实质多个feature map的线性组合。功能： 实现跨通道的交互和信息整合 进行卷积核通道数的变化(降维或升维) 保持feature map尺寸不变（即不损失分辨率）的前提下大幅增加非线性特征，把网络做的很deep。 参数少 缺陷：起不到context作用。 利用MLP代替传统的线性卷积核，从而提高网络的表达能力。文中同时利用了跨通道pooling的角度解释，认为文中提出的MLP其实等价于在传统卷积核后面接cccp层，从而实现多个feature map的线性组合，实现跨通道的信息整合。而cccp层是等价于1×1卷积的，因此细看NIN的caffe实现，就是在每个传统卷积层后面接了两个cccp层（其实就是接了两个1×1的卷积层）。 扩展阅读 1x1 Convolutions | Udacity Youtube没看懂， 参考https://blog.csdn.net/u014114990/article/details/50767786","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"维度尺寸设计 - 池化","date":"2018-07-25T11:34:28.009Z","path":"wiki/ML/trick/-维度尺寸设计-池化/","text":"bad caseTextCNN good caseOverlapping PoolingAlexNet中采用Overlapping Pooling 这个想法很好传统的Pooling层是不重叠的，而本论文提出使Pooling层重叠可以降低错误率，而且对防止过拟合有一定的效果。keras的resnet实现也采用了s=2 z=3的方式pooling ##","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"Xception","date":"2018-07-25T11:34:28.008Z","path":"wiki/ML/deep learning/model-basic/CNN/Xception/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"","date":"2018-07-25T11:34:28.007Z","path":"wiki/machine translation/竞赛 & 业界/-IWSLT/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"竞赛 & 业界","slug":"machine-translation/竞赛-业界","permalink":"http://yoursite.com/categories/machine-translation/竞赛-业界/"}]},{"title":"bleu","date":"2018-07-25T11:34:28.007Z","path":"wiki/machine translation/evaluation/-ppl/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"evaluation","slug":"machine-translation/evaluation","permalink":"http://yoursite.com/categories/machine-translation/evaluation/"}]},{"title":"cuda 计算","date":"2018-07-25T11:34:28.007Z","path":"wiki/CS/parallel computing-高性能计算/-cuda/计算/","text":"batch_size比较大时，P100加速比较明显。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"-cuda","slug":"CS/parallel-computing-高性能计算/cuda","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/cuda/"}]},{"title":"【机器翻译】- 资源集合","date":"2018-07-25T11:34:28.006Z","path":"wiki/machine translation/6. 附录/","text":"codes [常用深度学习工具包] pytorch seq2seq_translation tensorflow tutorial tensor2tensor OpenNMT - 支持tf和pytorch 公开数据集开源社区、toolbox汇总 Giza++ a training tool for IBM Model 1-5 (version for gcc-4) , and extension of Giza MGiza++是在Giza++基础上扩充的一中多线程Giza++工具 Pgiza++是运行在分布式机器上的Giza++工具，使用了MapReduce技术的框架 Moses, a complete SMT system UCAM-SMT, the Cambridge Statistical Machine Translation system Phrasal, a toolkit for phrase-based SMT cdec, a decoder for syntax-based SMT * Joshua, a decoder for syntax-based SMT Jane, decoder for syntax-based SMT Pharaoh a decoder for phrase-based SMT Rewrite a decoder for IBM Model 4 BLEU scoring tool for machine translation evaluation EgyptEgypt是在1999年约翰霍普金斯大学统计机器翻译夏季讨论班上，由一些研究人员共同合作开发的统计机器翻译工具包。它包括4个模块：Whittle：语料库预处理模块；GIZA：用于从句子对齐的双语语料库中训练词语对齐；Cairo：词语对齐的可视化工具Decoder：解码器，即用来执行具体的翻译过程模块，这一模块没有开放源码。 SRILMSRILM是一个建立和使用统计语言模型的开源工具包，从1995年开始由SRI 口语技术与研究实验室（SRI Speech Technology and Research Laboratory）开发，现在仍然不断推出新版本，被广泛应用于语音识别、机器翻译等领域。这个工具包包含一组C++类库、一组进行语言模型训练和应用的可执行程序等。利用它可以非常方便地训练和应用语言模型。 法老（Pharaoh）系统“法老”是较早公开的统计机器翻译系统，是由美国南加州大学信息科学实验室（Information Science Institute）的菲利普.科恩（Philipp Koehn）在2004年做博士论文期间编写的。可能由于较早的开源软件以“埃及（Egypt）”命名的缘故吧，这一系统也采用埃及的代表性事物“法老（Pharaoh）”命名。它是一个基于短语的（Phrased-based）统计机器翻译系统。。它利用了已有的开源软件GIZA++和SRILM，GIZA++用来训练词语对齐，SRILM训练语言模型。既然是以短语作为翻译的基本单元，因此还需要获得关于短语翻译的知识。通过前面的介绍我们知道通过GIZA++训练可以得到单词对齐，根据单词对齐我们可以进行短语抽取。 Moses当今最有名的开源统计机器翻译系统。绝大多数的统计机器翻译技术在Moses中都有支持，比如基于短语的模型、基于句法的模型、各种解码方法、各种特征权重训练方法。概括一下：历史悠久（相对），技术全面，性能出色，论文的baseline。“摩西”是“法老”的升级版本，增加了许多功能。它是由英国爱丁堡大学、德国亚琛工业大学等8家单位联合开发的一个基于短语的统计机器翻译系统。来自这8家单位的研究人员于2006年在约翰霍普金斯大学召开了一次研讨会，利用6个星期的时间共同开发了这一系统。整个系统用C++语言写成，从训练到解码完全开放源代码，可以运行在Windows平台和Linux平台。相比于“法老”，“摩西”主要有如下几个新的特性：a.使用要素翻译模型（Factored Translation Model）b.混合网络解码（Confusion Network Decoding）现在的Moses系统极其复杂，代码阅读起来是比较吃力的。如果是想学习统计机器翻译技术，我倒是觉得Joshua和NiuTrans是不错的选择。 SilkRoad 丝路中国第一个开源的统计机器翻译系统，“法老”的出现揭开了统计机器翻译的神秘面纱，然而其核心部分解码器的源码仍然没有公开。为此，中国的研究人员联合开发了一个完全开放源代码的统计机器翻译系统“丝路”。该系统由中国的五家研究机构和高校（中科院计算所、中科院自动化所、中科院软件所、厦门大学、哈尔滨工业大学）联合开发，并在2006年中国第二届统计机器翻译研讨会[14]上发布。“丝路”包括以下模块：语料预处理及后处理模块“仙人掌”、词语对齐模块“楼兰”、短语抽取模块“胡杨”、以及三个解码器（“骆驼”、“绿洲”和“商队”）。后期的更新和维护没有跟上，现在使用的似乎不是非常多。 NiuTransNiuTrans的特点是国人开发，性能稳定，翻译模型支持全面，NiuTrans团队对系统进行不断升级。从全世界范围来看，现在机器翻译的开源工具不下30个。还有其它的系统，比如Akamon等，还有比较相关的如GIZA++，SRILM等，但是这里就不详细介绍了。 参考文献 模型 paper year + 会议 简介 创新点 缺陷 code 基于短语的翻译（PBMT） IBM 1989 模型超复杂 Sequence to Sequence Learning with Neural Networks NIPS 2014 tensorflow Learning Phrase Representations using RNN Encoder-Decoder for SMT EMNLP2014 Effective Approaches to Attention-based Neural Machine Translation EMNLP 2015 基于高斯分布推导了Local Attention,比较了Global Align Attention和Local Align Attention， 和视频处理里面 Soft Attention 和 Hard Attention建立了联系。 code Neural machine translation by jointly learning to align and translate ICLR 2015 RNN+attention 首次加入attention，ALIGN AND TRANSLATE GNMT Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation 2016 deep_LSTM, residual, attention, converage，subword 宗成庆：《自然语言理解》- 必看 GNMT | 谷歌2016 — 官方code Multilingual-NMT 实现多语言翻译和zero-shot翻译| Google 2016 conv-seq2seq 利用多跳注意（multi-hop attention）和门控（gating）来改善翻译效果| Facebook 2017 Attention Is All You Need 不用CNN和RNN| Google 2017 Achieving Human Parity on Automatic Chinese to English News Translation | 微软2018","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"}]},{"title":"【机器翻译】- 系统","date":"2018-07-25T11:34:28.004Z","path":"wiki/machine translation/-3. 系统 - system/","text":"解码器 if-else的trick ensemble rerank 融合统计与深度学习的方法 利用优先队列及候选翻译表 搜索算法 优化模型解码等技术，提高解码速度 模型压缩技术，将模型规模压缩70倍以上，手机端可存储，同时采用动态加载","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"}]},{"title":"无监督机器翻译","date":"2018-07-25T11:34:28.001Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/无监督/summary/","text":"简介平行语料比较匮乏 完全无监督 的方式训练 NMT 系统 仅需使用单语语料库 三角剖分（triangulation） 半监督学习技术 在近期关于无监督嵌入映射的研究基础上构建，包含经过少许修改的注意力编码器-解码器模型（attentional encoder-decoder model），该模型使用去噪和回译（backtranslation）结合的方式在单语语料库上进行训练 该模型的基本思想是, 通过将来自不同语言的句子映射到同一个隐空间下来进行句子翻译。 对语言 L1 中的每个句子，该系统都通过两个步骤进行训练： 去噪——利用共享编码器优化对句子带噪声版本进行编码和使用 L1 解码器重构句子的概率； 回译——在推断模式（inference mode）下翻译该句子（使用共享编码器编码该句子，使用 L2 解码器进行解码），利用共享编码器优化对译文句子进行编码和使用 L1 解码器恢复源句子的概率。交替执行这两个步骤对 L1 和 L2 进行训练，对 L2 的训练步骤和 L1 类似。 参考 Unsupervised Machine Translation Using Monolingual Corpora Only | Facebook ICLR 2018 Phrase-Based &amp; Neural Unsupervised Machine Translation https://www.jiqizhixin.com/articles/2017-11-03 阅读笔记 | 知乎 unsupervised MT | Facebook Github","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"},{"name":"无监督","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水/无监督","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/无监督/"}]},{"title":"如何ensemble","date":"2018-07-25T11:34:28.000Z","path":"wiki/machine translation/2. 主流model-研究现状/-ensemble/","text":"","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"}]},{"title":"【机器翻译】- 面临的挑战","date":"2018-07-25T11:34:27.997Z","path":"wiki/machine translation/-1. 核心问题 面临的挑战/","text":"面临的挑战NLP常见的问题见trick-NLP 机器翻译独有的问题歧义自然语言中普遍存在的歧义和未知现象 句法结构歧义/词汇歧义/语用歧义 … 新的词汇、术语、结构、语义 机器翻译不仅仅是字符串的转换不同语言之间文化的差异现有方法无法表示和利用世界知识和常识 bad case 未登录词(OOV)的影响以及策略NMT 系统为了能够控制计算的复杂度，有着一个固定大小的词汇表，通常会将词汇表限制在 30k 到 80k 之间，这就导致了其在翻译未登录词时有着严重的不足。 对于未出现在该词汇表中的词，NMT系统用 UNK 标记来替代。结果，NMT 系统不仅无法将它们翻译准确，而且破坏了句子的结构特征。 更多，见 ML/NLP/OOV 策略 长距离依赖 神经机器翻译有两个关键技术，一个是 gating，另外还有一个是 attention，这两个特别适合处理语言中长距离调序，生成的译文要比传统的方式生成的译文流利很多。 同步翻译/实时翻译 Learning to Translate in Real-time with Neural Machine Translation 多语种机器翻译的解不唯一，而且始终存在的人为的标准机器翻译不仅仅是字符串的转换 不同语言之间文化的差异 现有方法无法表示和利用世界知识和常识 翻译诗歌、散文和小说等高难度文艺作品 食品或菜单名的翻译： 123456789101112131415|馒头: steamed bread | Steamed bun || 夫妻肺片 | Husband and wife’s lung slices | Fuqifeipian/ Spicy beef || 童子鸡 | Young lad chicken | Spring chicken/ Broiler chicken |2011年，中国日报，翻译效果原文：WASHINGTON - China and the United States have far more shared interests than differences, and nothing can hold back the momentum of cooperation, Vice-Premier Wang Qishan said on Monday. He made the remark at the opening of the third round of the China-US Strategic &amp; Economic Dialogue in the US capital.google翻译：华盛顿－中国和美国有更多的共同利益大于分歧，没有什么能阻挡历史的合作势头，国务院副总理王岐山周一表示。 他在中国的中美战略与经济对话在美国首都第三轮开幕时作上述表示。SYSTRAN：华盛顿-中国和美国比区别有分享兴趣，并且什么都不能阻止合作的动量，在星期一，Wang Qishan 副总理说。 他发表了这个评论在中美战略&amp;经济对话的第三个回合的开头在美国首都。原文：Beijing made a third solemn representation to Manila and warned that it is hard to be optimistic about a territorial impasse over an island. Authorities say they have prepared for any escalation of the situation by Manila.Google Translator (2012.5.8)： 北京提出了第三次严正交涉，马尼拉，并警告说，这是大约一个多岛屿的领土僵局难以乐观。当局说，他们已经准备为任何升级的情况下由马尼拉。Google Translator 2013.5.7：北京做了第三马尼拉严正交涉，并警告说，这是很难被看好在一个小岛的领土僵局。当局说，他们已经准备任何马尼拉局势升级。SYSTRAN (2012.5.8)：北京交涉第三庄严的向马尼拉并且警告是乐观对在海岛的一个领土僵局是难。 当局说他们为这个情况的所有逐步升级做准备由马尼拉。 评价标准机器翻译的解不唯一，而且始终存在的人为的标准","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"}]},{"title":"【机器翻译】- 神经机器翻译 NMT","date":"2018-07-25T11:34:27.996Z","path":"wiki/machine translation/-0. related-work survey/nmt/","text":"Facebook总结的很好顺便介绍一下CNN缺陷，RNN缺陷 Convolutional Neural Networks (CNN) Dauphin et al. (2017): Language Modeling with Gated Convolutional Networks Gehring et al. (2017): Convolutional Sequence to Sequence Learning New Edunov et al. (2018): Classical Structured Prediction Losses for Sequence to Sequence Learning New Fan et al. (2018): Hierarchical Neural Story Generation Long Short-Term Memory (LSTM) networks Luong et al. (2015): Effective Approaches to Attention-based Neural Machine Translation Wiseman and Rush (2016): Sequence-to-Sequence Learning as Beam-Search Optimization Transformer (self-attention) networks Vaswani et al. (2017): Attention Is All You Need New Ott et al. (2018): Scaling Neural Machine Translation 时序建模见 ml/sequence 其他通用trick gated linear units residual connections 模型汇总 模型 paper 出处 简介 创新点 缺陷 code 基于规则的翻译 基于短语的翻译（PBMT） IBM 1989 较复杂 seq2seq-RNN Seq2seq Learning with NN NIPS 2014 code seq2seq-RNN Learning Phrase Representations using RNN Encoder-Decoder for SMT EMNLP2014 ☆seq2seq-RNN+attention Effective Approaches to Attention-based NMT EMNLP 2015 基于高斯分布推导了Local Attention,比较了Global Align Attention和Local Align Attention， 和视频处理里面 Soft Attention 和 Hard Attention建立了联系。 code seq2seq-attention Neural machine translation by jointly learning to align and translate ICLR 2015 RNN+attention 首次加入attention，ALIGN AND TRANSLATE On using very large target vocabulary for neural machine translation 2015 提出词表扩大的方法 ☆GNMT Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation Google 2016 deep_LSTM, residual, attention, converage，subword BPE Neural Machine Translation of Rare Words with Subword Units 2016 code-Sennrich Character Based Neural Machine Translation 2016 Achieving open vocabulary neural machine translation with hybrid word-character models 2016 ☆ConvSeq2seq paper1; paper2 Facebook 2016 code1; ☆Transformer Attention is all you need Google 2017 G-tf 扩展阅读 Google神经网络机器翻译上线历程回顾","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-0. related-work survey","slug":"machine-translation/0-related-work-survey","permalink":"http://yoursite.com/categories/machine-translation/0-related-work-survey/"}]},{"title":"【语言模型】- 模型评估与模型选择","date":"2018-07-25T11:34:27.995Z","path":"wiki/-language_model/evaluation/metric/","text":"如何评价一个语言模型的好坏？ 评价指标Perplexity ppllog perplexity是真实分布与预测结果分布之间的交叉熵 $$2^{H(p)}=2^{-\\sum_{x}p(x)\\log_{2}p(x)}$$ predict看看效果标点lm按照贪婪 生成看看生成top-n，看看 不同的初始值 lm 与 am结合�始值 lm 与 am结合","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"evaluation","slug":"language-model/evaluation","permalink":"http://yoursite.com/categories/language-model/evaluation/"}]},{"title":"","date":"2018-07-25T10:53:15.447Z","path":"wiki/others/economy/-名词/","text":"经济 &amp; 金融 &amp; 财经 区别finace和economy的区别","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"}]},{"title":"","date":"2018-07-25T10:53:15.447Z","path":"wiki/others/economy/体制/-社会主义/","text":"社会主义的本质，是解放生产力，发展生产力，消灭剥削，消除两极分化，最终达到共同富裕。 前面不是 “左”带有革命色彩，好像越“左”越革命。“左”的东西在我们党的历史上可怕呀！","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"体制","slug":"others/economy/体制","permalink":"http://yoursite.com/categories/others/economy/体制/"}]},{"title":"","date":"2018-07-25T10:53:15.447Z","path":"wiki/others/economy/经济学原理/-宏观经济学/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"经济学原理","slug":"others/economy/经济学原理","permalink":"http://yoursite.com/categories/others/economy/经济学原理/"}]},{"title":"","date":"2018-07-25T10:53:15.447Z","path":"wiki/others/economy/经济学原理/-微观经济学/","text":"生产可能性边界 PPF(production possibilities frontier) 生产可能性边界，是指不偷懒的生产上限。 线上的任何一点都实现了生产效率(productive efficiency)，超出的生产是impossible 机会成本 opportunity cost 如果你想catch一个opportunity，你必要要放弃的东西，give up 示例：the opportunity cost of 20 more berries is one rabbit 边缘成本 marginal cost marginal cost of each incremental rabbit 每增加一只兔子的机会成本， the opportunity cost of one incremental unit is just the marginal cost. 一个增量单位的机会成本实际上也就是边际成本 额外生产一单位的成本。比如多生产一个兔子的机会成本是20个berry 递增机会成本 incresing 为什么机会递增成本在经济学模型中？ 一开始能打到笨兔子，笨兔子少了渐渐难度变困难了 不仅仅经济学模型 考试0-06很简单，98-&gt;100很难 摩尔定律，扯淡吧。摩尔定律是指数级吗？多项式增量？ 配置效率(allocative efficiency) &amp; 边际效率 &amp; 边际效益(marginal benefit) B点，每天打4个兔子，100个果子， 边际成本：自己亲自打一只兔子，要放弃100个果子 () 边际效益：买个兔子只愿意用20个果子 (因为余量中，兔子多，果子少。) 总结：我何必去辛辛苦苦打一只兔子(消耗100果)，还是去买兔子划算(20果) 疑问：要考虑整个市场的供需，而不是个体吧？这里是把个体视为整个市场吗？市场上兔子多，果子少，应该果子贵啊？？？ F点，每天打0个兔子，100+80+60+40+20=300个果子 边际成本：自己亲自打一个兔子，要放弃 边际效益： 这里貌似涉及定价，如何定价。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"经济学原理","slug":"others/economy/经济学原理","permalink":"http://yoursite.com/categories/others/economy/经济学原理/"}]},{"title":"","date":"2018-07-25T10:53:15.446Z","path":"wiki/others/economy/-reading-list/","text":"经济学原理 微观经济学 尼克尔森《微观经济理论：基本原理与拓展》和 宏观经济学 曼昆的《宏观经济学》 中级微观经济学 政治经济学 #","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"}]},{"title":"","date":"2018-07-25T10:53:15.446Z","path":"wiki/others/economy/-九鼎谈投资/","text":"九鼎投资公司年会音频整理 实际控制人吴刚讲话：价差是盈利的核心来源，价差包括基础价差和泡沫价差…基础价差坚持一买二，如果我们碰上运气好或者我们运作运作然后以一个泡沫高价卖给傻瓜、一群傻瓜，就是股民，一个傻瓜或一个傻逼接盘者，这就是泡沫价差，没有我们就把基础价差给赚了。 实际控制人吴刚讲话：投资成败不能寄希望于增长，只能寄希望于价差，买的便宜是赚钱的王道，…当然这不能对外讲，对外讲这不是占别人便宜吗，但赚钱就是这样的，有人吃亏你才能赚钱，就是要利用别人不对，所以你每个项目就要思考为什么能赚钱，是不是有人要犯傻，别人犯傻你就能赚钱，这就是本质。你们不要对外讲，讲了不符合社会主义价值观。接下来讲我们的赚钱方式，我们赚钱只能靠捡钱而不能靠挣钱，什么叫捡钱什么叫挣钱，我个人定义能力圈内赚钱叫捡钱，能力圈外赚钱叫挣钱，…在能力圈里做事就很轻松，…所以我们一定要坚持捡钱，只有我们轻轻松松百分之百挣钱了，凡是不轻松的钱你挣不了，天底下赚大钱的人都是捡钱赚的，没有人靠挣钱赚大钱，我堂哥就是挣钱，每天八点起床上班，天天在工地上打工搬砖但是赚不到钱，因为他不是通过捡的方式，他是真正的挣了，他没有在一个小小的能力圈里弄到极致。所以我们要有这个意识，就是捡钱，在能力圈里面把这个钱给赚了，轻轻松松，挣钱太难，我们都没有挣钱的本事，…人类和平时期的唯一战争就是赚钱。…在我们这个圈子里面，总有些傻子不太懂的哗的就撞进来了，后面我们就把他按住拿下，这样躺着就把钱赚了，这才是真正赚大钱的办法，要摒弃挣钱。 还有就是国有制企业，我们一共投了七八个，没有一个成功，在我们这是百分之百不成功比率，国有企业全世界来说都不成功，对中国来说也是不成功，你要在不成功的世界里面做特例成功很难…还有就是实际控制人为老人和女人，实际控制人为老人，老年人没动力…女的，我不是有歧视，在商业世界里，在中国做一个民营企业的老板是很不容易的，我们要克服那么多艰难困苦，说白了要用很多各种各样的手段，合法的和半合法的，这女的很难，压力太大… 大部分人只会限定思维，大部分人只会别人怎么想自己就怎么想，不独立思考，那么我们作为理性投资者就要逮住他们这些傻逼犯错误的机会，这时候我们才能赚钱。还有一种情况，就是卖的人应急卖出，有的老板借了高利贷必须要还，股份必须马上尽快卖掉，他必须马上卖一些股份给我们，他不卖给你他玩不转，趁人之危，他感恩你知道吧，清仓式甩卖，到期了必须要卖，没人愿意接这个股票他要把它续上，我们就低价买下，趁人之危，清仓型应急卖出。还有就是合谋，私有化就是合谋，和管理团队合谋，把小组的钱赚了，等把今年业绩和明年业绩做差，股价哗哗跌，第二年第三年一丢，这就是合谋。…只有这些无效，我们才能赚钱，每一个项目都要合谋，为什么我们能赚到钱，你们现在开发项目跟进的时候就要想到这件事情，要朝这个方向去运作，只有运作那些无效机会我们才能够赚钱，或者识别或者发现无效机会。我们有一句话，就是打牌的时候，你如果没有看到谁是傻瓜，你就是傻瓜，所以你在做交易的时候，你一定要要看到谁是傻瓜，我们占了谁的便宜赚到钱，如果你都没发现，那你就是傻瓜，就是接盘侠，你就被骗了。这就是赚钱里面的基础价差。 九鼎投资定增会议音频整理 实际控制人吴刚讲话：一是我们帮你做税收策划，二是你想偷税可以继续偷税…不因为装到上市公司来它就要规范化运作，它装到上市公司来，照样不用规范化运作。…万科现在净资产七八百亿，我们比万科还大，我们有一千亿净资产，是中国第一号房地产公司。…我们只需要看看就可以了，不用评估，不需要花一分钱的审计评估费，签完协议就往上市公司装，我们不需要报证监会审批，也不需要国土资源部出什么文件。直接装就完成，百分之百就是这样的。…肯定完成，不需要任何人审批。…九鼎现在啥项目都不用做啥项目都不用投，你们整天整那些破项目弄点破钱，都是无关紧要的事，结果发现都是毛毛雨。…一个项目不投，一分钱不募，只要把这个事给我做成了就OK了。…你们募能募几个钱，投能投几个鸟项目，我这一整就是一千亿啊，永续资金啊兄弟们。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"}]},{"title":"","date":"2018-07-25T10:53:15.443Z","path":"wiki/ML/trick/-过拟合-数据增强/","text":"实例lexNet中的做法: NLP中的数据增强","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-25T10:53:15.443Z","path":"wiki/ML/trick/-过拟合-稀疏/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-25T10:53:15.443Z","path":"wiki/ML/trick/-过拟合-综述/","text":"模型参数较多，学习能力强，但是在数据不足的情况下也容易造成过拟合。 常用的解决过拟合的办法有：","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-25T10:53:15.442Z","path":"wiki/ML/trick/-标准化-layerNorm/","text":"LayerNorm是Batch Normalization的一个变体，BN针对一个minibatch的输入样本，计算均值和方差，基于计算的均值和方差来对某一层神经网络的输入X中每一个case进行归一化操作。但BN有两个明显不足：1、高度依赖于mini-batch的大小，实际使用中会对mini-Batch大小进行约束，不适合类似在线学习（mini-batch为1）情况；2、不适用于RNN网络中normalize操作：BN实际使用时需要计算并且保存某一层神经网络mini-batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其的sequence长很多，这样training时，计算很麻烦。但LN可以有效解决上面这两个问题。LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；而BN中则针对不同神经元输入计算均值和方差，同一个minibatch中的输入拥有相同的均值和方差。因此，LN不依赖于mini-batch的大小和输入sequence的深度，因此可以用于bath-size为1和RNN中对边长的输入sequence的normalize操作。 参考深度学习加速器Layer Normalization-LN","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-25T10:53:15.442Z","path":"wiki/ML/trick/-激活函数/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"神经网络里的low-rank","date":"2018-07-25T10:53:15.442Z","path":"wiki/ML/trick/-过拟合-low-rank/","text":"背景假设M是一个m×n阶矩阵，其中的元素全部属于域K，也就是实数域或复数域。如此则存在一个分解使得 {\\displaystyle M=U\\Sigma V^{},\\,} M = U \\Sigma V^, \\,其中U是m×m阶酉矩阵；Σ是m×n阶非负实数对角矩阵；而V*，即V的共轭转置，是n×n阶酉矩阵。这样的分解就称作M的奇异值分解。Σ对角线上的元素Σi,i即为M的奇异值。 low rank约束SVD 压 RNN 参数A: 如果有一个 mn 的参数矩阵 W，改成 mr, r*n 的两个矩阵的乘积吗？这种方式我做过效果很差。 B: 数学上是这样没错，但是具体你是用在什么问题什么模型结构上？大致的构造和训练流程是怎么样的？这种方法在几个常见情况下挺好用的，调起来也没什么技巧，国内外很多企业都在实际产品里用很久了。 A: 用在机器翻译， attentional sequence to sequence model 上。就是把 GRU 内部所有权重矩阵分解开，比如 1k1k 的矩阵变成 1k200 和 200*1k 的矩阵，然后从头开始训练。 B: SVD 压 embedding layer网络结构约束bootle-neck网络ResNet中采用了这个策略。有点类似low-rank吧，SVD分解的思想？ U = S V D RNN中是否也可采用这个策略？如何加？方式一：同上，对RNN的参数加SVD约束。方式二： 正交约束","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-25T10:53:15.441Z","path":"wiki/ML/trick/-标准化-groupNorm/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"各种各样的卷积，卷积的设计","date":"2018-07-25T10:53:15.440Z","path":"wiki/ML/trick/-layer-conv/","text":"卷积padding: 空洞卷积（atrous convolutions）又名扩张卷积（dilated convolutions）transposed Convolutions）又名反卷积（deconvolution）疑问：填充方式是怎样的？ Separable ConvolutionSeparable Convolution in Image Processing$$ H = \\begin{bmatrix}1 &amp; 0 &amp; -1 \\ 2 &amp; 0 &amp; -2 \\ 1 &amp; 0 &amp; -1 \\end{bmatrix} = \\begin{bmatrix}1 \\ 2 \\ -1 \\end{bmatrix} * \\begin{bmatrix}1 &amp; 0 &amp; -1 \\end{bmatrix} $$ 参考 https://zhuanlan.zhihu.com/p/28186857 http://anishshah.github.io/ml/2017/06/27/SeparableConv.html","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-25T10:53:15.439Z","path":"wiki/ML/deep learning/model-basic/GAN/-GAN/","text":"简介所谓生成对抗模型，就是道高一尺，魔高一丈。 StarGAN - CVPR 2018 https://github.com/yunjey/StarGANseqGAN 竟然1RuntimeError: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! GAN完整理论推导与实现，Perfect！ 搞事！ICLR 2018七篇对抗样本防御论文被新研究攻破，Goodfellow论战","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"GAN","slug":"ML/deep-learning/model-basic/GAN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/GAN/"}]},{"title":"","date":"2018-07-25T10:53:15.438Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-tensorRT/","text":"见 deep learning/ 优化/inference/tensorRT","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"","date":"2018-07-25T10:53:15.437Z","path":"wiki/CS/tools/同步与版本管理/git/-snapshot/","text":"snapshot中文翻译是不靠谱的。Snapshot:In computer systems, a snapshot is the state of a system at a particular point in time.和”快“没有任何关联。 Git在每一次commit时，都会完整的存储当前版本所有修改的文件，而非只存储diff。 blobtree常见错误HEAD detached at be2dbb9Detached head means you are no longer on a branch, you have checked out a single commit in the history (in this case the commit previous to HEAD, i.e. HEAD^).解决办法 git checkout master 参考：https://stackoverflow.com/questions/3965676/why-did-my-git-repo-enter-a-detached-head-state/3965714#3965714","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-07-25T10:53:15.436Z","path":"wiki/CS/OS/-mac/快捷键/","text":"参考 https://support.apple.com/zh-cn/HT201236 command + A 全选 command + B 加粗 command + C 复制 command + D 收藏 command + F 查找 command + N 新建 command + O 打开 command + P 打印 command + Q 退出当前程序 command + R 刷新 command + S 保存 command + U 下划线 command + V 粘贴 command + W 关闭窗口 command + X 剪切 command + Y 重做 下划线 command + Z 撤销 command + shift + 3 截屏 command + shift + 4 选择截屏 command + option + esc 任务管理器 command + option + h 隐藏其他窗口 command + delete 移到废纸篓","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-mac","slug":"CS/OS/mac","permalink":"http://yoursite.com/categories/CS/OS/mac/"}]},{"title":"","date":"2018-07-25T10:53:15.436Z","path":"wiki/CS/OS/-mac/包管理器/","text":"https://brew.sh/ Homebrew 能干什么?使用 Homebrew 安装 Apple 没有预装但 你需要的东西。 比如 1$ brew install wget 为什么不通过app store安装呢？因为wget tree等基本东西，app store里没有。为啥呢？ brew安装与app-store安装有什么不同？brew会把软件安装到/usr/local下，而从网上下载dmg/pkg安装包复制安装的目标路径是/applications Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local 。 s##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-mac","slug":"CS/OS/mac","permalink":"http://yoursite.com/categories/CS/OS/mac/"}]},{"title":"","date":"2018-07-25T10:53:15.436Z","path":"wiki/CS/OS/-mac/文件系统/","text":"123456789101112131415161718192021$ tree -L 1 -a.├── .CFUserTextEncoding├── .DS_Store├── .Trash├── .atom├── .bash_history├── .bash_sessions├── .sogouinput├── .ssh # ssh key 目录，类似linux├── .viminfo├── Applications├── Desktop├── Documents├── Downloads├── Library├── Movies├── Music├── Pictures├── Public└── Zotero # 为什么zotero会在这儿？ 既然类似linux，为什么没有.bashrc目录？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-mac","slug":"CS/OS/mac","permalink":"http://yoursite.com/categories/CS/OS/mac/"}]},{"title":"","date":"2018-07-25T10:53:15.435Z","path":"wiki/CS/OS/-mac/app-store/","text":"app store会将软件安装在","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-mac","slug":"CS/OS/mac","permalink":"http://yoursite.com/categories/CS/OS/mac/"}]},{"title":"mac中遇到的坑","date":"2018-07-25T10:53:15.435Z","path":"wiki/CS/OS/-mac/mac的坑/","text":"粘贴板的坑比如chrome的粘贴板有时会独立于系统粘贴板，在系统其它地方command + C复制的内容，在chrome粘贴不上。 解决办法: 方式一：重启一下chrome或者那个app 方式二：运行命令killall pboard，重启粘贴板 #","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-mac","slug":"CS/OS/mac","permalink":"http://yoursite.com/categories/CS/OS/mac/"}]},{"title":"","date":"2018-07-25T10:53:15.435Z","path":"wiki/CS/OS/-mac/mac的必备神器/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-mac","slug":"CS/OS/mac","permalink":"http://yoursite.com/categories/CS/OS/mac/"}]},{"title":"文件系统 - 文件","date":"2018-07-25T10:53:15.435Z","path":"wiki/CS/OS/-linux/linux kenel/文件系统/文件系统-文件/","text":"一切皆文件UNIX 系统中除进程之外的一切皆是文件，而 Linux 保持了这一特性。为了便于文件的管理，Linux 还引入了目录（有时亦被称为文件夹）这一概念。 Linux 系统的顶层目录结构12345678910111213141516171819/ 根目录├── bin 存放用户二进制文件├── boot 存放内核引导配置文件├── dev 存放设备文件├── etc 存放系统配置文件├── home 用户主目录├── lib 动态共享库├── lost+found 文件系统恢复时的恢复文件├── media 可卸载存储介质挂载点├── mnt 文件系统临时挂载点├── opt 附加的应用程序包├── proc 系统内存的映射目录，提供内核与进程信息├── root root 用户主目录├── sbin 存放系统二进制文件├── srv 存放服务相关数据├── sys sys 虚拟文件系统挂载点├── tmp 存放临时文件├── usr 存放用户应用程序└── var 存放邮件、系统日志等变化文件 Linux 与其他类 UNIX 系统一样并不区分文件与目录：目录是记录了其他文件名的文件。使用命令 mkdir 创建目录时，若期望创建的目录的名称与现有的文件名（或目录名）重复，则会创建失败。 元数据 VS 用户数据我们知道文件都有文件名与数据，这在 Linux 上被分成两个部分：用户数据 (user data) 与元数据 (metadata)。 用户数据，即文件数据块 (data block)，数据块是记录文件真实内容的地方； 元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。 通过文件名打开文件 软链接 VS 硬链接为解决文件的共享使用，Linux 系统引入了两种链接：硬链接 (hard link) 与软链接（又称符号链接，即 soft link 或 symbolic link） 链接为 Linux 系统解决了文件的共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。若一个 inode 号对应多个文件名，则称这些文件为硬链接。换言之，硬链接就是同一个文件使用了多个别名（见 图 2.hard link 就是 file 的一个别名，他们有共同的 inode）。硬链接可由命令 link 或 ln 创建。如下是对文件 oldfile 创建硬链接。 由于硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性： 文件有相同的 inode 及 data block； 只能对已存在的文件进行创建； 不能交叉文件系统进行硬链接的创建； 删除一个硬链接文件并不影响其他有相同 inode 号的文件。(删除的只是filename) 不能对目录进行创建，只可对文件创建； 逐个详解 ： 1. 2. 3. 硬链接不能对目录进行创建，只可对文件创建； 目录是树形结构。ls -a能看到目录底下有. 和.. 指向本目录和父目录，如果对父目录建立软连接就有可能会成环，破坏树形结构 5. 1234567891011121314151617181920$ echo sss &gt; oldfile$ link oldfile newfile # 2. oldfile要存在，newfile必须不存在，$ ls -li6277186 -rw-r--r-- 2 xusong staff 4 Jul 24 20:54 newfile6277186 -rw-r--r-- 2 xusong staff 4 Jul 24 20:54 oldfile# 5. 删除一个硬链接文件并不影响其他有相同 inode 号的文件。(删除的只是filename)$ rm oldfile$ ls -li6277186 -rw-r--r-- 1 xusong staff 4 Jul 24 20:54 newfile# 5. 不能对目录进行创建，只可对文件创建；# 目录是树形结构。ls -a能看到目录底下有. 和.. 指向本目录和父目录，如果对父目录建立软连接就有可能会成环，破坏树形结构$ mkdir old_dir$ ls -lia6277575 drwxr-xr-x 3 xusong staff 96 Jul 24 21:04 .6277177 drwxr-xr-x 6 xusong staff 192 Jul 24 21:04 ..6277580 drwxr-xr-x 2 xusong staff 64 Jul 24 21:04 old_dir$ link old_dir new_dirlink: old_dir: Is a directory FAQ思考软链接，是链接的node号还是路径名？路径名。在git中看到的是路径名。另外，被link的目录删除再新建一个一样的，照样能识别。 123456# bash1cd a/b/c# bash2mv test test #","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"文件系统","slug":"CS/OS/linux/linux-kenel/文件系统","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/"}]},{"title":"【Docker系列】docker中的权限","date":"2018-07-20T16:00:00.000Z","path":"wiki/docker/tutorial/-permission/","text":"docker 客户端12$ ls -lh /usr/bin/docker-rwxr-xr-x 1 root root 37M Apr 26 15:18 /usr/bin/docker 默认所有用户都能够执行docker命令，但是执行其他命令，会出现权限问题。 docker 服务12$ docker imagesGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied 执行查询镜像命令，报错。因为该用户不在docker用户组。而只有docker用户组才有权限访问docker server。 12345$ cd /var/run/$ ls -lh | grep dockerdrwx------ 9 root root 200 Jul 7 11:03 docker-rw-r--r-- 1 root root 4 Jul 6 14:33 docker.pidsrw-rw---- 1 root docker 0 Jul 6 14:32 docker.sock # docker server docker.sock属于docker用户组。 12$ cat /etc/group | grep dockerdocker:x:999:song.xu01 添加权限1$ usermod -aG docker 用户名 # 添加到docker用户组","tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://yoursite.com/tags/cloud/"}],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"【Docker系列】Docker的存储","date":"2018-07-20T16:00:00.000Z","path":"wiki/docker/tutorial/-storage/","text":"简介https://docs.docker.com/storage/storagedriver/ 每个Docker镜像（Image）都引用了一些只读的（read-only）层（layer），不同的文件系统layer也不同。这些layer堆叠在一起构成了容器（Container）的根文件系统（root filesystem）。 当你基于Ubuntu 创建一个新的容器的时候，你其实只是在它的上层又增加了一个新的、薄的、可写层。这个新增的可写层称为容器层（container layer）。当这个新的容器运行时，所有的改动（比如创建新文件、修改已有文件、删除文件等）都会写到这一层。 存储 - 镜像层(Layers)镜像层依赖于一系列的底层技术，比如文件系统(filesystems)、写时复制(copy-on-write)、联合挂载(union mounts)等 容器层是可写层。 例如：docker history tensorflow/tensorflow:1.8.0-gpu tensorflow镜像 nvidia-cuda镜像 ubuntu镜像 写时拷贝策略(CopyOnWrite)CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，之后再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 缺点 内存占用问题：在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。 docker的什么操作会写容器？不涉及文件写操作的会涉及到容器的写操作吗？只有commit操作会写操作？ 数据一致性问题 COW的应用CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。 COW在java从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet COW在C++C++的STL中，曾经也有过Copy-On-Write的玩法，参见陈皓的《C++ STL String类中的Copy-On-Write》，后来，因为有很多线程安全上的事，就被去掉了。 数据持久化配置本地镜像与容器的存储位置默认情况下Docker的存放位置为：/var/lib/docker可以通过下面命令查看具体位置：1docker info | grep \"Docker Root Dir\" 解决这个问题，最直接的方法当然是挂载分区到这个目录，但是我的数据盘还有其他东西，这肯定不好管理，所以采用修改镜像和容器的存放路径的方式达到目的。 这个方法里将通过软连接来实现。 首先停掉Docker服务：123systemctl restart docker或者service docker stop 然后移动整个/var/lib/docker目录到目的路径： 12mv /var/lib/docker /root/data/dockerln -s /root/data/docker /var/lib/docker 这时候启动Docker时发现存储目录依旧是/var/lib/docker，但是实际上是存储在数据盘的，你可以在数据盘上看到容量变化。 docker的挂载unmount 系统文件夹使用的是devicemapper文件系统，可以用来限制容器的磁盘使用。 在devicemapper驱动下，多出两个文件，一个是 devicemapper 一个是metadata 文件目录1234567891011121314/var/lib/docker# lsaufsbuilderbuildkitcontainerdcontainersimagenetworkpluginsruntimesswarmtmptrustvolumes 参考 Docker镜像分层技术 JAVA中的COPYONWRITE容器 Docker配置本地镜像与容器的存储位置","tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://yoursite.com/tags/cloud/"},{"name":"写时拷贝","slug":"写时拷贝","permalink":"http://yoursite.com/tags/写时拷贝/"}],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"【Docker系列】Docker入门教程","date":"2018-07-20T16:00:00.000Z","path":"wiki/docker/tutorial/get-started/","text":"环境配置的难题如果你正好是一个运维工程师而且你正感觉你的运维环境一团糟，麻烦请你思考一下这是为什么？你是不是正在运维着一个使用 php、java、C#甚至 C/C++等用各种语言编写的应用都在运行的环境里？这个环境是不是因为某种历史原因，使你的操作系统运行着各个版本的内核甚至还有 windows？即使是同样语言编写的业务也运行着不同版本的库？你的整个系统环境是不是甚至找不出来两台硬件、操作系统、库版本以及语言版本完全一样的环境？于是你每次遇到问题都要去排查到底那个坑到底在那里？从网络、内核到应用逻辑。你每次遇到产品升级都要在各种环境上做稳定性测试，发现不同的环境代码 crash 的原因都不尽相同。你就像一个老中医一样去经历各种疑难杂症，如果遇到问题能找到原因甚至都是幸运的，绝大多数情况是解决了但不知道原因和没解决自动好了也不知道原因。于是你们在一个特定的公司的环境中积累着“经验”，成为你们组新手眼中的大神，凭借历经故障养成的条件反射在快速解决不断发生的重复问题，并故弄玄虚的说：这就是工作经验。因为经验经常是搞不清楚原因时的最后一个遮羞布。当别人抱怨你们部门效率低的时候，你一般的反应是：”you can you up，no can no 逼逼！“ 来自知乎 简介 &amp; 简单原理 可重复 可移植。镜像应该可以运行在任何主机上并且运行尽可能多的次数。 用了 Docker，就像世界出现了集装箱，这样你的业务就可以随意的、无拘无束的运行在任何地方。 Docker 公司的口号：Build，Ship，and Run Any App，Anywhere。大概意思就是编译好一个应用后，可以在任何地方运行，不会像传统的程序一样，一旦换了运行环境，往往就会出现缺这个库，少那个包的问题。 Docker concepts 镜像（Image）：Docker 把应用程序及其依赖，打包在 image 文件里面 容器（Container）: 镜像本身是只读的，容器从镜像启动时，Docker在镜像的上层创建一个可写层，镜像本身不变。同一个 image 文件，可以生成多个同时运行的容器实例。 注册服务器（Registry）: 存放实际的镜像的地方，比如Docker的官方仓库Docker Hub、Docker Store 仓库（Repository）: 仓库是存放一组关联镜像的集合，比如同一个应用的不同版本的镜像。比如tensorflow 基本操作关于镜像的基本操作1234567docker images # 列出本机所有的docker镜像docker inspect img_id # 查看镜像详细信息docker history img_id # 查看镜像分层docker rmi img_id # 删除镜像docker rmi -f $(docker images -q) # 删除所有镜像docker pull repository:tag # 拉取镜像，类似 git pulldocker push repository:tag # 上传镜像，类似git push 关于容器的基本操作123456789101112131415161718192021222324252627282930# 1. 基于镜像启动一个容器NAME=name_test # 命名你的容器，姓名_任务_其他PROJECT_DIR=`pwd`/tutorialnvidia-docker run -it \\ --name $NAME \\ -v $PROJECT_DIR:/root/ \\ tensorflow/tensorflow:latest-gpu bash# 2. 运行程序cd /rootexport CUDA_VISIBLE_DEVICES= # 只占用cpupython convolutional.py# 3. 退出容器ctrl+p+q # 临时退出容器而不终止它 (不关闭bash进程)# ctrl+d # 退出shell，退出容器# 4. 查看所有正在运行的容器，并通过name找到你运行的容器docker ps# 5. 查看运行日志docker logs container_id# 6. 重新进入容器docker attach container_id # 进入同一个bash# 或者docker exec -it container_id bash # 重新创建一个bash# 7. 删除容器docker rm container_id# 8. 删除所有容器docker rm -f $(docker ps -a -q)# 9. Copy a file from host to container 注意区别dockerfile的COPY命令docker cp foo.txt 72ca2488b353:/foo.txt 思考attach 与 exec的区别docker cp 与 dockerfile中的COPY的区别ctrl+p+q 与 ctrl+d的区别 exit退出容器后，为什么容器并未删除？ 使用建议 合理命名镜像和容器 少用port 不要把频繁更新的项目打入镜像 不用的镜像及时删除 不用的容器及时退出 扩展阅读 操作 Docker 容器 | Docker从入门到实践 定制自己的镜像 - Dockerfile自己写dockerfile FROM: 指定基础镜像 MAINTAINER：用来指定维护者的姓名和联系方式 ENV: 设置环境变量 RUN：在shell或者exec的环境下执行的命令。RUN指令会在新创建的镜像上添加新的层 EXPOSE: 指定容器在运行时监听的端口 COPY: VOLUME: 授权访问从容器内到主机上的目录。用于containers之间共享数据 WORKDIR: 指定RUN、CMD与ENTRYPOINT命令的工作目录。 ENTRYPOINT: CMD: 提供了容器默认的执行命令 注意 CMD与 ENTRYPOINT 的区别： CMD不能接受参数，运行时可被覆盖； ENTRYPOINT能够接收参数，运行时不可被覆盖 COPY与映射-v的区别 示例dockerfile build images从文件进行build1docker build -f dockerfile . -t tensorflow/t2t:nmt 或 从标准输入中读取 Dockerfile 进行构建1cat dockerfile | docker build - docker镜像升级 更改 &amp; commit的方式 (不推荐) 一定不要用别人commit的镜像，是坑，用的时间越长坑越多 更改dockerfile，重新build镜像 (推荐) Dockerfile的优化技巧apt-get install之前先apt-get update尽量选取满足需求但较小的基础镜像，(比如debian:wheezy，仅有86MB大小)清理编译生成文件、安装包的缓存等临时文件安装各个软件时候要指定准确的版本号，并避免引入不需要的依赖从安全的角度考虑，应用尽量使用系统的库和依赖使用Dockerfile创建镜像时候要添加.dockerignore文件或使用干净的工作目录 扩展阅读: Best practices for writing Dockerfiles | 官网 练习登录服务器ssh docker1@**.**.**.12 关于镜像的操作参考上文↑ 关于容器的基本操作 从已有docker启动容器，参考https://hub.docker.com/r/tensorflow/tensorflow/ 从bash启动容器，参考上文↑ optinal: httpd: 利用docker搭一个http server gitlab: 利用docker搭一个gitlab server kaldi: 利用docker跑kaldi pytorch: 利用docker跑pytorch Dockerfile相关 找到tensorflow的dockerfile，并参考 找到nvidia/cuda的dockerfile，并参考 自己根据需求，修改dockerfile，build image 思考卸载 + commit 操作，镜像会变小吗？run yum clean cache这样写dockerfile，镜像会变小吗？可以在一个容器中同时运行多个应用进程吗？Docker运行时内部删除的文件，如何恢复？RUN rm -rf somefile 镜像会减小吗？示例 扩展阅读 什么是 Docker ？ | 腾讯云社区 Docker 入门教程 | 阮一峰 docker practice","tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"cloud","slug":"cloud","permalink":"http://yoursite.com/tags/cloud/"}],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"}]},{"title":"从wmt竞赛看机器翻译史","date":"2018-07-19T08:41:39.527Z","path":"wiki/machine translation/竞赛 & 业界/WMT/","text":"简介 &amp; 汇总 wmt15 wmt16 wmt17 wmt18 WMT15WMT16WMT2017搜狗机器翻译团队获得 WMT 2017 中英机器翻译冠军 尚未出现transformer，主流模型是attention-RNN。 核心问题通常是如何优化神经网络结构以便解决机器翻译中的词对齐、罕见词、长句等难点问题。 2014 年提出的注意力（attention）模块就是针对性处理因为不同语言语法结构不同产生的语序不同、来源词与目标词对齐难的问题。注意力机制通过选全局性的选择关注源语言橘子的不同部分，动态地构建上下文向量来对传统 RNN 编码器-解码器进行了优化，极大改善了语言调序，尤其是中长距离调序问题。 WMT2018腾讯信息安全部征战世界机器翻译大赛获不俗战绩 - 2018 阿里、腾讯冠军。主流方法transformer。比wmt17提升 阿里达摩院 - 5项冠军5个项目包括英文-中文翻译、英文-俄罗斯语互译、英文-土耳其语互译，达摩院在这几个项目的自动评测指标BLEU都位居第一。 陈博兴博士 司罗教授 - NLP 首席科学家 基于业界最新的Transformer结构，进行了网络结构的改进和对词语位置信息的充分利用。 尽管 Transformer 在解码速度和位置编码等方面有一些缺点，但它仍然是当前效果最好的神经机器翻译基本架构 腾讯transformer改进将 Transformer 中的 Multi-Head Attention 替换为多个自注意力分支，而模型会在训练阶段中将学习结合这些分支注意力模块。其次，阿里采用了一种编码相对位置的表征以扩展自注意力机制，并令模型能更好地理解序列元素间的相对距离。 多模型融合 主体是transformer rnn seq2seq每一种翻译任务都集成了几十上百个基础模型 参考专访达摩院 云知声 - 第三transformer + 数据生成（back translation）、多形态模型融合（ensemble）、多特征重排序（rerank）等，优化翻译效果。","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"竞赛 & 业界","slug":"machine-translation/竞赛-业界","permalink":"http://yoursite.com/categories/machine-translation/竞赛-业界/"}]},{"title":"马尔可夫模型（Markov models","date":"2018-07-19T08:41:39.489Z","path":"wiki/ML/ml 传统方法/supervised/-马尔科夫模型/","text":"马尔可夫性质（英语：Markov property）是概率论中的一个概念，因为俄国数学家安德雷·马尔可夫得名。当一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态；换句话说，在给定现在状态时，它与过去状态（即该过程的历史路径）是条件独立的，那么此随机过程即具有马尔可夫性质。具有马尔可夫性质的过程通常称之为马尔可夫过程。 马尔可夫模型（Markov models）包括四种： 全观测 部分观测 System is autonomous 马尔科夫链 HMM System is controlled 马尔科夫决策过程 部分观测马尔科夫决策过程 马尔可夫链（英语：Markov chain），又称离散时间马可夫链（discrete-time Markov chain) 。下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。 m阶马尔可夫链。未来状态取决于其前m个状态 这个的转移概率矩阵，是什么样的？这个矩阵会特别大吧？ Markov random field bi-gram的转义概率是个二元矩阵，n-gram的转义概率是什么？n元的tensor吗？n元的tensor会非常稀疏。 n-gram的n大小对性能的影响n更大的时候n: 对下一个词出现的约束性信息更多，更大的辨别力，但是更稀疏，并且n-gram的总数也更多，为 V^n 个（V为词汇表的大小） n更小的时候在训练语料库中出现的次数更多，更可靠的统计结果，更高的可靠性 ，但是约束信息更少 其中当N为特定值的时候，我们来看一下n-gram可能的总数，如下表 词表中词的个数 |V|=20,000词 n 所有可能的n-gram数 2 bigram 400,000,000 3 trigram 8,0000,0000,0000,0000 4 4-grams 1.6 *10^17 3gram数据太大了","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"}]},{"title":"","date":"2018-07-19T08:41:39.486Z","path":"wiki/ML/trick/-label-smooth/","text":"相关工作google的inception-v1-4 Szegedy在网络实现的时候，令 label_smoothing = 0.1，num_classes = 1000。Label smooth提高了网络精度0.2%。 google的[transformer]","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"GPU cuda安装指南","date":"2018-07-19T08:41:39.481Z","path":"wiki/CS/parallel computing-高性能计算/-cuda/N卡-GPU型号/","text":"支持cuda的nvidia GPUhttps://developer.nvidia.com/cuda-gpus ## NVIDIA TX1/TX2优点： 性能强 NVIDIA嵌入式级GPU CUDA配套好缺点 价格高 自己做底板 不能跑Android 查看有没有 Verify You Have a CUDA-Capable GPU12345$ lspci | grep -i nvidia83:00.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1)84:00.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1)87:00.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1)88:00.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1) 1$ nvidia-smi 参考-","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"parallel computing-高性能计算","slug":"CS/parallel-computing-高性能计算","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/"},{"name":"-cuda","slug":"CS/parallel-computing-高性能计算/cuda","permalink":"http://yoursite.com/categories/CS/parallel-computing-高性能计算/cuda/"}]},{"title":"","date":"2018-07-19T08:41:39.480Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-上层包/tensor2tensor/架构/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-上层包","slug":"ML/deep-learning/toolbox/tensorflow/上层包","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/上层包/"},{"name":"tensor2tensor","slug":"ML/deep-learning/toolbox/tensorflow/上层包/tensor2tensor","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/上层包/tensor2tensor/"}]},{"title":"","date":"2018-07-19T08:41:39.479Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-常见错误/","text":"error 11ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory nvcc –versino tensorflow和cuda版本的问题。 #","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"【tensorflow系列】tensor","date":"2018-07-19T08:41:39.478Z","path":"wiki/ML/deep learning/toolbox/tensorflow/low-level-api/-tensor/","text":"扩展阅读 Tensors | tensorflow guide","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"low-level-api","slug":"ML/deep-learning/toolbox/tensorflow/low-level-api","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/low-level-api/"}]},{"title":"【tensorflow系列】variable","date":"2018-07-19T08:41:39.478Z","path":"wiki/ML/deep learning/toolbox/tensorflow/low-level-api/-variable/","text":"A Variable is a special kind of operation that returns a handle to a persistent mutable tensorthat survives across executions of a graph. tf.Variable类 - 源码 继承自 checkpointable.CheckpointableBase 扩展阅读 Variables | tensorflow guide","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"low-level-api","slug":"ML/deep-learning/toolbox/tensorflow/low-level-api","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/low-level-api/"}]},{"title":"tensorflow gpu","date":"2018-07-19T08:41:39.477Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-gpu-tf/","text":"tensorflow gputensorflow默认抢占服务器所有GPU的所有显存，一段小程序也会占用所有GPU资源。 解决方案： 为tf指定GPU：123import osos.environ[‘CUDA_VISIBLE_DEVICE’] = ‘1,2'# os.environ['CUDA_VISIBLE_DEVICES'] = '' # 设置为空，则使用cpu。或者='-1' 或者12345678910import tensorflow as tfwith tf.device('/gpu:0'): # Run nodes with GPU 0 m1 = tf.constant([[3, 5]]) m2 = tf.constant([[2],[4]]) product = tf.matmul(m1, m2) sess = tf.Session()print(sess.run(product))sess.close() 或者设置环境变量123$ export CUDA_VISIBLE_DEVICES=0,1# 指定cpu，指定 visible devices为空$ export CUDA_VISIBLE_DEVICES= 其次是限制在每个可用GPU上占据需要使用的内存大小：12gpu_options = tf.GPUOptions(allow_growth=True)sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) 该设置会启用最少的GPU显存来运行程序。 在tensorflow中定义session时作如下设置，该设置会强制程序只占用指定比例的GPU显存。123config = tf.ConfigProto()config.gpu_options.per_process_gpu_memory_fraction = 0.4 # 占用GPU40%的显存session = tf.Session(config=config) 多GPU1234567891011121314151617181920import tensorflow as tfc = []for i, d in enumerate(['/gpu:0', '/gpu:1', '/gpu:2']): with tf.device(d): a = tf.get_variable(f\"a_&#123;i&#125;\", [2, 3], initializer=tf.random_uniform_initializer(-1, 1)) b = tf.get_variable(f\"b_&#123;i&#125;\", [3, 2], initializer=tf.random_uniform_initializer(-1, 1)) c.append(tf.matmul(a, b))with tf.device('/cpu:0'): sum = tf.add_n(c)sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))init = tf.global_variables_initializer()sess.run(init)print(sess.run(sum))# [[-0.36499196 -0.07454088]# [-0.33966339 0.30250686]] 如何设置多个worker gputensor2tensor中的worker-gpu配置，是怎样实现的。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"","date":"2018-07-19T08:41:39.477Z","path":"wiki/ML/deep learning/toolbox/tensorflow/low-level-api/-placeholder/","text":"源码 123@tf_export(\"placeholder\")def placeholder(dtype, shape=None, name=None): ...","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"low-level-api","slug":"ML/deep-learning/toolbox/tensorflow/low-level-api","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/low-level-api/"}]},{"title":"","date":"2018-07-19T08:41:39.475Z","path":"wiki/ML/app/nlp/trick/trick-nlp/-OOV - subword/","text":"未登录词替换2015Addressing the rare word problem in neural machine translation 最小意义单元 - subword2016A character level decoder without explicit segmentation for neural machine translation. 2016Character Based Neural Machine Translation Achieving open vocabulary neural machine translation with hybrid word-character models 2016Fully Character Level Neural Machine Translation without Explicit Segmentation","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-nlp","slug":"ML/app/nlp/trick/trick-nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-nlp/"}]},{"title":"","date":"2018-07-19T08:41:39.475Z","path":"wiki/ML/app/nlp/trick/trick-nlp/-词表扩大/","text":"2015On using very large target vocabulary for neural machine translation 提出词表扩大的方法","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-nlp","slug":"ML/app/nlp/trick/trick-nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-nlp/"}]},{"title":"","date":"2018-07-19T08:41:39.474Z","path":"wiki/ML/app/nlp/trick/trick-nlp/-zero-shot/","text":"Zero-shot learning 指的是我们之前没有这个类别的训练样本。但是我们可以学习到一个映射X-&gt;Y。如果这个映射足够好的话，我们就可以处理没有看到的类了。 比如，我们在训练时没有看见过狮子的图像，但是我们可以用这个映射得到狮子的特征。一个好的狮子特征，可能就和猫，老虎等等比较接近，和汽车，飞机比较远离。 https://www.zhihu.com/question/50996014/answer/157230966 跟oov的关系？","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-nlp","slug":"ML/app/nlp/trick/trick-nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-nlp/"}]},{"title":"","date":"2018-07-19T08:41:39.474Z","path":"wiki/ML/app/nlp/trick/trick-nlp/-多任务/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-nlp","slug":"ML/app/nlp/trick/trick-nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-nlp/"}]},{"title":"","date":"2018-07-19T08:41:39.474Z","path":"wiki/ML/app/nlp/trick/trick-nlp/-最小意义单元/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-nlp","slug":"ML/app/nlp/trick/trick-nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-nlp/"}]},{"title":"【词向量】汇总","date":"2018-07-19T08:41:39.471Z","path":"wiki/ML/app/nlp/app/word-vector/-summary/","text":"之前的word representation？ 还有一种C&amp;W模型，是将context和target-word同时放在网络的同一层。与NNLM的思想不太一样。还有GloVe模型， 汇总 one-hot representation 容易受维数灾难的困扰 不能很好地刻画词与词之间的相似性 distributed representation (分布式表示，也叫word embedding) 基于矩阵的分布表示 基于聚类的分布表示 基于神经网络的分布表示 NNLM: softmax复杂度高 word2vec: 用CBOW和Skip-gram来简化NNLM GloVe Glove: Global vectors for word representation, 2014 EMNLP pdf WordRank ELMo subword，解决oov问题 传统方法见到oov的单词，会采用相同的embedding （UNK） char的应用，有CNN over characters，有token embeddings Enriching Word Vectors with Subword, Bojanowski et al.,2017 pdf Word2Vec using Character n-grams, Wiseman et al. 2016 Charagram: Embedding words and sentences via character n-grams, Wieting et al., 2016 Joint Learning of Character and Word Embeddings FastText BPE 多义 每个单词学习多个embedding，learning separate vectors for each word sense Efficient nonparametric estimation of multiple embeddings per word in vector space, Neelakantan et al., 2014 context-dependent 为什么要context-depent context2vec: Learning generic context embedding with bidirectional lstm, CoNLL 2016 deep: 不同的层表征不同level的信息 deep cnn/lstm EMLo attention transformer也能用来学习embedding 半监督 Semisupervised sequence learning, Dai and Le 2015 Improving sequence to sequence learning with unlabeled data, Ramachandran et al. 2017 双向- 其他:- Learned in translation: Contextualized word vectors, McCann et al., 2017 Cluster-based character embeddings 对每个字的所有 occurrence 进行聚类，然后对每个类建一个 embedding Position-based character embeddings 区分字在词中出现的位置，也就是用 char+pos 来表示字，idea 是通常一个字可能出现在词的开始、中间、尾部。如车道、人行道和道法、道经中的道就不是一个含义； word2vec与语言模型 word2vec- word distance embedding distance edit distance，编辑距离体现character级别的信息。 idea enriching word vector with character information 采用cnn 采用rnn 采用编辑距离 约束 主要方向 semantic-level: HMM: lstm: 前面context 重构后面 supervised lstm for embedding bi-lstm: word2vec: 前后context 重构中间。并强制遵循向量加减法。（有点类似RBM到autoencoder，挺好） supervised word2vec char-level: 比如fatherland-father-land, beautiful-beauty, 北京电影学院-北影 context-based: 不同上下文，具有不同的含义 采用multichannel 一个channel采用word2vec学习到的embedding 一个channel采用charCNN学习到的embedding 一个channel采用自变量(类似cnn_for_text_classification) 原理见paper &amp; zotero ideapretrained w2v fastText 294 languages, trained on Wikipedia using fastText. w2v-api eval见https://bitbucket.org/song_xu/word2vec-evaluation/src codetraining c official python tensorflow [theano] [gensim] java IO &amp; service python word2vec-api java load model 实验结果tensorflow word2vec结果 tensorflow language_model结果","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"}]},{"title":"","date":"2018-07-19T08:41:39.470Z","path":"wiki/ML/app/nlp/app/word-vector/model/-subword/character n-gram/","text":"where and n = 3 as an example, it will berepresented by the character n-grams: &lt;wh, whe, her, ere, re&gt;","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-subword","slug":"ML/app/nlp/app/word-vector/model/subword","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/subword/"}]},{"title":"","date":"2018-07-19T08:41:39.469Z","path":"wiki/-audio/ASR/声学模型/CD-GMM-HMM框架/","text":"音素：单词的发音由音素构成。对英语，一种常用的音素集是卡内基梅隆大学的一套由39个音素构成的音素集，参见The CMU PronouncingDictionary。汉语一般直接用全部声母和韵母作为音素集，另外汉语识别还分有调无调 状态：这里理解成比音素更细致的语音单位就行啦。通常把一个音素划分成3个状态。 若干帧语音对应一个状态，每三个状态组合成一个音素，若干个音素组合成一个单词 语音识别是怎么工作的呢？实际上一点都不神秘，无非是： 把帧识别成状态（难点）。 把状态组合成音素。 把音素组合成单词。 参考https://www.zhihu.com/question/20398418","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"声学模型","slug":"audio/ASR/声学模型","permalink":"http://yoursite.com/categories/audio/ASR/声学模型/"}]},{"title":"行存储 VS 列存储","date":"2018-07-19T08:41:39.466Z","path":"wiki/CS/-database/row-VS-column/","text":"每行是一条数据。每列是一个field。 按行存储示例： 123[ &#123;A: 1, B:42&#125;, &#123;A: 5, B:12&#125;, &#123;A: 5, B:6&#125; ], 按行获取数据比较方便，获取一列数据比较慢。 按列存储示例： 12&#123; A: [1, 5, 5], B: [42, 12, 6]&#125;. 按列获取数据比较方便，获取一行数据比较慢。 通常情况下，只有少数field会经常用。按列存储还能够更好利用cpu缓存。 more efficient for queries that target a limited number of fields by making better use of CPU caches。- 实例 - luceneDoc values are a Lucene 4.x feature which allow for storing field values on disk in a column stride fashion, which is filesystem cache friendly and suitable for custom scoring, sorting or faceting, exactly like field data. https://www.elastic.co/blog/disk-based-field-data-a-k-a-doc-values 实例","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"}]},{"title":"","date":"2018-07-18T01:42:04.746Z","path":"wiki/ML/trick/-过拟合-正则/","text":"稀疏，算在另外一个文件","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-07-13T06:52:08.272Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/排序-大数据排序/","text":"题目 给定1亿个数（范围1-1亿，可重复出现）。给定任意个数，求出该数在该数组中的大概排序？(非内存处理)？ 10亿个数中找出最大的10000个数（top K问题） 棘手点： 不能一次性读入内存- 默认的sort函数shell的sort命令，采用了归并排序，排序时候的临时小文件是默认放在/tmp路径下的，有时候/tmp的空间有限制，比如4G，那么，超过4G的文件就没有办法用sort了。当然也可以用sort -T Path 来临时文件的目录。 python的sort java的sort C++的sort 排序算法1.如果是无重复整型，果断位排序，（编程珠玑有介绍）。2.如果有重复的整型，果断计数排序，3.如果是字符串，果断字典树来排序啊。。当然，就算不是字典树，我们也可以转化为字典树来解答。。 遍历一次，累计给定的数大于多少个元素，不就是准确的排行么？如果要大概，也可以抽样，累计大于样本的数目，估计一个百分比。如果题目是指，遍历一次后，需求任意个数的排行，那么可在遍历时生成直方图，然后转为累计直方图，最后可以直方图区间插值得出估计的排行。 归并排序特点，它是读取次数最少得排序，因为若内存空间不足，则必须将数据存在硬盘中，要尽量减少I/0的次数。 快排1.快速排序的概率时间是接近o（n）的，是几种 nlogn中最好的2.快速排序的空间复杂度是 o（n）的，优于归并的 o（2n）3.内存的好处就是读取存取速度快，而恰恰快排是依赖R/W的排序 A: 当数据本身有一定次序时，快排会退化为o(n^2)B: 恩，不过这种情况一般不会发生，可以通过random参数来fix的，算法导论排序那章讨论过这个特例和fix方法的。 请问一下为什么快排的空间复杂度是O(n)呢？。不是原地排序吗？是递归使用的栈内存吗？ 桶排序O（n）这算脑筋急转弯 参考 https://www.zhihu.com/question/19833105-","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"语音识别 基本框架","date":"2018-06-26T16:00:00.000Z","path":"wiki/-audio/ASR/ASR框架/","text":"流程1 . 准备声学模型训练数据 音素词典 发音词典 初次模型训练数据 准备开发验证集数据 语音数据增强的方法，借鉴百度Deep speech2中说到的方法进行扩充语料。 细节$$\\begin{split}W^{*}&amp;=\\mathop{\\arg\\max}{w} P(W|Y)\\&amp;=\\mathop{\\arg\\max}{w} \\frac{P(Y|W)P(W)}{P(Y)}\\&amp;=\\mathop{\\arg\\max}{w} \\underbrace{P(Y|W)}{AM} \\underbrace{P(W)}_{LM}\\\\end{split}$$ 上式中W表示文字序列，Y表示语音输入。公式1表示语音识别的目标是在给定语音输入的情况下，找到可能性最大的文字序列。根据Baye’ Rule，可以得到公式2，其中分母表示出现这条语音的概率，它相比于求解的文字序列没有参数关系，可以在求解时忽略，进而得到公式3。公式3中第一部分表示给定一个文字序列出现这条音频的概率，它就是语音识别中的声学模型；第二部分表示出现这个文字序列的概率，它就是语音识别中的语言模型。无论是传统的方法也好，现在火热的深 度神经网络的方法也罢，目前的语音识别架构都没有脱离上面的公式，也就是说都离不开AM和LM。下面分别对这两部分进行介绍 参考https://www.zhihu.com/question/20398418","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"}]},{"title":"文本特征提取","date":"2018-06-25T16:00:00.000Z","path":"wiki/ML/app/nlp/-预处理&特征提取/","text":"简介特征 [BOW] 参考 https://github.com/facebookresearch/fastText/blob/master/wikifil.pl 文本特征提取","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"}]},{"title":"","date":"2018-06-25T02:00:42.010Z","path":"wiki/others/-足球/世界杯/2018世界杯/-尼日利亚-穆萨/","text":"VS 冰岛穆萨独进2球","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"世界杯","slug":"others/足球/世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/"},{"name":"2018世界杯","slug":"others/足球/世界杯/2018世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/2018世界杯/"}]},{"title":"","date":"2018-06-25T02:00:42.005Z","path":"wiki/CS/tools/formatting/markdown/-render-pandoc/","text":"tools formatting markdown","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"markdown","slug":"CS/tools/formatting/markdown","permalink":"http://yoursite.com/categories/CS/tools/formatting/markdown/"}]},{"title":"","date":"2018-06-25T02:00:42.003Z","path":"wiki/CS/network/爬虫/-反爬虫-登录/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"爬虫","slug":"CS/network/爬虫","permalink":"http://yoursite.com/categories/CS/network/爬虫/"}]},{"title":"","date":"2018-06-25T02:00:42.003Z","path":"wiki/CS/network/爬虫/-反爬虫-验证码/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"爬虫","slug":"CS/network/爬虫","permalink":"http://yoursite.com/categories/CS/network/爬虫/"}]},{"title":"【反爬虫系列】代理IP","date":"2018-06-25T02:00:42.003Z","path":"wiki/CS/network/爬虫/爬虫-代理IP/","text":"简介市面上的免费代理IP种类繁多，很多品牌被吹嘘得天花乱坠，让用户在挑选时不知道该如何下手。其实对于大部分用户来说，选择一款服务器稳定的代理IP资源是十分明智的，而对于免费代理IP来说，稳定性恰恰是它们的通用诟病，你需要花费大量的时间精力来筛选可用IP资源， 资源免费IPhttps://github.com/jhao104/proxy_pool 收费IP 供应商 节点来源 协议支持 线路类型 价格 代理云 宽带拨号 Http/Https/Socks4 5 电信、联通、移动 最低5000IP/日（起售），最高可满足10万IP/日 [太阳HTTP] Http/Https/Socks5 每日免费领20个IP。公司给买的每天300个IP，估计是最低套餐 方式 HTTP代理IP从成本上区分有免费版和付费版两种，免费IP获取方便，在百度搜索关键词就可以得到大量资源，缺点是免费IP服务器存在不安全因素，用户的访问信息有可能会被记录，造成个人隐私泄漏，无法保障使用者的安全性。由于代理IP传输的特殊性，甚至还可能掉进一些伪造的钓鱼网站，带来不必要的麻烦。 分布式高质量代理IP变成了爬虫业的刚需，通过接入代理云平台，直接进行多线程操作 代理云为爬虫提供分布式代理IP解决方案 # 代理IP速度慢的原因有很多，原因一，代理IP服务器所处网络速度不佳；原因二，代理IP服务器性能差；原因三，代理IP服务器传输距离远；原因四，目标站点速度不稳定；原因五，用户电脑配置差；原因六，用户网速慢。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"爬虫","slug":"CS/network/爬虫","permalink":"http://yoursite.com/categories/CS/network/爬虫/"}]},{"title":"【2018世界杯】巴西 - 内马尔","date":"2018-06-22T16:00:00.000Z","path":"wiki/others/-足球/世界杯/2018世界杯/-巴西-内马尔/","text":"97分钟，内马尔进球。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"世界杯","slug":"others/足球/世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/"},{"name":"2018世界杯","slug":"others/足球/世界杯/2018世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/2018世界杯/"}]},{"title":"C罗","date":"2018-06-21T16:00:00.000Z","path":"wiki/others/-足球/球星/C罗/","text":"这位33岁的葡萄牙头号球星，面对劲敌西班牙队，独中三元，以一己之力拯救了整个国家队，为球队拿下宝贵的一个积分，瞬间就炸翻了全世界的朋友圈！","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"球星","slug":"others/足球/球星","permalink":"http://yoursite.com/categories/others/足球/球星/"}]},{"title":"神奇的冰岛","date":"2018-06-21T16:00:00.000Z","path":"wiki/others/-足球/世界杯/2018世界杯/-冰岛/","text":"12345678910111213141516171819202122232425262728293031根据最新的人口统计结果冰岛全国只有332529人减去女性165259人减去18岁以下的男性40549人减去35岁以上的男性82313人再减去太胖不适合踢球的22136人剩下的冰岛男性中有1246人忙着观鲸旅游业314人忙着监测地震164人忙着观测火山1934人忙着放羊1464人忙着剪羊毛而剩下的冰岛男人中有23位银行家在坐牢194人是盲人7564人有病在身还有564人在医院、消防队等工作实在走不开还剩下的冰岛男人中有两位队医有两位帮着球场送水7人在帮助运营球队除了要看球的球迷最后冰岛全国就只剩下23人他们都在哪？全部入选了冰岛国家队 因为冰岛劳动力少，运动员人数就更少，所以几乎全队上下都有兼职。除了门将哈尔达松是一位拍摄MV和广告的导演以外，据媒体报道——123456主力右边锋格维兹蒙松是一名优秀的电竞玩家中场（队长）贡纳尔松是一名手球运动员中场西于尔兹松是房地产公司老板主力右后卫塞瓦尔松曾经差点当了飞行员中后卫奥德纳松是美国阿德尔菲大学攻读企业管理硕士学生后卫沙瓦臣是一名普通工人 就连他们的主教练，也是来兼职的，在不踢球的时候，他是一名牙医。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"世界杯","slug":"others/足球/世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/"},{"name":"2018世界杯","slug":"others/足球/世界杯/2018世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/2018世界杯/"}]},{"title":"【2018世界杯】葡萄牙 - C罗","date":"2018-06-21T16:00:00.000Z","path":"wiki/others/-足球/世界杯/2018世界杯/葡萄牙-C罗/","text":"首场：葡萄牙 VS 西班牙开场第4分钟，C罗突入禁区左侧在纳乔防守下倒地，主裁判果断判罚点球，C罗亲自操刀主罚命中！ 第44分钟，葡萄牙中场右路起长传，格德斯禁区弧顶得球后分给C罗，C罗起脚远射，德赫亚关键时刻黄油手，皮球滚入网窝。 第88分钟，葡萄牙获得禁区弧顶任意球机会，C罗主罚标志性轰门，皮球越过人墙急速下坠后飞入球门右侧，比分定格在3 : 3。C罗把葡萄牙在悬崖边上拽了回来。 C罗牛逼，西班牙的守门员是不是也有点水？看人家冰岛守门员多厉害。 冰岛 VS 尼日利亚，输了两球。 参考 33岁的C罗，23岁的身体，一人扛起整个国家队：自律的人究竟有多可怕","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"世界杯","slug":"others/足球/世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/"},{"name":"2018世界杯","slug":"others/足球/世界杯/2018世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/2018世界杯/"}]},{"title":"【2018世界杯】梅西","date":"2018-06-21T16:00:00.000Z","path":"wiki/others/-足球/世界杯/2018世界杯/阿根廷-梅西/","text":"阿根廷 - 梅西 首场： VS 冰岛1:1 阿根廷防守是豆腐渣工程。马拉多纳也在现场 在昨晚小组赛阿根廷vs冰岛的比赛中，第19分钟，阿圭罗在禁区内爆射得分；4分钟后，芬博阿松禁区内混战破门，打入冰岛世界杯历史首个进球。 第63分钟，梅西主罚点球，却被冰岛守门员哈尔多松神勇扑出，最终冰岛1:1逼平阿根廷！ 其他人看梅西一个人干活，很形象。 C罗的点球进了，梅西的被扑了C罗的任意球进了，梅西的打偏了C罗的远射进了，梅西再次射偏C罗带球突破，梅西迷失在冰岛的森林中 每次球到梅西才能发动进攻。阿根廷太容易被防守了。 参考 梅西的点球被一位导演扑出！这个队里还有牙医、电竞玩家","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"世界杯","slug":"others/足球/世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/"},{"name":"2018世界杯","slug":"others/足球/世界杯/2018世界杯","permalink":"http://yoursite.com/categories/others/足球/世界杯/2018世界杯/"}]},{"title":"","date":"2018-06-21T06:37:08.934Z","path":"wiki/CS/tools/formatting/markdown/-render-github/","text":"tools formatting markdown","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"markdown","slug":"CS/tools/formatting/markdown","permalink":"http://yoursite.com/categories/CS/tools/formatting/markdown/"}]},{"title":"马尔科夫模型","date":"2018-06-21T03:58:24.416Z","path":"wiki/ML/ml 传统方法/supervised/hmm/","text":"参考 隐马尔可夫模型 | 宗成庆","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"}]},{"title":"","date":"2018-06-21T03:58:24.411Z","path":"wiki/CS/web/front-end/example/youdao/-robots/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"example","slug":"CS/web/front-end/example","permalink":"http://yoursite.com/categories/CS/web/front-end/example/"},{"name":"youdao","slug":"CS/web/front-end/example/youdao","permalink":"http://yoursite.com/categories/CS/web/front-end/example/youdao/"}]},{"title":"【语言模型】n-gram","date":"2018-06-20T16:00:00.000Z","path":"wiki/-language_model/-model/n-gram/","text":"简介n-gram模型也称为n-1阶马尔科夫模型，它有一个有限历史假设：当前词的出现概率仅仅与前面n-1个词相关。因此(1)式可以近似为： 当n取1、2、3时，n-gram模型分别称为unigram、bigram和trigram语言模型。n-gram模型的参数就是条件概率 假设词表的大小为100,000，那么n-gram模型的参数数量为 n越大，模型越准确，也越复杂，需要的计算量越大。最常用的是bigram，其次是unigram和trigram，n取≥4的情况较少。 n-gram中的back offbackuoff penalty bigram模型的计算bigram的最大似然估计: $$P_{MLE}(w_i|w_{i-1})={count(w_{i-1},w_i) \\over count(w_{i-1})}$$ 这其中需要统计bigram词频$count(w_{i-1},w_i)$和unigram词频$count(w_{i-1})$。 示例通过统计9222个句子，得到： bigram统计量(词频) bigram概率 unigram统计量(词频) 根据unigram统计量进行归一化得到概率 这个例子中，i一共出现了2533次，其中i want 出现827次。归一化后的概率为827/2533=0.33 模型怎么存？模型存的是什么？ n-gram概率？还是原始的n-gram词频？ 按照稀疏矩阵存？还是全矩阵？ 实践技巧所有的操作在log空间 avoid underflow (also adding is faster than multiplying) 回退 backoff smooth 回退revisitngram是基于统计的还是基于学习的？优化 因为ngram的最大似然估计，最优解是解析解，因此无需优化。统计和学习不冲突？ 参考 All Our N-gram are Belong to You | Google 2006","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"}]},{"title":"【语言模型】RNN - LSTM/GRU","date":"2018-06-20T16:00:00.000Z","path":"wiki/-language_model/-model/nnlm/rnnlm/","text":"ss参考 RNN tutorial| tensorflow-","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"},{"name":"model","slug":"language-model/model","permalink":"http://yoursite.com/categories/language-model/model/"},{"name":"nnlm","slug":"language-model/model/nnlm","permalink":"http://yoursite.com/categories/language-model/model/nnlm/"}]},{"title":"自然语言处理 - 从规则到统计","date":"2018-06-20T16:00:00.000Z","path":"wiki/ML/app/nlp/框架-综述/NLP-从规则到统计/","text":"语言字母(或者中文的笔画)、文字和数字实际上是信息编码的不同单元。任何一种语言都是一种编码的方式，而语言的语法规则是编解码的算法。 我们把一个要表达的意思，通过某种语言的一句话表达出来，就是用这种语言的编码方式对头脑中的信息做了一次编码，编码的结果就是一串文字。而如果对方懂得这门语言，他就可以用这门语言的解码方法获得说话人要表达的信息。这就是语言的数学本质。 基本名词 文法、语法 Grammer 文法包括词法和句法 词法主要研究词的内部结构，包括变形、构词法。又称形态学(Morphologic) 句法研究句子结构成分的相关关系 上下文无关文法 (Context Independent Grammar)，比如程序设计语言。计算复杂度大约是句子长度的2次方 上下文有关文法 (Context dependency Grammar)，比如自然语言。计算复杂度大约是语句长度的6次方。 自然语言理解 人是怎样理解语言的？ 机器能否像人一样理解语言？ 今天，机器翻译和语音识别已经做得不错，但大部分这个领域之外的人依然错误地认为这两个应用是靠计算机理解了自然语言而完成的。事实上，它们全都靠得是数学，更准确地说是靠统计。 门派 基于规则的：专家根据自己的经验 人工撰写规则。 背景： 优点：设计规则，简单有效。 缺点：费时费力；规则不能覆盖各种语言现象 基于统计的： 背景：上个世纪80年代后期，机器学习算法被引入到自然语言处理中，这要归功于不断提高的计算能力。 优点：相对基于规则的方法，更鲁棒 缺点/局限性：data-driven，强烈依赖数据，需要大规模的训练语料。计算能力 基于统计的方法代替传统的方法，需要等原有的一批语言学家退休。 今天几乎不再有科学家宣称自己是基于规则方法的捍卫者。而自然语言处理的研究也从单纯的句法分析和语义理解，变成了非常贴近应用的机器翻译、语音识别、文本到数据库自动生成、数据挖掘和知识的获取等等。 上面是什么意思？从无监督学习变成了有监督学习？贬低语义理解？ 门派斗争 基于统计的方法只能处理浅层的自然语言处理问题，无法进入生层次的研究 基于规则的自然语言处理语法规则(Gramar Rules)、词性(Part of Speech)、构词法(Morphologic)等，这些规则是人类学习语言(尤其是外语)的好工具。而恰恰这些语法规则又很容易用计算机的算法描述，这就更坚定了大家对基于规则的自然语言处理的信心。 语法树太复杂 基于统计的自然语言处理由于计算量十分庞大，在20世纪70年代，基于规则的句法分析很快走到了尽头。 1970年以后统计语言学的出现使得自然语言处理重获新生。当时，基于统计的方法核心模型是通信系统加隐马尔科夫模型。这个系统的输入和输出都是一维的符号序列，而且保持原有的次序(即sequence labeling问题)。最早获得成功的是语音识别，接下来是磁性分析。 但是在句法分析中，输入时一维的句子，输出是二维的分析树。在机器翻译中，输出的次序会有很大的变化（翻译不再是sequence labeling问题）。HMM就不太管用了。1988年，IBM的Peter Brown等人提出了基于统计的机器翻译方法，框架是对的，但是效果很差，因为当时既没有足够的数据，也没有足够强大的模型来解决不同语言语序颠倒的问题。 参考 《数学之美》 | 吴军 《》","tags":[{"name":"rule","slug":"rule","permalink":"http://yoursite.com/tags/rule/"},{"name":"nlp","slug":"nlp","permalink":"http://yoursite.com/tags/nlp/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"框架-综述","slug":"ML/app/nlp/框架-综述","permalink":"http://yoursite.com/categories/ML/app/nlp/框架-综述/"}]},{"title":"","date":"2018-06-20T13:12:51.127Z","path":"wiki/others/-足球/球星/梅西/","text":"里奥·梅西（Lionel Messi），1987年6月24日出生于阿根廷圣菲省罗萨里奥市，阿根廷足球运动员，司职前锋，现效力于巴塞罗那足球俱乐部。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-足球","slug":"others/足球","permalink":"http://yoursite.com/categories/others/足球/"},{"name":"球星","slug":"others/足球/球星","permalink":"http://yoursite.com/categories/others/足球/球星/"}]},{"title":"","date":"2018-06-20T13:12:51.126Z","path":"wiki/Math/-信号处理/-傅里叶变换/","text":"傅里叶分析之掐死教程（完整版）更新于2014.06.06 简介历史渊源傅里叶变换是怎样发明的？怎样想到的？ 疑问为什么用 附录三角函数之正交性 证明正交是线性代数的概念，是垂直这一直观概念的推广。作为一个形容词，只有在一个确定的内积空间中才有意义。若内积空间中两向量的内积为0，则称它们是正交的。如果能够定义向量间的夹角，则正交可以直观的理解为垂直。 对于两个函数f 和g，可以定义如下的内积： $$ \\langle f,g\\rangle_{w}=\\int_{a}^{b}f(x)g(x)w(x)\\,dx. $$ 这里引进一个非负的权函数 $w(x)$。这个内积叫做带权$w(x)$的内积。 正交 - 维基百科 http://www.cosmosshadow.com/math/others/2015/08/24/%E7%94%A8%E5%9B%BE%E6%9D%A5%E8%A7%A3%E9%87%8A%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86.html%A6%E5%8E%9F%E7%90%86.html","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-信号处理","slug":"Math/信号处理","permalink":"http://yoursite.com/categories/Math/信号处理/"}]},{"title":"","date":"2018-06-20T13:12:51.124Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-upgrade_cuda_tensorflow/","text":"Upgrade cuda &amp; tensorflowStep 1: Remove previous cuda completely To uninstall the CUDA Toolkit, run the uninstallation script provided in the bin directory of the toolkit. By default, it is located in /usr/local/cuda-7.5/bin:$ sudo /usr/local/cuda-7.5/bin/uninstall_cuda_7.5.pl run the uninstall script in /usr/local/cuda-9.2/bin To uninstall the NVIDIA Driver, run nvidia-uninstall:$ sudo nvidia-uninstall Remove all nvidia drivers completelysudo apt-get autoremove –purge nvidia-* Step 2: Install Cuda Toolkit Description: Toolkit contains NVIDIA Accelerated Graphics Driver OpenGL libraries CUDA 8.0 Toolkit Hit CTRL+ALT+F1 and login using your credentials. kill your current X server session by typing sudo service lightdm stop or sudo lightdm stop Enter runlevel 3 by typing sudo init 3 and install your .run file.Run sudo sh cuda_8.0.44_linux.run You might be required to reboot when the installation finishes.If not, run sudo service lightdm start or sudo start lightdm to start your X server again. Step 3: Environment Setup export PATH=/usr/local/cuda/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH Step 4: Install CuDNN download CuDNN from https://developer.nvidia.com/cudnn Uncompress and copy the cuDNN files into the toolkit directory. Assuming the toolkit isinstalled in /usr/local/cuda, run the following commands tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda/include sudo cp cuda/lib64/libcudnn /usr/local/cuda/lib64 sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn Step 5: Upgrade tensorflow Ubuntu/Linux 64-bit, GPU enabled, Python 2.7Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see “Installing from sources” below.$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl $ sudo pip install –upgrade $TF_BINARY_URL","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"【tensorflow系列】graph & session","date":"2018-06-20T13:12:51.124Z","path":"wiki/ML/deep learning/toolbox/tensorflow/low-level-api/-graph-and-session/","text":"1234567891011121314151617# method 1 sess = tf.Session() print sess.run(…) sess.close() # method 2 with tf.Session() as sess: print sess.run(…) # method 3 - 仅用于交互式环境 sess = tf.InteractiveSession() a = tf.constant(1.0) b = tf.constant(2.0) c = a + b # 我们直接使用&apos;c.eval()&apos; 而不是&apos;sess.run&apos; print(c.eval()) sess.close() 对于 Graph 和 Session 的关系，需要记住，Graph 可以在对应多个 Session 中执行。 扩展阅读 Graphs and Sessions | tensorflow guide","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"low-level-api","slug":"ML/deep-learning/toolbox/tensorflow/low-level-api","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/low-level-api/"}]},{"title":"","date":"2018-06-20T13:12:51.120Z","path":"wiki/CS/web/-网站示例/baidu/","text":"百度首页https://www.zhihu.com/question/48903342 #","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-网站示例","slug":"CS/web/网站示例","permalink":"http://yoursite.com/categories/CS/web/网站示例/"}]},{"title":"","date":"2018-06-20T11:22:09.307Z","path":"wiki/-置顶/","text":"2018，刷刷刷经典回顾 可汗学院-算法 可汗学院-密码学 可汗学院-信息论 信号与系统 - 奥本海姆 数学分析 - 台大 隋唐英雄传 - 催睡小曲 资本的故事 下饭片，毫无压力 三体 前沿 将门 其他 自动求导 cuda基础","tags":[],"categories":[]},{"title":"","date":"2018-06-20T11:22:09.307Z","path":"wiki/others/机器人/Nao/-NAOqi OS/","text":"账号信息姓名： ala see邮箱: qq密码：l 用户名， 密码nao naoroot root （常用端口 ftp 21ssh 22telnet 23smtp 25） sudoSudo and root permissions¶ sudo is available on NAOqi OS. Its usage is limited for shutting down Aldebaran robot. $ sudo shutdown -h nowFor any others commands requiring root permissions, you will have to use su and authenticate using the root user password. Nao基本信息系统版本 Naoqi 2.1.2.17 (两个机器人都是这个版本)自动更新：： 我已经下载了系统版本 2.1.4.13。请重新启动我以便安装它。（断手机器人） cat /proc/versionLinux version 2.6.33.9-rt31-aldebaran-rt (portage@bnob-2) (gcc version 4.5.3 (Gentoo 4.5.3-r1 p1.0, pie-0.4.5) ) #1 SMP PREEMPT RT Fri Nov 21 10:50:40 CET 2014 我的opennao虚拟机中的版本是 (portage@bnob-3) ‘’’ cat /proc/cpuinfoprocessor : 0vendor_id : GenuineIntelcpu family : 6model : 28model name : Intel(R) Atom(TM) CPU Z530 @ 1.60GHzstepping : 2cpu MHz : 1600.000cache size : 512 KBphysical id : 0siblings : 2core id : 0cpu cores : 1apicid : 0initial apicid : 0fdiv_bug : nohlt_bug : nof00f_bug : nocoma_bug : nofpu : yesfpu_exception : yescpuid level : 10wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe nx constant_tsc arch_perfmon pebs bts aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 xtpr pdcm movbe lahf_lm tpr_shadow vnmi flexprioritybogomips : 3191.62clflush size : 64cache_alignment : 64address sizes : 32 bits physical, 32 bits virtualpower management: processor : 1vendor_id : GenuineIntelcpu family : 6model : 28model name : Intel(R) Atom(TM) CPU Z530 @ 1.60GHzstepping : 2cpu MHz : 1600.000cache size : 512 KBphysical id : 0siblings : 2core id : 0cpu cores : 1apicid : 1initial apicid : 1fdiv_bug : nohlt_bug : nof00f_bug : nocoma_bug : nofpu : yesfpu_exception : yescpuid level : 10wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe nx constant_tsc arch_perfmon pebs bts aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 xtpr pdcm movbe lahf_lm tpr_shadow vnmi flexprioritybogomips : 3191.83clflush size : 64cache_alignment : 64address sizes : 32 bits physical, 32 bits virtualpower management: df -lhFilesystem Size Used Avail Use% Mounted onrootfs 886M 807M 35M 96% //dev/root 886M 807M 35M 96% /rc-svcdir 1.0M 92K 932K 9% /lib/rc/init.dcgroup_root 10M 0 10M 0% /sys/fs/cgroupudev 10M 124K 9.9M 2% /devtmpfs 502M 1.1M 501M 1% /dev/shmtmpfs 502M 1.1M 501M 1% /var/volatile/dev/mmcblk0p1 15G 1.1G 13G 8% /var/persistent/dev/sda1 124M 6.8M 111M 6% /var/persistent/media/internal top - 16:42:02 up 8:47, 2 users, load average: 1.76, 1.40, 1.13Tasks: 149 total, 1 running, 148 sleeping, 0 stopped, 0 zombieCpu(s): 52.9%us, 10.8%sy, 0.0%ni, 14.1%id, 17.6%wa, 2.3%hi, 2.3%si, 0.0%stMem: 1026636k total（1G）, 1010188k used, 16448k free, 81196k buffersSwap: 0k total, 0k used, 0k free, 454308k cached Filesystem 1K-blocks Used Available Use% Mounted onrootfs 907096 826444 34572 96% //dev/root 907096 826444 34572 96% /rc-svcdir 1024 92 932 9% /lib/rc/init.dcgroup_root 10240 0 10240 0% /sys/fs/cgroupudev 10240 124 10116 2% /devtmpfs 513316 2800 510516 1% /dev/shmtmpfs 513316 2636 510680 1% /var/volatile/dev/mmcblk0p1 15312852 1365068 13169928 10% /var/persistent/dev/sda1 126931 6905 113473 6% /var/persistent/media/internaltotal 18302111（18G） 3030513 14395029 18% 32位系统 （运行： getconf LONG_BIT） Base commands and programshtop monitor process activity (many options are available use F1)ldd list library dependenciesgdbserver start a remote gdb server","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"机器人","slug":"others/机器人","permalink":"http://yoursite.com/categories/others/机器人/"},{"name":"Nao","slug":"others/机器人/Nao","permalink":"http://yoursite.com/categories/others/机器人/Nao/"}]},{"title":"心脑血管疾病","date":"2018-06-20T11:22:09.305Z","path":"wiki/others/医疗/-心脑血管/","text":"心脑血管疾病是怎么得的？血管怎么一天天被油脂堵死 黄色的“油脂”就是堵死血管的罪魁祸首 血管年龄 最近情绪感到压抑 对事情过于认真 爱吃方便食品、饼干或点心 喜食肉类 缺少一定的锻炼 吸烟指数（每天吸烟支数×吸烟年数）大于400 爬楼时会感到胸痛 常常觉得手足发凉、麻木 经常丢三落四 。。。。。。。我偶尔丢三落四 血压偏高 胆固醇或者血糖值偏高 亲属中有人死于心脑血管疾病 结论：0～4 项：你的血管年龄正常。5～7 项：血管年龄比生理年龄大10岁。8～12 项：血管年龄比生理年龄大20岁。 我觉得 打印版参考 []https://www.zhihu.com/question/34149140/answer/131500346","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"医疗","slug":"others/医疗","permalink":"http://yoursite.com/categories/others/医疗/"}]},{"title":"","date":"2018-06-20T11:22:09.304Z","path":"wiki/others/-物理学/-电/","text":"为什么所有的插头上的铁片都使用银而不使用铜？ 导电性：从电阻率表中我们看到，导电性最好的是银，其次是铜，再其次是锡。 硬度：事实上，接插件是需要一定强度的。而锡和银很软，根本就没法满足接插件的插接强度。所以，接插件的本体都是铜，表面镀锡或者镀银而已。 接插件镀锡镀银真的仅仅只是为了提高导电性吗？当导电材料流过电流后，只要电流的频率不太高，则电流是流过导电材料的整个截面的。即使当频率很高时，材料的趋肤效应也有一定的穿透深度。例如铜在50赫兹下的穿透深度是9.3毫米。 接插件一般都十分纤细，趋肤效应不是很大，因此电流会流过接插件的整个截面。 结论是：电接触其实是有很深的理论的。它涉及到材料、电化学、电气接触和温升理论、发热理论等等。其内容博大精深，涵盖了众多基础理论和工程实践。因此，有关电接触的表述绝不是这个蜻蜓点水帖子能够说明清楚的。 https://www.zhihu.com/question/57329327","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"-物理学","slug":"others/物理学","permalink":"http://yoursite.com/categories/others/物理学/"}]},{"title":"","date":"2018-06-20T11:22:09.303Z","path":"wiki/others/politics/-american/-反恐/","text":"什么是反恐谁是恐？反恐要反谁？恐怖分子是指一波人？还是一波国家？还是某些团体？ # 恐 中国怎么反恐，为什么要反恐？反不同国家说的反恐 是一回事吗？伊斯兰国家如何看待中国的反恐？伊斯兰国家里是怎么看待伊斯兰恐怖主义的？恐怖主义国家怎么看待自己？恐怖分子怎么看待自己？伊斯兰怎么看待伊斯兰恐怖主义，就好比问纳粹如何看待法西斯灭犹，问皇军如何看待三光主义。这还用问吗？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-american","slug":"others/politics/american","permalink":"http://yoursite.com/categories/others/politics/american/"}]},{"title":"","date":"2018-06-20T11:22:09.301Z","path":"wiki/others/politics/china/国家领袖/国家主席/-README/","text":"国家主席为礼仪性和象征性虚位国家元首[注 1]，与全国人民代表大会常务委员会共同行使国家元首的职权[2]","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家领袖","slug":"others/politics/china/国家领袖","permalink":"http://yoursite.com/categories/others/politics/china/国家领袖/"},{"name":"国家主席","slug":"others/politics/china/国家领袖/国家主席","permalink":"http://yoursite.com/categories/others/politics/china/国家领袖/国家主席/"}]},{"title":"","date":"2018-06-20T11:22:09.298Z","path":"wiki/others/politics/china/-关于媒体/","text":"被墙苹果国际 台湾媒体 繁体字 tw.news.appledaily.com 言论普遍不友好 万维读者网 creaders.net 未被墙bbc中文网 http://www.bbc.com/zhongwen/simp","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"","date":"2018-06-20T11:22:09.296Z","path":"wiki/others/politics/china/党的机构/-党书记/","text":"「书记」一职，是如何演变为「一把手」的？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"党的机构","slug":"others/politics/china/党的机构","permalink":"http://yoursite.com/categories/others/politics/china/党的机构/"}]},{"title":"","date":"2018-06-20T11:22:09.296Z","path":"wiki/others/politics/china/党的机构/中央书记处/-党书记/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"党的机构","slug":"others/politics/china/党的机构","permalink":"http://yoursite.com/categories/others/politics/china/党的机构/"},{"name":"中央书记处","slug":"others/politics/china/党的机构/中央书记处","permalink":"http://yoursite.com/categories/others/politics/china/党的机构/中央书记处/"}]},{"title":"","date":"2018-06-20T11:22:09.293Z","path":"wiki/others/politics/china/人物/-习近平/","text":"摘要习近平执政5年间，先后处理了薄熙来、周永康、徐才厚、郭伯雄、令计划、孙政才、苏荣等7名江派国级大员，拿下了40名江派在任中央委员、候补委员，收回了江派此前长期掌管的公安、武警部队及军权。 #","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"","date":"2018-06-20T11:22:09.292Z","path":"wiki/others/politics/china/人物/-邓小平/","text":"南巡邓小平南巡虽然有风险，但不是没有底。他虽然没有当军委主席，但还有忠于他的杨尚昆兄弟执掌军队。邓小平南巡的时候，杨尚昆紧随邓的身边，杨白冰在北京警惕地掌握军事按钮。 89 - 64 邓小平，牛逼呀1898.6.9 邓: 这场风波迟早要来，这是国内和国际形势决定的。一看就知道要干什么，打到共产党，打到社会主义，建立一个完全西方化的国家。也许这样会使我们的步子前进的更稳，更好，甚至于更快。三中全会以来制定的战略目标(三部曲,一个中心，两个基本点)正确不正确？ 总结过去，改革开放这个点错了没？没错， A: 邓小平确实是巨人，面对这么严峻的形式能举重若轻两三句话说明情况。他有资格说那句“一看就知道是怎么回事”，因为他经历过长征、解放战争、建国后的各种曲折，能在三次被打倒的情况下三次复出。有这样波澜壮阔的阅历，还有什么现象他抓不住本质、看不穿表象的？不过学生确实最好骗，没有社会阅历，生活在象牙塔。如果换成是我，说不定也会参与进去。学生运动、革命，听着多高大上，显得自己多么崇高！现在他们回忆当年，只有后悔。学潮的发生主要还是国内自身的问题（确实有大量问题），美国只是顺势推了一把，但走改革开放这条路是没错的，否则哪有今天的成绩。走西方民主的路就是死路一条，经济建设都没搞好，谈什么民主。不过没有哪条路是完美的，经济建设这条路上是一定会出问题的，根本不可避免，没有哪个社会发展时不出这些问题（腐败、贫富差距等），但长远看这条路是对的，而且这些问题虽然一直存在，但会得到解决。就像你之前一穷二白，然后决心创业挣钱，奋斗时你或许会变得势力、圆滑，对自己的路觉得迷茫，因为利益纠葛和朋友决裂，甚至做出很多越过自己底线的事，但最终你富有了，生活质量上去了，和那个穷人有了天壤之别。富有了之后，人开始追求更上层的更精神的东西。 A: 不得不说邓公真的是有魄力，当时西方国家也希望中国领导人是戈尔巴乔夫吧，把苏联端了顺带把中国端了。A: 每多一年对邓小平的敬佩敬仰就增加一分。 A: 矮人火枪手，85岁高龄，钦定了我蛤，六四的锅自己来背，独自面对全世界的声讨，保全了后二十年的高速发展，这种自我牺牲的勇气现在的领导人敢不敢有 ， 牛逼，牛逼 A: 中共能不能带领中国实现民族复兴我们尚不清楚，但以美国为首的西方国家是绝对不希望看到一个强大的中国出现的！美国做梦都想搞垮中国！所谓的政治意识形态，所谓的人权，所谓的民主，全是美国想要搞垮中国的借口！苏联解体后，俄罗斯然道没有走向西方的民主道路吗？看看西方是如何对待俄罗斯的！上个世纪80年代，日本经济大有超越美国的趋势，看看美国是如何逼迫日本签《广场协议》，迫使日元升值，让日本经济停滞到今天，然道日本和美国不共享共同的政治意识形态和人权价值观念的民主国家吗？总之，只要你对美国产生威胁，美国绝对会不择手段肉体上消灭，名誉上搞臭！ ## A: 之前一直觉得64是威权是镇压学运 看过《天安门》后才深感中共当时处境做出当时决定是对的 如果真的让学运分子当权现在中国不知是什么样子 A: 管理国家，又是这么大的国家，手腕必须强硬 A: 国外希望我们这条巨龙四分五裂成小蛇，没得惩，现在看看这现实，如今我们在威胁谁 A: 今天竟然还有人说，如果当时64不镇压，中国就是全球第一，这种睁眼说瞎话的人，用心歹毒！A: 如果不是邓小平的高瞻远瞩，当机立断粉碎六四事件，中国今天不就是 苏联分裂或者叙利亚么？ 还能有gdp全球第二？个别外国或地区媒体，用心险恶，把法轮功吹成人权，真心无语！！A: 国家稳定最重要A: 当年轮子还没出现呀，轮子是江任期的事情 A: 既然觉得共产党这不好那不好，你说该咋做，让老百姓都逃离中国，投奔西方民主，还是说搞一个民族战争推翻共产党，然后中国经济倒退10年20年，弄得大家都吃不上饭！我很赞成共产党，不是很好，但比如维护国家稳定，经济发展，这也对老百姓是有好处的！中东国家的民主转变，已经给我们上了一课了，不能再走人家的老路！ 邓是否同意江的做法？为什么制定江为继承人？","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"","date":"2018-06-20T11:22:09.292Z","path":"wiki/others/politics/china/人物/-陈云/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"","date":"2018-06-20T11:22:09.292Z","path":"wiki/others/politics/china/人物/-薄一波/","text":"薄一波家系薄一波家系薄昌福&nbsp;胡秀清&nbsp;&nbsp;&nbsp;&nbsp;李如明&nbsp;薄一波&nbsp;胡明李雪峰&nbsp;翟英谷景生&nbsp;范承秀&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;郑耀文&nbsp;薄熙莹薄熙永薄洁莹薄小莹薄熙成薄熙宁薄熙来&nbsp;李丹宇&nbsp;谷开来&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;薄望知薄瓜瓜 参考 维基百科","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"","date":"2018-06-20T11:22:09.291Z","path":"wiki/others/politics/china/人物/-李克强/","text":"","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"","date":"2018-06-20T11:22:09.289Z","path":"wiki/others/politics/china/国家机构/-两会/","text":"疑问参加人大，和政协会议，是同一拨人吗？有人要同时参加两个会议怎么办？ 代表委员的座位是怎么安排的？代表们的座位采取轮换制，将所有代表分成5组，5年里每组都有坐到会场中间的机会，再将每个代表团的代表分成5组，每个人也有坐到前排的机会。(来源：人民日报)http://sike.news.cn/hot/2018/skwd/index.html 全国两会为什么每年3月开？3月举行两会，可以给上年决算和当年预算留出时间，而且地方两会均已召开完毕，上一年度经济社会等方面的成绩也已统计完成。其次，也有人性化的考虑，选择3月份可以避免与春节重叠，给代表委员们充裕的时间准备。 为何政协称“会议”，人大称“大会”?中央党校原副校长李君如：周恩来总理曾解释过“大会”和“会议”的区别，“大会”是由选举产生的代表组成的；“会议”是由邀请来的各个党派、各方面社会的名流以及各方面界别的代表组成的，是邀请来共同来参政议政的。二者是选举和邀请的区别。（来源：人民政协网） 政协为什么比人大提前两天开？一般而言，政协会议比人大会议提前召开一至两天，这主要是为了保证政协履行其职能。政协主要职能是政治协商、民主监督、参政议政。人大在做决策之前，要把决策先提交给人民以及各界代表，在政协里面进行协商、讨论。把政治协商纳入到决策层面中，决策前要进行充分协商。（来源：新华网）","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家机构","slug":"others/politics/china/国家机构","permalink":"http://yoursite.com/categories/others/politics/china/国家机构/"}]},{"title":"","date":"2018-06-20T11:22:09.288Z","path":"wiki/others/politics/china/国家机构/-2018-两会-全国人民代表大会/","text":"3月5日，第十三届全国人民代表大会第一次会议在北京人民大会堂开幕。国务院总理李克强作政府工作报告。 政府工作报告–极简版 2018年重点工作123456789101112131415161718192021#收入: 提高个人所得税起征点。#教育: 切实降低农村学生辍学率，着力解决中小学生课外负担重问题。医疗：居民基本医保人均财政补助标准再增加40元。扩大跨省异地就医直接结算范围。# 现在产能过剩及落后产能占比太重的情况已经相当严重，必须政府干预。# 产能过剩及落后产能占比太重----这就是非市场化的果，政府过多干预的果。然后还想通过政府干预来纠正？这怎么可能？煤炭就是一个很好的例子。过剩-干预-煤价暴涨-又释放产能两亿吨。# 供大于求，所以铁价很低。去产能会不会导致价格高涨？# 这种方法根本没用,让民企进入这些行业才是王道,自动淘汰# https://www.zhihu.com/question/46868907去产能: 再压减钢铁产能3000万吨左右，退出煤炭产能1.5亿吨左右。创新: 加强新一代人工智能研发应用。加强雾霾治理、癌症等重大疾病防治攻关。# 是不是该抓住这个机会买新能源。但是新能源车牌号排到了201消费: 新能源汽车车辆购置税优惠政策再延长三年。降低重点国有景区门票价格。开放: 放宽或取消银行、证券、基金管理、期货、金融资产管理公司等外资股比限制。探索建设自由贸易港。 科技领域今天，总理在今年“两会”政府工作报告中再次指出，加强新一代人工智能研发应用，在医疗、养老、教育、文化、体育等多领域推进“互联网+”。发展智能产业，拓展智能生活。 目前，北京市科技产业呈现“三城一区”新格局。1234567891011“三城”：中关村科学城，作为原始创新策源地；怀柔科学城作为世界一流科学城； # 中科院、航空航天等高科技产业。倒是名副其实 科学城未来科学城技术作为创新主阵地；# 位于昌平北七家附近，都是些中字头老企业，电力、钢铁、能源、建材、# 西二旗中关村软件园才应该是趋势啊，还有望京。也许是因为信息产业算不上科学。“一区”：北京经济技术开发区，作为高精尖结构新的增长极。 # 亦庄附近，南城# 其他南城的建设为什么没提？雄安有没有提？难道是悄悄","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家机构","slug":"others/politics/china/国家机构","permalink":"http://yoursite.com/categories/others/politics/china/国家机构/"}]},{"title":"","date":"2018-06-20T11:22:09.287Z","path":"wiki/others/politics/china/国家机构/-两会-中国人民政治协商会议/","text":"中国人民政治协商会议-wikipedia 官网 简介名字由来1945年抗日战争胜利后，1945年8月至10月国共重庆谈判时，中国共产党代表周恩来认为谈判重点就是召开政治会议讨论建国方案，便提出召集党派会议的协定草案。国民政府代表王世杰不同意“党派会议”的名称[注 1]，赫尔利提出“政治会议”名称，各方接受。为充分尊重各方意愿，提出在“政治会议”中加入“协商”二字。 1949年9月21日，中国人民政治协商会议第一届全体会议在北平召开。 所谓政治协商，是指对国家和地方的大政方针以及政治、经济、文化和社会生活中的重要问题与中共或国家机关在决策之前及在决策执行过程中的重要问题进行协商。 法律相关组织架构，组成和机构常务委员会 - 主席会议 （主席 副主席 秘书长) 常务委员 主 席 俞正声 副主席 杜青林 韩启德 帕巴拉·格列朗杰 董建华 万钢 林文漪 罗富和 何厚铧 张庆黎 李海峰 陈元 卢展工 周小川 王家瑞 王正伟 马飚 齐续春 陈晓光 马培华 刘晓峰 王钦敏 梁振英 秘书长 张庆黎（兼） 经全体会议选举产生主席1人、副主席若干人，秘书长1人，并设立常务委员会主持会务。常委会由主席、副主席、秘书长和常务委员组成； 政协第十二届全国委员会共设34个界别，分别为： 12341、 中国共产党2、 中国国民党革命委员会3、 中国民主同盟... 流程 第一次会议 预备会议 3月2日新华社北京3月2日电 中国人民政治协商会议第十三届全国委员会第一次会议预备会议2日下午在人民大会堂举行。 会议由十二届全国政协主席俞正声主持。 会议以举手表决等方式，审议通过了政协第十三届全国委员会第一次会议主席团、主席团会议主持人和秘书长名单，政协第十三届全国委员会第一次会议议程和日程以及政协第十三届全国委员会第一次会议提案审查委员会名单。由主席团主持第一次全体会议，第二次第三次呢？ 俞正声 中国人民政治协商会议全国委员会主席。主管新疆和西藏工作，分管台湾事务。 曾经担任建设部部长、中共湖北省委书记、中共上海市委书记等职务。 梁振英 - 香港特别行政区第4任行政长官、全国政协副主席、全国政协常委。梁振英同时兼任国家领导人和行政长官，成为首例。 ## 主席团常务主席名单 汪洋、张庆黎、刘奇葆、帕巴拉·格列朗杰（藏族）、董建华、万钢、何厚铧、卢展工、王正伟（回族）、马飚（壮族）、陈晓光、梁振英（完） 第十二届委员名单-2013年3月2日-2018年3月2日 ##","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家机构","slug":"others/politics/china/国家机构","permalink":"http://yoursite.com/categories/others/politics/china/国家机构/"}]},{"title":"","date":"2018-06-20T11:22:09.286Z","path":"wiki/others/politics/china/-八卦/cas/","text":"关于白老白当了个主任委员，引起了大家的无限遐想。其实有几个大学校长也当了副主任委员，李静海也当了副主任委员，这些人原先的职位都是要继续当下去的。 另外，老白还是发展中国家科学院院长，他年龄也没到退休，不会轻易把他从中科院院长位置调走，还需要这么个人物在国际舞台上发声。无论老丁还是老侯，国际声誉方面都差老白一大截，倒是张杰可以与他比比。即使侯回科学院，很可能也要先从常务副院长，党组书记这个位置做起。 只是没有以前的中科院院长地位高(历届就他没副国级,三院院长现在都是这个情况啊 ),也没有丁仲礼上升快相对于普通正部级干部,老白这个退休待遇也不错了,大多数正部级干部退休也就能捞到副主任委员,省长几乎都捞不到主任委员吧,省委书记也不到一半能捞到主任委员或以上职位 他的两个手下都副国了（陈竺，都是民主党派的），情何以堪！ 人家是民主党派,爬起来就是比你快,这没办法.与民主党派比,那当初就不该入党啊 从上届人大副和政协副缩编之后,三院院长上副国级已经很难了,上了也只能是偶然事件 老白改革太慢,与其性格可能有关上台也快7年了,四类机构还没分好 就知道喊口号四类所搞到现在基本跟改之前没啥区别而且给大家一种好像又不改了的感觉早就该把他撸了换执行力强的人来改 老白的执行力明显比老丁和张杰差一大截 老丁老丁在2016年接受某个知名环保人士的采访，该环保人士身份是央视记者，其名字忘了。采访记录公布后，社会影响很大！据说很多人看完，很感动，对老丁竖起大拇哥，微信和微博评论一边倒。 老丁能上副国，绝不是一朝一夕之间领导拍脑袋决定的。 因专业关系，2016年前，本人几乎没关注他。不过本人一个认识的朋友他的小孩考上国科大，全省排名第八。他小孩之所以选国科大，就是因为看了老丁的几次视频后，决定上国科大。本人听说之后，才开始关注老丁。说实话，小孩都能觉得他不错，那些大人物估计也会关注的。 家宝能把哥本哈根搅和黄了，老丁肯定也是有贡献的。那肯定的，当年有新闻直接打出标题：温家宝顾问丁仲礼 从去年12月起,老丁的第一身份就是正部级的民盟主席从今年三月开始,老丁的第一身份副国级的副委员长,第二身份是正部级的民盟主席,第三身份才是副部级中科院副院长 张杰有可能接党组书记，但是没丁接院长希望那么大 国务院部委只管事，不管人，科学院的实体这么庞大，不可能让非党人事来管人。 其实非党员的副院长的确没啥权力，当初严济慈身为人大副委员长兼科学院副院长，科大校长，想给科大办事都非常的难，在科学院内部都有人不鸟他，丁这个副院长的位子比严老应该要弱势许多。 丁16年上半年的时候就说自己18年才会卸任国科大校长,明显在暗示要升官 #","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"-八卦","slug":"others/politics/china/八卦","permalink":"http://yoursite.com/categories/others/politics/china/八卦/"}]},{"title":"","date":"2018-06-20T11:22:09.285Z","path":"wiki/others/politics/china/-草稿/","text":"江泽民是在1989年天安门抗议活动期间被任命为中共中央总书记的，他从1993到2003年担任了两届国家主席，但他一直掌权到2004年，因为他保留了控制中国军队的委员会的职务。 现年69岁的王岐山是习近平的亲密盟友，也是习近平严厉打击腐败、打击对党不忠运动的执行者。由于年龄的原因，王岐山去年已不再担任党内的职务。 人们把习近平的铁腕风格与俄罗斯总统弗拉基米尔·V·普京(Vladimir V. Putin)进行比较。但就连已经积累了相当多的个人权力的普京，在2008年任期将满时，也没有试图删除俄罗斯宪法中对连续担任两届总统的任期限制。 普京的做法是，他安排了一位没有多少个人影响力的亲密顾问德米特里·A·梅德韦杰夫(Dmitri A. Medvedev)担任总统一职，由自己担任总理。2012年，普京再次当选总统，今年还将竞选连任。 关于公民基本权利和义务54宪法中 中华人民共和国公民有居住和迁徙的自由 这条在之后的三版宪法中都未在出现 82宪法中 中华人民共和国公民有言论、出版、集会、结社、游行、示威的自由 之前三版宪法中的罢工自由没有了 75,78宪法中 有信仰宗教的自由和不信仰宗教、宣传无神论的自由 而在54和82宪法中的是 中华人民共和国公民有宗教信仰自由 ## 54宪法 82宪法 均设立国家主席 82宪法则另行创立中央军委主席一职","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"","date":"2018-06-20T11:22:09.283Z","path":"wiki/others/思想 哲学/-意识形态/马克思主义/共产党宣言/","text":"共产主义的中心要点，归根到底，是一个没有阶级、没有政府的公社社会，权利的概念无关紧要。马克思甚至认为家庭是“令人厌恶”的资产阶级产物，最终将随着乌托邦的到来而消失。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"思想 哲学","slug":"others/思想-哲学","permalink":"http://yoursite.com/categories/others/思想-哲学/"},{"name":"-意识形态","slug":"others/思想-哲学/意识形态","permalink":"http://yoursite.com/categories/others/思想-哲学/意识形态/"},{"name":"马克思主义","slug":"others/思想-哲学/意识形态/马克思主义","permalink":"http://yoursite.com/categories/others/思想-哲学/意识形态/马克思主义/"}]},{"title":"","date":"2018-06-20T11:22:09.282Z","path":"wiki/others/思想 哲学/-意识形态/墙/","text":"keywords: 围城 墙 城墙 防火墙 进击的巨人 川普的边境墙政策 扎克伯格在夏威夷豪宅上修高墙 非法移民 双刃剑 简介围墙有两种含义： 一种是现实中存在的物理意义上的空间隔断结构，用以离合、分割或保护某一区域； 另一种是由前一种引申出的比喻，寓意某种产生阻隔作用的力量。 比如，钱钟书先生最著名的“围城”即是对人生的比喻。比喻的好处是形象，给人留下的印象深刻，但也往往容易混淆事物的本质。就大学而言，有没有围墙是一回事，是不是开放自由是另一回事。在我看来，围墙和大学精神风马牛不相及，用围墙来隐喻大学之自由开放，恐怕是某些不了解实际情况的人的牵强附会了。 什么样的墙也挡不住决心要翻越的人。但是多了一道高墙，会对作案者增加很多困难，让他们觉得与其翻墙进去，不如找一点更容易得手的目标。 疑罪从无” 参考 与中国相比，西方发达国家的治安是不是普遍不好？为什么？ | 知乎扎克伯格指责川普的边境墙政策却毫不犹豫的在自己的夏威夷豪宅上修高墙，这算不算虚伪？ | 知乎 巴黎的治安问题真很严重吗？ 安保不到位？ 如何理解「中国是发达国家的粉碎机」这一说法？ 如今的中国在西方发达国家眼中是个什么样的角色？ 扎克伯格为什么认为 Facebook 进入中国市场以后会成功？ 为什么美国等国家要以中国为敌对国家？ 天下熙熙皆为利来## 我认为，就是社会发展程度达不到，即没发展到那个阶段。路不拾遗 夜不闭户是社会发展到一定阶段才能实现的。 为什么西方媒体要将中国塑造成一个负面的形象？https://www.zhihu.com/question/63352743 肛里拉出个电锯: 因为墙呗遗留症我是说美国的墙，虽然那会儿没有网，他们是1917年开始，42年体制化，45年整合，60年代几乎完全建立。所以美国是一个自由的国家，因为只要内部实力水位充满到和墙一样的高度，那么在水库中间游泳的人是看不到大坝的存在的现在只是延续以前的方法维持稳定，毕竟美国领袖不是蒋介石，不会挖大坝的。 李君杰: 文明与文化向外扩张，那墙确实看不到，但低水位流不进去，低水位的人也会自我麻痹说人家高大上，只有不停地加高自己这边水位且有自己的本位才能向他们那流，那时修的墙会更高，也更明显 IS-3: 拿一个意识形态，告诉你这是普世价值，然后让你以为全世界都信这个，不信这个就是不好的负面的国家。然后树一个靶子当怪兽，让你以为全世界就他和你不一样，让你彻底忽视你和“你的盟友”之间更大的差距(就像美帝和沙特)。 旅鼠: 根本目的是控制，封锁只是手段之一，中国是采取封锁制度，但美国不是封锁而是正向淹没，类似于纳粹的方法。 肛里拉出个电锯: 美国倒是没有封锁和控制，他们管这叫宣传，美国人不搞宣传，他们的同类行为是心理控制。内容是一样的，但是用词不一样，所以严格来说美国没有宣传也没有封锁和控制。差别就相当于用7.62mm子弹枪毙和用5.56子弹枪毙一样 肛里拉出个电锯: 美国也是封锁，而且是世界最严封锁，比wg和苏联还厉害得多，只不过过了这个阶段并获胜以后，就看不见墙了 天长地久终不死: 美国对意识形态的管控，可以说是全球最强的。要不是川普是总统候选人，估计早就把川普给封杀掉了。 配合头像食用更佳: 美国对意识形态的控制确实非常强、非常严格、甚至僵化，但这种意识形态似乎并不是来自于某个中央机构（如政府部门、某个具体传媒公司、等等），而是整个社会在博弈过程中形成的一种平衡点。美国人不是被别人蒙住了眼睛，而是心甘情愿地自己遮住了双眼、而且拒绝拿下眼罩。对意识形态的引领权可能是掌握在美国的某个阶级的手里（传说中的大资产阶级），但中下层对这套意识形态的崇拜与盲从完全可以用“极权”来形容，我很好奇美国是如何达成这个平衡点的。 为什么在信息开放的西方丑化中国如此深入人心，在信息封闭的中国丑化西方却如此失败甚至出现各种崇拜？https://www.zhihu.com/question/48057749 第一，西方媒体自以为媒体的主要责任是揭露和监督，而不是歌颂。 vczh: 我们也丑化印度和朝鲜，大家不一样也是很开心。评论大家都觉得印度和朝鲜本来就很丑啊，其实西方人民也是这么想中国的，简直如出一辙 Ivony: 简单说就是经济实力。你再怎么丑化富人，大家还是想成为富人。你再怎么美化穷人，大家还是想要钱。 wangzhonggw：穷人是不需要媒体刻意丑化的，百度搜索趋势已经很好地反映了这个问题，我想中国媒体也从未刻意去丑化非洲吧。所以其他答案扯那么一堆“墙、管制、记者”什么的都没答到点子上，“本来就有黑点”算看到了现象，但没有分析原因。原因就是中国穷，西方富。因为穷，所以才有这么多黑点。因为穷，所以国人普遍崇拜西方。 为什么美国大学没有围墙？大学里的师生均为年满十八岁的成人，不需要额外特殊的保护——这正是虽然美国大学没有围墙，但美国中小学却都有围墙的原因——一旦出现危害校园安全的事件，警方会立即采取行动。也就是说，围墙并不能使校园变得更加安全，大学自然没有修建围墙的需要和动力。 贸易壁垒技术壁垒专利也是一种墙， 中国芯片X66芯片的专利被申请 阿里巴巴、腾讯为何无法国际化？ https://www.zhihu.com/question/45612721 君临：不是说有了先进入者，后来的就没有成功的机会，但问题是，你的技术差距真的能大幅超越先来者的本土化应用体验吗？如果不能，就很难动摇用户的更换意愿。正是这种技术差距小于本土化应用体验的局面，让过去的几年，中美的互联网公司之间形成了划江而治的微妙对峙格局。我们将他们抵御在了墙外，他们也将我们困在了墙内，彼此有一点新技术出来，都很容易被对方偷师而去，谁都没有吊打谁的实力。 vczh：就阿里系app这个收集数据的行为，出来得直接被打死。远山：腾讯的微信在东南亚那边做的很好，怎么就不算国际化？ 参考 http://edu.sina.com.cn/zl/oversea/blog/2014-10-21/10391822/1402756050/539c5bd20102v2hp.shtml ## 刷知乎太多了，刷点书呢？ 《资本论》 《马克思恩格斯全集》","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"思想 哲学","slug":"others/思想-哲学","permalink":"http://yoursite.com/categories/others/思想-哲学/"},{"name":"-意识形态","slug":"others/思想-哲学/意识形态","permalink":"http://yoursite.com/categories/others/思想-哲学/意识形态/"}]},{"title":"","date":"2018-06-20T11:22:09.276Z","path":"wiki/电子/芯片/芯片类型/TPU/-TPU/","text":"TPU明显是死路一条，因为现在DNN的技术还没有稳定，应该用FPGA／GPU这种能快速迭代的平台来开发。而不是用ASIC，一旦做好不能升级。 tpu也有它的灵活性的，通过编译器可以支持各种变化 参考 https://www.zhihu.com/question/58089445","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"芯片类型","slug":"电子/芯片/芯片类型","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/"},{"name":"TPU","slug":"电子/芯片/芯片类型/TPU","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/TPU/"}]},{"title":"","date":"2018-06-20T11:22:09.275Z","path":"wiki/电子/芯片/-芯片架构/-地平线机器人/","text":"","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"-芯片架构","slug":"电子/芯片/芯片架构","permalink":"http://yoursite.com/categories/电子/芯片/芯片架构/"}]},{"title":"","date":"2018-06-20T11:22:09.275Z","path":"wiki/电子/芯片/厂商/-华为海思/","text":"Verilog中","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"厂商","slug":"电子/芯片/厂商","permalink":"http://yoursite.com/categories/电子/芯片/厂商/"}]},{"title":"AI芯片","date":"2018-06-20T11:22:09.275Z","path":"wiki/电子/芯片/芯片类型/-AI芯片/","text":"AI芯片在AI运算中提供加速功能。 目前，在人工智能普及化的驱动下，蛋糕正越来越大，并进入“百家争鸣”的非零和博弈阶段。 行情在深度学习上游训练端（主要在云计算数据中心中），GPU是当仁不让的第一选择。而ASIC包括谷歌的TPU和寒武纪的NPU等，也如雨后春笋般涌现。下游推理端更接近终端应用，需求更细分，GPU为主流芯片之外，包括CPU/FPGA/ASIC也可以在该领域发挥各自的优势特点。 GPUnvidia + AMD ASIC TPU NPU BAT FPGA深鉴科技被xilinx收购 人工智能芯片 深度学习加速芯片主要有四种，按灵活易用排CPU&gt;GPU&gt;FPGA&gt;ASIC，效率则是相反的（还有DSP，不过个人不太了解）。谷歌这次的TPU属于ASIC， 袁建斌：“芯片危机最大的打击，就是中国的5G技术，这个是我认为最重要的一点，受到这个芯片的影响，所有的电子技术都会倒退很多年。” 阿里巴巴全资收购中天微系统公司，打算自主研发国产CPU，阿里巴巴主要还是出于公司战略的考虑，因为中兴遭受打击之后，中共将以举国之力下血本鼓励国产芯片的研发制造，所以阿里巴巴想抢先占据这个领跑地位。 坑太深。 扩展阅读 一文看懂人工智能芯片的产业生态及竞争格局 | 雷锋网 中国的芯片现状如何？ | 知乎 如何评价「台湾将中兴通讯列为出口管制对象」? | 知乎","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"芯片类型","slug":"电子/芯片/芯片类型","permalink":"http://yoursite.com/categories/电子/芯片/芯片类型/"}]},{"title":"","date":"2018-06-20T11:22:09.274Z","path":"wiki/电子/芯片/-true-north/","text":"","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"}]},{"title":"","date":"2018-06-20T11:22:09.272Z","path":"wiki/电子/芯片/基础知识/-基础知识/","text":"Verilog中，若X不是常数，data[X+ , 8]可以综合 控制芯片分为两大类， 软件编程的（如单片机，ARM，DSP） 即 通用芯片 单片机，是内部已经被人写好了寄存器，与或非门，外部通过汇编语言转换成机器语言，送到机器内部的逻辑门进行运算 硬件编程的（如FPGA,CPLD） 硬件实现逻辑，就是给你一堆与或非门，通过编写程序，让这一堆与或非门组合实现逻辑功能 FPGA 与单片机的区别： FPGA是硬件编程，单片机是软件编程 (核心区别) FPGA是用空间换时间，单片机是用时间换空间。 FPGA可以并行执行，单片机是顺序执行 FPGA是硬件编程，单片机是软件编程 FPGA（现场可编程门阵列）主要是用于VLSI（超大规模集成电路）设计的，主要是数字系统，是一些逻辑电路的模块，通过可编程的布线网络来连接这些逻辑模块（可对硬件进行排列组合），从而实现不同的逻辑功能。 单片机等是通过执行程序来做事的，但FPGA不同，我们用VHDL语言编程，下载后不是让FPGA执行程序，而是通过程序改变FPGA内部电路。使FPGA变成我们设计的那种电路图，C语言等是软件语言，芯片执行的时候是一条条执行，而VHDL是硬件语言，执行的时候是并行的，就是所有的语句块同时执行。VHDL是一种语言，是一种硬件语言，可以编出我们要的电路图。FPGA是一种芯片，里面全是门电路，触发器，通过VHDL程序的要求完成门电路的连接。 fpga和vhdl的关系fpga和vhdl的关系，就像8051单片机和c语言的关系 VHDL是FPGA编程语言的一种，进行FPGA设计时 首先用VHDL或者Verilog写源代码 ，然后用综合工具将源代码综合成网表，下一步通过布局布线工具（与FPGA具体型号相关）将综合的网表映射到具体型号的FPGA上（包括布局布线，期间加入时序约束，管脚约束），基本就是这么一个流程，一般的大厂商的开发工具都是集成了上述所有的工具，如altera的quartus ,xilinx的ISE 以及actel的libero ww","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"基础知识","slug":"电子/芯片/基础知识","permalink":"http://yoursite.com/categories/电子/芯片/基础知识/"}]},{"title":"","date":"2018-06-20T11:22:09.271Z","path":"wiki/电子/芯片/厂商/-比特大陆/","text":"","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"厂商","slug":"电子/芯片/厂商","permalink":"http://yoursite.com/categories/电子/芯片/厂商/"}]},{"title":"","date":"2018-06-20T11:22:09.267Z","path":"wiki/block-chain/-拓扑结构-中心-去中心/","text":"见 p2p","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"}]},{"title":"","date":"2018-06-20T11:22:09.267Z","path":"wiki/block-chain/区块链/-区块链-git区别/","text":"都是分布式数据库，节点保存整个数据库。 都存在一个缺陷，节点数据量大。(.git目录很大，比特币的整个链要很多G) P2P的节点是否需要保存整个数据库？","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"区块链","slug":"block-chain/区块链","permalink":"http://yoursite.com/categories/block-chain/区块链/"}]},{"title":"区域链和P2P技术的区别是什么？","date":"2018-06-20T11:22:09.267Z","path":"wiki/block-chain/区块链/-区块链-P2P区别/","text":"https://www.zhihu.com/question/268891927","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"区块链","slug":"block-chain/区块链","permalink":"http://yoursite.com/categories/block-chain/区块链/"}]},{"title":"","date":"2018-06-20T11:22:09.266Z","path":"wiki/block-chain/区块链/-区块链-比特币区别/","text":"","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"区块链","slug":"block-chain/区块链","permalink":"http://yoursite.com/categories/block-chain/区块链/"}]},{"title":"","date":"2018-06-20T11:22:09.264Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-比特币-客户端/","text":"简介Bitcoin（以下称比特币）是一个P2P网络，它的客户端有Full Node（全功能客户端）、SPV （Simplified Payment Verification，简化支付验证协议[1]，即只支持简化支付验证协议的客户端）。SPV有时也称作Thin Clients, light-weight clients，它们在维基[2]上的页面引用是一样的。 Full Node会下载包含所有交易信息（而不仅仅是区块的headers）的完整区块链，到目前为止，这会要求为它保留145GB以上的磁盘空间，并且还在以每10分钟1M的速度增加着。这些数据将会在交易验证中用到，因此Full Node不容易被欺骗，它们是bitcoin网络中的安全基石。 SPV，或者说Thin Clients，则只会下载整个区块链中所有区块的头信息。正如比特币白皮书: Bitcoin: A Peer-to-Peer Electronic Cash System（以下简称白皮书）所说，一个区块头大概80字节大小，假设每10分钟生成一个新的区块，那么每年只会产生4.2MB的头信息数据，因此这些信息全部放在内存中都不是问题。然而，在安全性上SPV并不如Full Node那么健壮。 安装Full Node是程序员的不二选择。比特币官网就提供了一个Full Node客户端，称作bitcoin core，有时候也被叫作Satoshi（即“聪”）客户端。如果想看看其它的客户端，包括SPV客户端， 除了比特币的官方钱包外，我们还有其他各种钱包可供选择。 Bitcoin-Qt - 基于 C++/Qt 的 Bitcoin 比特币客户端图形化界面，支持 Linux/MacOSX/Windows，全功能。现在作为官方客户端使用，不过有个缺点，就是需要同步数据，超级慢啊。所以就难怪网络上一堆人在那里叫：比特币钱包同步怎么这么慢啊？实在是没法快起来，数据包太大了。如果实在受不了，只想要一个钱包地址的话，那么不妨试试手机客户端或者以下其他几种客户端吧。 下载地址：http://bitcoin.org/en/download MultiBit - 一个安全、轻量级、国际化的 Bitcoin 比特币钱包，支持 Windows、MacOS 和 Linux。MultiBit比特币客户端主要面向非技术用户，目标是为了让普通用户更快更方便的使用比特币。主要特征有“秒同步”（同步速度飞快），客户端可以创建和管理多个钱包，另外每个钱包都可以创建无数个收款地址。唯一的一点不好，选项里面有一个0.001的交易手续费，且不能取消。这是不是意味着，每次付款都要付出至少0.001的手续费呢？小编使用的就是这个客户端，强烈推荐。网站：https://multibit.org/ Armory - 是一个开放源代码的钱包客户端。它从一开始就设计用来给大量投资比特币的用户提供最高级别的安全性，同时仍然保持了高度的易用性和便利性。其易于使用和大量先进的功能，使它成为最流行的比特币客户端之一。Armory是基于 Python 的客户端，当前处在 Alpha 测试阶段，Beta 版本由多人资助。网站：https://bitcoinarmory.com/ Electrum - 是一个轻量级的、易于使用的比特币客户端，它可以保护你的比特币，避免遭受到因为备份错误或者电脑故障而造成的损失。你的钱包可以从一个秘密的短语中恢复，你可以把这段密语写在纸上或者记在心里。它并不下载比特币的块链数据，所以当你启动客户端时，你会发现不需要等待（众所周知官方客户端启动超慢）。网址：http://electrum.org/ 参考https://zhuanlan.zhihu.com/p/33646408","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"","date":"2018-06-20T11:22:09.263Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-道听途说/","text":"我司老板十台蚂蚁矿机S9，挖了3个月才挖到1个一天电费300块一台矿机买来2.7w，估计要一年多才能回本","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"","date":"2018-06-20T11:22:09.262Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/源码/-导读/","text":"依赖包括Boost, openssl , libevent以及QT等等 入口https://github.com/bitcoin/bitcoin/blob/master/src/bitcoind.cpp 12345678910111213第一步：设置运行环境；第二步：连接bitcoind信号处理对象；第三步：应用程序初始化操作；第四步：控制台命令传入参数解析；第五步：解析后参数的处理；第六步：初始化日志打印；第七步：初始化参数设置；第八步：初始化应用程序基本上下文环境；第九步：应用程序参数设置；第十步：应用程序完整性检查；第十一步：应用程序运行主函数；第十二部：循环等待关闭消息；第十三步：程序关闭。 参考 https://www.jianshu.com/p/2c2b0c0af659 主要数据结构比特币在代码中定义许多的类，有些我们在各种文章中经常看到例如 交易(CTransaction)， 区块(CBlock)， 交易池(CTxMemPool)等等，还有些不常见的例如共识(Consensus)，脚本(CScript)等等，这些数据结构在代码中随处可见，所以这部分单独拿出来对这些类包含的变量和成员函数进行解释，同时也便于之后的查阅。","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"源码","slug":"block-chain/虚拟货币/币种/比特币-BTC/源码","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/源码/"}]},{"title":"挖矿","date":"2018-06-20T11:22:09.261Z","path":"wiki/block-chain/虚拟货币/-挖矿/","text":"比特币怎么获得？ 挖矿 什么是挖矿？挖矿就是切蛋糕，总共一个，越切越少。 什么是切蛋糕？切蛋糕就是挖矿，总共一个矿，越挖越少。 goto 2 好吧，跳出无限循环。 比特币挖矿=贡献自己的计算资源。 虚拟货币比特币，是一串乱码组成，互联网金融，肯定是存在于互联网中，每一枚比特币都是一串数字，每一枚比特币的数字是独一无二的，都是由计算机计算出来的，很形象把这种计算比喻做挖矿。 独一无二的数字多了，为什么不用素数？素数也是越来越难算，或者设计个其他数字。如何保证数字主人的唯一性？数字被别人知道了，是不是比特币就被盗了？大家都知道这个数字怎么办？p2p，分布式账本/数据库 ##","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"}]},{"title":"","date":"2018-06-20T11:22:09.260Z","path":"wiki/Math/-运筹学-动态规划/启发式算法/-遗传算法/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"启发式算法","slug":"Math/运筹学-动态规划/启发式算法","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/启发式算法/"}]},{"title":"","date":"2018-06-20T11:22:09.259Z","path":"wiki/Math/-运筹学-动态规划/启发式算法/-蚁群算法/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"启发式算法","slug":"Math/运筹学-动态规划/启发式算法","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/启发式算法/"}]},{"title":"数字推盘游戏","date":"2018-06-20T11:22:09.258Z","path":"wiki/Math/-运筹学-动态规划/常见问题/-数字推盘游戏/","text":"寻找数字推盘游戏的一个解相对容易，但寻找最优解是一个NP困难问题。","tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"常见问题","slug":"Math/运筹学-动态规划/常见问题","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/常见问题/"}]},{"title":"【算法整理】A ∗ search 算法实现八数码问题","date":"2018-06-20T11:22:09.257Z","path":"wiki/Math/-运筹学-动态规划/常见问题/-n-puzzle/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"常见问题","slug":"Math/运筹学-动态规划/常见问题","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/常见问题/"}]},{"title":"","date":"2018-06-20T11:22:09.257Z","path":"wiki/Math/-运筹学-动态规划/常见问题/-旅行推销员问题/","text":"","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"常见问题","slug":"Math/运筹学-动态规划/常见问题","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/常见问题/"}]},{"title":"","date":"2018-06-20T11:22:09.256Z","path":"wiki/Math/-概率论与数理统计/-mcmc/","text":"什么是MCMC以管窥豹。 通俗一点地说，蒙特卡罗算法是一类比较笨的,依靠不停的随机模拟以不停逼近更精确或者在约束条件下更优化的解的算法. 随机算法，在采样不全时，通常不能保证找到最优解，只能说是尽量找。那么根据怎么个“尽量”法儿，我们我们把随机算法分成两类： 蒙特卡罗算法：采样越多，越近似最优解； 拉斯维加斯算法：采样越多，越有机会找到最优解； 举个例子，假如筐里有100个苹果，让我每次闭眼拿1个，挑出最大的。于是我随机拿1个，再随机拿1个跟它比，留下大的，再随机拿1个……我每拿一次，留下的苹果都至少不比上次的小。拿的次数越多，挑出的苹果就越大，但我除非拿100次，否则无法肯定挑出了最大的。这个挑苹果的算法，就属于蒙特卡罗算法——尽量找好的，但不保证是最好的。 而拉斯维加斯算法，则是另一种情况。假如有一把锁，给我100把钥匙，只有1把是对的。于是我每次随机拿1把钥匙去试，打不开就再换1把。我试的次数越多，打开（最优解）的机会就越大，但在打开之前，那些错的钥匙都是没有用的。这个试钥匙的算法，就是拉斯维加斯的——尽量找最好的，但不保证能找到。 MCMC最优要拿完。拉斯维加斯则不用拿完 这两个词本身是两座著名赌城，因为赌博中体现了许多随机算法，所以借过来命名。 如果问题要求在有限采样内，必须给出一个解，但不要求是最优解，那就要用蒙特卡罗算法。 反之，如果问题要求必须给出最优解，但对采样没有限制，那就要用拉斯维加斯算法。 例子下棋对于机器围棋程序而言，因为每一步棋的运算时间、堆栈空间都是有限的，而且不要求最优解，所以ZEN涉及的随机算法，肯定是蒙特卡罗式的。 机器下棋的算法本质都是搜索树，围棋难在它的树宽可以达到好几百（国际象棋只有几十）。在有限时间内要遍历这么宽的树，就只能牺牲深度（俗称“往后看几步”），但围棋又是依赖远见的游戏，甚至不仅是看“几步”的问题。所以，要想保证搜索深度，就只能放弃遍历，改为随机采样——这就是为什么在没有MCTS（蒙特卡罗搜树）类的方法之前，机器围棋的水平几乎是笑话。而采用了MCTS方法后，搜索深度就大大增加了。 求无理数 - 投针求pi针投的越多结果越准，但是找不好最优解，只能找到近似。 求无理数 - 求解积分求解交通状况 堵塞模型规模零件集成后的不合格率https://www.zhihu.com/question/20254139/answer/33572009 蒙特卡洛树搜索蒙特卡洛树搜索（英语：Monte Carlo tree search；简称：MCTS）是一种用于某些决策过程的启发式搜索算法，最引人注目的是在游戏中的使用。一个主要例子是电脑围棋程序[1]，它也用于其他棋盘游戏、即时电子游戏以及不确定性游戏。 不穷举所有组合，找到最优或次优位置 围棋棋面总共有$19 * 19 = 361$ 个落子位置。假如电脑有足够的计算能力，理论上来说，我们可以穷举黑白双方所有可能的落子位置，找到最优落子策略。 但是，如果穷举黑白双方所有可能的落子位置，各种组合的总数，大约是 $250^{150}$数量级。这个数太大了，以至于用当今世界最强大云计算系统，算几十年也算不完。 需要说明的是，蒙特卡罗树搜索并不是只有一种算法，而是一类算法。其中最流行的算法之一就是UCT（upper confidence bounds applied to trees）。 蒙特卡洛树搜索（英语：Monte Carlo tree search；简称：MCTS）是一种用于某些决策过程的启发式搜索算法，最引人注目的是在游戏中的使用。一个主要例子是电脑围棋程序[1]，它也用于其他棋盘游戏、即时电子游戏以及不确定性游戏。 下棋其实就是一个马尔科夫决策过程（MDP），根据当前棋面状态，确定下一步动作。 在每个模拟游戏中，AlphaGo都有两个大脑指引它进行搜索：价值网络（value network）和政策网络（policy network）。“政策网络”观察棋盘布局企图找到较好的下法，“价值网络”则预测这样下的话对方棋手赢棋的可能。结合这两个建议，AlphaGo最终决定怎样落子才是胜算最大的。 维特比为什么不用维特比算法，能把指数级搜索缩小到N^2级。而且是最优化解。","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-概率论与数理统计","slug":"Math/概率论与数理统计","permalink":"http://yoursite.com/categories/Math/概率论与数理统计/"}]},{"title":"","date":"2018-06-20T11:22:09.256Z","path":"wiki/Math/-运筹学-动态规划/-NP/","text":"P：算起来很快的问题NP：算起来不一定快，但对于任何答案我们都可以快速的验证这个答案对不对NP-hard：比所有的NP问题都难的问题NP-complete：满足两点： 是NP hard的问题 是NP问题 参考https://www.zhihu.com/question/27039635","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"}]},{"title":"优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）","date":"2018-06-20T11:22:09.254Z","path":"wiki/Math/-optimization/sgd/","text":"参考 为什么说随机最速下降法(SGD)是一个很好的方法？ | 知乎 SGD在两层神经网络上是怎么收敛的？ An overview of gradient descent optimization algorithms | 经典 繁体翻译 - 隨機梯度下降（SGD）優化算法及可視化 知乎翻译 keras的优化器","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-optimization","slug":"Math/optimization","permalink":"http://yoursite.com/categories/Math/optimization/"}]},{"title":"SVD、PCA、LDA、LSA、PLSA、LDA","date":"2018-06-20T11:22:09.254Z","path":"wiki/ML/ml 传统方法/降维/SVD与PCA/","text":"PCAPCA有两种通俗易懂的解释，1)是最大化投影后数据的方差(让数据更分散)；2)是最小化投影造成的损失。这两个思路最后都能推导出同样的结果。 其方法主要是通过对协方差矩阵进行特征分解[2]，以得出数据的主成分（即特征向量）与它们的权值（即特征值[3]）。PCA是最简单的以特征量分析多元统计分布的方法。其结果可以理解为对原数据中的方差做出解释：哪一个方向上的数据值对方差的影响最大？换而言之，PCA提供了一种降低数据维度的有效办法；如果分析者在原数据中除掉最小的特征值所对应的成分，那么所得的低维度数据必定是最优化的（也即，这样降低维度必定是失去讯息最少的方法）。主成分分析在分析复杂数据时尤为有用，比如人脸识别。 PCA和SVD的关系？一个根据covariave。一个是特征值。有什么联系。 LDA不记得了。 图片来自 https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca PCA与FA因子分析(FA)与主成分分析(PCA)的区别(1)主成分分析是将主要成分表示为原始观察变量的线性组合，而因子分析是将原始观察变量表示为新因子的线性组合，原始观察变量在两种情况下所处的位置不同。 PCA与SVD简介Matrix FactorizationSVD u = -0.825066 -0.047735 -0.563016-0.443084 -0.563669 0.697104-0.350631 0.824620 0.443914 s = Diagonal Matrix 9.2654 0 0 0 3.2340 0 0 0 1.3016 v = -0.636527 -0.770982 -0.020485-0.476317 0.372083 0.796666-0.606593 0.516857 -0.604073 U V有个特性，每行，每列的平方和都等于1. Matrix Factorization应该是，Diagonal Matrix中比较大的值，对应的U，V相应的行列，影响权值越大。特征值分解必须针对方阵，即只有方阵才有特征值，这也是特征值分解的一个局限 Q是矩阵A的特征向量组成的矩阵，Q不唯一一个矩阵其实就是一个线性变换，因为一个矩阵乘以一个向量后得到的向量，其实就相当于将这个向量进行了线性变换 奇异值分解在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了 一个很好的tutorial fed实质是降维对矩阵X和V的理解，X是latent vector representations ，V是词典，也就是latent space的坐标系。当然也可以U作为表达，sigma*V作为词典 我的实验要解决的问题：对1000个样本进行降维，我们可以采用SVD分解。如果又来了一个新样本，如何获得这个样本的降维表示？方法一：与原始样本组成1001的矩阵，然后整体矩阵进行SVD分解（计算复杂度较高）。因此我们提出一下问题 SVD分解是否对新增样本具有不变性，包括1.降维表达不变性；2.词典不变性？？？对 100030的矩阵进行svd分解，并降维到100020。100030=【100020】【2020】【2030】=【100020】【20*30】 ，这里第一项是降维表示，第二项是词典 新增一个样本，变为100130，对其SVD分解，U,S，V 与原始的USV几乎不变，只是增加了相应的行和列。这就寻找到了一个不变的量。然后具体如何获得一个新样本的降维表示呢？130=【120】【20*30】Ax=Y，超定方程组，一般无解，只能求近似解类似超定方程求解，以下程序的方法不一定很好 。 1234567891011121314151617---------------------------------------------------------------clear,clca=rand(100,1); %a作为训练集[U,S,V]=svd(a);a20=U*S(:,1:20)*(V(1:20,:))&apos;; %降维到20维后的重建error=sum(sum(abs(a-a20)));aplus=[a;rand(1,30)];%方法一：[U1,S1,V1]=svd(aplus); % 对所有样本进行SVD分解P1=U1(101,:)*S1(:,1:20); % 新样本降到20维后的表示%方法二：利用求解超定方程组的方法P2=inv(V&apos;*V)*V&apos;*aa&apos; %利用训练集得到的词典，求得的新样本表示P3=inv(V1&apos;*V1)*V1&apos;*aa&apos; %利用所有样本降维后的词典，求得的新样本表示-------------------------------------------------------------------P1=P3。说明这个方法很好，也就是把超定方程组化为普通方程组。这个方法有点类似 疑问对于稀疏矩阵，降维策略可以有哪些优化？ 参考 http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html http://www.puffinwarellc.com/index.php/news-and-articles/articles/30-singular-value-decomposition-tutorial.html?showall=1 http://www.ams.org/samplings/feature-column/fcarc-svd https://blog.csdn.net/Dark_Scope/article/details/53150883 https://www.zhihu.com/question/38319536","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"降维","slug":"ML/ml-传统方法/降维","permalink":"http://yoursite.com/categories/ML/ml-传统方法/降维/"}]},{"title":"","date":"2018-06-20T11:22:09.251Z","path":"wiki/ML/deep learning/model-basic/-MusicTaggerCRNN/","text":"https://github.com/fchollet/deep-learning-models","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"变分自编码器","date":"2018-06-20T11:22:09.250Z","path":"wiki/ML/deep learning/model-basic/生成模型/-VAE/","text":"变分自编码器（Variational auto-encoder，VAE）是一类重要的生成模型（generative model），它于2013年由Diederik P.Kingma和Max Welling提出[1]。2016年Carl Doersch写了一篇VAEs的tutorial[2]，对VAEs做了更详细的介绍，比文献[1]更易懂。这篇读书笔记基于文献[1]。 扩展阅读 https://zhuanlan.zhihu.com/p/25401928-","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"生成模型","slug":"ML/deep-learning/model-basic/生成模型","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/生成模型/"}]},{"title":"","date":"2018-06-20T11:22:09.248Z","path":"wiki/ML/deep learning/model-basic/-胶囊/","text":"卷积神经网络已经被hiton自己的新的胶囊网络代替，建议多上一点胶囊网络的资料stargan他其实就是想取代CNN，只不过capsule现在还不是特别work","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"ss","date":"2018-06-20T11:22:09.241Z","path":"wiki/ML/deep learning/model-basic/-style-transfer/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"","date":"2018-06-20T11:22:09.239Z","path":"wiki/ML/deep learning/model-basic/-NTM/","text":"其实memory cell的记忆能力也是有界限的。更好一点就是搞静态内存之类的吧.","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"","date":"2018-06-20T11:22:09.236Z","path":"wiki/ML/trick/-data-augmentation/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-06-20T11:22:09.236Z","path":"wiki/ML/trick/-sparse/","text":"ReLU L1正则","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-06-20T11:22:09.234Z","path":"wiki/ML/trick/-identity/","text":"源自ResNet CNN中的跨层连接 RNN中也有跨层连接。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"","date":"2018-06-20T11:22:09.234Z","path":"wiki/ML/trick/optimizer/-Momentum/","text":"动量（Momentum）随机梯度下降和小批量梯度下降是机器学习中最常见的优化技术，然而在大规模应用和复杂模型中，算法学习的效率是非常低的。而动量策略旨在加速学习过程，特别是在具有较高曲率的情况下。动量算法利用先前梯度的指数衰减滑动平均值在该方向上进行回退 [26]。该算法引入了变量 v 作为参数在参数空间中持续移动的速度向量，速度一般可以设置为负梯度的指数衰减滑动平均值。对于一个给定需要最小化的代价函数，动量可以表达为： 一文概览深度学习中的五大正则化方法和七大优化策略","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"},{"name":"optimizer","slug":"ML/trick/optimizer","permalink":"http://yoursite.com/categories/ML/trick/optimizer/"}]},{"title":"","date":"2018-06-20T11:22:09.234Z","path":"wiki/ML/trick/optimizer/-initializations/","text":"全0初始化 random initialization serves the purpose of symmetry breaking(对称失效). 随机初始化，为了摆脱对初始化数值的依赖性","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"},{"name":"optimizer","slug":"ML/trick/optimizer","permalink":"http://yoursite.com/categories/ML/trick/optimizer/"}]},{"title":"","date":"2018-06-20T11:22:09.233Z","path":"wiki/ML/trick/-activation/","text":"A cartoon drawing of a biological neuron (left) and its mathematical model (right). RNN中为什么要采用tanh而不是ReLu作为激活函数？ | 知乎 ReLU（1）优点： Krizhevsky et al. 发现使用 ReLU 得到的SGD的收敛速度会比 Sigmoid/tanh 快很多(看右图)。有人说这是因为它是linear，而且 non-saturating ，相比于 Sigmoid/tanh，ReLU 只需要一个阈值就可以得到激活值，而不用去算一大堆复杂的运算。（2）缺点： 当然 ReLU 也有缺点，就是训练的时候很”脆弱”，很容易就”die”了。举个例子：一个非常大的梯度流过ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了。 如果这个情况发生了，那么这个神经元的梯度就永远都会是0。注：实际操作中，设置learning rate 很大，那么很有可能你网络中的40%的神经元都”dead”了。 设置一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁。 参考 cs231n","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"自动求导","date":"2018-06-20T11:22:09.231Z","path":"wiki/ML/deep learning/toolbox/-自动求导/","text":"tensorflow一般机器学习系统可以提供两类接口，命令式（Imperative）和声明式（Declarative）。命令式就是直接把一些op的正向运算和求导运算都直接实现了，例如下面的Python代码。12345678def square(x): return x * x;def square_grad(x): return 2 * xprint(square(10))print(square_grad(10)) 参考https://www.zhihu.com/question/66200879https://www.zhihu.com/question/56443480 pytorch问题tensorflow和pytorch的求导，是在cpu中进行的还是gpu？pytorch采用命令式编程，是不是很吃内存？ 参考https://pytorch-cn.readthedocs.io/zh/latest/notes/autograd/","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"}]},{"title":"","date":"2018-06-20T11:22:09.231Z","path":"wiki/ML/deep learning/toolbox/-pytorch/static graph/","text":"哪些是动态图？现实中有哪些例子？tensorflow是怎样解决动态图问题的？动态图示例： pytorch示例：http://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-control-flow-weight-sharing - ## In PyTorch, each forward pass defines a new computational graph. A graph contains enough information to compute derivatives 每次forward定义一个graph backward都要重新build graph， pytorch在什么阶段build的graph？应该是在backward阶段吧，求导阶段意味着graph完成了。a graph contains enough information to compute derivatives. http://pytorch.org/tutorials/beginner/pytorch_with_examples.html#tensorflow-static-graphs","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-pytorch","slug":"ML/deep-learning/toolbox/pytorch","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/pytorch/"}]},{"title":"","date":"2018-06-20T11:22:09.231Z","path":"wiki/ML/deep learning/toolbox/-pytorch/torch.text.架构/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-pytorch","slug":"ML/deep-learning/toolbox/pytorch","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/pytorch/"}]},{"title":"torch.text","date":"2018-06-20T11:22:09.230Z","path":"wiki/ML/deep learning/toolbox/-pytorch/torch.text/","text":"简介依赖 NLTK 因为NLTK自身提供了很多NLP数据库的加载，为了不重复造轮子，torchtext尽可能复用NLTK 复用 nltk.tree 复用 ss 模块torchtext主要包含两大模块， torchtext.dataset 收录了常用的NLP数据库 torchtext.data 包含基本的数据结构，比如torchtext.data.example.Example torchtext.dataset依赖torchtext.data，一般两者要配合使用。 如何利用pytorch框架，管理其他数据库 继承torchtext.data.Dataset。 这里的某些类变量未定义，是不是算接口啊？ 定义类变量 urls、dirname、name 貌似就ok了。有没有文档啊 示例SNLI的例子 123456789from torchtext import datafrom torchtext import datasetsinputs = data.Field(lower=True)answers = data.Field(sequential=False)train, dev, test = datasets.SNLI.splits(inputs, answers)type(train) # torchtext.datasets.snli.SNLItype(train[0]) # torchtext.data.example.Example 主要涉及的两个类 torchtext.datasets.snli.SNLI torchtext.data.example.Example 详解torchtext.data.Dataset架构定义一个类， class SNLI(data.TabularDataset): torchtext.datatorchtext.dataset#","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-pytorch","slug":"ML/deep-learning/toolbox/pytorch","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/pytorch/"}]},{"title":"","date":"2018-06-20T11:22:09.229Z","path":"wiki/ML/deep learning/toolbox/-AI平台部/","text":"各大公司纷纷建立AI平台部，这个部门到底是干嘛的？ # #","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"}]},{"title":"","date":"2018-06-20T11:22:09.229Z","path":"wiki/ML/deep learning/toolbox/-pytorch/backwards/","text":"参考Why cant I see .grad of an intermediate variable? RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time credit assignment problem with BP/BPTT, 开头1234567891011121314151617def backward(self, gradient=None, retain_graph=None, create_graph=False): \"\"\"Computes the gradient of current variable w.r.t. graph leaves. The graph is differentiated using the chain rule. If the variable is non-scalar (i.e. its data has more than one element) and requires gradient, the function additionally requires specifying ``gradient``. It should be a tensor of matching type and location, that contains the gradient of the differentiated function w.r.t. ``self``. This function accumulates gradients in the leaves - you might need to zero them before calling it. Arguments: gradient (Tensor, Variable or None): Gradient w.r.t. the variable. If it is a tensor, it will be automatically converted to a Variable that does not require grad unless ``create_graph`` is True. None values can be specified for scalar Variables or ones that don't require grad. If a None value would be acceptable then this argument is optional. 这里的 current variable 指的是out.backward()中的out，不是input variable/ param accumulates gradients in the leaves 这句话的意思是？见 http://blog.csdn.net/qq_24401379/article/details/77970049跟bp的链式法则什么关系，梯度叠加是这个意思吗？ https://sherlockliao.github.io/2017/07/10/backward/ 为什么要累积梯度？ 为什么要zero-gradient？This allows us to cumulate gradients over several samples or several batches before using the gradients to update the weights.Once you have updated the weights you don’t want to keep those gradients around because if you reuse them, then you will push the weights too far.即 several batches共同更新一次梯度的时候，需要累积梯度。update weights后要马上zero-gradient，不然会影响下次update gradient有什么作用？是给out加的一个权重。 给out 加一个gradient权重的意义是什么呢？严格意义上，gradient是个矩阵，即jacob矩阵。 gradient可以起到selector的作用，选择矩阵中的哪个点，就置为1，其他位置为0。导出整个jacob矩阵，要分别backward n次(n为output的data数目，比如[2,3]的output，n=6) tensor output做backward的用途？多数情况下都采用标量作为loss，比如(分类问题中的MSE，回归问题中的..)。什么情况下会用到tensor output的梯度？ 纯数学问题，比如你要得到jacob矩阵 ML问题， 多维的output和多维的input，在求梯度的时候，实质上都是等价于flatten成一维向量。最终都是求和。1234567891011import torchfrom torch.autograd import Variablex = Variable(torch.ones(2, 3), requires_grad=True)a = Variable(torch.ones(3, 4))out = torch.mm(x,a) # shape: (2,4)gradient = torch.FloatTensor([[1,2,3,4],[5,6,7,8]]) # shape=(2,4)#gradient = torch.ones(4, 4)out.backward(gradient)print(x.grad) x x_11 x_12 x_13 x_21 x_22 x_23 out x_11+x_12+x_13 x_11+x_12+x_13 x_11+x_12+x_13 x_11+x_12+x_13 x_21+x_22+x_23 x_21+x_22+x_23 x_21+x_22+x_23 x_21+x_22+x_23 d(out)/dx d(out_11) d(out_12) d(out_13 d(out_14 d(out_21) d(out_22) d(out_23) d(out_24) d(x_11) 1 1 1 1 d(x_12) 1 1 1 1 d(x_13) 1 1 1 1 d(x_14) 1 1 1 1 d(x_21) 1 1 1 1 … gradient*out x_11+x_12+x_13 2x_11+2x_12+2x_13 3x_11+3x_12+3x_13 4x_11+4x_12+4x_13 5x_21+5x_22+5x_23 6x_21+6x_22+6x_23 7x_21+7x_22+7x_23 8x_21+8x_22+8x_23 x.grad 123Variable containing: 10 10 10 26 26 26 10 = 1+2+3+426=5+6+7+8 x.grad should has the same shape with x.data, for update weight gradient should has the same shape with out (current variable) The effect of gradient a","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-pytorch","slug":"ML/deep-learning/toolbox/pytorch","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/pytorch/"}]},{"title":"ss","date":"2018-06-20T11:22:09.228Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-工业化/-google讲座/","text":"# 数据并行 worker服务器 参数服务器 kubernates 云计算，管理很多机器， # TF-Hub 很多模型，模型间共享， piplinetf.data GPU不再是瓶颈，cpu的输入是瓶颈。充分利用cpu gpu，cpu不断 # deep&amp;wide在推荐系统上很好。 产业界：TFX逐渐开放中 京东利用tf做的OCR。小米用tf become GDETF发展规划 快 可用性 tf js tflight，移动端- 更易用、简捷，降低门槛 tf hub tfx autoML 降低重复工作，降低调参 未来的突破 无人驾驶车/出租车 医疗，诊断，医疗图像 对话，google assistant 农业、环境，希望有影响 教育 金融，金融数据比较多 制造业，传统产业相对更难一些 重要的是时间问题、方式问题、切入点问题 工程与研究如何平衡研究要基于真实的问题，要和产业结合。立足真实的问题。 不要关起门来做科研！！","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-工业化","slug":"ML/deep-learning/toolbox/tensorflow/工业化","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/工业化/"}]},{"title":"tf优化","date":"2018-06-20T11:22:09.228Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-工业化/tf的优化/","text":"（1）部署在移动终端上的（例如ios、android），场景：图像识别等。用freeze_graph合成pb和ckpt文件，然后用optimize_for_inference、quantize_graph进行优化。再用TensorFlowInferenceInterface调用（这个，不知道ios和android是否相同，入坑中…）。 （2）部署在服务端提供服务使用的，场景：推荐系统等。使用tensorflow serving进行模型服务化。 阿里妈妈基于TensorFlow做了哪些深度优化？TensorFlowRS架构解析","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"},{"name":"-工业化","slug":"ML/deep-learning/toolbox/tensorflow/工业化","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/工业化/"}]},{"title":"","date":"2018-06-20T11:22:09.227Z","path":"wiki/ML/deep learning/toolbox/tensorflow/-陈佳&wanwan组会/","text":"陈佳分享file queueexample queue的 batch shuffle入 queue 会shuffle，出queue不shuffle。出queue锁死 “ops/gen_data_flow_ops.py”, 是C++中load进来的ops是operations的简写：An op takes zero or more Tensors, performs some computation, and produces zero or more Tensors. http://9.186.106.71/dongx/tensorflow/tree/master/tensorflow/cc/ops 是批量生成的 C++自动生成 http://9.186.106.71/dongx/tensorflow/blob/master/tensorflow/core/kernels/random_shuffle_queue_op.cc C++11的lambda表达式 f.OutOfRangeError. This i epoc 所有epoc过多少轮，， reader为什么要一次把文件都读完？？ reduce_sum 意思是： reduce类似mapreduce，采用sum的方式进行reduce。 tutorials/mnist/beginnerstest和validation为什么不放在tf.placeholder，而是放在tf.constant？这两种数据结构有什么本质区别？因为placeholder是个符号，容器，开始并不直接存入数值。 tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) 这是什么评价指标？10个类别，y_=[0.1,0.2,0.5,0.8….] tf.argmax(y,1)指的是向量中最大的index，即4. ##cifar10 activation_summary是什么鬼？ loss层的summary merge summary是什么鬼？ op是什么鬼？ optimization losses 是多个显卡，多个loss control dependency， wanwan组会不支持scan，需要定长，theano加mask，tensorflow必须定长，，生成batch， theano没封装到cell，， :~$ =====basic rnn cell为什么返回return output, output ====input output都可以dropout 多个cell拼在一起， stacked RNN ====ptb是什么鬼？一个数据库 =====baket为了防止白算，聚类， =====translate是什么鬼？翻译模型，数据库貌似很大 linear.linear隐藏了 w+b=====basic lstm cell多了几个gate而已 =====rnn.py可以lstm，可以gru，sequence_length用于batch model。并未做mask，什么意思？ if sequence_length: (output, state) = control_flow_ops.cond( time &gt;= max_sequence_length, lambda: zero_output_state, lambda: output_state) =========seq2seqencoder,训练过程，rnn_decoder class based word prediction, the more class, (c|history) p(w|c)p(w|c)是如何定义的？？前者信息损失很大， 郭浩 重安装 pip install过程中有时会出现问题 下载的安装文件，跑代码是有时跑挂 因此下载源代码，自己编译 安装","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"tensorflow","slug":"ML/deep-learning/toolbox/tensorflow","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/tensorflow/"}]},{"title":"符号编程 VS 命令编程","date":"2018-06-20T11:22:09.220Z","path":"wiki/ML/deep learning/toolbox/-符号编程与命令编程/","text":"2015年之前框架都是符号式编程 pytorch命令式编程的方式，随时能够运行结果 tensorflow要先定义graph，然后一个session去运行；bug难调","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"}]},{"title":"静态图 VS 动态图","date":"2018-06-20T11:22:09.219Z","path":"wiki/ML/deep learning/toolbox/-静态图-动态图/静态图 VS 动态图/","text":"现在的深度学习平台在定义模型的时候主要用两种方式：static computation graph(静态图模型) 和 dynamic computation graph(动态图模型) 静态图：TensorFlow, Theano, Caffe，Keras等。动态图：PyTorch, Chainer, Dynet，TensorFlow Fold 部署：静态。为什么？ imperative mode做control flow，很多框架其实并不是自己做control flow，而是利用python来做，框架自己只记录一个static graph。这样的缺点是你没法部署到真正核心的产品里面，一旦要部署，就必须回到static graph去 - 很多产品，比如大规模推荐系统和移动端，是不可能用python的，overhead太大。 pytorch更容易重构函数，但是如果需要部署的话就还是得像TF或者其他一些框架一样老老实实做dirty work。 其实是抽象程度和可控程度之间的balance， 控制流真的在产品中很关键吗？因为控制流会影响整个内存的预测和建图，对性能还是有伤害的吧？真的需要性能直接通过C++接口的话会不会overhead可以接受一点？答：的确对于性能会有影响。比如说在手机端C2的策略是完全不用dispatcher和动态内存，一切都静态分配。不过在比较复杂的网络情况下，真要控制流的话还是需要有一定tradeoff的。另外实际应用中的确控制流用到的不多。 作者：贾扬清链接：https://www.zhihu.com/question/63342728/answer/208898814来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 静态图定义的缺陷是在处理数据前必须定义好完整的一套模型，能够处理所有的边际情况。比如在声明模型前必须知道整个数据中句子的最大长度。相反动态图模型(现有的平台比如PyTorch, Chainer, Dynet)能够非常自由的定义模型。举个例子，传统的LSTM往往处理一个句子的时候都是以word为单位，然后利用word2vec来初始化词向量。但是往往有一些很奇怪的词在vocabulary里是找不到的，也就是没法用word2vec初始化词向量。这时候你可能想用characer-level(字符)级别的表示来初始化那个单词，就需要借助动态图模型的定义了。简单来说动态图模型允许你在运行程序的时候动态去修正你的模型结构，来处理各种奇奇怪怪的边角输入，这在学术研究的时候的灵活性就体现出来了。 静态图需要在处理数据前定义好一套完整的模型；而动态图模型允许用户先定义好一套基本的框架再根据数据来实时修正模型。 能不能用指针形容一下动态和静态实现的区别？tensorflow中的动态图dynamic_rnn dynamic-rnn可以允许不同batch的sequence length不同。是否允许同一个batch内的sequence length不同？ 是动态图实现的？还是模拟的动态图？ dynamic-rnn到达sequence length之后终止计算吗？ 超出序列长度 seq_len，就复制 zero output 和之前的 state 到下一个时间步。避免了padding污染 能batch training吗？ 跟普通rnn比较，会变慢吗？还是更快？ 推荐用普通rnn还是动态rnn？ Why I Use raw_rnn Instead of dynamic_rnn in Tensorflow and So Should You s 为了得到没有padding污染的hidden state（LSTM，GRU会倾向于记住更多后面的信息，padding会对前向RNN的final state产生负面影响），需要传入sequence被pad前的长度；而为了加快计算速度，还是需要对整个数据集根据长度做bucketing。 https://www.zhihu.com/question/52200883/answer/208377796 Is padding necessary for LSTM network?","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"},{"name":"-静态图-动态图","slug":"ML/deep-learning/toolbox/静态图-动态图","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/静态图-动态图/"}]},{"title":"理解深度学习，机器学习，学到的是什么？人工智能可怕吗？","date":"2018-06-20T11:22:09.216Z","path":"wiki/ML/deep learning/-understanding-deep/","text":"深度学习学的是什么？目前人工智能做到的是什么？ 自然语言理解，下棋，自动驾驶，人脸识别，等任务，机器是真的理解了吗？机器学到了什么？ 机器学到的只不过是套路？只不过是对对子的升级版？类似天王盖地虎，对出宝塔镇河妖。 套路就是规律，是统计特性，是概率分布。 CNN学到的不同层面的特征， 怎样才算机器理解了？ 机器学到的套路，算不算理解了？学到的 人是怎样理解的？ 人的理解也无非是总结的套路/规律 人的学习和机器学习的区别是什么呢？ 人和机器的区别是什么？情感？幽默？创新？饿？疼痛？生老病死？ 人：这些无非是上帝在制造人的时候赋予的奖惩点，让人趋利避害，从而生存，最大化奖励。 机器：人的这些机器也可以有，只不过机器的奖惩点不同。机器 星球大战，终结者，理论上可行吗？ 可行吧 不要以提到人工智能，就想着机器人。 一个程序，繁殖是奖励，被kill掉是惩罚。让他在模拟环境中自生自灭。同时模拟一些killer，强化学习，自我增强。道高一尺，魔高一丈。 - 人工智能什么水平 弱人工智能，擅长单个领域 强人工智能，各方面与人类比肩。。。 这条路很难走 超人工智能，超过所有领域最聪明的人类 强人工智能实现的瓶颈是什么 算力，量子计算发展中 &amp; 云计算 终结者的瓶颈是什么？ 能源，电影里的机器人一般都伴随能量球、能量棒、超级能量。很有道理的。如果能云充电、太阳能充电等方式，那就更无敌了。 # https://www.zhihu.com/question/27864852","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"}]},{"title":"","date":"2018-06-20T11:22:09.215Z","path":"wiki/-audio/-相关企业和研究方向/","text":"语音方面的人工智能创业公司 思必驰 原阿里iDST语音团队负责人初敏加入思必驰，任北京研发院院长 (中科院声学所-&gt;微软-&gt;阿里) 语音识别、语音合成、自然语言理解、智能交互决策、声纹识别、性别及年龄识别、情绪识别等 其语音识别、声纹识别、口语对话系统等技术曾经多次在美国国家标准局、美国国防部、国际研究机构评测中夺得冠军 云知声 腾讯AI Lab 副主任俞栋 他们还是非常偏重云端的。地平线的语音则一开始就强调云端+嵌入式。 面临的挑战 效率 嘈杂环境 - 鸡尾酒会问题 把手机拿远一点，Siri就gg了。这里主要的原因是人说话的语音信号与手机麦克风所采拾的环境噪声之间信噪比（SNR）较小，噪声影响了正常识别系统的性能，这里的噪声包括环境的背景音，以及声音的混响（reverberation）。 在嘈杂环境下（SNR较小），噪声种类千变万化，导致每种音素的分布在各个方向偏移较大，数据分布变得复杂，使得需要更复杂的分类器，甚至也不一定能区分 解决方法： 前端：使用麦克风阵列采集多个信源的信号，综合分析出噪声和语音;传统的DSP方法对语音信号进行消除噪音处理。另外也有一些信号分离，语音增强，信号降噪的方法可以做。消噪处理有 降混响，回声消除，声源定位后接馅零处理，基于统计的单麦克风噪声消除，麦克风阵列处理。 平稳的噪声结合基于统计的单麦克风和VAD就很好解决掉，跟人声频谱相叠加的噪音就会很麻烦，麦克风阵列的声源定位和馅零可以解决掉空间上的噪音来源，而对于有参考信号的噪音来源，可以使用回声消除算法消除。 GAN 特定场景 语言理解 现在市面上不管哪个语音助手聊天机器人，你跟它聊几分钟你就知道它有多傻了，离真正的理解、对话、交互还差得远，这里有很多事情要做。 — 初敏 系统鲁棒性 数据没覆盖的情况就做不好， 自适应算法 参考 腾讯AI Lab副主任俞栋：语音识别领域的现状与进展","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"}]},{"title":"","date":"2018-06-20T11:22:09.215Z","path":"wiki/-audio/TTS/tts/","text":"WaveNet TacotronTacotron 2 (包括一个循环序列到序列特征预测网络和一个改良的 WaveNet 模型)paper 牛建伟：我们现在已有的是一个相对来说比较主流的技术框架。文本处理前端就是利用 NLP 相关算法、资源进行文本的规整，提取词法和语法信息。后端主要集中在参数合成，这一环节比较容易放到嵌入式的端上面进行，因为它的资源量比较小。这样的话 TTS 系统只需要占用几十 MB 的空间，对计算的要求也可控。后端我们用的就是一个相对主流的 BLSTM 模型，这基本上也是各家都在用的。 至于 WaveNet，它相对来说提高了合成语音的自然度，还有舒适度，但是它存在一个问题就是计算量很大。语音是 16K 采样，一秒钟它就要预测 16000 次。当然可以再做加速，但现在加速的效果还没有那么好，现在基本上还是 100 倍的实时率，就是合成一秒钟语音还需要 100 多秒的计算时间。这没办法直接用到产品上面，所以我们还是在追踪 WaveNet 的阶段。 可视化语音分析：深度对比Wavenet、t-SNE和PCA等算法 Gated CNN 跟 9 月份的 WaveNet 其实有点类似，因为它相当于是把显示的那种循环结构改了一下。","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"TTS","slug":"audio/TTS","permalink":"http://yoursite.com/categories/audio/TTS/"}]},{"title":"","date":"2018-06-20T11:22:09.214Z","path":"wiki/-audio/audioClassification/","text":"dataseturban sound dataset（https://serv.cusp.nyu.edu/projects/urbansounddataset/） Google AudioSet，它是基于有标签的 YouTube 视频片段 . YouTube-8M","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"}]},{"title":"","date":"2018-06-20T11:22:09.203Z","path":"wiki/-audio/ASR/api/xunfei/xf_errorlog/","text":"讯飞出现的错误 java端未说话，则出现以下错误：错误原因：您好像没有说话哦. at com.iflytek.cloud.b.c.a.do(Unknown Source) at com.iflytek.cloud.b.c.a.f(Unknown Source) at com.iflytek.cloud.b.c.a.i(Unknown Source) at com.iflytek.cloud.b.c.a.char(Unknown Source) at com.iflytek.cloud.b.e.a$1.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) windows下没有msc32.dll，或者linux下没有加载.so文件，则会出现以下错误：Exception in thread “Thread-670” java.lang.UnsatisfiedLinkError:.MSC.QISRSessionBegin([B[BLcom/iflytek/msc/MSCSessionInfo;)[C at com.iflytek.msc.MSC.QISRSessionBegin(Native Method) at com.iflytek.cloud.b.c.c.a(Unknown Source)Xunfei: no speak python端未启动java.net.ConnectException: Connection refused at java.net.PlainSocketImpl.socketConnect(Native Method) java中设置的端口号，必须要与python端设置的端口号一致！！！ 端口占用 kill 掉占用进程: lsof -i|23333 socket.shutdown然后socket.close 允许端口复用 程序只能等到下一个连接到来时，才能关闭线程。 （解决办法，加入监听等待超时）socket.setdefaulttimeout(timeout)这样默认20秒之后就会超时。5. 教程 http://bbs.chinaunix.net/thread-4083249-1-1.html say重复多次os.system(‘java -jar /var/persistent/home/nao/java/xf_lib/xunfeiutf.jar’) choregraphe中运行python, 该句在terminal中执行， ok 直接加入python脚本，运行 python comm_server.py ok 加入choregraphe中，运行 not ok t=os.system(‘/var/persistent/home/nao/java/xf_lib/run_jar.sh’) # 调用python脚本或jar包都返回512, 其他返回0t=os.system(‘echo fdfd&gt;&gt;/var/persistent/home/nao/java/xf_lib/test1.txt’) # 返回0t=os.system(‘java -jar /var/persistent/home/nao/java/xf_lib/xunfeiutf.jar’) # 返回32512 原因： choregraphe中不识别系统Path变量，因此不识别java，可以加入java的全路径，如下：os.system(‘/var/persistent/home/nao/java/jre1.7.0_79/bin/java -jar /var/persistent/home/nao/java/xf_lib/xunfeiutf.jar’) 卡在java -jar /var/persistent/home/nao/java/xf_lib/xunfeiutf.jar原因：也许都集成在nao-bin程序中，调用的jar也集成，并非进程间通信。 解决办法： 测试通过方式3，调用jar，写一个文件，看是否输出 替代做法： python 调用jar，不采用进程间通信 python直接调用c包（无音频前后端点检测） 采用多进程，新建一个进程， 编码问题文件编码：在eclipse中， terminal显示编码： 要求是utf-8编码显示sys.getdefaultencoding() 显示的是ascii xunfeiwriternosocket.jar 在windows上写出来是好的，在小森上是乱码考虑采用utf-8编码之后，再写文件 xunfei.jar python接收信号，并写出，是乱码xunfeiutf.jar python接收信号，并写出，是乱码","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"api","slug":"audio/ASR/api","permalink":"http://yoursite.com/categories/audio/ASR/api/"},{"name":"xunfei","slug":"audio/ASR/api/xunfei","permalink":"http://yoursite.com/categories/audio/ASR/api/xunfei/"}]},{"title":"","date":"2018-06-20T11:22:09.203Z","path":"wiki/-audio/ASR/api/xunfei/用法/","text":"讯飞应用到nao中的几种方式： python直接调用c包（无音频前后端点检测，放弃） python与jar包进程间通信 （我们目前采用的是该方法） python 调用jar，不采用进程间通信（可行） 讯飞限制 讯飞账号信息，需要绑定微信手机账号 申请认证， 多个appid，代码更新，需要多个appid单独编译并打包， 比较繁琐 支持简单英文(中英文混杂场景)，不支持纯英文场景","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"},{"name":"api","slug":"audio/ASR/api","permalink":"http://yoursite.com/categories/audio/ASR/api/"},{"name":"xunfei","slug":"audio/ASR/api/xunfei","permalink":"http://yoursite.com/categories/audio/ASR/api/xunfei/"}]},{"title":"","date":"2018-06-20T11:22:09.202Z","path":"wiki/-audio/toolbox/kaldi/thchs30/kaldi数据准备/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"toolbox","slug":"audio/toolbox","permalink":"http://yoursite.com/categories/audio/toolbox/"},{"name":"kaldi","slug":"audio/toolbox/kaldi","permalink":"http://yoursite.com/categories/audio/toolbox/kaldi/"},{"name":"thchs30","slug":"audio/toolbox/kaldi/thchs30","permalink":"http://yoursite.com/categories/audio/toolbox/kaldi/thchs30/"}]},{"title":"kaldi简介","date":"2018-06-20T11:22:09.201Z","path":"wiki/-audio/toolbox/kaldi/kaldi-intro/","text":"kaldi 学习thchs30的脚本：https://github.com/kaldi-asr/kaldi/tree/master/egs/thchs30/s5 中文语音识别 学习kaldi的话，先从hmm-gmm入手比较好， steps/train_delta.sh build-tree命令那部分的代码对应htk book第十章tree-based clustering, gmm-est命令那部分的代码对应htk book第八章的Parameter Re-Estimation Formulae; steps/train_fmllr.sh, steps/decode.sh这些脚本都是基于hmm-gmm模型。 神经网络 nnet1 hmm-dnn架构，相关的知识可以查阅微软俞栋2009-2013期间发表的论文 nnet2 同样是hmm-dnn架构，但是使用的是dan povey团队设计的NSGD算法，支持多线程并行训练，学习nnet2可以追dan povey从2012年之后的论文 nnet3 chain model,以及其他的神经网路结构(rn,cnn,lstm)的学习 扩展阅读 语音识别kaldi该如何学习？ | 知乎","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"toolbox","slug":"audio/toolbox","permalink":"http://yoursite.com/categories/audio/toolbox/"},{"name":"kaldi","slug":"audio/toolbox/kaldi","permalink":"http://yoursite.com/categories/audio/toolbox/kaldi/"}]},{"title":"","date":"2018-06-20T11:22:09.201Z","path":"wiki/-audio/toolbox/kaldi/-分布式训练/","text":"见 multi-gpu项目","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"toolbox","slug":"audio/toolbox","permalink":"http://yoursite.com/categories/audio/toolbox/"},{"name":"kaldi","slug":"audio/toolbox/kaldi","permalink":"http://yoursite.com/categories/audio/toolbox/kaldi/"}]},{"title":"语音识别 - 资源整合","date":"2018-06-20T11:22:09.200Z","path":"wiki/-audio/ASR/资源整合/","text":"数据见 audio/dataset 书籍 Speech and Language Processing 第三版本草稿| 斯坦福 Dan Jurafsky code Sphinx和HTK比较老了 Kaldi: 实现了hmm-gmm、hmm-dnn、chain-model等模型 DFSMN: code-ali, code-张世良 warp-ctc: 百度开源，对CTC的并行加速。很久未更新 tensorflow Deep Speech 实现了百度的Deep Speech模型 中文、英文语音识别: zzw922cn开源的，基于tensorflow的语音识别， pytorch Deep Speech2: 基于百度的wrap-ctc实现了百度的Deep Speech2模型- 课程 CS224S - Spoken Language Processing | stanford cs224n 第13讲 ASR 2017-18 cmu课程，slides和homework，2011年 学习如何提取特征，怎样实现HMM训练，DNN怎么构建，如何去HVite 论文集 Dan Povey的论文，多看Kaldi原文档，多逛Kaldi论坛 博客 u010384318的专栏","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"ASR","slug":"audio/ASR","permalink":"http://yoursite.com/categories/audio/ASR/"}]},{"title":"","date":"2018-06-20T11:22:09.198Z","path":"wiki/-audio/-唤醒/","text":"FAQ语音唤醒会用VAD吗？一般不用。唤醒词、非唤醒词、噪音。 (不靠谱的回答) 语音唤醒是识别任务，还是分类任务？两者都有，triger不固定的时候，或者triger自定义时，识别更靠谱。 语音唤醒程序运行在DSP芯片上？还是系统内？通常把语音唤醒算法porting到DSP芯片。包含三个模块： 特征提取 声学模型计算，GMM-DNN。 解码","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"}]},{"title":"","date":"2018-06-20T11:22:09.198Z","path":"wiki/-audio/dl-music/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"}]},{"title":"","date":"2018-06-20T11:22:09.198Z","path":"wiki/-audio/基础知识/编码/PCM/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"基础知识","slug":"audio/基础知识","permalink":"http://yoursite.com/categories/audio/基础知识/"},{"name":"编码","slug":"audio/基础知识/编码","permalink":"http://yoursite.com/categories/audio/基础知识/编码/"}]},{"title":"","date":"2018-06-20T11:22:09.197Z","path":"wiki/-audio/基础知识/打包类型/Mp3、WMA、AAC、OGG音质对比/","text":"","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"基础知识","slug":"audio/基础知识","permalink":"http://yoursite.com/categories/audio/基础知识/"},{"name":"打包类型","slug":"audio/基础知识/打包类型","permalink":"http://yoursite.com/categories/audio/基础知识/打包类型/"}]},{"title":"","date":"2018-06-20T11:22:09.196Z","path":"wiki/-audio/基础知识/特征/MFCC/","text":"MFCC（Mel频率倒谱系数）对应的物理含义是什么?https://www.zhihu.com/question/21302276 FAQ用深度学习进行语音识别为什么还要算mfcc？ 特征提取本身，是一种数据降维手段，可以有效的降低后续模式识别系统的复杂度/运算量。 深度学习确实可以自动提取特征，可以直接用pcm码进行训练，但这样会面临一些问题，如维度太高； 维度高，一方面计算量大，一方面模型也更大，容易过拟合 语音识别业界也一致在尝试使用深度学习从原始音频当中提取特征去替代mfcc和mel fbank。 参考：https://www.zhihu.com/question/67487899","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"基础知识","slug":"audio/基础知识","permalink":"http://yoursite.com/categories/audio/基础知识/"},{"name":"特征","slug":"audio/基础知识/特征","permalink":"http://yoursite.com/categories/audio/基础知识/特征/"}]},{"title":"","date":"2018-06-20T11:22:09.195Z","path":"wiki/-audio/基础知识/什么是声波/","text":"声音的传播实质上是声波的传播过程，声波作用到人耳所引起的感觉，称为声音，可见，声波是声音传播的本质。 什么是声波时域频域对于实值函数，函数的傅里叶级数可以写成： [ {\\displaystyle f(x)={\\frac {a_{0}}{2}}+\\sum {n=1}^{\\infty }\\left[a{n}\\cos(nx)+b_{n}\\sin(nx)\\right]} ] 即 时域 频域为什么要采用频域分析？因为时域不够鲁棒， 音频文件的保存采集的音频数据是时域的 音频文件的保存，是按照时域保存的，还是频域？为什么时域 2. 声波的描述参数相应于振动，声波也分为周期性声波和非周期性声波，最简单的周期声波是单频的声波，也称为纯音。它是由简谐振动产生的频率固定、并按正弦变化的声波。与单频音相对应的是复合声，复合声（也称为复声）是由一些频率不同的单频音组成，由傅立叶变换可知，可将任何复声分解成一系列单频音。 集中质量-弹簧模型的振动形式为简谐振动，我们都知道其运动方程的正弦表达形式。同样，单频声波也可以用这个函数来表示，即 声音的三个要素是音调、音强和音色。声波或正弦波有三个重要参数：频率 ω0、幅度A n 和相位ψn ，这也就决定了音频信号的特征。 对于声波而言，除了以上参数之外，还有另外两个参数：波长和波数。 正弦波的组合可以表示信号 波长是指周期声波中相邻的等声压点之间的距离，通常用λ表示。波长等于声速c与声波频率f之比，也等于声速c与周期T之积，即","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"基础知识","slug":"audio/基础知识","permalink":"http://yoursite.com/categories/audio/基础知识/"}]},{"title":"","date":"2018-06-20T11:22:09.192Z","path":"wiki/ML/app/nlp/-metric/","text":"distance Minkowski-Form Distance L1 distance L2 distance(欧氏距离) L∞ Histogram Intersection 马氏距离 Kullback-Leibler Divergence编辑距离 wmd: BOW + EMD 无序 referencesklearn.metrics string metric","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"}]},{"title":"","date":"2018-06-20T11:22:09.192Z","path":"wiki/ML/app/nlp/app/conversation/-_webqq/","text":"web.qq Smart QQ发送消息https://d1.web2.qq.com/channel/send_qun_msg2f r:{“group_uin”:477667670,”content”:”[\\”h\\”,[\\”font\\”,{\\”name\\”:\\”宋体\\”,\\”size\\”:10,\\”style\\”:[0,0,0],\\”color\\”:\\”000000\\”}]]”,”face”:669,”clientid”:53999199,”msg_id”:61090003,”psessionid”:”8368046764001d636f6e6e7365727665725f77656271714031302e3133332e34312e383400001ad00000066b026e040015808a206d0000000a406172314338344a69526d0000002859185d94e66218548d1ecb1a12513c86126b3afb97a3c2955b1070324790733ddb059ab166de6857”} r:{“group_uin”:477667670,”content”:”[\\”hello\\”,[\\”font\\”,{\\”name\\”:\\”宋体\\”,\\”size\\”:10,\\”style\\”:[0,0,0],\\”color\\”:\\”000000\\”}]]”,”face”:669,”clientid”:53999199,”msg_id”:61090004,”psessionid”:”8368046764001d636f6e6e7365727665725f77656271714031302e3133332e34312e383400001ad00000066b026e040015808a206d0000000a406172314338344a69526d0000002859185d94e66218548d1ecb1a12513c86126b3afb97a3c2955b1070324790733ddb059ab166de6857”} 返回{“errCode”:0,”msg”:”send ok”} 发送的明文啊，post的明文。 接收消息https://d1.web2.qq.com/channel/poll2每隔","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"conversation","slug":"ML/app/nlp/app/conversation","permalink":"http://yoursite.com/categories/ML/app/nlp/app/conversation/"}]},{"title":"","date":"2018-06-20T11:22:09.189Z","path":"wiki/ML/app/nlp/-web_service/index/","text":"function loadXMLDoc() { $.post(\"/nlp/text/distance\", { text1:$(\"#text1\").val(), text2:$(\"#text2\").val() }, function(data, status){ document.getElementById(\"text_distance\").innerHTML=data; }); } text distance Enter text here... Enter text here... submit text distance:ddd","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"-web_service","slug":"ML/app/nlp/web-service","permalink":"http://yoursite.com/categories/ML/app/nlp/web-service/"}]},{"title":"","date":"2018-06-20T11:22:09.188Z","path":"wiki/ML/app/nlp/app/text_retrieval/-lambda_rank/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"text_retrieval","slug":"ML/app/nlp/app/text-retrieval","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-retrieval/"}]},{"title":"","date":"2018-06-20T11:22:09.186Z","path":"wiki/ML/app/nlp/app/text_classification/-aspect-level-classification/","text":"数据预处理 模型 Optimizer num max-length attn accuracy comment 20 atae 70% 过拟合 20 mean 过拟合 20","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"text_classification","slug":"ML/app/nlp/app/text-classification","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-classification/"}]},{"title":"","date":"2018-06-20T11:22:09.186Z","path":"wiki/ML/app/nlp/app/阅读理解/-code/","text":"Reading Wikipedia to Answer Open-Domain Questions | facebook官方 | pytorch","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"阅读理解","slug":"ML/app/nlp/app/阅读理解","permalink":"http://yoursite.com/categories/ML/app/nlp/app/阅读理解/"}]},{"title":"语言模型 数据集","date":"2018-06-20T11:22:09.172Z","path":"wiki/-language_model/-dataset/","text":"ss语言数据联盟LDC (Linguistic Data Consortium) 见nmt asr lm的数据 enwik8 &amp; text8简介 enwiki8是从wikipedia上扒下来的前100,000,000个字符。最早是用来做文本压缩的。 text8是enwiki8的clean text all from Matt Mahoney’s page enwik8.zip download text8.zip download 格式：12345 enwik8 （复杂格式）&apos;&apos;&apos;Anarchism&apos;&apos;&apos; originated as a term of abuse first used against early [[working class]] [[radical]]s including the [[Diggers]] of the [[English Revolution]] and the [[sans-culotte|&apos;&apos;sans-culottes&apos;&apos;]] of the [[French Revolution]].[http://uk.encarta.msn.com/encyclopedia_761568770/Anarchism.html] Whilst the term is still used in a pejorative way to describe &apos;&apos;&amp;quot; text8 (1行，10^8个字符) anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the .... text8 all_size vocab_size 95M dd 71290 + UNK (tensorflow显示的) 预处理: (enwik8–&gt;text8) 只包含27种字符：小写的从a到z，以及空格符 大写字符 –&gt; 小写字符， 数字 –&gt; 对应的英语单词 比如：’s也换成了空格+s e.g被处理成了e g used in google word2vec tensorflow/word2vec Latest Wikipedia dumpptbptb.train.txtb.train.txt","tags":[],"categories":[{"name":"language_model","slug":"language-model","permalink":"http://yoursite.com/categories/language-model/"}]},{"title":"","date":"2018-06-20T11:22:09.171Z","path":"wiki/ML/app/nlp/app/-text_match/text_match/","text":"Introductiondatasetsummary MSRParaphraseCorpus 这个库，是二分类。tfidf的方法效果很差，因为不match的句子也有很多共有词汇。 msr_paraphrase_test.txt 转到excel，然后再转到markdown的表格格式。 12345Quality #1 ID #2 ID #1 String #2 String1 1089874 1089925 PCCW&apos;s chief operating officer, Mike Butcher, and Alex Arena, the chief financial officer, will report directly to Mr So. Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So.1 3019446 3019327 The world&apos;s two largest automakers said their U.S. sales declined more than predicted last month as a late summer sales frenzy caused more of an industry backlash than expected. Domestic sales at both GM and No. 2 Ford Motor Co. declined more than predicted as a late summer sales frenzy prompted a larger-than-expected industry backlash.1 1945605 1945824 According to the federal Centers for Disease Control and Prevention (news - web sites), there were 19 reported cases of measles in the United States in 2002. The Centers for Disease Control and Prevention said there were 19 reported cases of measles in the United States in 2002.0 1430402 1430329 A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night. A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night. STS_Data_2012_15seq2seq的数据貌似也可以用。text similarity的数据库也可用semantic matching Textual matching: TF-IDF, BM25 Topical matching: LDA Embedding matching: word2vec Translated text matching","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"-text_match","slug":"ML/app/nlp/app/text-match","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-match/"}]},{"title":"","date":"2018-06-20T11:22:09.171Z","path":"wiki/ML/app/nlp/app/-text_match/text_similarity/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"-text_match","slug":"ML/app/nlp/app/text-match","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-match/"}]},{"title":"","date":"2018-06-20T11:22:09.152Z","path":"wiki/ML/app/nlp/app/-0 NLU/-sequence_modeling/","text":"inputsequence of point sequence of vector/embedding sequence-dim: 1, 2(image) text 2d-image RGB-image video audio method markov n-gram: 离散时间的markov rnn： markov的增强版 cnn reference","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"-0 NLU","slug":"ML/app/nlp/app/0-NLU","permalink":"http://yoursite.com/categories/ML/app/nlp/app/0-NLU/"}]},{"title":"","date":"2018-06-20T11:22:09.150Z","path":"wiki/ML/app/nlp/app/word-vector/-rnn/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"}]},{"title":"","date":"2018-06-20T11:22:09.150Z","path":"wiki/ML/app/nlp/app/word-vector/model/-glove/glove/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-glove","slug":"ML/app/nlp/app/word-vector/model/glove","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/glove/"}]},{"title":"","date":"2018-06-20T11:22:09.149Z","path":"wiki/ML/app/nlp/app/word-vector/model/-subword/subword/","text":"Introductionhttps://github.com/facebookresearch/fastText Enriching Word Vectors with Subword InformationP. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, 速度慢，效果差？","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"-subword","slug":"ML/app/nlp/app/word-vector/model/subword","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/subword/"}]},{"title":"","date":"2018-06-20T11:22:09.147Z","path":"wiki/ML/app/nlp/app/word-vector/-pretrain-model/","text":"raw embedding file GoogleNews-vectors-negative300.bin is download from google processed file *.dat is array stored in a binary file on disk.using numpy.memmap api .vocab is the vocab related to .dat","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"}]},{"title":"SNLI模型","date":"2018-06-20T11:22:09.144Z","path":"wiki/ML/app/nlp/app/entailment/dataset/-snli_刷库模型/","text":"了解前沿模型， 刷库榜这个库刷了好多模型，刷不动了吧？18年还刷了3个模型。后面都是Ensemble模型了 但是这是一个检验模型的很好数据库，同时能跟进前沿模型。 NLI using Bi-LSTM and Inner-Attention | 2016 Yang Liu Directional self-attention network encoders (code) code pytorch官方code facebook官方code 待看博客 https://tangxiangru.github.io/2017/11/05/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%8E%A8%E7%90%86/","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"entailment","slug":"ML/app/nlp/app/entailment","permalink":"http://yoursite.com/categories/ML/app/nlp/app/entailment/"},{"name":"dataset","slug":"ML/app/nlp/app/entailment/dataset","permalink":"http://yoursite.com/categories/ML/app/nlp/app/entailment/dataset/"}]},{"title":"tfidf","date":"2018-06-20T11:22:09.139Z","path":"wiki/ML/app/nlp/app/-text-vector/vsm_tfidf/tfidf/","text":"12345&gt;&gt;&gt; from sklearn.feature_extraction.text import TfidfTransformer&gt;&gt;&gt; transformer = TfidfTransformer(smooth_idf=False)&gt;&gt;&gt; transformerTfidfTransformer(norm=...'l2', smooth_idf=False, sublinear_tf=False, use_idf=True)","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"-text-vector","slug":"ML/app/nlp/app/text-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-vector/"},{"name":"vsm_tfidf","slug":"ML/app/nlp/app/text-vector/vsm-tfidf","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-vector/vsm-tfidf/"}]},{"title":"","date":"2018-06-20T11:22:09.133Z","path":"wiki/ML/app/nlp/-text_preprocess/","text":"nltkkerasdoc: https://keras.io/preprocessing/text/ example_code: https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/ tensorflowhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/preprocessing/text.py pytorch","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"}]},{"title":"","date":"2018-06-20T11:22:09.131Z","path":"wiki/ML/app/vision/-autoencoder VS word2vec/","text":"## autoencoder是自己预测自己 word2vec是针对时序 markov autoencoder呢？","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"}]},{"title":"","date":"2018-06-20T11:22:09.130Z","path":"wiki/ML/app/vision/-tools/java-video/","text":"web camera using JavaI have tried number of ways to do this, from a long time. JMF - Now it is deadFMJ - Now it is dead tooVLCJ - too much because I am not creating a music/video player and it expect VLC to be installedXuggler - too much and hard workJMyron - didn’t workJavaFX - I thought it could do it, but seems like it can’t JavaCV http://docs.opencv.org/2.4/doc/tutorials/introduction/desktop_java/java_dev_intro.html https://github.com/sarxos/webcam-capture ##","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"-tools","slug":"ML/app/vision/tools","permalink":"http://yoursite.com/categories/ML/app/vision/tools/"}]},{"title":"","date":"2018-06-20T11:22:09.130Z","path":"wiki/ML/app/vision/app/OCR/-Document-layout-analysis/","text":"Document/Layout Analysis for OCRBefore the “character” recognition will take place, the logical structure of the document has to be be analyzed and defined. For example: Where are text blocks, paragraphs, lines? Is there a table that should be reconstructed? Are there any “images” on the page(s)? Are there any barcodes to read? https://abbyy.technology/en:features:ocr:document_analysis","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"OCR","slug":"ML/app/vision/app/OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/"}]},{"title":"","date":"2018-06-20T11:22:09.129Z","path":"wiki/ML/app/vision/app/OCR/-patent/","text":"document layout ocr 全局layout– tesera oCR出样式吗？上下级，平行关系。 法律条款的额结构分析。 OCR结构 – 识别内容，，相互加强。multi-task 学习。。 collection –","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"OCR","slug":"ML/app/vision/app/OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/"}]},{"title":"","date":"2018-06-20T11:22:09.129Z","path":"wiki/ML/app/vision/app/OCR/Tesseract-OCR/-模型 & 训练/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"OCR","slug":"ML/app/vision/app/OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/"},{"name":"Tesseract-OCR","slug":"ML/app/vision/app/OCR/Tesseract-OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/Tesseract-OCR/"}]},{"title":"","date":"2018-06-20T11:22:09.128Z","path":"wiki/ML/app/vision/app/OCR/Tesseract-OCR/-架构/","text":"Tesseract引擎功能强大，概括地可以分为两部分： 图片布局分析 字符分割和识别 图片布局分析，是字符识别的准备工作。工作内容：通过一种混合的基于制表位检测的页面布局分析方法，将图像的表格、文本、图片等内容进行区分。 字符分割和识别是整个Tesseract的设计目标，工作内容最为复杂。首先是字符切割，Tesseract采用两步走战略： 参考：http://blog.csdn.net/guzhenping/article/details/51019010","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"OCR","slug":"ML/app/vision/app/OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/"},{"name":"Tesseract-OCR","slug":"ML/app/vision/app/OCR/Tesseract-OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/Tesseract-OCR/"}]},{"title":"物体识别 - 综述","date":"2018-06-20T11:22:09.124Z","path":"wiki/ML/app/vision/app/Object Recognition/survey/","text":"名词解释 detection: find all objects (bounding box) classification: classify objects recognition: whether one is object segmentation: cut all objects (pixel wise) localization: find certain object (bounding box) 任务 广义的识别（Object Recognition/visual recognition），包括 图像分类/识别: 识别图片里是猫是狗 物体定位/检测: 不仅可以告诉你分类，还可以告诉你目标物体的坐标(框) 目标识别 语义分割: 不仅需要把物体检测出来， 还要把它从图片中扣出来 实体分割 关键点检测 其他任务：以图搜图、图像生成、 图像风格迁移 再细分 Scene categorization Image-level annotation: are there people? 主要模型发展历史： 从最初2013年提出的R-CNN、OverFeat，到后面的Fast/Faster R-CNN，SSD，YOLO系列，再到2018年最近的Pelee。短短不到五年时间，基于深度学习的目标检测技术，在网络结构上，从two stage到one stage，从bottom-up only到Top-Down，从single scale network到feature pyramid network，从面向PC端到面向手机端，都涌现出许多好的算法技术，这些算法在开放目标检测数据集上的检测效果和性能都很出色。 物体检测发展主要集中在两个方向： two stage算法 R-CNN系列 FPN 最好的two-stage one stage算法 YOLO SSD RetinaNet 是最好的one stage 两者的主要区别在于two stage算法需要先生成proposal（一个有可能包含待检物体的预选框），然后进行细粒度的物体检测。而one stage算法会直接在网络中提取特征来预测物体分类和位置。 two stageFaster R-CNN网络包括两个步骤： 使用RPN(region proposal network)提取proposal信息 使用R-CNN对候选框位置进行预测和物体类别识别。 Faster R‑CNN是首个利用CNN来完成proposals的预测的，之后的很多目标检测网络都是借助了Faster R‑CNN的思想 one stagereference History of Object Recognition | github 基于深度学习的目标检测算法综述 | 知乎专栏 - 美图","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"}]},{"title":"","date":"2018-06-20T11:22:09.123Z","path":"wiki/ML/app/vision/-from autoencoder to cnn/","text":"title from autoencoder to cnn from fully-connect from small image to large image 可以用autoencoder学习到的filter作为cnn的pre_train filter吧？unsupervised_pretrain是不是更好些 ## UFLDL介绍顺序很好，图像分类方法一： 全部串起来，全连接softmax方法二： 小图片，利用sparse autoencoder全连接学映射，然后再softmax方法三： 大图片，学习位置无关映射(即filter，类似于crop后的全连接)其中二和三隐约觉的有什么联系。 大图片如何学习位置无关映射？方法一：random_crop + autoencoder (unsupervised)方法二：cnn (supervised) 疑问又来了，方法一学到的映射可否用于分类？与方法二中学到的映射有什么区别？详见–UFLDL: Learning color features with SparseAutoencoders 两者的区别无非是监督与非监督而已(暂不考虑pooling)","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"}]},{"title":"","date":"2018-06-20T11:22:09.122Z","path":"wiki/ML/app/IR/-LSH/","text":"semantic hash加速环节： 检索v1 bit[] [1 0 0 0 1 0 1],.v2 bit[] [1 0 0 0 1 1 1] |v1-V2| 分类v1 double[] softmax(v1)=v2 double[] |v1-v2|cosine() 局部敏感哈希(Locality Sensitive Hashing，LSH) 传统 Hash 希望即使两个数据有一点点不一样，也要尽可能差异大。 而LSH则是希望相似的 value 对应的 Hash 值越相似越好。 常见的使用场景: 判重 Near-duplicate detection 摘要 Sketching 聚类 Clustering 相似搜索 Near-neighbor search 如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。 参考局部敏感哈希(Locality Sensitive Hashing，LSH) http://www.cnblogs.com/maybe2030/p/4953039.html","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"IR","slug":"ML/app/IR","permalink":"http://yoursite.com/categories/ML/app/IR/"}]},{"title":"","date":"2018-06-20T11:22:09.122Z","path":"wiki/ML/app/IR/-survey/","text":"# 索引 VS 检索 索引技术 - 综述在检索技术中，索引一直需要研究的核心技术。当下，索引技术主要分为三类：基于树的索引技术（tree-based index）、基于哈希的索引技术（hashing-based index）与基于词的倒排索引（visual words based inverted index）[1]。本文主要对哈希索引技术进行介绍。 相似度度量方法 LSH算法 Hamming Sampling Hash Jaccard Min Hash Angle Sim Hash","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"IR","slug":"ML/app/IR","permalink":"http://yoursite.com/categories/ML/app/IR/"}]},{"title":"","date":"2018-06-20T11:22:09.118Z","path":"wiki/ML/ml 传统方法/-有向图 VS 无向图/","text":"判别式VS生成式中已经说过，生成式模型重在建模联合分布同（联合分布决定了）无向图与有向图的核心区别就在于—建模联合分布的方式不同 有向图建模条件分布，来间接构建联合分布。无向图则直接构建联合分布。 图模型画法， 有向图把参数也画出来了，而无向图(RBM)中省略了参数w 举例：有向图： alpha–&gt; theta–&gt;y. 构建联合分布 p(y, theta) 是参数 alpha 的函数。 目的是寻找参数alpha，使得观测 y 最大似然无向图： RBM中 x—y, p(x, y) 是参数 w 的函数。目的是寻找参数 w， 使得观测 y 最大似然。 问题集：为什么RBM中不把x，w都视为参数。 目的寻找合适的x ，w， 使得观测 y 最大似然？ DBM的优化的pretraining中，利用的是两层两层的优化。有向图中是否可以这样做？答： 共同之处 将复杂的联合分布分解为多个因子的乘积 不同之处 无向图模型因子是势函数，需要全局归一 有向图模型因子是概率分布，无需全局归一 优缺点 无向图中的势函数设计不受概率分布约束，设计灵活，但全局归一代价高 有向图无需全局归一、训练相对高效","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"","date":"2018-06-20T11:22:09.117Z","path":"wiki/ML/ml 传统方法/-一句话机器学习/","text":"——-归一化—–普通归一化，不能搞定负值softmax归一化， 能搞定负值 ——-降维—–单模态：PCA：选取最大方差的方向（选择一组映射/基，使得映射后的数据方差最大）。做法：协方差矩阵的特征值分解，取最大几个。SPM：对图像取不同层次的特征，构成金字塔LDA：线性判别分析，sparse coding: 即矩阵分解时，编码是稀疏的，字典未必稀疏。目的：学习compact representations of images Dictionary learning:represent learning:compressive sensing:validation set:验证集，决定什么时候应该停止训练。test set: 测试现场运行性能 CCA： （典型相关分析）两个模态映射到同一空间，使person相关系数最大。寻找同一对象两组变量间线性相关性的一种常用的多元统计分析方法ECA：增强相关分析ICA： ISOMAP（等距映射）： 定义了一种新的距离度量，首先对所有样本点做全连接，定义两点间的距离是两点间的最短路距离（比较新颖，但是计算量较大）LE： laplace eigenmaps （拉普拉斯特征图法）–LPP: locality preserving projection（局部保持投影）– 引入graph laplace项，使得降维前后保持近邻关系LLE: locally linear embedding（局部线性嵌入）–哈尔小波：降采样+残差 —–特征选择—–决策树–根据信息量大小（信息增益，或区分能力,或其他策略），决定先选哪个特征。 —–聚类—–K-Means：把n的对象根据他们的属性分为k个分割(k &lt; n)。它与处理混合正态分布的最大期望算法(本十大算法第五条)很相似，因为他们都试图找到数据中自然聚类的中心。它假设对象属性来自于空间向量，并且目标是使各个群组内部的均方误差总和最小。 —–回归分类—–感知机： 分类超平面 f(x) = sign(wx+b)，损失函数是误分类点到划分超平面S(w.x+b=0)的总距离KNN： 给定一个样本，找到k个近邻，k近邻多数属于的类别，判定为该样本的类别。sigmoid函数： 实数域 到 自然数域 的一个映射。logistc回归： 似然服从sigmoid函数，的 MLE。多类问题采用softmax函数probit回归： 似然服从正态分布的累积分布最大熵模型：max H(y|D),跟logistic回归形式类似，都称为对数似然模型。最小二乘法： 误差服从gauss分布，的MLESVM：最大类间几何间隔，误差服从 hinge losspagerank: Ax=x ，已知A求x的问题。一个高等级的页面指向可以使其他低等级页面的等级提升。naive bayes: 一种分类方法；类条件独立假设，减少了参数数目。 p(Y) P(X|Y) –&gt; P(Y|X)。 详见李航书bayesian estimation： 一种参数估计方法，P(X) P(Y|X) –&gt; P(X|Y) 核函数： 低维空间线性不可分，可以通过非线性映射，映射到高维空间去 ——优化—–共轭梯度法： 固定其他变量，优化一个 拉普拉斯分布： 就是背靠背的双指数分布","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"从决策树到随机森林：树型算法的原理与实现","date":"2018-06-20T11:22:09.114Z","path":"wiki/ML/ml 传统方法/supervised/-random-forest/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"}]},{"title":"","date":"2018-06-20T11:22:09.114Z","path":"wiki/ML/ml 传统方法/supervised/SVM/-SVM/","text":"低维空间内，线性不可分时，可以采用非线性。这样等同于映射到高维空间，然后采用线性分类器分类。 比如二类分界面是 y=3x^2+2x+6,我们可采用把原始x映射到（1，x，x^2）空间中，进行线性分类。 核函数可以简单理解成 一种相似性度量大部分核函数可以归结为两种，内积和1/d比如矩阵分解中，两个向量的内积来作为相似性度量。高斯核函数是， 1/exp(d) 也可以用KL距离吧 IsanSVMassimpleassayingit'sadiscriminativeclassifierthatsimplyoptimizesthehingeloss? SVMissimplya**linearclassifier,optimizinghingelosswithL2regularization**. Orisitmorecomplexthanthat? No,itisjustthat,howevertherearedifferentwaysoflookingatthismodelleadingtocomplex,interestingconclusions.Inparticular,thisspecificchoiceoflossfunctionleadstoextremelyefficientkernelization,whichisnottrueforlogloss(logisticregression)normse(linearregression).Furthermoreyoucanshowveryimportanttheoreticalproperties,suchasthoserelatedtoVapnik-Chervonenkisdimensionreductionleadingtosmallerchanceofoverfitting. 支持向量有什么作用？ Supportvectorsaresimplysamplesplacednearthedecisionboundary(loselyspeaking).Forlinearcaseitdoesnotchangemuch,butasmostofthepowerofSVMliesin**itskernelization**-thereSVsareextremelyimportant.Onceyouintroducekernel,duetohingeloss,SVMsolutioncanbeobtained**efficiently**,andsupportvectorsaretheonlysamplesrememberedfromthetrainingset,thusbuildinganon-lineardecisionboundarywiththesubsetofthetrainingdata. 为什么CNN通常采用logloss(softmax)，为什么很少采用hingeloss?CNN+hinge-loss能叫deepSVM吗? https://www.reddit.com/[object Object]comments/40680m/why_isnt_cnns_with_hinge_loss_popular_can_we_call/ hingeloss和ReLU很像，有什么关系吗？ 参考 很经典，很赞，常见SVM的疑问 https://stackoverflow.com/questions/34325759/whats-the-relationship-between-an-svm-and-hinge-loss","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"SVM","slug":"ML/ml-传统方法/supervised/SVM","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/SVM/"}]},{"title":"","date":"2018-06-20T11:22:09.113Z","path":"wiki/ML/ml 传统方法/supervised/-gbdt/","text":"GBDT和XGBOOST的区别有哪些？最初的GBDT发展到现在的XGBoost，改进是一点一滴来的，是一篇篇论文的积累， xgboost相比传统gbdt有何不同？xgboost为什么快？xgboost如何支持并行？ https://www.zhihu.com/question/41354392","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"}]},{"title":"","date":"2018-06-20T11:22:09.112Z","path":"wiki/ML/ml 传统方法/-boosting tree/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"","date":"2018-06-20T11:22:09.111Z","path":"wiki/ML/ml 传统方法/-判别式 VS 生成式/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"","date":"2018-06-20T11:22:09.106Z","path":"wiki/ML/recommender-system/-基于spark-streaming实时推荐系统/","text":"https://blog.csdn.net/pztyz314151/article/details/5302572851/article/details/53025728","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"recommender-system","slug":"ML/recommender-system","permalink":"http://yoursite.com/categories/ML/recommender-system/"}]},{"title":"FM","date":"2018-06-20T11:22:09.105Z","path":"wiki/ML/recommender-system/model/-FM/","text":"已经过去很多年了，FM依然牛逼去很多年了，FM依然牛逼","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"recommender-system","slug":"ML/recommender-system","permalink":"http://yoursite.com/categories/ML/recommender-system/"},{"name":"model","slug":"ML/recommender-system/model","permalink":"http://yoursite.com/categories/ML/recommender-system/model/"}]},{"title":"阿里天池大数据之移动推荐算法大赛","date":"2018-06-20T11:22:09.105Z","path":"wiki/ML/recommender-system/竞赛/-ali-天池/","text":"简介入围选手需登录天池平台，访问和使用海量淘宝数据，并利用Map&amp;Reduce、SQL及各种平台集成的机器学习算法包调试模型，提交结果； 算法总结数据初赛数据 初赛阶段提供10000用户的完整行为数据以及百万级的商品信息；训练和预测的数据将会在4月20日进行一次切换（即切换为另一批10000用户的数据）。 决赛数据 决赛阶段提供500万用户的完整行为数据以及千万级的商品信息。 总结�级的商品信息。 总结","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"recommender-system","slug":"ML/recommender-system","permalink":"http://yoursite.com/categories/ML/recommender-system/"},{"name":"竞赛","slug":"ML/recommender-system/竞赛","permalink":"http://yoursite.com/categories/ML/recommender-system/竞赛/"}]},{"title":"Frequently Asked Questions","date":"2018-06-20T11:22:09.103Z","path":"wiki/-FAQ/","text":"ss源码： 点击展开答案 象 您的浏览器不支持 video 标签。 FAQ样式 https://www.tutorialspoint.com/about/faq.htm-","tags":[],"categories":[]},{"title":"","date":"2018-06-20T11:22:09.103Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/进程切换/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.103Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/进程链表/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.102Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/简介/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.102Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/进程描述符/","text":"http://edsionte.com/techblog/archives/tag/%E8%BF%9B%E7%A8%8B%E6%8F%8F%E8%BF%B0%E7%AC%A6","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.102Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/轻量级进程/","text":"轻量级进程（LWP）是一种实现多任务的方法。 与普通进程相比，LWP与其他进程共享所有（或大部分）它的逻辑地址空间和系统资源； 与线程相比，LWP有它自己的进程标识符，并和其他进程有着父子关系；这是和类Unix操作系统的系统调用vfork()生成的进程一样的。另外，线程既可由应用程序管理，又可由内核管理，而LWP只能由内核管理并像普通进程一样被调度。Linux内核是支持LWP的典型例子。 LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息，而这也是它之所以被称为轻量级的原因。 在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息，而这也是它之所以被称为轻量级的原因。一般来说，一个进程代表程序的一个实例，而LWP代表程序的执行线程（其实，在内核不支持线程的时候，LWP可以很方便地提供线程的实现）。因为一个执行线程不像进程那样需要那么多状态信息，所以LWP也不带有这样的信息。 为什么说linux是轻量级进程？因为linux并没有为线程准备特定的数据结构。在内核看来，只有进程而没有线程，在调度时也是当做进程来调度。linux所谓的线程其实是与其他进程共享资源的进程。为什么说是轻量级？在于它只有一个最小的执行上下文和调度程序所需的统计信息。他是进程的执行部分，只带有执行相关的信息。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.102Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/进程管理/","text":"进程管理.md","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.101Z","path":"wiki/CS/OS/-linux/linux kenel/1.内核引导/内核引导/","text":"参考 http://home.ustc.edu.cn/~boj/courses/linux_kernel/1_boot.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"1.内核引导","slug":"CS/OS/linux/linux-kenel/1-内核引导","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/1-内核引导/"}]},{"title":"","date":"2018-06-20T11:22:09.101Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/创建进程/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.101Z","path":"wiki/CS/OS/-linux/linux kenel/进程管理/进程调度/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"进程管理","slug":"CS/OS/linux/linux-kenel/进程管理","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/进程管理/"}]},{"title":"","date":"2018-06-20T11:22:09.100Z","path":"wiki/CS/OS/-linux/linux kenel/1.内核引导/BIOS/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"1.内核引导","slug":"CS/OS/linux/linux-kenel/1-内核引导","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/1-内核引导/"}]},{"title":"如何阅读Linux源码","date":"2018-06-20T11:22:09.099Z","path":"wiki/CS/OS/-linux/linux kenel/如何阅读Linux源码/","text":"## Linux源代码阅读——环境准备 http://home.ustc.edu.cn/~boj/courses/linux_kernel/0_prepare.html 阅读工具Linux下：vim+ctags+cscope sudo apt-get install vim ctags cscope 在github上阅读也挺不错 获取源码方式一： 1git clone git://git.kernel.org/cgit/linux/kernel/git/stable/linux-stable.git 这是下载所有版本，很慢 方式二： 推荐版本 1.0 源码 2.2 Understanding the Linux Kernel, 1st Edition 2000 2.4.0 源码 https://mirrors.edge.kernel.org/pub/linux/kernel/v2.4/linux-2.4.0.tar.gz ss 《LINUX内核源代码情景分析》(毛德操，胡希明) 2001 Understanding the Linux Kernel, 2nd Edition 2002 《深入分析Linux内核源代码》陈莉君 2002 2.6 源码 Understanding the Linux Kernel, 3rd Edition 2005 扩展阅读 https://github.com/torvalds/linux https://www.kernel.org/pub 这里可以指定下载的版本b 这里可以指定下载的版本","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"}]},{"title":"","date":"2018-06-20T11:22:09.099Z","path":"wiki/CS/OS/-linux/linux kenel/文件系统/文件系统/","text":"基本概念实体概念 相对硬盘heads 磁头sectors 扇区 每个扇区512byte（现在新的硬盘每个扇区有4K）cylinders 柱面 虚拟概念 相对文件系统block：文件系统不是一个扇区一个扇区的来读数据，太慢了，所以有了block（块）的概念，它是一个块一个块的读取的，block才是文件存取的最小单位。 硬盘容量就是headssectorscylinders*512 注意：硬盘的最小存储单位就是扇区了，而且硬盘本身并没有block的概念。 Unix文件系统概述文件Unix文件是以字节序列组成的信息载体(container)，内核不解释文件的内容。 参考《深入理解linux内核》 问题集1.假设Apache产生的日志文件名为access_log,在apache正在运行时,执行命令mv access_log access_log.bak,执行完后,请问新的apache的日志会打印到哪里，请选择下列描述正确的是？ A. 系统会检查access_log文件是否存在，若不存在则创建。B. 虽然此时文件被改名，但是由于服务正在运行，因为它的inode节点的位置没有变，程序打开的fd仍然会指向原来那个inode，不会因为文件名的改变而改变。apache会继续向已改名的文件中追加日志。正确答案: B mv对inode的影响： 前提：使用mv命令搬移的文件目的地跟原文件在同一文件系统内 系统会新建一个目录项，将新档案名称对应到inode number （注意，inode number并没有变，只是对应了新的名字） 删除旧档案 （搬移档案的行为对inode table没有任何影响，也不会将档案搬移到其他的block） 由此可见，在我们看来access_log 和 access_log.bak 是两个不同的文件，其实他们是同一个文件，只是换了名字而已。由于程序打开的fd指向原来的iNode，而MV操作并不会改变这个inode，因此对正在运行的程序不会产生影响。 参考 4KB 扇区磁盘上的 Linux：实际建议","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"文件系统","slug":"CS/OS/linux/linux-kenel/文件系统","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/"}]},{"title":"","date":"2018-06-20T11:22:09.098Z","path":"wiki/CS/OS/-linux/linux kenel/文件系统/存储管理/","text":"存储管理.md","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"文件系统","slug":"CS/OS/linux/linux-kenel/文件系统","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/文件系统/"}]},{"title":"","date":"2018-06-20T11:22:09.097Z","path":"wiki/CS/OS/-linux/linux kenel/源码/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"}]},{"title":"","date":"2018-06-20T11:22:09.095Z","path":"wiki/CS/cloud/google/-google-vpc/","text":"基础Virtual Private Network 虚拟私有云VPC官网文档 DNS serverEach instance’s metadata server acts as a DNS server. It stores the DNS entries for all VPC network IP addresses in the local VPC network and calls Google’s public DNS server for entries outside the VPC network.","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"cloud","slug":"CS/cloud","permalink":"http://yoursite.com/categories/CS/cloud/"},{"name":"google","slug":"CS/cloud/google","permalink":"http://yoursite.com/categories/CS/cloud/google/"}]},{"title":"","date":"2018-06-20T11:22:09.094Z","path":"wiki/CS/cloud/google/-GAE/","text":"GAE简介 PaaS: Platform-as-a-Service（平台即服务） GAE支持Node.js java python PHP Go Ruby 浏览器访问google，需要用翻墙（我用的代理） 但是本地开发，需要Google Cloud SDK。而且需要连接google cloud。需要vpn了。（囧）那就本地开发，把代码上传到git，然后clone到GAE GAE的云端shell配置&amp;默认环境 Debian GNU/Linux 8 10G硬盘(可用3.2G) 2G内存 python2.7 OpenJDK 1.7 我勒个草，GAE是提供的SaaS还是IaaS？ 搭建pyton应用 yaml git clone https://github.com/GoogleCloudPlatform/appengine-try-python-flask.git $TUTORIALDIR 测试应用使用了 Flask Web 框架。 部署应用 gcloud app deploy app.yaml –project my-first-project-164507Deploying to URL: [https://my-first-project-164507.appspot.com 部署完后，就能直接访问url了 本地应用开发 下载 Google Cloud SDK 并在本地进行开发 构建您的下一个应用：了解如何将 App 引擎与其他云端平台产品结合使用 java使用 App Engine Maven 插件将一个示例 Java 应用部署至 Google App 引擎 src/main/webapp/WEB-INF/appengine-web.xml 文件即web app中的web.xml文件 采用的jetty作为web server git clone https://github.com/GoogleCloudPlatform/appengine-try-java.git $TUTORIALDIR mvn appengine:run 编译，测试应用，能够本地预览了 mvn appengine:deploy 部署应用https://my-first-project-java-164508.appspot.com/ 编程指南/home/acmcqu087378/src/xu-song/java_gae_quickstart-2017-04-13-19-54/target/appengine-try-java-1.0/home/acmcqu087378/src/xu-song/java_gae_quickstart-2017-04-13-19-54/target/appengine-try-java-1.0/WEB-INF/classes/ 免费 配额每 24 小时重置一次 前端实例使用小时数 0.25 实例小时（上限为 28 实例小时） 传出带宽 0.000089 GB（上限为 1 GB） 云端存储A类操作次数 0（上限为 0.02） 注册免费试用，即可获得 300 美元的赠金，并可在 12 个月内试用 Google 云端平台提供的所有功能 免费版限制:如果不花钱的话……socket模块无法使用。也就是说，凡是用到import socket的东西都会出错。每天流量1GB，北京时间下午4点重置。urlfetch每分钟22M，传入传出带宽每分钟56M……所以GoAgent翻墙会有流量限制，而且这并不应当由GoAgent背锅。详细的资源限制可以到GAE控制面板的“配额”哪里查看。 功能支持 网址抓取（URL Fetch）：访问互联网上的资源，抓取检索数据。 邮件（Mail）： GAE可以利用基于Gmail的基础设施来发送电子邮件。 Memcache缓存：高性能的内存缓存保障，对于那些不需要持久性存储和事务功能的数据（例如临时数据或从数据存储区复制到缓存以进行高速访问的数据）很有用。 图像操作（Image Manipulation）：使用该 API，您可以对 JPEG 和 PNG 格式的图像进行缩放、裁剪、旋转和翻转，还能使用预先定义的算法提升图片的质量。 计划任务和任务队列（Scheduled Tasks &amp; Task Queues）：允许将任务计划为按指定间隔运行，这些任务通常称为Cron job。另外可以通过在一个队列插入任务（以Web Hook的形式）来实现后台处理，GAE会根据调度方面的设置来安排这个队列里面的任务执行。 GAE新的收费模式——process-instance-hour同AWS（Amazon Web Services）相比，GAE按照的是process-instance-hour收费模式，而AWS则是按照machine-instance-hour收费。这一点对开发人员相当重要，在AWS里，可以并行运行几十个进程，而在GAE中，当进程在等待I/O传输的过程中仍在收取费用。 这也意味着，在对支持的语言进行编译时，更少的CPU消耗时间等于更少的钱。但同时也意味着，运行多个进程等待的时间更长，收取的费用更高，对于Python开发者而言，这绝对不是一个好消息，因为Python开发往往需要多线程处理多个Web请求。从这个角度来看，GAE每个进程实例每小时0.08美元的收费要比AWS机器为实例0.085美元的收费似乎更为昂贵。 成功案例：适用于搭一些 已经成功搭了一个html游戏 https://xu-song.appspot.com/games/towerdefense/ 做一个online word2vec(中英文) &amp;&amp; online-doc2vec 做一个online ocr 做一个online image caption/classification 做一个online NLC 情感分析 QA 做一个online crawler 做一个online 提醒，（提醒备忘录，提醒股票买卖，提醒生日，提醒天气预报） 做一个反向代理，入口为https://xu-song.appspot.com/。/pythonapp/代理到python的web服务，javaapp/代理到java后台服务。 做一个online alphago 做一个online德州扑克（开源没） 经常访问的站点，不要放在GAE，耗流量比如博客，gitlab服务， 其他","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"cloud","slug":"CS/cloud","permalink":"http://yoursite.com/categories/CS/cloud/"},{"name":"google","slug":"CS/cloud/google","permalink":"http://yoursite.com/categories/CS/cloud/google/"}]},{"title":"","date":"2018-06-20T11:22:09.085Z","path":"wiki/CS/-database/solr/SolrServer/REST-API/","text":"Introduction这里指的solr-server提供的rest api 支持的操作： add index update delete retrive query faceting 12345678/select solr.SearchHandler（后台的类吧？是servlet吗）/query solr.SearchHandler/update/export solr.SearchHandler/browse solr.SearchHandler/update/extract solr.extraction.ExtractingRequestHandler/delete solrconfig.xml里没有 对应solr-server的？ core admin reference solrconfig.xml的RequestHandler模块* selectselect?q=: dataimport123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263查看状态/dataimport重建索引/dataimport?command=full-import&amp;clean=false&amp;offset=0&amp;endset=1000000增量索引/dataimport?command=delta-import重新加载配置/dataimport?command=reload-config终止一个在运行的操作/dataimport?command=abort创建索引库/admin/cores?action=CREATE&amp;name=collection3&amp;instanceDir=/data/solr/member/example/solr/collection3&amp;config=solrconfig.xml&amp;schema=schema.xml&amp;dataDir=data加载core/admin/cores?action=LOAD&amp;core=c6卸载core/admin/cores?action=UNLOAD&amp;core=collection2&amp;deleteIndex=true切换索引库/admin/cores?action=SWAP&amp;core=core1&amp;other=core1查看core的信息/admin/cores?action=STATUS重新加载core/admin/cores?action=RELOAD&amp;core=core0合并core/admin/cores?action=mergeindexes&amp;core=core0&amp;srcCore=core1&amp;srcCore=core2提交/update?commit=true根据id删除索引update/?stream.body=&lt;delete&gt;&lt;id&gt;6380736&lt;/id&gt;&lt;/delete&gt;&amp;stream.contentType=text/xml;charset=utf-8&amp;commit=true删除所有索引update/?stream.body=&lt;delete&gt;&lt;query&gt;*:*&lt;/query&gt;&lt;/delete&gt;&amp;stream.contentType=text/xml;charset=utf-8&amp;commit=true备份/replication?command=backup获得最新的索引版本/replication?command=indexversion让某从服务器不再从主服务器拉取索引/replication?command=abortfetch 使某从服务器可以从主服务器拉取修改的索引/replication?command=enablepoll返回配置和当前状态/replication?command=details f","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"},{"name":"solr","slug":"CS/database/solr","permalink":"http://yoursite.com/categories/CS/database/solr/"},{"name":"SolrServer","slug":"CS/database/solr/SolrServer","permalink":"http://yoursite.com/categories/CS/database/solr/SolrServer/"}]},{"title":"","date":"2018-06-20T11:22:09.085Z","path":"wiki/CS/-database/solr/SolrServer/SolrStart/","text":"solr start in jettysolr start in tomcat","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"},{"name":"solr","slug":"CS/database/solr","permalink":"http://yoursite.com/categories/CS/database/solr/"},{"name":"SolrServer","slug":"CS/database/solr/SolrServer","permalink":"http://yoursite.com/categories/CS/database/solr/SolrServer/"}]},{"title":"solr error log","date":"2018-06-20T11:22:09.084Z","path":"wiki/CS/-database/solr/errorlog/","text":"stack sizeThe stack size specified is too small, Specify at least 768kError: Could not create the Java Virtual Machine.Error: A fatal exception has occurred. Program will exit. 修改bin/solr.in.sh 中的xss ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"},{"name":"solr","slug":"CS/database/solr","permalink":"http://yoursite.com/categories/CS/database/solr/"}]},{"title":"","date":"2018-06-20T11:22:09.083Z","path":"wiki/CS/-database/solr/SolrClient/SolrJ/","text":"solrjsolrj核心就是调用的solr-server提供的restapi。 使用SolrJ操作Solr会比利用httpClient来操作Solr要简单。SolrJ是封装了httpClient方法，来操作solr的API的。SolrJ底层还是通过使用httpClient中的方法来完成Solr的操作。 SolrClientSolrClient 是一个抽象类，因此要连接到一个远程Solr实例，你需要创建一个 HttpSolrClient 或 CloudSolrClient 的实例。它们都通过 HTTP 来和 Solr 交流。然后你可以发送 SolrRequest 或 SolrQuery 并获取 SolrResponse HttpSolrClient单节点 Solr 客户端 ConcurrentUpdateSolrClient当实现一个将会一次性批量加载大量文档的 java 应用时，应该考虑使用 ConcurrentUpdateSolrClient 来替代 HttpSolrClient。 ConcurrentUpdateSolrClient 会缓冲所有被添加的文档并将它们写到开启的 HTTP 连接中。 这个类是线程安全的。 尽管任何 SolrClient 请求都可以通过该实现完成， 我们通常推荐仅将 ConcurrentUpdateSolrClient 用在 /update 上。 CloudSolrClient SolrCloud 客户端LBHttpSolrClientSolrQuerySolrRequestprocess操作 12345678910111213AbstractUpdateRequest ContentStreamUpdateRequest UpdateRequest 如果是add操作，UpdateRequest包含所需add的docCollectionAdminRequestCoreAdminRequestDirectXmlRequestDocumentAnalysisRequestFieldAnalysisRequestGenericSolrRequestLukeRequestQueryRequestSolrPing SolrResponseSimpleSolrResponseSolrResponseBase add 操作12345678910111213141516DefaultClientConnectionOperator.openConnection(OperatedClientConnection, HttpHost, InetAddress, HttpContext, HttpParams) line: 168ManagedClientConnectionImpl.open(HttpRoute, HttpContext, HttpParams) line: 304DefaultRequestDirector.tryConnect(RoutedRequest, HttpContext) line: 611DefaultRequestDirector.execute(HttpHost, HttpRequest, HttpContext) line: 446SystemDefaultHttpClient(AbstractHttpClient).doExecute(HttpHost, HttpRequest, HttpContext) line: 882SystemDefaultHttpClient(CloseableHttpClient).execute(HttpUriRequest, HttpContext) line: 82SystemDefaultHttpClient(CloseableHttpClient).execute(HttpUriRequest) line: 107SystemDefaultHttpClient(CloseableHttpClient).execute(HttpUriRequest) line: 55HttpSolrClient.executeMethod(HttpRequestBase, ResponseParser) line: 480HttpSolrClient.request(SolrRequest, ResponseParser, String) line: 241HttpSolrClient.request(SolrRequest, String) line: 230UpdateRequest(SolrRequest&lt;T&gt;).process(SolrClient, String) line: 150HttpSolrClient(SolrClient).add(String, SolrInputDocument, int) line: 174HttpSolrClient(SolrClient).add(String, SolrInputDocument) line: 139HttpSolrClient(SolrClient).add(SolrInputDocument) line: 153ClauseSolr.main(String[]) line: 44 soft VS hard commit参考 zotero/conf-core/solrconfig.xml.pdf","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"},{"name":"solr","slug":"CS/database/solr","permalink":"http://yoursite.com/categories/CS/database/solr/"},{"name":"SolrClient","slug":"CS/database/solr/SolrClient","permalink":"http://yoursite.com/categories/CS/database/solr/SolrClient/"}]},{"title":"","date":"2018-06-20T11:22:09.082Z","path":"wiki/CS/-database/solr/SolrClient/solr-web/","text":"Introductionsolr-web核心就是调用的solr-server提供的restapi。 该文档介绍localhost:8983/solr/ web页面的使用及原理 ## query下面：Request-Handler (qt) /select","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"},{"name":"solr","slug":"CS/database/solr","permalink":"http://yoursite.com/categories/CS/database/solr/"},{"name":"SolrClient","slug":"CS/database/solr/SolrClient","permalink":"http://yoursite.com/categories/CS/database/solr/SolrClient/"}]},{"title":"MongoDB 课程","date":"2018-06-20T11:22:09.081Z","path":"wiki/CS/-database/mongodb/week1/","text":"M101J: MongoDB for Java Developers 笔记class1what count for final grade? homework &amp; final exam class2 non-relational: store data not in table like relational. json hireachi schemaless: mongodb is document oriented not support joins between collectionos, not support sql has dynamic shcema- 3 0 MongoDB Relative to Relational 没看懂what features did mongodb omit inorder to retain scalability?joins &amp; transactions across multiple collectionsnot index, not secondary index Overview of building an app with mongodb spark java (a micro web framework inspired by sinatra) freemaker to create html views mongo java driver (connect to mongodb) install mongodb12345678910111213141516bin/mongod - The database process.bin/mongos - Sharding controller.bin/mongo - The database shell (uses interactive javascript).$ ./mongod --helpTo run a single server database:$ mkdir /data/db$ ./mongod$$ # The mongo javascript shell connects to localhost and test database by default:$ ./mongo&gt; help BSONmondodb stores data as BSON or binary JSON （格式转换由mongo java driver来完成） lightweight traversable 可通过的 穿越的 efficient CRUDcreatereadupdatedeletevideo.movies movies collection in the video database findOne m101.hw1 同一个collection中的所有doc必须有unique id the heart of the query language for mongodb is a query by example strategy SSspark java embeds jetty inside of it 视频中依赖java7 sparkjava 0.9.9.4sparkjava2必须要java8 hw1123456wget hw1....zipunzipmongorestore dumpmongo # mongo shelluse m101 # swith to database m101db.hw1.findOne() # list all the docs in m101.hw1, 也可以db.hw1.find() hw2hw3","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"},{"name":"mongodb","slug":"CS/database/mongodb","permalink":"http://yoursite.com/categories/CS/database/mongodb/"}]},{"title":"derby","date":"2018-06-20T11:22:09.080Z","path":"wiki/CS/-database/derby/","text":"derby.md","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-database","slug":"CS/database","permalink":"http://yoursite.com/categories/CS/database/"}]},{"title":"","date":"2018-06-20T11:22:09.079Z","path":"wiki/CS/network/-未分类/","text":"CDMA： https://www.nowcoder.com/question/next?pid=9013927&amp;qid=14574&amp;tid=13544960 FDM:频分多路复用FDM:频分多路复用利用通信线路的可用带宽超过了给定的带宽这一优点。频分多路复用的基本原理是：如果每路信号以不同的载波频率进行调制，而且各个载波频率是完全独立的，即各个信道所占用的频带不相互重叠，相邻信道之间用“警戒频带”隔离，那么每个信道就能独立地传输一路信号。 采用FDM技术进行多路复用时，复用后的信号的带宽通常大于复用前所有信号的带宽之和。 信道在同一信道上同一时刻，可进行双向数据传送的通信方式是 DTE是数据终端设备，一般有路由器和终端主机，DCE是数据通讯设备，一般有广域网交换机和MODEM 带宽首先说一下带宽的定义： 在模拟信号系统又叫频宽，是指在固定的时间可传输的资料数量，亦即在传输管道中可以传递数据的能力。通常以每秒传送周期或赫兹(Hz)来表示。 在数字设备中，带宽指单位时间能通过链路的数据量。通常以bps来表示，即每秒可传输之位数。在计算机系统中，用带宽作为标识总线和内存性能的指标之一。总线带宽指的是总线在单位时间内可以传输的数据总量，等于总线位宽与工作频率的乘积。例如：对于64位、800MHz的前端总线，它的数据传输率就等于64bit×800MHz÷8(Byte)=6.4GB/s内存带宽指的是内存总线所能提供的数据传输能力。例如：DDR400内存的数据传输频率为400MHz，那么单条模组就拥有64bit×400MHz÷8(Byte)=3.2GB/s的带宽。然后理解题意： 题目中已经说了传输速率，因此带宽不需要了，况且如果要带宽计算，那么也需要知道传输时通道的位数，是8位，16位还是32位，64位等等，因此直接用传输速率来计算即可 网络拓扑交换机 VS 路由器交换机，顾名思意，主要是起交换数据的作用。 路由器，不但起交换数据的作用，它还会寻找到该数据会传给谁，该怎么传。这是交换机和路由器最基本的区别。路由器不但可以交换数据，还可以寻址、路由。 路由器的好处是为不同类型的物理网络提供连接：以太网、令牌环网、点对点的链接和FDDI（光纤分布式数据接口）等等。 打个比方：A想给B传递一个东西，如果是在同一个房间内（网络上就是一个局域网内），他们彼此之间是认识的，那么A就可以直接给B这个东东。这就是一个交换机可以完成的事项；同样，A想给B传递一个东西，但是不在同一个房间内（网络上就是不同局域网内），他们彼此之间是不认识的，那么A就不得不通过其他媒介，寻找到适当的方式才可以给B这个东东。这就是一个路由器该完成的事项；但是交换机做不到。 不过，现在的3层交换机也可以有路由功能。但是，交换机拥有强大的数据交换能力，这是路由器做不到的；路由器有强大的路由功能及安全策略能力，也是交换机做不到的。交换机一般用在区域内起数据交换的功能，路由器一般用在区域间起路由转发的功能。 三层交换技术就是二层交换技术+三层转发技术。传统交换技术是在OSI网络标准模型第二层——数据链路层进行操作的，而三层交换技术是在网络模型中的第三层实现了数据包的高速转发，既可实现网络路由功能，又可根据不同网络状况做到最优网络性能。 一般意义上交换机工作在数据链路层，路由器工作在网络层 交换机根据MAC地址寻址，通过站表选择路由，站表的建立和维护由交换机自动进行 路由器根据IP地址进行寻址，通过路由表路由协议产生 交换机最大的好处是快速，路由器最大的好处是控制能力强 来自 https://www.nowcoder.com/questionTerminal/064e86d1f1244801ad3c61900d2528b3 3层交换机和路由器的区别？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"}]},{"title":"","date":"2018-06-20T11:22:09.078Z","path":"wiki/CS/network/网络编程-socket编程/-常见错误/","text":"java.net.SocketException: No buffer space available It certainly sounds like you are leaking Sockets somehow in your app. 这句话意思就是开了socket，没有关 Check that your code always closes the Sockets it opens … even in the event of some exception; i.e. do the close in a finally block. state 介绍 TIME_WAIT：表示主动关闭，通过优化系统内核参数可容易解决。 CLOSE_WAIT：表示被动关闭，需要从程序本身出发。 ESTABLISHED：表示正在通信 解决办法下次出现这种情况的时候，netstat -apn | grep javanetstat -apn | grep 8983 netstat -nap | grep pid检查一下本机java程序占用了多少端口，主要是跟8983的连接还是5000的连接？ 端口占用状态某次的结果 12345678910111213141516171819tcp 0 0 127.0.0.1:63342 0.0.0.0:* LISTEN 8959/javatcp 0 0 127.0.0.1:6942 0.0.0.0:* LISTEN 8959/javatcp 0 0 0.0.0.0:54152 0.0.0.0:* LISTEN 8959/javatcp6 0 0 127.0.0.1:7983 :::* LISTEN 23705/javatcp6 0 0 :::8080 :::* LISTEN 32668/java listen状态，是本地tomcat启动的项目，监听8080tcp6 0 0 :::8983 :::* LISTEN 23705/java listen状态，是本地jetty启动的solr，监听8983端口tcp6 0 0 :::53056 :::* LISTEN 9342/javatcp6 0 0 127.0.0.1:8005 :::* LISTEN 32668/javatcp6 0 0 :::8009 :::* LISTEN 32668/javatcp6 1 0 127.0.0.1:36061 127.0.0.1:8983 CLOSE_WAIT 32668/java tomcat启动的项目，向solr发送socket连接tcp6 1 0 127.0.0.1:36060 127.0.0.1:8983 CLOSE_WAIT 32668/javatcp6 1 0 127.0.0.1:36062 127.0.0.1:8983 CLOSE_WAIT 32668/javatcp6 0 0 9.186.100.11:57211 151.101.40.215:80 ESTABLISHED 9342/javatcp6 0 0 9.186.100.11:46481 151.101.44.215:80 ESTABLISHED 9342/javatcp6 0 0 9.186.100.11:46483 151.101.44.215:80 ESTABLISHED 9342/javatcp6 0 0 9.186.100.11:46482 151.101.44.215:80 ESTABLISHED 9342/javatcp6 0 0 9.186.100.11:46484 151.101.44.215:80 ESTABLISHED 9342/java 某次的结果12345678910111213tcp6 0 0 :::8080 :::* LISTEN 75106/javatcp6 0 0 :::8983 :::* LISTEN 74867/java tomcat启动的项目，向solr发送socket连接，怎么变这么多了？会存在多个线程采用同一个单例，向solr发送socket连接tcp6 1 0 127.0.0.1:48876 127.0.0.1:8983 CLOSE_WAIT 75106/java close的socket连接tcp6 1 0 127.0.0.1:45752 127.0.0.1:8983 CLOSE_WAIT 75106/java close的socket连接tcp6 1 0 127.0.0.1:48925 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48729 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48714 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48924 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48763 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48764 127.0.0.1:8983 CLOSE_WAIT 75106/java 过一段时间会有变化，下面标红色的，是新增的两个socket连接，12345678tcp6 1 0 127.0.0.1:48925 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48729 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:56303 127.0.0.1:8983 CLOSE_WAIT 75106/java 新增的socket连接tcp6 1 0 127.0.0.1:48714 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48924 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:48763 127.0.0.1:8983 CLOSE_WAIT 75106/javatcp6 1 0 127.0.0.1:56302 127.0.0.1:8983 CLOSE_WAIT 75106/java 新增的socket连接tcp6 1 0 127.0.0.1:48764 127.0.0.1:8983 CLOSE_WAIT 75106/java solrSearch.query(queryParameters); 会建立连接 默认采用GET方式发送请求还是 new HttpSolrClient(URL) 的尚未建立连接，只是做了一下config。 update的时候solr.add(doc) send the SolrInputDocument to the Solr update request handler over HTTP.","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络编程-socket编程","slug":"CS/network/网络编程-socket编程","permalink":"http://yoursite.com/categories/CS/network/网络编程-socket编程/"}]},{"title":"","date":"2018-06-20T11:22:09.078Z","path":"wiki/CS/network/网络编程-socket编程/-网络编程/","text":"概念什么是网络编程？传输层以下，一般在操作系统内核中执行。通常所说的网络编程，基本等价于socket编程，以及socket之上的编程？ 网络层也有对应的api，应该。 应用编程接口（TCP/IP详解 1.15节） 使用TCP/IP协议的应用程序通常采用两种应用编程接口（API）：socket和TLI（运输层接口： Transport Layer Interface）。前者有时称作“Berkeley socket”，表明它是从伯克利版发展而来的。后者起初是由 AT &amp; T开发的，有时称作 X T I（ X / O p e n运输层接口）， socket编程能干嘛？有什么是socket编程搞不定的，必须要改内核的？能干嘛 代理，比如shadowsocks vpn是吗？貌似vpn工作在底层，不算socket编程。vpn是通过编写一套网卡驱动并注册到操作系统实现的虚拟网卡。 猎豹wifi也是虚拟出一张网卡 Overview 目录名参考 java.net包， javax.net包 目的： 怎样算得上熟悉 TCP/IP 协议编程？能进行网络编程 一般书上只讲解了OSI模型中的七层模型，实验也只是socket通信。怎样算得上熟悉 TCP/IP 协议编程？ 如果你说你会select,epoll,iocp模型,那会让对方觉得更靠谱 如果你说出你做过im,下载之类那会让对方来兴趣. 如果你说设计了通讯协议,会让对方觉得更贴切 如果你说做过,熟悉, ftp http snmp smtp 这些简单的老古董协议,会加分,但不大. 如果你说熟悉bt,emule,udt等协议,那会对你很有好感. 如果你说你破解过某大牌 qq,360内某通讯协议,那会对你加分很大 参考知乎：https://www.zhihu.com/question/20795067/answer/16259037 问题集 现在可以写代码看到传输层的信息。 已经看到了http header, smtp header, 怎样打印tcp header? 可以看到更底层的报文吗？ 怎样打印更底层的header？通过java、python可以看到更底层的header吗? 公司的网络截断是怎样做的？猜测就是wireshark的封装，监听通过网卡的每个连接。 待学习资料 计算机网络自顶向下方法，其中有python的学习代码 未分类信息CRLFCRLF命令它表示键盘上的”Enter”键(可以用来模拟回车键)。CRLF注入就是说黑客能够将CRLF命令注入到系统中。它不是系统或服务器软件的漏洞，而是网站应用开发时，有些开发者没有意识到此类攻击存在的可能而造成的。针对这个漏洞黑客能够做什么？就算黑客发现网站存在CRLF注入，他们仍然受到应用结构和这个缺陷的严重程度的限制。对有些站点它将非常严重，而有些站点它只是很小的bug。HTTP Header CRLF Injection许多网络协议，包括HTTP也使用CRLF来表示每一行的结束。这就意味着用户可以通过CRLF注入自定义HTTP header，导致用户可以不经过应用层直接与Server对话。HTTP header的定义就是基于这样的”Key: Value”的结构，用CRLF命令表示一行的结尾。“Location:”头用来表示重定向的URL地址，”Set-Cookie:”头用来设置cookies。如果用户的输入经过验证，其中存在CRLF的字符就可以被用来达到欺骗的目的。 dfd","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络编程-socket编程","slug":"CS/network/网络编程-socket编程","permalink":"http://yoursite.com/categories/CS/network/网络编程-socket编程/"}]},{"title":"","date":"2018-06-20T11:22:09.077Z","path":"wiki/CS/network/网络工作方式-非协议-可以采用不同的通信协议/p2p/-p2p/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络工作方式-非协议-可以采用不同的通信协议","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/"},{"name":"p2p","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/p2p","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/p2p/"}]},{"title":"","date":"2018-06-20T11:22:09.076Z","path":"wiki/CS/network/网络工作方式-非协议-可以采用不同的通信协议/vpn/-VPC/","text":"虚拟私有云VPC随着网络规模的不断扩大，ARP欺骗、广播风暴、主机扫描等网络安全问题越来越严重，为了解决这些问题，出现了各种网络隔离技术，比如虚拟局域网（VLAN）、VPC等。虽然VLAN技术可以将网络的用户进行隔离，但是VLAN的数量最大只能支持到4096个，无法支撑公有云的巨大用户量。 虚拟私有云（VPC：Virtual Private Cloud）与VPN类似，实现VPC也需要利用隧道技术，以及SDN（软件定义网络）。利用VPC技术可以将公有云的网络隔离，每个VPC网络都有一个隧道号，相互之间逻辑上彻底隔离。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络工作方式-非协议-可以采用不同的通信协议","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/"},{"name":"vpn","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/vpn","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/vpn/"}]},{"title":"","date":"2018-06-20T11:22:09.075Z","path":"wiki/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/ssr/-源码/","text":"客户端客户端入口-local.py 服务端服务端入口- log分析 1234$ sudo python shadowsocks/server.py -p 443 -k password -m rc4-md52018-02-03 13:29:32 INFO loading libcrypto from libcrypto.so.1.0.02018-02-03 13:29:32 INFO server start with protocol[origin] password [password] method [rc4-md5] obfs [plain] obfs_param []... obfs：混淆，针对中国防火墙 与ss区别部分的源代码","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络工作方式-非协议-可以采用不同的通信协议","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/"},{"name":"proxy","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/"},{"name":"ssr","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/ssr","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/ssr/"}]},{"title":"","date":"2018-06-20T11:22:09.073Z","path":"wiki/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/ss/-原理-源码/","text":"Overview 官方代码 https://github.com/shadowsocksr-backup/ 由于官方代码是fork版本，不支持github search，因此建议采用以下仓库shadowsocks ## ss翻墙有一个必要的前提就是客户端本身必须支持socks5协议（比如浏览器一般都支持socks5配置），这样才能将和客户端本地的shadowsocks socks5代理进程互换数据，不过这也造成了很多软件是没法通过ss实现翻墙的 调试debug客户端客户端入口-local.py ss-local 总体工作流程如下： 监听来自本机浏览器的代理请求； 转发前加密数据； 转发socket数据到墙外代理服务端； 把服务端返回的数据转发给用户的浏览器。 服务端服务端入口- Shadowsocks 源码分析——协议与结构 https://loggerhead.me/posts/shadowsocks-yuan-ma-fen-xi-xie-yi-yu-jie-gou.html Shadowsocks 源码分析——UDP 代理 https://loggerhead.me/posts/shadowsocks-yuan-ma-fen-xi-udp-dai-li.html 客户端与服务端共用的方法socks5作用？ 中继器给shadowsocks添加中继功能 https://github.com/shadowsocks/shadowsocks/issues/695 利用Socket 实现中继(中转/端口转发)加速。 Shadowsocks利用 iptables 实现中继(中转/端口转发)加速 TCPRelay 中继器 UDPRelay 中继器 加密方法 - 待看 你也能写个 Shadowsocks, 用Golang实现轻量级网络混淆代理","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络工作方式-非协议-可以采用不同的通信协议","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/"},{"name":"proxy","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/"},{"name":"ss","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/ss","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/ss/"}]},{"title":"","date":"2018-06-20T11:22:09.072Z","path":"wiki/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/-匿名、透明、HTTP、SSL、SOCKS代理的区别/","text":"关于代理设置–SwitchyOmega为什么HTTP和HTTPS都需要验证(Authentication)，而SOCKS4和SOCKS5不需要验证？ Bypass List（默认）123127.0.0.1[::1]localhost 如何分析 路由分析 抓包分析，好像用不着这么底层 其他socks5是协议，不是加密算法采用socks协议的代理服务器就是SOCKS服务器，是一种通用的代理服务器。 HTTPS代理是不是只能访问https的页面？还是代理服务器要求必须要https连接？ SSL是一种国际标准的加密及身份认证通信协议，可作为访问加密网站的代理。加密网站是指以https://开始的网站。ssl的标准端口为443。 socks4/socks5只是简单地将一端的系统连接到另外一端。socks 4只支持TCP协议而socks 5支持TCP/UDP协议， 参考https://blog.mimvp.com/article/7443.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络工作方式-非协议-可以采用不同的通信协议","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/"},{"name":"proxy","slug":"CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy","permalink":"http://yoursite.com/categories/CS/network/网络工作方式-非协议-可以采用不同的通信协议/proxy/"}]},{"title":"","date":"2018-06-20T11:22:09.071Z","path":"wiki/CS/network/网络诊断/-wifi有限的访问权限/","text":"wifi有限的访问权限原因一般情况都是说明你只能连接到网关(路由器)，但是不能接入互联网，所以叫做“有限访问”。 不会跳转怎么办？我采用的方法是手动在浏览器输入要跳转到的url 很多时候往往是等录过后一段时间就变成“有限的访问权限”，而且是断断续续的，怎么解决？关闭windows网络连接状态指示器的活动测试，点击开始按钮，在运行命令框中输入“gpedit.msc”后按回车，依次打开 计算机配置-》管理模块-》系统-》internet通信设置-》internet通信设置，双击“关闭windows网络连接状态指示器的活动测试”，选择“已禁用”，点击确定按钮退出。 然后再断开连接在重连就好了 关闭windows网络连接状态指示器的活动测试此策略设置会关闭由 Windows 网络连接状态指示器(NCSI)执行的活动测试，而该测试可以确定计算机是连接到 Internet 还是连接到受较多限制的网络。NCSI 作为确定连接级别的一部分，会执行以下两种活动测试之一: 从专用 Web 服务器下载页面，或对专用地址执行 DNS 请求。如果启用此策略设置，则 NCSI 将不运行这两种活动测试的任何一种。 这可能会降低 NCSI 以及使用 NCSI 的其他组件确定 Internet 访问的能力。 如果禁用或未配置此策略设置，NCSI 将运行这两种活动测试之一。 禁用DHCP，使用静态IP重启路由器##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络诊断","slug":"CS/network/网络诊断","permalink":"http://yoursite.com/categories/CS/network/网络诊断/"}]},{"title":"","date":"2018-06-20T11:22:09.071Z","path":"wiki/CS/network/网络诊断/-常用诊断工具/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络诊断","slug":"CS/network/网络诊断","permalink":"http://yoursite.com/categories/CS/network/网络诊断/"}]},{"title":"","date":"2018-06-20T11:22:09.070Z","path":"wiki/CS/network/网络诊断/-网络慢/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络诊断","slug":"CS/network/网络诊断","permalink":"http://yoursite.com/categories/CS/network/网络诊断/"}]},{"title":"","date":"2018-06-20T11:22:09.069Z","path":"wiki/CS/network/网络协议-OSI七层模型/5. 第三层 网络层/-IP网际协议/","text":"不可靠（unreliable）的意思是它不能保证IP数据报能成功地到达目的地。IP仅提供最好的传输服务。如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送 ICMP消息报给信源端。任何要求的可靠性必须由上层来提供（如TCP）。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"5. 第三层 网络层","slug":"CS/network/网络协议-OSI七层模型/5-第三层-网络层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/5-第三层-网络层/"}]},{"title":"","date":"2018-06-20T11:22:09.069Z","path":"wiki/CS/network/网络协议-OSI七层模型/5. 第三层 网络层/-三层交换机/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"5. 第三层 网络层","slug":"CS/network/网络协议-OSI七层模型/5-第三层-网络层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/5-第三层-网络层/"}]},{"title":"","date":"2018-06-20T11:22:09.067Z","path":"wiki/CS/network/网络协议-OSI七层模型/4. 第四层 传输层/-tcp/","text":"TCP的状态变迁图摘自《TCP-IP详解》 摘自《Unix网络编程》 2.5节 The Transport Layer: TCP, UDP, and SCTP ssTCP在不可靠的IP层上提供了一个可靠的运输层。为了提供这种可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"4. 第四层 传输层","slug":"CS/network/网络协议-OSI七层模型/4-第四层-传输层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/4-第四层-传输层/"}]},{"title":"","date":"2018-06-20T11:22:09.067Z","path":"wiki/CS/network/网络协议-OSI七层模型/4. 第四层 传输层/-tcp源码/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"4. 第四层 传输层","slug":"CS/network/网络协议-OSI七层模型/4-第四层-传输层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/4-第四层-传输层/"}]},{"title":"","date":"2018-06-20T11:22:09.066Z","path":"wiki/CS/network/网络协议-OSI七层模型/6. 第二层 链路层/-ARP/","text":"ARP属于链路层还是网络层，https://www.zhihu.com/question/27668104 连MAC都不知道的算第1层，例如已经死绝了的hub只知道MAC不知道IP的算第2层，例如普通交换机只知道IP不知道port（也就不管TCP还是UDP）的算第3层，例如普通路由器知道IP还知道port的算第4层，例如 NAT关心payload的算第7层，例如 http proxy 作者：陈硕 如果要在TCP/IP协议栈中选择一个”最不安全的协议”，那么我会毫不犹豫把票投给ARP协议。我们经常听到的这些术语，包括”网络扫描”、”内网渗透”、”中间人拦截”、”局域网流控”、”流量欺骗”，基本都跟ARP脱不了干系。大量的安全工具，例如大名鼎鼎的Cain、功能完备的Ettercap、操作傻瓜式的P2P终结者，底层都要基于ARP实现。 当一台主机把以太网数据帧发送到位于同一局域网上的另一台主机时，是根据 48 bit的以太网地址来确定目的接口的。设备驱动程序从不检查IP数据报中的目的IP地址。地址解析为这两种不同的地址形式提供映射： 32 bit的IP ARP是解决统一局域网上的主机路由器的IP地址和硬件地址的映射问题。每一个主机都设有一个ARP高速缓存，里面有本局网上的各主机和路由器的IP地址到硬件地址的映射表。当主机A要向本局域网上的某个主机B的IP地址发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址，如果有，就在ARP高速缓存器中查找出其对应的硬件地址，再把这个硬件地址写入mac帧中，然后通过局域网把mac帧发往此硬件地址，否则主机A就自动运行ARP，然后按以下步骤找出主机B的硬件地址：（1）ARP进程在本局网上广播发送一个ARP请求分组。（2）在本局域网上的所有主机上运行的ARP进程都收到此ARP请求分组。（3）主机B的IP地址与ARP请求分组中要查询的IP地址一致就收下这个ARP请求分组，并向主机A发送ARP响应分组，并在这个ARP响应分组中写如自己的硬件地址。（4）主机A收到主机B的ARP响应分组后，就在其ARP高速缓存中写入主机B的IP地址到硬件地址的映射。 123456# 我的GPU虚机，为什么只缓存了两条记录？$ arp -vAddress HWtype HWaddress Flags Mask Iface192.168.4.2 ether fa:16:3e:45:99:f4 C eth0192.168.4.1 ether fa:16:3e:e1:79:74 C eth0Entries: 2 Skipped: 0 Found: 2 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# -v参数显示环回接口C:\\Users\\ADMIN&gt;arp -a -v接口: 127.0.0.1 --- 0x1 # 环回接口，虚拟网卡。并不表示“本机” Internet 地址 物理地址 类型 224.0.0.22 静态 # 224.0.0.251 静态 239.255.255.250 静态接口: 9.186.102.45 --- 0xc # 以太网适配器。连接特定的DNS后缀: crl.ibm.com Internet 地址 物理地址 类型 9.186.102.1 00-00-0c-07-ac-52 动态 # 网关。动态说明可以改变。手工绑定之后，就不会受ARP攻击的影响了 9.186.102.3 e8-ba-70-42-96-c0 动态 # 后面这些是干嘛的， 9.186.102.4 e8-ba-70-42-89-c0 动态 9.186.102.100 d4-81-d7-8b-4d-31 动态 9.186.102.108 44-37-e6-c3-a4-b9 动态 # 我曾经远程桌面连接过的服务器 9.186.102.154 00-21-86-f1-47-ae 动态 9.186.102.176 3c-97-0e-b6-5c-56 动态 9.186.102.255 ff-ff-ff-ff-ff-ff 静态 # ff:ff:ff:ff:ff:ff是广播地址。 224.0.0.22 01-00-5e-00-00-16 静态 # 01:00:5e:xx:xx:xx是IPv4多播地址 224.0.0.251 01-00-5e-00-00-fb 静态 # 不同多播地址，什么含义？是代表我的主机曾经连接过这些主机，是吧 224.0.0.252 01-00-5e-00-00-fc 静态 239.255.255.250 01-00-5e-7f-ff-fa 静态 255.255.255.255 ff-ff-ff-ff-ff-ff 静态 # 为什么两个广播地址。接口: 9.186.59.118 --- 0xd Internet 地址 物理地址 类型 9.186.58.1 00-00-00-00-00-00 无效 # 网关 9.186.59.255 ff-ff-ff-ff-ff-ff 静态 224.0.0.22 01-00-5e-00-00-16 静态 224.0.0.251 01-00-5e-00-00-fb 静态 224.0.0.252 01-00-5e-00-00-fc 静态 239.255.255.250 01-00-5e-7f-ff-fa 静态 255.255.255.255 ff-ff-ff-ff-ff-ff 静态接口: 0.0.0.0 --- 0xffffffff # 表示“本网络中的本机” Internet 地址 物理地址 类型 224.0.0.22 01-00-5e-00-00-16 静态 224.0.0.251 01-00-5e-00-00-fb 静态 255.255.255.255 ff-ff-ff-ff-ff-ff 静态接口: 192.168.191.1 --- 0x31 Internet 地址 物理地址 类型 192.168.191.2 d4-90-9c-57-ad-75 静态 192.168.191.255 ff-ff-ff-ff-ff-ff 静态 224.0.0.22 01-00-5e-00-00-16 静态 224.0.0.251 01-00-5e-00-00-fb 静态 224.0.0.252 01-00-5e-00-00-fc 静态 239.255.255.250 01-00-5e-7f-ff-fa 静态 255.255.255.255 ff-ff-ff-ff-ff-ff 静态 采用双向绑定的方法解决并且防止ARP欺骗疑问ARP协议：不知道局域网有多少IP，首先广播。在局域网里每个机子收到广播后，回复mac。拿到信息会有一个ARP表。 ARP表存在哪？每台设备都会维护一份ARP表。 每台机器会维护全部表吗？会维护全表。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"6. 第二层 链路层","slug":"CS/network/网络协议-OSI七层模型/6-第二层-链路层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/6-第二层-链路层/"}]},{"title":"","date":"2018-06-20T11:22:09.065Z","path":"wiki/CS/network/网络协议-OSI七层模型/6. 第二层 链路层/-MAC地址/","text":"有了 IP 地址，为什么还要用 MAC 地址？一. 整体与局部信息传递时候，需要知道的其实是两个地址： 终点地址（Final destination address） 下一跳的地址（Next hop address） IP地址本质上是终点地址，它在跳过路由器（hop）的时候不会改变，而MAC地址则是下一跳的地址，每跳过一次路由器都会改变。 这就是为什么还要用MAC地址的原因之一，它起到了记录下一跳的信息的作用。 注：一般来说IP地址经过路由器是不变的，不过NAT（Network address translation）例外，这也是有些人反对NAT而支持IPV6的原因之一。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"6. 第二层 链路层","slug":"CS/network/网络协议-OSI七层模型/6-第二层-链路层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/6-第二层-链路层/"}]},{"title":"","date":"2018-06-20T11:22:09.064Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/-smtp/","text":"introduction三种实现： python的smtplib javamail.lib 自己写简易socket实现 telnet实现 smtplib实现发送email 利用smtplib发送email，源代码。 见song.common.autoalert.email.send.py: 12345678910111213141516171819202122232425262728293031# 以python源代码为基准import smtplib from email.mime.text import MIMEText from config import *import socketdef send_mail(to_list,subject,content): me=\"hello\"+\"&lt;\"+mail_user+\"@\"+mail_postfix+\"&gt;\" msg = MIMEText(content,_subtype='plain',_charset='gb2312') msg['Subject'] = subject msg['From'] = me msg['To'] = \";\".join(to_list) try: server = smtplib.SMTP() server.connect(smtp_host, smtp_port) # 这里有response吗？加ssl连接吗？ server.ehlo() # 与服务器打招呼，并告知客户端使用的机器名字，可以随便填写 server.starttls() # 登录时需要启动TLS加密 (smtp服务器规定的) server.login(mail_user,mail_pass) # 这里做了什么？建立了tls加密的socket连接，然后发送加密后的数据获取认证吗？ server.sendmail(me, to_list, msg.as_string()) # 这里有response吗，没有response应该就是UDP连接吧 server.close() return True except Exception, e: print str(e) return False if __name__ == '__main__': if send_mail(mailto_list,\"hello\",\"send from python smtplib\"): print \"发送成功\" else: print \"发送失败\" 修改源代码 smtpliba.py 12345678def putcmd(self, cmd, args=\"\"): \"\"\"Send a command to the server.\"\"\" if args == \"\": str = '%s%s' % (cmd, CRLF) else: str = '%s %s%s' % (cmd, args, CRLF) print 'sending:' + str # 在smtpliba.py中添加这一行代码 self.send(str) 运行 123456789101112131415161718192021222324# Authentication methodsAuthentication methods the server supports:authlist: ['LOGIN', 'PLAIN', 'XOAUTH2'] # outlook竟然还支持plain的登录方式？# authmethod = AUTH_PLAINsending: ehlo [192.168.253.1]sending: STARTTLSsending: ehlo [192.168.253.1]sending: AUTH PLAIN AHMyamFja3NvbkBob3RtYWlsLmNvbQBrZGY4KmRmNSFzNF9qsending: mail FROM:&lt;s2jackson@hotmail.com&gt; size=215sending: rcpt TO:&lt;13521649928@139.com&gt;sending: data# 发送成功# authmethod = AUTH_LOGINsending: ehlo [192.168.253.1]sending: STARTTLSsending: ehlo [192.168.253.1]sending: AUTH LOGIN czJqYWNrc29uQGhvdG1haWwuY29tsending: a2RmOCpkZjUhczRfag==sending: mail FROM:&lt;s2jackson@hotmail.com&gt; size=215sending: rcpt TO:&lt;13521649928@139.com&gt;sending: data# 发送成功 javamail实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 以java源代码为基准package song.net.mail.demo;import javax.mail.*;import javax.mail.internet.*;import javax.mail.Authenticator;import javax.mail.Message;import javax.mail.PasswordAuthentication;import java.util.Properties;import song.config.Info;public class SendWithAuth &#123; private static final String SMTP_HOST_NAME = Info.SMTP_HOST; private static final Integer SMTP_PORT = Info.SMTP_PORT; private static final String SMTP_AUTH_USER = Info.SMTP_AUTH_USER; private static final String SMTP_AUTH_PWD = Info.SMTP_AUTH_PWD; private static final String MAIL_TO = Info.MAIL_TO; public static void main(String[] args) throws Exception&#123; new SendWithAuth().test(); &#125; public void test() throws Exception&#123; Properties props = new Properties(); // property列表，见 https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html props.put(\"mail.transport.protocol\", \"smtp\"); props.put(\"mail.smtp.host\", SMTP_HOST_NAME); props.put(\"mail.smtp.port\", SMTP_PORT); // 默认是25端口，但是这个smtp服务器要求是587端口 props.put(\"mail.smtp.auth\", \"true\"); props.put(\"mail.smtp.starttls.enable\", true); // 登录时需要启动TLS加密 (smtp服务器规定的) Authenticator auth = new SMTPAuthenticator(); Session mailSession = Session.getDefaultInstance(props, auth); Transport transport = mailSession.getTransport(); // header是在什么时候加的？比如Subject，from，to, cc等 MimeMessage message = new MimeMessage(mailSession); message.setContent(\"send from java mail\", \"text/plain\"); // 等价于message.setText message.setFrom(new InternetAddress(SMTP_AUTH_USER)); // Set From: header field of the header. message.addRecipient(Message.RecipientType.TO, new InternetAddress(MAIL_TO)); // Set To: header field of the header. message.setSubject(\"hi\"); // Set Subject: header field， 可省略 transport.connect(); transport.sendMessage(message, message.getRecipients(Message.RecipientType.TO)); transport.close(); &#125; private class SMTPAuthenticator extends javax.mail.Authenticator &#123; public PasswordAuthentication getPasswordAuthentication() &#123; String username = SMTP_AUTH_USER; String password = SMTP_AUTH_PWD; return new PasswordAuthentication(username, password); &#125; &#125;&#125; 自己写简易socket实现smtp邮件发送telnet实现smtp邮件发送","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"}]},{"title":"","date":"2018-06-20T11:22:09.064Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/DNS/-DNS用TCP还是UDP/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"DNS","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS/"}]},{"title":"","date":"2018-06-20T11:22:09.064Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/DNS/-DNS解析原理-过程/","text":"## nameserver root zone How Domain Name Servers WorkHow the Domain Name System (DNS) Works 区域文件要理解不同的 DNS 记录，首先必须了解区域文件是什么? 区域文件区域文件是名称服务器存储其所知道的域名的信息的方式。名称服务器知道的每个域名都存储在区域文件中。对于名称服务器来说，大多数请求都不能在它自己服务器中找到区域文件。 如果它被配置成可以递归查询，如解析名称服务器，那它会递归找到结果并返回。否则，它会告诉请求者方下一步到哪里查询。 名称服务器具有的区域文件越多，它能够权威回答的请求越多。 解析过程DNS地址解析器的核心功能能 gethostbyname 主机名-&gt;ip gethostbyaddr ip-主机名 gethostbyname 主机名–&gt;ipDNS服务器在名称解析过程中正确的查询顺序为:本地缓存记录→区域记录→根域名服务器→转发域名服务器 具体步骤如下： 客户机提交域名解析请求，并将该请求发送给本地域名服务器。 当本地的域名服务器收到请求后，就先查询本地缓存。如果有查询的DNS信息记录，则直接返回查询的结果。如果没有该记录，本地域名服务器就把请求发给根域名服务器。 根域名服务器再返回给本地域名服务器一个所查询域的顶级域名服务器的地址。 本地服务器再向返回的域名服务器发送请求。 接收到该查询请求的域名服务器查询其缓存和记录，如果有相关信息则返回本地域名服务器查询结果，否则通知本地域名服务器下级的域名服务器的地址。 本地域名服务器将查询请求发送给下级的域名服务器的地址，直到获取查询结果。 本地域名服务器将返回的结果保存到缓存，并且将结果返回给客户机，完成解析过程。 通常情况下，我们是先设定DNS解析规则，然后ISP(供应商)依据指定的解析规则进行DNS解析。同样，我们通过测试解析结果，也可以反推DNS解析规则。本文以百度首页为例，分析其DNS解析规则。 域名的层级本机只向自己的DNS服务器查询，dig命令有一个@参数，显示向其他DNS服务器查询的结果。 DNS服务器怎么会知道每个域名的IP地址呢？答案是分级查询。 举例来说，www.example.com真正的域名是www.example.com.root，简写为www.example.com.。因为，根域名.root对于所有域名都是一样的，所以平时是省略的。 根域名的下一级，叫做”顶级域名”（top-level domain，缩写为TLD），比如.com、.net；再下一级叫做”次级域名”（second-level domain，缩写为SLD），比如www.example.com里面的.example，这一级域名是用户可以注册的；再下一级是主机名（host），比如www.example.com里面的www，又称为&quot;三级域名&quot;，这是用户在自己的域里面为服务器分配的名称，是用户可以任意分配的。 流程因为DNS系统是分层的，每个DNS只知道自己所管理的域，并不知道其他域。我的电脑DNS服务器设置为8.8.8.8，当我要解析www.zhihu.com的时候，假如8.8.8.8这台DNS服务器并没有缓存关于www.zhihu.com的信息，那么8.8.8.8就要向13台根服务器查询，这13台服务器也不知道www.zhihu.com的IP，但是它知道.com,.net等这些顶级域的DNS的IP地址，于是告诉8.8.8.8向这些顶级域的服务器去查询www.zhihu.com的信息，.com再告诉8.8.8.8要向zhihu.com的DNS服务器查询www这台主机的IP地址，最终才能解析www.zhihu.com。所以在目前来说（.）是整个DNS系统的核心，在DNS系统里面是必须存在的，如果没有（.），DNS的层级结构就被破坏的。 https://www.zhihu.com/question/21499001/answer/18432636 其他ICANN拒绝谷歌将.search变成无点顶级域名 非常好的文章–http://colobu.com/2016/09/29/more-about-dns/ 权威DNS权威DNS是经过上一级授权对域名进行解析的服务器，同时它可以把解析授权转授给其他人，如COM顶级服务器可以授权xxorg.com这个域名的的权威服务器为NS.ABC.COM，同时NS.ABC.COM还可以把授权转授给NS.DDD.COM，这样NS.DDD.COM就成了ABC.COM实际上的权威服务器了。平时我们解析域名的结果都源自权威DNS。比如xxorg.com的权威DNS服务器就是dnspod的F1G1NS1.DNSPOD.NET和F1G1NS2.DNSPOD.NET。 从字面意思也可以看出，权威就是该域名及下级域名的“说了算”的服务器；在权威上可以设置，修改，删除该区域内的解析记录， 而非权威DNS只能是查询。 Local DNSLocal DNS 也是和我们日常上网接触最多的DNS包括你的服务提供商（ISP）分配给你的DNS（一般为两个），或者接下来讲到的公共DNS。又因为填写在你的本地电脑上，所以也称为Local DNS。 公共DNS公共DNS不是： 不是根服务器 不是权威dns托管商，不提供域名注册等服务，比如万网和DNSpod 不是权威dns，不针对个别域名进行解析 公共DNS服务的特点就是服务的域名数量巨大，用户数多，同时要求具有安全性和抗攻击性，低延迟（响应快），无拦截（无广告）以及对解析成功率要求非常的高。 12345678910Google DNS: 8.8.8.8 8.8.4.4OpenDNS: 208.67.222.222 208.67.220.220V2EX DNS: 199.91.73.222 178.79.131.110OpenerDNS: 42.120.21.30 （无添加剂）香港: 205.252.144.228 202.181.224.2澳门：202.175.3.8 202.175.3.3台湾: 168.95.192.1 168.95.1.1114DNS: 114.114.114.114,114.114.115.115阿里DNS: 223.5.5.5,223.6.6.6百度DNS: 180.76.76.76 用114DNS真的会被嵌广告 递归DNS就是local dns。递归DNS可以理解为是一种功能复杂些的resolver，其核心功能一个是缓存、一个是递归查询。收到域名查询请求后其首先看本地缓存是否有记录，如果没有则一级一级的查询根、顶级域、二级域……直到获取到结果然后返回给用户。日常上网中运营商分配的DNSNS如8.8.8.8即这里所说的递归DNS。 递归服务器怎么知道根权威服务器的地址？很简单，在递归服务器上都保存有一份根服务器的地址列表，如上面表格列出的根服务器的地址。 递归服务器每次查询域名都要向根那里找权威服务器吗？不是的，一旦成功一次，递归服务器就会把权威服务器列表缓存下来（如COM顶级服务器列表可以缓存48小时）。 根域名服务器一般说的13个根DNS服务器，指的是逻辑上有13个，而不是物理上13个服务器。 所有 root DNS的坐标：http://root-servers.org/ 。截至2014年10月，全球有504台根服务器，被编号为A到M共13个标号。 中国大陆在北京有三台编号为L的镜像，编号为F、I、J的镜像各一台，共6台；香港有编号为D、J的镜像各2台，编号为A、F、I、L的镜像各一台，共8台；台湾则有编号为F、I、J各一台，共3台。(镜像技术) 值的注意的是，在中国的只是根服务器的镜像，而不是根服务器的管理者，没有控制权。而且一经发现镜像服务器频繁出错，管理者有权将这个镜像踢出路由表。2010年就发生过此事。 为什么不能在中国设立第十四个根域名服务器https://commondatastorage.googleapis.com/letscorp_archive/archives/73147 美国放松根域名服务器管控：不会彻底放手，但中国应抓住契机 为什么 DNS 根服务器只有 13 个 IP 为什么中国不建立根服务器？ 一个IP如何实现全球部署？ 任播（Anycast）技术这是网络层的技术，详见网络层 通常一个IP都是对应一台通讯主机。谷歌DNS服务8.8.8.8也是一台主机吗？根域名服务器只有13台吗？如何实现一个IP却全球部署? 虽然IP地址相同，但是服务器确可能有多台。 。大部分借由任播（Anycast）技术，编号相同的根服务器使用同一个IP，504台根服务器总共只使用13个IP，因此可以抵抗针对其所进行的分布式拒绝服务攻击（DDoS）。在IP网络上通过一个Anycast地址标识一组DNS服务群，访问该地址的报文可以被IP网络路由到这一组DNS群的任何一台主机上，因此不同区域的用户会被路由到最近的服务器。 任播Anycasting最初是在RFC1546中提出并定义的，它的最初语义是，在IP网络上通过一个Anycast地址标识一组提供特定服务的主机，同时服务访问方并不关心提供服务的具体是哪一台主机(比如DNS或者镜像服务)，访问该地址的报文可以被IP网络路由到这一组目标中的任何一台主机上，它提供的是一种无状态的、尽力而为的服务。 DNS劫持也是类似的原理吗？假装IP是8.8.8.8 如何查询8.8.8.8背后有哪些ip提供服务？https://www.v2ex.com/t/259939 原理 DNS劫持 DNS污染指的是用户访问一个地址，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。 为了减免网络上的交通，一般的域名都会把外间的域名服务器数据暂存起来，待下次有其他机器要求解析域名时，可以立即提供服务。一旦有关网域的局域域名服务器的缓存受到污染，就会把网域内的电脑导引往错误的服务器或服务器的网址。 某个国家出现过多次的DNS污染， 参看知乎。 8.8.8.8告诉我youtube网站的IP是1.2.3.4。我是该怀疑谁？说明你被劫持了 如果traceroute 8.8.8.8时，从国内ip直接跳到8.8.8.8，那极可能是运营商自己搞的假服务器，中国移动的宽带，基本上将网上公开的公众dns都搞了个假的，目的就是完全劫持网内的dns查询。 我假装我是8.8.8.8不行吗？你假装真不行，运营商假装才行。有的地区的运营商是会劫持8.8.8.8到它的服务器的 如何检查DNS是否被劫持DNS劫持是什么原理DNS缓存查询DNS的时候可能会有多个地方存在缓存： 浏览器 DNS缓存Java DNS缓存OS DNS缓存Local DNS缓存","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"DNS","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS/"}]},{"title":"","date":"2018-06-20T11:22:09.062Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/-IMAP/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"}]},{"title":"通过http请求 看整个协议栈","date":"2018-06-20T11:22:09.061Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/HTTP/-http请求看整个协议栈/","text":"涉及HTTP DNS TCP IP http -&gt; DNS解析 (发起DNS)http &lt;- DNS解析 用wiresharp抓包既然是要看全过程，就不要在filter中填任何东西，我们要抓所有的数据包。 ## ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"HTTP","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/HTTP","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/HTTP/"}]},{"title":"","date":"2018-06-20T11:22:09.060Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/-IRC/","text":"IRC（Internet Relay Chat的缩写，“因特网中继聊天”）是一种通过网络的即时聊天方式。其主要用于群体聊天，但同样也可以用于个人对个人的聊天。芬兰人雅尔可·欧伊卡利宁（Jarkko Oikarinen）于1988年8月创造了IRC来替换一个叫做MUT的程序。 IRC是一种公开的协议，采用TCP和SSL协议。一个IRC服务器可以连接其他的IRC服务器以扩展为一个IRC网络。IRC用户通过客户端软件和服务器相连。大多数的IRC服务器不需要客户注册登录，虽然在连接前必须设定好昵称（nickname），但客户端一般都会自动分给一个。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"}]},{"title":"","date":"2018-06-20T11:22:09.058Z","path":"wiki/CS/network/tools/BT-p2p/-BT种子嗅探器/","text":"https://github.com/shiyanhui/dht/wiki/%E3%80%90%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%95%99%E4%BD%A0%E5%86%99BT%E7%A7%8D%E5%AD%90%E5%97%85%E6%8E%A2%E5%99%A8%E3%80%91DHT%E7%AF%87","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"BT-p2p","slug":"CS/network/tools/BT-p2p","permalink":"http://yoursite.com/categories/CS/network/tools/BT-p2p/"}]},{"title":"","date":"2018-06-20T11:22:09.058Z","path":"wiki/CS/network/tools/BT-p2p/-网络拓扑/","text":"中心化拓扑咱们每天上网访问的网站中，其实绝大多数都是“服务器-客户机”架构的，这是一种中心化的架构，基本长成这个样子（图片来自 wikipedia 的 p2p 的页面）： 可以看出，这里有个老大地位很不一样，大家都去访问他，跟他要内容。 缺陷去中心，反脆弱。 在中心化的这种架构中，中央戊己土坐着的那个老大看上去很牛，其实就是他最脆弱。比如，一旦他瘫痪了，整个系统就瘫痪了，一旦他被一个强权势力关停了，那么整个这个系统也就完蛋了。 P2P 对等拓扑/去中心/分布式在 P2P 网络上，随便有几个节点突然没有了，整个系统也不会受到影响。举个例子，比特币系统就是 P2P 网络在金融方面的一个应用，系统的核心数据库，也就是比特币的公共账本，的安全是整个系统继续运行的关键。所以在设计上，必须认为每一个网络节点都是不完全可信的，每个节点都可能遭受攻击或者被行政命令关停，所以去中心化的 P2P 网络就成为了比特币系统设计上的必然选择。 非结构化网络结构化网络在结构化的对等网络中，叠加层被组织成一个特定的拓扑结构，并且该协议可以确保任何节点都可以有效地在网络中搜索文件/资源​​，即使资源极其稀少。 分布式散列表 DHT最常见的结构化P2P网络类型实现了分布式散列表（DHT），其中使用一致散列的变体来将每个文件的所有权分配给特定对等体。这使同伴能够使用哈希表在网络上搜索资源：即（密钥，值）对存储在DHT中，并且任何参与节点可以有效地检索与给定密钥相关联的值。 一个文件被分成很多块，下载时同时进行块的下载。 发展BitTorrent 使用”分布式哈希表”(DHT)来为无 tracker 的种子(torrents)存储 peer 之间的联系信息。这样每个 peer 都成了 tracker。这个协议基于 Kademila 网络并且在 UDP 上实现。在使用DHT分发Peer之前，Tracker是找到Peer的唯一方法。 2005年5月2日，Azureus 2.3.0.0（现在称为Vuze）发布，通过称为“分布式数据库”的系统引入了对“无tracker”种子的支持。该系统是一个分布式散列表DHT实现，它允许客户端使用没有BitTorrent tracker的种子。接下来的一个月，BitTorrent公司发布了Mainline BitTorrent客户端的4.2.0版本，该客户端支持与Azureus不兼容的另一种DHT实现（俗称“ Mainline DHT ”，在其网站上的草稿中概述）。最近的测量显示，Mainline DHT的用户从1000万到2500万，每日活跃至少1000万。 主线DHT可以说是世界上最大的DHT。 动画展示BT下载过程地址 参考 P2P网络与BitTorrent技术简介 分而不散的 P2P 网络","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"BT-p2p","slug":"CS/network/tools/BT-p2p","permalink":"http://yoursite.com/categories/CS/network/tools/BT-p2p/"}]},{"title":"","date":"2018-06-20T11:22:09.057Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--网站/-vpn/","text":"需要分别抓虚拟网卡 和 主网卡吧？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--网站","slug":"CS/network/tools/wireshark/抓包实例分析-网站","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-网站/"}]},{"title":"抓包 斗鱼","date":"2018-06-20T11:22:09.057Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--网站/-douyu/","text":"浏览器信息浏览器访问的URL 12http://www.douyu.com/ # 浏览器访问斗鱼的主页，下面是对视频的请求http://175.25.168.26/hdl3.douyucdn.cn/live/868191rzb9Z8BR7r.flv?wsAuth=927a7c21a4c2303678529e208271ea1b&amp;token=web-566086-868191-d17a433e9e430492d1b7be4cf13dc183&amp;logo=0&amp;expire=0&amp;wsiphost=ipdb socket会keep-alive，复用同一个socket，url保持不变。 Request Header 123456789GET /hdl3.douyucdn.cn/live/852315r71MZwNkYi.flv?wsAuth=98cdd891123dc85668196c67d741a853&amp;token=web-566086-852315-c12ea88bc6b9657e3e6bf1e3f7794fa9&amp;logo=0&amp;expire=0&amp;wsiphost=local HTTP/1.1Host: 114.64.222.49 # 首页会因为直播间不同，而Host和URL不同。Connection: keep-aliveX-Requested-With: ShockwaveFlash/22.0.0.192User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36Accept: */*Referer: http://www.douyu.com/Accept-Encoding: gzip, deflate, sdchAccept-Language: zh-CN,zh;q=0.8,en;q=0.6,en-US;q=0.4 Response Header 1234567HTTP/1.1 200 OKExpires: Sat, 30 Jul 2016 09:28:28 GMTCache-Control: no-cacheContent-Type: video/x-flvPragma: no-cacheVia: 1.1 zdx49:7755 (Cdn Cache Server V2.0)Connection: close wireshark抓包filter: ip.dst==114.64.222.49 or ip.src==114.64.222.49 filter之后显示的连接数据包如下： 1234567891011121314151617181920No Time Source Destination Protocol length Info# 三次握手1672 15.896971 9.186.58.171 114.64.222.49 TCP 66 54185 → 80 [SYN] Seq=0 Win=8192 Len=0 MSS=1460 WS=4 SACK_PERM=11674 15.906057 114.64.222.49 9.186.58.171 TCP 66 80 → 54185 [SYN, ACK] Seq=0 Ack=1 Win=1460 Len=0 MSS=1380 SACK_PERM=1 WS=1281675 15.906271 9.186.58.171 114.64.222.49 TCP 54 54185 → 80 [ACK] Seq=1 Ack=1 Win=16560 Len=0# 握手成功，第四个包才是http的1676 15.907013 9.186.58.171 114.64.222.49 HTTP 592 GET /hdl3.douyucdn.cn/live/852315r71MZwNkYi.flv?wsAuth=98cdd891123dc85668196c67d741a853&amp;token=web-566086-852315-c12ea88bc6b9657e3e6bf1e3f7794fa9&amp;logo=0&amp;expire=0&amp;wsiphost=local HTTP/1.1# server向client发送一个ack码，约定以后客户端必须通过seq=539来确认收到的总字节数目1677 15.916612 114.64.222.49 9.186.58.171 TCP 54 80 → 54185 [ACK] Seq=1 Ack=539 Win=15744 Len=0# 传输视频流数据1679 16.376026 114.64.222.49 9.186.58.171 TCP 247 [TCP segment of a reassembled PDU]1680 16.378970 114.64.222.49 9.186.58.171 TCP 1434 [TCP segment of a reassembled PDU]1681 16.379198 114.64.222.49 9.186.58.171 TCP 1434 [TCP segment of a reassembled PDU]1682 16.379304 114.64.222.49 9.186.58.171 TCP 1434 [TCP segment of a reassembled PDU]1683 16.379412 114.64.222.49 9.186.58.171 TCP 1434 [TCP Previous segment not captured] [TCP segment of a reassembled PDU]1684 16.379451 114.64.222.49 9.186.58.171 TCP 1434 [TCP segment of a reassembled PDU]1685 16.379476 114.64.222.49 9.186.58.171 TCP 1434 [TCP Out-Of-Order] [TCP segment of a reassembled PDU]1686 16.379921 9.186.58.171 114.64.222.49 TCP 54 54185 → 80 [ACK] Seq=539 Ack=1574 Win=16560 Len=0 #1687 16.379937 9.186.58.171 114.64.222.49 TCP 54 54185 → 80 [ACK] Seq=539 Ack=4334 Win=16560 Len=0 连接流程 123456三次握手: 第一次握手：客户端向服务器发送连接请求包，标志位SYN（同步序号）置为1，序号为X=0 第二次握手：服务器收到客户端发过来报文，由SYN=1知道客户端要求建立联机。向客户端发送一个SYN和ACK都置为1的TCP报文，设置初始序号Y=0，将确认序号(Acknowledgement Number)设置为客户的序列号加1，即X+1 = 0+1=1, 第三次握手：客户端收到服务器发来的包后检查确认序号(Acknowledgement Number)是否正确，即第一次发送的序号加1（X+1=1）。以及标志位ACK是否为1。若正确，服务器再次发送确认包，ACK标志位为1，SYN标志位为0。确认序号(Acknowledgement Number)=Y+1=0+1=1，发送序号为X+1=1。客户端收到后确认序号值与ACK=1则连接建立成功，可以传送数据了。HTTP请求:断开连接: (客户端要求断开连接则需要四次挥手) HTTP包(No 1676)1234567物理层: Frame: 1676: 592 bytes on wire (4736 bits), 592 bytes captured (4736 bits) on interface 0 // 物理层的数据帧概况链路层: Ethernet II, Src: IntelCor_09:85:f8 (e8:b1:fc:09:85:f8), Dst: All-HSRP-routers_65 (00:00:0c:07:ac:65) // 数据链路层以太网帧头部信息，e8:b1:fc:09:85:f8这是我的mac地址网络层: Internet Protocol Version 4, Src: 9.186.58.171, Dst: 114.64.222.49 // 9.186.58.171是本机ipconfig显示的ip，也就是局域网ip (不是网关ip，也不是外网ip)传输层: Transmission Control Protocol, Src Port: 54185 (54185), Dst Port: 80 (80), Seq: 1, Ack: 1, Len: 538应用层: 跟浏览器中的request header相同注意: Frame = sum[header] + content(null)，即一堆header叠加在一起，封装在物理层数据帧中，没有内容 TCP视频流数据包(No 1680)123456物理层: Frame 1680: 1434 bytes on wire (11472 bits), 1434 bytes captured (11472 bits) on interface 0链路层: Ethernet II, Src: CiscoInc_42:96:c0 (e8:ba:70:42:96:c0), Dst: IntelCor_09:85:f8 (e8:b1:fc:09:85:f8)网络层: Internet Protocol Version 4, Src: 114.64.222.49, Dst: 9.186.58.171传输层: Transmission Control Protocol, Src Port: 80 (80), Dst Port: 54185 (54185), Seq: 194, Ack: 539, Len: 1380注意: Frame = sum[header] + content(很多内容) 其他细节TCP out of order原因：多半是网络拥塞，导致顺序包抵达时间不同，延时太长，或者包丢失，需要重新组合数据单元，因为他们可能是通过不同的路径到达的。TCP Out-Of-Order ，有些 Packet 可能 Lost，所以重新传送造成。另一个可能是因为 Client 到 Server 间有两条网路路径，像是 Load Balance 之类的架构。因此若两个封包走不同路径，晚送的封包却比早送的到达，就会发生 Out-Of-Order。 解决方法: reassembling packets into order forcing retries of out-of-order packets. 参考 https://en.wikipedia.org/wiki/Out-of-order_delivery comments 能够看出是一直复用的一个连接: 5418980 端口之间建立的socket连接 疑问 为什么采用TCP TCP阻塞问题怎样解决的 tcp丢包是否还会续传？续传仍然丢包呢 socket编程中，send之后的status只怎么来的？应该是两个数据包吧？可以试试","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--网站","slug":"CS/network/tools/wireshark/抓包实例分析-网站","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-网站/"}]},{"title":"","date":"2018-06-20T11:22:09.056Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--网站/-mail/","text":"notes发送邮件12345678filter: ip.dst==114.64.222.49 or ip.src==114.64.222.49(not arp) and (not icmp) #tcp.port eq 25 or tcp.port eq 587 or icmp # Show only SMTP (port 25) and ICMP traffic:IBM nots SMTP servertcp.port eq 25 or tcp.port eq 587 or tcp.port eq 26 or tcp.port eq 465 or icmp hotmail发邮件wireshark 抓包","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--网站","slug":"CS/network/tools/wireshark/抓包实例分析-网站","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-网站/"}]},{"title":"","date":"2018-06-20T11:22:09.056Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--网站/-http.bluescan/","text":"introduction python socket编程 java socket编程 python socket编程测试1import socket def sendHttpViaSocket(): tcpsoc = socket.socket(socket.AF_INET, socket.SOCK_STREAM) print tcpsoc.connect(('9.186.102.103', 8080)) # 三次握手 (三个包) print tcpsoc.send('GET /bluescan/ HTTP/1.1\\r\\nHOST:anystring\\r\\n\\r\\n') # 进行get请求，并获取数据 response = tcpsoc.recv(1000000) # 不发送数据包 print response if __name__ == '__main__': sendHttpViaSocket() console输出:None 43 HTTP/1.1 200 OK Server: Apache-Coyote/1.1 Accept-Ranges: bytes ETag: W/&quot;2946-1467880723568&quot; Last-Modified: Thu, 07 Jul 2016 08:38:43 GMT Content-Type: text/html;charset=UTF-8 Content-Length: 2946 Date: Sat, 30 Jul 2016 12:14:57 GMT &lt;!DOCTYPE html&gt; &lt;html&gt; ... &lt;/html&gt; wireshark抓包:filter: ip.dst==9.186.102.103 or ip.src==9.186.102.103 No Time Source Destination Pro Len Info // tcpsoc.connect((&apos;9.186.102.103&apos;, 8080)) # 往返发送三个数据包，进行三次握手 66 3.063170 9.186.58.171 9.186.102.103 TCP 66 58415 → 8080 [SYN] Seq=0 Win=8192 Len=0 MSS=1460 WS=4 SACK_PERM=1 67 3.064642 9.186.102.103 9.186.58.171 TCP 66 8080 → 58415 [SYN, ACK] Seq=0 Ack=1 Win=8192 Len=0 MSS=1460 WS=256 SACK_PERM=1 68 3.064861 9.186.58.171 9.186.102.103 TCP 54 58415 → 8080 [ACK] Seq=1 Ack=1 Win=17520 Len=0 // tcpsoc.send(&apos;GET /bluescan/ HTTP/1.1\\r\\nHOST:anystring\\r\\n\\r\\n&apos;) // 一个html文件比较大，会分成几个数据包发送。 69 3.065188 9.186.58.171 9.186.102.103 HTTP 94 GET /bluescan/ HTTP/1.1 70 3.070695 9.186.102.103 9.186.58.171 TCP 1514 [TCP segment of a reassembled PDU] 71 3.071086 9.186.102.103 9.186.58.171 TCP 1514 [TCP segment of a reassembled PDU] 72 3.071471 9.186.58.171 9.186.102.103 TCP 54 58415 → 8080 [ACK] Seq=41 Ack=2921 Win=17520 Len=0 73 3.072820 9.186.102.103 9.186.58.171 HTTP 322 HTTP/1.1 200 OK (text/html) // 这里会对之前的数据包做一个拼接(只拼接No) // 程序结束，socket由客户端自动结束 (四次挥手) 74 3.074085 9.186.58.171 9.186.102.103 TCP 54 58415 → 8080 [FIN, ACK] Seq=41 Ack=3189 Win=17252 Len=0 75 3.076070 9.186.102.103 9.186.58.171 TCP 54 8080 → 58415 [ACK] Seq=3189 Ack=42 Win=65536 Len=0 76 3.076118 9.186.102.103 9.186.58.171 TCP 54 8080 → 58415 [FIN, ACK] Seq=3189 Ack=42 Win=65536 Len=0 77 3.076302 9.186.58.171 9.186.102.103 TCP 54 58415 → 8080 [ACK] Seq=42 Ack=3190 Win=17252 Len=0 其中HTTP包(No 70) 物理层: Frame 49: 1514 bytes on wire (12112 bits), 1514 bytes captured (12112 bits) on interface 0 链路层: Ethernet II, Src: CiscoInc_42:89:c0 (e8:ba:70:42:89:c0), Dst: IntelCor_09:85:f8 (e8:b1:fc:09:85:f8) 网络层: Internet Protocol Version 4, Src: 9.186.102.103, Dst: 9.186.58.203 传输层: Transmission Control Protocol, Src Port: 8080 (8080), Dst Port: 58415 (58415), Seq: 1, Ack: 44, Len: 1460 ## 测试2，分小包发送import socket # 一口气能说完的话，非要分开很多包发送，很贱哎 def sendHttpViaSocket(): tcpsoc = socket.socket(socket.AF_INET, socket.SOCK_STREAM) print tcpsoc.connect((&apos;9.186.102.103&apos;, 8080)) # 三次握手 (三个包) tcpsoc.send(&apos;GET /bluescan/ HTTP/1.1&apos;) # 发送一个数据包，server返回一个ack (两个包) tcpsoc.send(&apos;\\r\\n&apos;) # 发送一个数据包，server返回一个ack (两个包) tcpsoc.send(&apos;HOST:anystring\\r\\n&apos;) # 发送一个数据包，server返回一个ack (两个包) tcpsoc.send(&apos;\\r\\n&apos;) # 到这才开始发送http请求数据包，并收到数据 response = tcpsoc.recv(1000000) # do nothing print response if __name__ == &apos;__main__&apos;: sendHttpViaSocket() java socket编程client端代码 package song.net.socket; /** * download from * http://www.javatpoint.com/socket-programming */ import java.io.*; import java.net.*; public class MyClientOneside { public static void main(String[] args) { try { Socket s = new Socket(&quot;9.186.102.103&quot;, 6666); // 进行三次握手 (三个数据包) DataOutputStream dout = new DataOutputStream(s.getOutputStream()); // 没包 dout.writeUTF(&quot;Hello Server&quot;); // 发送一个数据包，返回一个确认包 (两个包) dout.flush(); dout.close(); s.close(); } catch (Exception e) { System.out.println(e); } } } server端代码: package song.net.socket; /** * download from * http://www.javatpoint.com/socket-programming */ import java.io.*; import java.net.*; public class MyServerOneside { public static void main(String[] args) { try { ServerSocket ss = new ServerSocket(6666); Socket s = ss.accept();// establishes connection，等待连接，client端 new Socket(&quot;localhost&quot;, 6666)后，这一行执行好 DataInputStream dis = new DataInputStream(s.getInputStream()); // server端接收socket的信息 String str = (String) dis.readUTF(); //这里会卡住，等待client端 dout.writeUTF(&quot;Hello Server&quot;); System.out.println(&quot;message= &quot; + str); ss.close(); } catch (Exception e) { System.out.println(e); } } } 浏览器访问‘’’ Name Status Type Initiator Size login.html 304 document Other 123 B 349 ms // server返回304，表示浏览器可以直接在本地缓存中读取资源，省去传输消耗 jquery-1.7.2.min.js 304 script login.html:43 124 B util.js 304 script login.html:44 124 B 01_BlueSCAN_sign-in.gif 304 gif login.html:43 125 B BlueSCAN_input_username.png 304 png login.html:43 123 B BlueSCAN_input_password.png 304 png login.html:43 123 B nudge-icon-arrow-up.png 200 png Preview.js:28 (from cache) nudge-icon-arrow-down.png 200 png Preview.js:28 (from cache) nudge-icon-arrow-lr.png 200 png Preview.js:28 (from cache) nudge-icon-return.png 200 png Preview.js:28 wireshark抓包 comments java socket编程怎么这么丑啊！！！ 疑问","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--网站","slug":"CS/network/tools/wireshark/抓包实例分析-网站","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-网站/"}]},{"title":"","date":"2018-06-20T11:22:09.056Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--网站/-proxy/","text":"以https://www.weibo.com/为例 无代理时12345Request URL: https://www.weibo.com/Request Method: GETStatus Code: 200 OKRemote Address: 180.149.134.141:443Referrer Policy: no-referrer-when-downgrade 有代理时公司代理，不需要客户端。浏览器代理配置：123Protocol: HTTPserver: webproxy.abc.def.comport: 8080 shadowsocks","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--网站","slug":"CS/network/tools/wireshark/抓包实例分析-网站","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-网站/"}]},{"title":"","date":"2018-06-20T11:22:09.055Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--网站/-websocket/","text":"demo首先，去web/html5/websocket教程中查看demo， 建立连接webSocket建立以后不再有tcp连接建立: 过滤规则(rules in filter)方式一：按端口过滤1tcp.dstport == your_websoket_port 方式二：按协议过滤1websocket 抓包分析 – echo.websocket.org我的ip 9.186.58.178echo.websocket.org 174.129.224.73 12No Time Source Destination Protocol length Info12821 649.588871 174.129.224.73 9.186.58.178 WebSocket 84 WebSocket Text [FIN] 1234567Frame 12821: 84 bytes on wire (672 bits), 84 bytes captured (672 bits) on interface 0Ethernet II, Src: Cisco_42:89:c0 (e8:ba:70:42:89:c0), Dst: IntelCor_09:85:f8 (e8:b1:fc:09:85:f8)Internet Protocol Version 4, Src: 174.129.224.73, Dst: 9.186.58.178Transmission Control Protocol, Src Port: 80, Dst Port: 65331, Seq: 543, Ack: 667, Len: 30WebSocketLine-based text data Rock it with HTML5 WebSocket 疑问[FIN] 和 [FIN][MASKED]什么区别？ websocket为什么是单独的一个层？是不是算在了应用层和传输层之间的某个层。line-based text data包含数据，为什么也是单独的一个层？ 是否明文传输？是明文传输的! 我为啥开了ssl也能看见明文？（用https握手之后用wss连接的） – 来自知乎 参考http://blog.csdn.net/lusyoe/article/details/53858320","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--网站","slug":"CS/network/tools/wireshark/抓包实例分析-网站","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-网站/"}]},{"title":"一次完整的HTTP请求过程","date":"2018-06-20T11:22:09.053Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--协议/-http/","text":"域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户 ## 使用命令 wget www.baidu.com 来请求，发现直接使用chrome浏览器请求时，干扰请求比较多，所以就使用wget命令来请求，不过使用wget命令只能把index.html请求回来，并不会对index.html中包含的静态资源（js、css等文件）进行请求。 待看https://www.cnblogs.com/engeng/articles/5959335.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--协议","slug":"CS/network/tools/wireshark/抓包实例分析-协议","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-协议/"}]},{"title":"","date":"2018-06-20T11:22:09.053Z","path":"wiki/CS/network/tools/wireshark/抓包实例分析--协议/-dns/","text":"抓之前最好先清一下dns缓存 123456# windows$ ipconfig /displaydns #查看本地缓存的DNS信息$ ipconfig /flushdns #清除本地缓存的DNS信息# linux$ /etc/rc.d/init.d/nscd restar","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"},{"name":"抓包实例分析--协议","slug":"CS/network/tools/wireshark/抓包实例分析-协议","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/抓包实例分析-协议/"}]},{"title":"","date":"2018-06-20T11:22:09.049Z","path":"wiki/CS/web/-back-end/后端框架/-后端框架/","text":"简介常见后端框架 java spring PHP thinkphp- node- 对比VS 前端框架VS 后端模板#","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"后端框架","slug":"CS/web/back-end/后端框架","permalink":"http://yoursite.com/categories/CS/web/back-end/后端框架/"}]},{"title":"","date":"2018-06-20T11:22:09.048Z","path":"wiki/CS/web/-web安全 非网络安全/前端安全/","text":"安全XSS攻击XSS注入防护重要的是呈现任何内容的时候进行HTML编码，例如&lt;&gt;。 问题知乎怎样做到的禁用js注入？ 知乎的编辑器根本就不允许用户自定义样式、格式，更别说自定义HTML代码了，危险系数极低。 XSS攻击可以在任何用户可定制内容的地方进行，例如图片引用，在知乎上发表站外图片的引用，知乎会在服务器自动下载转换为自己的图片。 作为一个UGC网站，知乎提供的内容输入的功能可说是简陋至极，没有太多的XSS攻击需要考虑。 github怎样做到的？ markdown起码能支持 等标签吧 discuss也做了吧- 自己的网站如何做建议xss防护？ 可以把comments托管到gist，经审核后再放行 把comments托管到discuss","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-web安全 非网络安全","slug":"CS/web/web安全-非网络安全","permalink":"http://yoursite.com/categories/CS/web/web安全-非网络安全/"}]},{"title":"","date":"2018-06-20T11:22:09.047Z","path":"wiki/CS/web/-open-graph/","text":"兴趣图谱（Open Graph）兴趣图谱帮助用户在使用应用时，快捷分享关于兴趣、生活的交互故事。他是一套标准化、结构化的信息传播方法，为开发者提供了将其应用或网站，深入连接到微博的途径。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"}]},{"title":"","date":"2018-06-20T11:22:09.047Z","path":"wiki/CS/web/front-end/-前端发展史/","text":"通过直接编写 JavaScript、CSS、HTML 开发 Web 应用的方式已经无法应对当前 Web 应用的发展。近年来前端社区涌现出许多新思想与框架 新框架在 Web 应用变得庞大复杂时，采用直接操作 DOM 的方式去开发将会使代码变得复杂和难以维护， 许多新思想被引入到网页开发中以减少开发难度、提升开发效率。 ReactReact 框架引入 JSX 语法到 JavaScript 语言层面中，以更灵活地控制视图的渲染逻辑。 12let has = true;render(has ? &lt;h1&gt;hello,react&lt;/h1&gt; : &lt;div&gt;404&lt;/div&gt;); VueVue 框架把一个组件相关的 HTML 模版、JavaScript 逻辑代码、CSS 样式代码都写在一个文件里，这非常直观。 12345678910111213141516171819202122&lt;!--HTML 模版--&gt;&lt;template&gt; &lt;div class=\"example\"&gt;&#123;&#123; msg &#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;!--JavaScript 组件逻辑--&gt;&lt;script&gt;export default &#123; data () &#123; return &#123; msg: 'Hello world!' &#125; &#125;&#125;&lt;/script&gt;&lt;!--CSS 样式--&gt;&lt;style&gt;.example &#123; font-weight: bold;&#125;&lt;/style&gt; Angular2Angular2 推崇采用 TypeScript 语言去开发应用，并且可以通过注解的语法描述组件的各种属性。 新语言 ES6 TypeScript：除了支持 ES6 的所有功能，还提供了静态类型检查。 Flow SCSS：用程序员的方式写 CSS。它是一种 CSS 预处理器，基本思想是用和 CSS 相似的编程语言写完后再编译成正常的 CSS 文件。采用 SCSS 去写 CSS 的好处在于可以方便地管理代码，抽离公共的部分，通过逻辑写出更灵活的代码。 和 SCSS 类似的 CSS 预处理器还有 LESS 等。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"}]},{"title":"","date":"2018-06-20T11:22:09.047Z","path":"wiki/CS/web/front-end/js/-常用插件/","text":"Echo.js – 简单易用的图片延迟加载插件Lazyr.js – 延迟加载图片（Lazy Loading）","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"js","slug":"CS/web/front-end/js","permalink":"http://yoursite.com/categories/CS/web/front-end/js/"}]},{"title":"","date":"2018-06-20T11:22:09.046Z","path":"wiki/CS/web/front-end/-前端大神博客/","text":"阿里云龙 https://github.com/fouber","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"}]},{"title":"trick","date":"2018-06-20T11:22:09.043Z","path":"wiki/CS/web/front-end/js/-trick/","text":"如何动态加载js123var newScript = document.createElement(\"script\");newScript.src = \"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML\";document.getElementsByTagName('head')[0].appendChild(newScript); 同步加载wScript);` 同步加载","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"js","slug":"CS/web/front-end/js","permalink":"http://yoursite.com/categories/CS/web/front-end/js/"}]},{"title":"","date":"2018-06-20T11:22:09.041Z","path":"wiki/CS/web/front-end/framework/-前端框架/","text":"Angular的适用领域相对窄一些，React可以拓展到服务端，移动端Native部分，而Vue因为比较轻量 分类 css框架 Bootstrap: 一套ui皮肤+少量js组成的框架，属于封装度偏低的框架 js框架诸如AngularJS、Ember.js、Meteor.js、ExtJS和React等面向网页浏览器的JavaScript框架采纳了单页应用（SPA）原则。 AngularJS是一个全面的客户端侧框架。其模板基于双向UI数据绑定。数据绑定是一种自动方法，在模型改变时更新视图，以及在视图改变时更新模型。其HTML模板在浏览器中编译。编译步骤创建纯HTML，浏览器将其重新渲染到实时视图。该步骤会在随后的页面浏览中重复。在传统的服务器端HTML编程中，控制器和模型等概念在服务器进程中进行交互以产生新的HTML视图。在AngularJS框架中，控制器和模型状态在客户端的浏览器中维护，从而使生成新页面不依赖与服务器的交互。 Ember.js是基于模型-视图-控制器（MVC）软件架构模型的客户端侧JavaScript Web应用程序框架。它允许开发人员在一个框架中通过常用的习惯用语和最佳实践来创建可伸缩的单页面应用程序。该框架提供丰富的对象模型、声明性双向数据绑定、计算属性，Handlebars.js提供的自动更新模板，以及一个路由器管理应用程序状态。 Meteor.js是一个专门为单页应用设计的全栈（客户端-服务器）JavaScript框架。它具有比Angular、Ember或ReactJS更简单的数据绑定特性[6]，并且使用Distributed Data Protocol[7]和一个发布/订阅来自动将数据更改传播到客户端，无需开发人员编写任何同步代码。全栈反应确保从数据库到模板的所有层都可以在必要时自动更新。诸如服务器端渲染[8]等生态系统包则解决搜索引擎优化（SEO）等问题。 Aurelia是一个适用于移动设备、桌面和网页的JavaScript客户端框架。它类似AngularJS，但更新、更匹配标准，并采用模块化举措。Aurelia使用下一代ECMAScript编写。[来源请求] Vue.js（通常称为Vue）是一个用于构建用户界面的开源渐进式JavaScript框架。 React（通常写为React.js或ReactJS）是一个构建用户界面的JavaScript库。它由Facebook、Instagram和个人开发者以及企业社区维护。React最大的优势是易于使用——基本上任何熟悉HTML的开发人员都可以创建React应用程序。另一个所称的优势是可能使用相同的技术堆栈来同时创建Web与移动应用程序。有多家公司使用React和Redux库来让开发人员创建复杂但可扩展的Web应用程序。[9]Fulcro是一个全栈库，它采用Netflix的Falcor，Facebook的Relay和Om Next对反应性，功能性，数据驱动软件进行改编的数据驱动原则。 BootStrap Foundation Semantic UI Angular React Preact Vue jQuery 人气 Preact 受众最小，但增长最快 说明 Bootstrap是最流行的HTML，CSS和JavaScript框架，用于在网络上开发响应式、移动的Web项目 世界上最先进的响应式前端框架 基于自然语言原则的UI组件框架 框架只负责”View”层，这意味着其它业务逻辑是完全解耦的，并且能以任何方式来实现。 核心概念/原则 RWD和移动端优先。 RWD，移动端优先，语义 Semantic, tag ambivalence, responsive 框架大小 154 KB 197.5 KB 806 KB 预处理器 Less和Sass Sass 少 响应式布局 √ √ √ 模块化 √ √ √ 启动模板/布局 √ √ √ 图标集 Glyphicons Halflings设置 基础图标字体 Font Awesome bootstrapbootstrap基本就是 Bootstrap是最流行的HTML，CSS和JavaScript框架，用于在网络上开发响应式、移动的Web项目。 掌握 LESS 有助于理解 Bootstrap。 1234567891011&lt;!-- Latest compiled and minified CSS这是编译后的版本，119K，有点大。有些人建议采用编译前的less，选择性引用。--&gt;&lt;link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\" integrity=\"sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\" crossorigin=\"anonymous\"&gt;&lt;!-- Optional theme --&gt;&lt;link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css\" integrity=\"sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp\" crossorigin=\"anonymous\"&gt;&lt;!-- Latest compiled and minified JavaScript --&gt;&lt;script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\" integrity=\"sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa\" crossorigin=\"anonymous\"&gt;&lt;/script&gt; 自己整理css的话工作量太大。 bootstrap主要是样式侵入性太强，个性化定制太麻烦 bootstrap.min.css 100多k。 会加载整个css吗？还是只加载用到的？如果引用bootstrap.min.css，肯定会加载所有样式。所以很多人不建议直接引用bootstrap.min.css，而是下载bootstrap source的less，然后选择性引用。 grid system是什么鬼？ bootstrap.min.css 119khttps://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"framework","slug":"CS/web/front-end/framework","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/"}]},{"title":"","date":"2018-06-20T11:22:09.040Z","path":"wiki/CS/web/front-end/-前端技术点/","text":"面试分享：一年经验初探阿里巴巴前端社招 - https://github.com/jawil/blog/issues/22","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"}]},{"title":"","date":"2018-06-20T11:22:09.039Z","path":"wiki/CS/web/front-end/前端构建工具/webpack/-webpack-example/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"前端构建工具","slug":"CS/web/front-end/前端构建工具","permalink":"http://yoursite.com/categories/CS/web/front-end/前端构建工具/"},{"name":"webpack","slug":"CS/web/front-end/前端构建工具/webpack","permalink":"http://yoursite.com/categories/CS/web/front-end/前端构建工具/webpack/"}]},{"title":"","date":"2018-06-20T11:22:09.037Z","path":"wiki/CS/web/建站/seo/-二级域名VS二级目录/","text":"二级目录301重定向到二级域名一般在网站权重还不足够高时，要建子站的话，都是放在二级目录里面。比如SEO朋友喜欢在二级目录建博客或论坛，好处是可以继承主站的权重。当网站足够强大了，就可以放到二级域名或者其他新域名。 对于搜索引擎来说，二级域名就是新域名，以一个新的站点来看待。如何保证转移后有效继承原来的权重不被降权？最好的办法就是做301。下面具体介绍二级目录301重定向到二级域名的两种方法： http://www.jb51.net/yunying/116837.html ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"seo","slug":"CS/web/建站/seo","permalink":"http://yoursite.com/categories/CS/web/建站/seo/"}]},{"title":"","date":"2018-06-20T11:22:09.035Z","path":"wiki/CS/web/建站/plugin-for-static-site/-math/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"plugin-for-static-site","slug":"CS/web/建站/plugin-for-static-site","permalink":"http://yoursite.com/categories/CS/web/建站/plugin-for-static-site/"}]},{"title":"","date":"2018-06-20T11:22:09.035Z","path":"wiki/CS/web/建站/seo/-baidu-seo/","text":"新网站做了一个月的 SEO，百度仍没有收录，怎么解决？ 我查了下URL 也有外链了 我相信爬虫肯定也都爬过了 你先去日志查看下 有没有baiduspider ~ 如果没有跟我说有的话 说明你这个站的内容不行 对用户没什么价值另外可以用百度站长工具查看网站索引量 有可能在百度工具里查询是有索引量的但是用site指令却是没有的 说明虽然网站内容已经索引放入数据库里 但是不释放出来有可能过段时间就释放页面出来了也有可能就不放了 归根到底还是内容不行啊ps：看了下你的网站，内容貌似多是采集的吧。。 现在百度对新站相当严 1、有没有写好robots文件；2、有没有向各大搜索引擎提交你们的网站；3、网站是否有内容，不是用的JS加载；4、有没有给网站交换一些友链导权重引蜘蛛；5、有没有给网站发一些高质量的外链。 如果上面的几个问题你们都做好了，网站基本很快就会收录。 需要站外推广 + 站内优化 多分析网站后台日志，分析来的抓取的蜘蛛频率和什么类型的蜘蛛；如果你网站基础得分（站内内链、url、网站结构、内容原创）等规划的合理，被蜘蛛抓取是迟早的事情，这个时候可以适当的引一下蜘蛛，但忌发过多的垃圾外链，尽量做一些高质量的外链引蜘蛛， 2、爬取多 不一定收录多 原因就是内容差 知乎：https://www.zhihu.com/question/54135646 https://zhuanlan.zhihu.com/p/24643667 提交给百度 百度站长提交给google https://www.google.com/webmasters/雅虎提交给bing https://www.bing.com/webmaster/sogou","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"seo","slug":"CS/web/建站/seo","permalink":"http://yoursite.com/categories/CS/web/建站/seo/"}]},{"title":"","date":"2018-06-20T11:22:09.034Z","path":"wiki/CS/web/建站/plugin-for-static-site/-实时通信模块/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"plugin-for-static-site","slug":"CS/web/建站/plugin-for-static-site","permalink":"http://yoursite.com/categories/CS/web/建站/plugin-for-static-site/"}]},{"title":"","date":"2018-06-20T11:22:09.032Z","path":"wiki/CS/web/建站/-备选域名/","text":"注册有商业价值的域名 域名 价格 到期日期 备注 xu.song 显示Reserved Domain Name。 难道是被预定了？还是不开放注册？ 这个域名目前尚未开放，近期将会开放注册。www.nic.song/ .song是供亚马逊平台专用的域名，可以同时保护其品牌完整性与商誉。 u.song iam.song xusong.com 2023年1月16日 双拼 xusong.org 2019年1月16日 首字母 xsong.com 2018年10月24日 域名短，但不容易记，(不是双拼，无英文意思) xsong.org 757/10年 xsong.tech 297/10年 usong.com 2018年7月11日 优于xsong.com usong.tech 297/10年 前缀 pysong.com 676/10年 前缀py，python pysong.org 757/10年 其他双拼 deepsong.com 英文双拼 deepsong.org codingsong.com codingsong.org 757/10年 eson.com 2024年09月30日 eson.net 2018年07月14日 eson.org cxzz.org 残血站长 朝鲜战争 传销组织 aipk.org 爱拍客 艾派克","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"}]},{"title":"","date":"2018-06-20T11:22:09.032Z","path":"wiki/CS/web/建站/CDN与加速/-CDN原理/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"CDN与加速","slug":"CS/web/建站/CDN与加速","permalink":"http://yoursite.com/categories/CS/web/建站/CDN与加速/"}]},{"title":"","date":"2018-06-20T11:22:09.031Z","path":"wiki/CS/web/建站/host/-图片服务器/","text":"http://chuantu.biz/ 新浪图床 # [图片云存储服务商在阿里云和又拍云之间如何选择？](https://www.zhihu.com/question/20115323 17个支持图片外链的免费相册","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"}]},{"title":"","date":"2018-06-20T11:22:09.020Z","path":"wiki/CS/web/建站/推广/-屏蔽推广/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"推广","slug":"CS/web/建站/推广","permalink":"http://yoursite.com/categories/CS/web/建站/推广/"}]},{"title":"","date":"2018-06-20T11:22:09.016Z","path":"wiki/CS/web/blog-framework/-好看的主题/","text":"distill.pub https://cloud.tencent.com/info/list_10003_12 MSRA深度文章 https://www.msra.cn/zh-cn/news?wd&amp;content-type=posts腾讯 其他模板 https://github.com/BlackrockDigital/startbootstrap Resume 不错 Creative Grayscale不错 http://www.eson.eu/#smooth-scroll-top https://bootstrapmade.com/demo/Squadfree/ https://bootstraptaste.com/squadfree-free-bootstrap-template-creative/ http://faso.me/ http://www.jiasule.top/index.html-","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"}]},{"title":"","date":"2018-06-20T11:22:09.015Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/theme/-写一个自己的主题/","text":"简书的description页不错。就是简单的，左右格式，左字右图","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"theme","slug":"CS/web/blog-framework/nodejs-hexo/theme","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/theme/"}]},{"title":"","date":"2018-06-20T11:22:09.014Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/-Hexo如何在线可视化写博客/","text":"hexo-admin能够管理文章，添加分类和标签，也可以一键部署到pages","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"","date":"2018-06-20T11:22:09.014Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/-hexo https/","text":"Hexo之使用CodingPages实现全站","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"","date":"2018-06-20T11:22:09.013Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/console/-hexo/","text":"hexo newhexo generaterk nodejs-hexo plugin console hexo newhexo generate","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"console","slug":"CS/web/blog-framework/nodejs-hexo/plugin/console","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/console/"}]},{"title":"【Hexo插件系列】hexo cli 源码","date":"2018-06-20T11:22:09.013Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/console/-hexo_cli/","text":"提供hexo init、hexo help、hexo version命令 简介源码根入口 package.jsonpackage.json 的核心配置 123456&#123; \"name\": \"hexo-cli\", \"main\": \"lib/hexo\", # 入口文件，即 lib/hexo.js \"bin\": &#123; \"hexo\": \"./bin/hexo\" # 该文件会拷贝到系统bin目录，即hexo命令。 &#125;, hexo命令hexo-cli/bin/hexo这个文件会被link到/usr/bin/hexo，实现全局hexo命令。实质是node的js可执行脚本。 1require('../lib/hexo')(); hexo-cli/lib/hexo.js的核心代码，引入了三个子命令。 12345entry.console = &#123; init: require('./console/init'), // hexo init help: require('./console/help'), // hexo help version: require('./console/version') // hexo version&#125;; hexo init1234567891011121314151617module.exports = function(ctx) &#123; var console = ctx.extend.console; // 注册 hexo help 命令 console.register('help', 'Get help on a command.', &#123;&#125;, require('./help')); // 注册 hexo init 命令 console.register('init', 'Create a new Hexo folder.', &#123; desc: '...', usage: '[...]', arguments: [... ], options: [... ] &#125;, require('./init')); // 注册 hexo version 命令 console.register('version', 'Display version information.', &#123;&#125;, require('./version'));&#125;; hexo help、hexo version 三个子命令hexo version 三个子命令","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"console","slug":"CS/web/blog-framework/nodejs-hexo/plugin/console","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/console/"}]},{"title":"","date":"2018-06-20T11:22:09.012Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-generator-category/","text":"入口12345678910'use strict';var assign = require('object-assign');hexo.config.category_generator = assign(&#123; per_page: typeof hexo.config.per_page === 'undefined' ? 10 : hexo.config.per_page&#125;, hexo.config.category_generator);// 注册category钩子hexo.extend.generator.register('category', require('./lib/generator')); 其他.travis.yml 12345678910111213141516171819language: node_jsnode_js:- '0.10'- '0.11'- '0.12'- iojsscript:- npm testafter_script:- cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.jsdeploy: provider: npm email: dev@adrianhaasler.com api_key: secure: OK0bKCkTZmTiexyO58dv0MqIn+WyYA/iJtnt0uhSICBT+69225UOhDJjai0kFRyBZ1ELQ0kEDaQAdyzNHavofjbp/wzXdKJMdiHJGjH0rshvsJqm4oGHJryH/LAIJ/XCFeLcte+RCfY466JJk2yqK6rh2SwiKG7RrmkL2BuCAzItW7Y7v1MaaFA2A9cX7ymPpB4qlFAgMtrVBtirUNgJEKJJA2wXTld1tceEi/TwziSVdALZA03ou7ljtW/wgmPi+1jS0+yh7Fak78TcfUc7M8Hb/Cfr1IKbXl2Z9xOAfQ1WoFcTCoXRPqo0Um9QOIaEBQlUl/oegW1rvuhPyWmU+GEUhVpZr4CcbKbsn4Nkl08OisNYUfIwoxExxaHIzvExTLKo+Mmh2x4M7ywsmS1xnWBmUSurQrCLEp3p2eXTvIVYmpsl0RZaZLU9UHBxVZ/OVfk85Leefg5k7vlbaCOM0s8Qpxq8PAUoZTN+o+uBxtcPQvNRst+Qz+xhcroSNWboc9G2hRyfKXsm7Y0K+Cg5LAvXE44n/iyHc4mZhKP0Rumxpjtk/9BhokqWAERSxe1OBjKGA5VanO5DeEHiEHcXP3+2TVtYLgvp4evYasD+VQhchZJnFhM89n9NMgpF6y88lQkLc2VPuxIroBDx1AaAZ1fnhLN8ao2qJjRe88JQ43Q= on: tags: true repo: ahaasler/hexo-generator-multilingual-category node: '0.12'","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.011Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-server/","text":"Hexo 3.0 把服务器独立成了个别模块，您必须先安装 hexo-server 才能使用。 1$ npm install hexo-server -g 在服务器启动期间，Hexo 会监视文件变动并自动更新，您无须重启服务器。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.011Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/2/-在线编辑模块/","text":"edit online 实现在线编辑， 读取github fork 写入github 提交pull request 可是实现Blog的多人协作","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"2","slug":"CS/web/blog-framework/nodejs-hexo/plugin/2","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/2/"}]},{"title":"","date":"2018-06-20T11:22:09.010Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-generator-search/","text":"http://moxfive.xyz/2016/05/31/hexo-local-search/","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.010Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-renderer-pandoc/","text":"hexo-renderer-pandoc 简介pandoc是什么？pandoc是一个标记语言(也可以说排版语言)转换器。可以将一种标记语言(如markdown、textile、tex、latex、html、epub等)转换到另一种标记语言。 常见的markdown引擎有 markdown_strict (original unextended markdown) 原生markdown pandoc’s extended markdown markdown_phpextra (PHP Markdown Extra extended markdown) markdown_github (github extended markdown) 即GFW(Github Flavored Markdown) markdown_mmd (MultiMarkdown)。 hexo markdown渲染引擎和mathjax冲突问题，因此安装hexo-renderer-pandoc。这会替换掉hexo自带的markdown引擎。 这个插件依赖pandoc 1pandoc -s -o output.html source/_posts/demo/test.md 其他类似插件hexo-math和hexo-renderer-mathjax来实现， 常见错误1.123$ pandoc -s -o output.html OSM-export-plain-text.txtpandoc: YAML header is not an object \"source\" (line 130, column 1)pandoc: YAML header is not an object \"source\" (line 17, column 1) 原因是文档内部有---，会与front matter的符号混淆。应该跟插件无关，是pandoc的原因。 参考：https://github.com/olivierkes/manuskript/issues/124 ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.008Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/-hexo-generator/","text":"生成器","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"","date":"2018-06-20T11:22:09.008Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/2/-实时聊天组件/","text":"做一个实时talk平台，dao voice基于微信公众号，很烂 gitter.im 需要join room。这是个群聊的聊天室。 依赖现有的移动端im app，比如微信。 gitter很牛逼啊，tensor2tensor就采用的gitter聊天室 https://gitter.im/tensor2tensor/Lobby gittalk这是评论插件，不是实时聊天 TODO可以基于git issue做一个群聊 聊天室。 借鉴git comment","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"2","slug":"CS/web/blog-framework/nodejs-hexo/plugin/2","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/2/"}]},{"title":"","date":"2018-06-20T11:22:09.007Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-filter/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.007Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/theme-level/-hexo-wordcount/","text":"web blog-framework nodejs-hexo plugin theme-level","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"theme-level","slug":"CS/web/blog-framework/nodejs-hexo/plugin/theme-level","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/theme-level/"}]},{"title":"","date":"2018-06-20T11:22:09.006Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-generator-baidu-sitemap/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.006Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/2/-评论组件/","text":"评论组件 Hypercomments 是国外的一个第三方评论平台 多说 在2017年06月01日就关闭评论服务了 网易云跟贴 2017年08月01日也停止服务了 来必力 (韩国人弄的)总是乱码 DISQUS 外国的，加载慢，被墙 基于github issue的评论系统。Gitment存在的问题： 每次发布文章时需要登录下自己的github账号去初始化一下评论，评论功能才能使用，否则会提示“未开放评论” 解决办法：添加第一条评论时自动初始化 更改文章title，会找不到对应的issue。解决办法：采用href作为id。目前确实采用的href作为id，但是不会改title 2. 登入 button: 登入 GitalkGitalk 是一个基于 GitHub Issue 和 Preact 开发的评论插件。 Gitalk，样式也挺漂亮的，于是打算尝试一下移植到Next主题上。https://newdee.cf/posts/4da30c7/ demo: https://gitalk.github.io/ 做一个基于git issue的在线编辑博客。。做一个基于git 仓库的在线编辑博客。。 ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"2","slug":"CS/web/blog-framework/nodejs-hexo/plugin/2","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/2/"}]},{"title":"","date":"2018-06-20T11:22:09.004Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-blog-encrypt/","text":"加密https://github.com/MikeCoder/hexo-blog-encrypt/blob/master/index.js#L81 1data.content = CryptoJS.AES.encrypt(data.content, String(data.password)).toString(); 解密https://github.com/MikeCoder/hexo-blog-encrypt/blob/master/lib/blog-encrypt.js#L8 12var content = CryptoJS.AES.decrypt(document.getElementById(\"encrypt-blog\").innerHTML.trim(), pass); // 加密content = decodeBase64(content); 其他 文章加密访问","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.004Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-deployer-git/","text":"web blog-framework nodejs-hexo plugin ‘1’","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.004Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/1/-hexo-renderer-mathjax/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"1","slug":"CS/web/blog-framework/nodejs-hexo/plugin/1","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/1/"}]},{"title":"","date":"2018-06-20T11:22:09.003Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/-theme dev and contribute/","text":"## ## ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"","date":"2018-06-20T11:22:09.001Z","path":"wiki/CS/web/-cluster 集群要解决的问题/fileServer/","text":"文件服务器: 一份 mount 直接二进制存储到(db2、solr、redis ftp、samba等文件共享应用 多份rsync 分布式文件系统","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-cluster 集群要解决的问题","slug":"CS/web/cluster-集群要解决的问题","permalink":"http://yoursite.com/categories/CS/web/cluster-集群要解决的问题/"}]},{"title":"","date":"2018-06-20T11:22:09.000Z","path":"wiki/CS/web/-cluster 集群要解决的问题/session/","text":"一、工作中因为要使用到Tomcat集群部署，此时就涉及到了Session共享问题，主要有三种解决方案： tomcat自带的session共享 使用数据库来存储Session 使用Cookie来存储Session 使用Redis来存储Session。优点：使用Session的代码没有任何变化，Tomcat默认把Session保存到Redis上面了。 二、本文中主要讲一下第3种方案，也就是使用Redis来存储Session，Github中已经有该开源组件（tomcat-redis-session-manager），下面讲一下配置的步骤 1、配置tomcat配置文件context.xml","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-cluster 集群要解决的问题","slug":"CS/web/cluster-集群要解决的问题","permalink":"http://yoursite.com/categories/CS/web/cluster-集群要解决的问题/"}]},{"title":"","date":"2018-06-20T11:22:09.000Z","path":"wiki/CS/web/-cluster 集群要解决的问题/bluescan-HA/","text":"HA 应用服务器HA/集群 &amp; 负载均衡 &amp; session共享hi zhili ，我用nginx搭的负载均衡。 入口：http://172.29.163.101:8080/bluescan/ 实际节点：http://172.29.163.104:8081/bluescan/http://172.29.163.101:8081/bluescan/ 目前采用的round-robin的轮替方式，暂时没发现什么问题。另外绑定ip的方式，当一个节点故障，nginx会自动切换到另外节点。所以source-ip轮替方式也差不多够用 负载均衡session共享 数据库 &amp; 缓存为什么要用solr？不全文检索，就没必要用solr derby？小，稳定，但是只有本地版， mysql？ redis postgres ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-cluster 集群要解决的问题","slug":"CS/web/cluster-集群要解决的问题","permalink":"http://yoursite.com/categories/CS/web/cluster-集群要解决的问题/"}]},{"title":"","date":"2018-06-20T11:22:08.998Z","path":"wiki/CS/programing/lan/java/-java语言的诞生/","text":"背景C和C++ reference https://jimmylv.gitbooks.io/learning-java/content/2014-11-18-python-to-java-02.html 《think in java》写在前面的话","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"}]},{"title":"","date":"2018-06-20T11:22:08.997Z","path":"wiki/CS/programing/lan/java/-tools/javac/","text":"tools.jar com.sun.tools.javac.* 源码在openjdk\\langtools\\src\\share\\classes\\com\\sun\\tools\\javac目录下","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"-tools","slug":"CS/programing/lan/java/tools","permalink":"http://yoursite.com/categories/CS/programing/lan/java/tools/"}]},{"title":"","date":"2018-06-20T11:22:08.997Z","path":"wiki/CS/programing/lan/java/-tools/javap/","text":"com.sun.tools.javap.*","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"-tools","slug":"CS/programing/lan/java/tools","permalink":"http://yoursite.com/categories/CS/programing/lan/java/tools/"}]},{"title":"【java源码系列】工具类 - Arrays","date":"2018-06-20T11:22:08.992Z","path":"wiki/CS/programing/lan/java/jdk/rt/util/-Arrays/","text":"此类包含用来操作数组（比如排序和搜索）的各种方法。此类还包含一个允许将数组作为列表来查看的静态工厂。 为什么不写到intArrays.toString( 它提供的操作包括： 排序 sort 查找 binarySearch() 比较 equals 填充 fill 转列表 asList() 哈希 Hash() 转字符串 toString() 扩展阅读 https://www.jianshu.com/p/d083332c3c29","tags":[{"name":"java源码","slug":"java源码","permalink":"http://yoursite.com/tags/java源码/"},{"name":"collection","slug":"collection","permalink":"http://yoursite.com/tags/collection/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"util","slug":"CS/programing/lan/java/jdk/rt/util","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/util/"}]},{"title":"","date":"2018-06-20T11:22:08.988Z","path":"wiki/CS/programing/lan/java/jdk/jvm/-Class/","text":"Class 文件格式中精确地定义了类与接口的表示形式 Java 语言中的各种变量、关键字和运算符的语义最终都是由多条字节码命令组合而成的，因此字节码命令所能提供的语义描述能力肯定会比Java语言本身更强大，这便为其他语言实现一些有别于Java的语言特性提供了基础，而且这也正是在类加载时要进行安全验证的原因。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"jvm","slug":"CS/programing/lan/java/jdk/jvm","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/"}]},{"title":"","date":"2018-06-20T11:22:08.988Z","path":"wiki/CS/programing/lan/java/jdk/jvm/HotSpot/-classloader/","text":"A classloader doesn’t just load bytecode","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"jvm","slug":"CS/programing/lan/java/jdk/jvm","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/"},{"name":"HotSpot","slug":"CS/programing/lan/java/jdk/jvm/HotSpot","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/HotSpot/"}]},{"title":"","date":"2018-06-20T11:22:08.985Z","path":"wiki/CS/programing/lan/python/-多版本共存/","text":"python版本多样 有python2 python3，另外还有anaconda-python conda-python。 有pip pip3 看清楚自己用的哪个。which python或者where python。 可能出现的混用，比如pip用的python2的，python命令对应的conda的。也就是包装了也找不到","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"}]},{"title":"源码分析python sleep函数实现原理","date":"2018-06-20T11:22:08.984Z","path":"wiki/CS/programing/lan/python/-sleep/","text":"疑问linux下sleep()函数是如何实现的，他的原理是啥？ 跟python time.sleep()是否一样.","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"}]},{"title":"python3之字符串和编码","date":"2018-06-20T11:22:08.984Z","path":"wiki/CS/programing/lan/python/python3/-python3编码/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"python3","slug":"CS/programing/lan/python/python3","permalink":"http://yoursite.com/categories/CS/programing/lan/python/python3/"}]},{"title":"","date":"2018-06-20T11:22:08.983Z","path":"wiki/CS/programing/lan/python/-包管理机制-package-module/","text":"什么是module。一个文件、一个文件夹文件中的class不是module。 from module import class或者变量 import module.submodule as�者变量 import module.submodule as","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"}]},{"title":"","date":"2018-06-20T11:22:08.981Z","path":"wiki/CS/programing/-协程/","text":"协程 | 廖雪峰","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"}]},{"title":"","date":"2018-06-20T11:22:08.980Z","path":"wiki/CS/security/密码学/远程加密类，两方加密/-远程加密/","text":"远程加密，区分公钥和私钥 ssh 电报加密","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"security","slug":"CS/security","permalink":"http://yoursite.com/categories/CS/security/"},{"name":"密码学","slug":"CS/security/密码学","permalink":"http://yoursite.com/categories/CS/security/密码学/"},{"name":"远程加密类，两方加密","slug":"CS/security/密码学/远程加密类，两方加密","permalink":"http://yoursite.com/categories/CS/security/密码学/远程加密类，两方加密/"}]},{"title":"","date":"2018-06-20T11:22:08.979Z","path":"wiki/CS/security/密码学/前端加密类，单方加密/-windows登录加密算法/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"security","slug":"CS/security","permalink":"http://yoursite.com/categories/CS/security/"},{"name":"密码学","slug":"CS/security/密码学","permalink":"http://yoursite.com/categories/CS/security/密码学/"},{"name":"前端加密类，单方加密","slug":"CS/security/密码学/前端加密类，单方加密","permalink":"http://yoursite.com/categories/CS/security/密码学/前端加密类，单方加密/"}]},{"title":"","date":"2018-06-20T11:22:08.979Z","path":"wiki/CS/security/密码学/前端加密类，单方加密/-hexo-encript/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"security","slug":"CS/security","permalink":"http://yoursite.com/categories/CS/security/"},{"name":"密码学","slug":"CS/security/密码学","permalink":"http://yoursite.com/categories/CS/security/密码学/"},{"name":"前端加密类，单方加密","slug":"CS/security/密码学/前端加密类，单方加密","permalink":"http://yoursite.com/categories/CS/security/密码学/前端加密类，单方加密/"}]},{"title":"","date":"2018-06-20T11:22:08.979Z","path":"wiki/CS/security/密码学/前端加密类，单方加密/-前端加密/","text":"前端加密，不区分公钥私钥，但并非鸡肋。 常见的有： 系统登录密码 web前端加密","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"security","slug":"CS/security","permalink":"http://yoursite.com/categories/CS/security/"},{"name":"密码学","slug":"CS/security/密码学","permalink":"http://yoursite.com/categories/CS/security/密码学/"},{"name":"前端加密类，单方加密","slug":"CS/security/密码学/前端加密类，单方加密","permalink":"http://yoursite.com/categories/CS/security/密码学/前端加密类，单方加密/"}]},{"title":"","date":"2018-06-20T11:22:08.977Z","path":"wiki/CS/tools/同步与版本管理/git/-git hook/","text":"s文档 中文教程 客户端钩子由诸如提交和合并这样的操作所调用 而服务器端钩子作用于诸如接收被推送的提交这样的联网操作。 pre-commit.sample 钩子在键入提交信息前运行。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.977Z","path":"wiki/CS/tools/同步与版本管理/git/-git原理探究/","text":"核心思想: 观察.git目录的变化。 git in git如何方便的查看.git目录的变化？一个简单的方式是利用git仓库本身，即git in git 流程123$ cd .git$ git init$ 要探究的问题index到底是什么东西？多次index会自动合并为一个吗？还是会保留多次index的历史？ commit后到底是什么？ stash存到哪了？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.977Z","path":"wiki/CS/tools/同步与版本管理/git/-关于多人项目管理，PR/","text":"12345678910111213# 删除远程分支git push origin --delete &lt;branchName&gt;# 删除taggit push origin --delete tag &lt;tagname&gt;##### 创建分支# 创建一个orphan的分支，这个分支是独立的git checkout --orphan gh-pages# 删除原来代码树下的所有文件git rm -rf .rm \\'.gitignore\\' 利用branch管理自己的project和需要PR的project 主要目的也是为了不和自己的修改绞在一起产生混乱。比如我从next仓库fork到我自己的仓库，然后我做了一些只用于我自己的个性化修改，这时候我的master分支和远程master分支之间的变动越来越大了。然后我碰到一个适用于所有人的变动，这时候想提交个pr，最好的方式显然是切换到远程master分支，然后做修改，之后提交到一个新的分支，再然后就可以去github上提交pr了，不会把自己master上的一些修改混到里面不过如果自己master和远程master始终保持完全一致的话倒是可以直接提交到自己master上，然后直接用自己master分支提交pr – by tsanie 为什么要用branch，什么时候用？比如next项目，我没权限，只能fork下来用。如果不用branch，我在自己的master上修改，时间久了，与remote差异越来越大。我想更新功能，可以在remote上pull下来。但是我想提交change到remote呢，这就出问题了。因为提交commit首先要checkout到remote的master。 最好的方式是有一个branch跟remote同步，用这个branch与remote交互。 如果没有提交PR到remote的需求，可以不用branch。 说一下特殊情况。我用两个git账号(俩仓库俩master)，一个做pull用，一个给remote提PR用。那我是不是就没必要设置branch了。 如何pull remote到local？Merging an upstream repository into your fork https://help.github.com/articles/merging-an-upstream-repository-into-your-fork/ 如何 merge本地分支到mastergit checkout mastergit pull origin mastergit merge testgit push origin master 有冲突怎么办？老简单了https://help.github.com/articles/resolving-a-merge-conflict-using-the-command-line/ ##","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.976Z","path":"wiki/CS/tools/同步与版本管理/git/-git server/","text":"## gitgithubgitlab gitserver: 单纯的server没有UI","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.976Z","path":"wiki/CS/tools/同步与版本管理/git/-gitlog/","text":"Git log 高级用法","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.976Z","path":"wiki/CS/tools/同步与版本管理/git/-git-缺陷/","text":"如何实现移动端的git？.git目录很大 比如用git管理日志，或者代码，每次都需要打开电脑记录，比较麻烦。方式： 采用dropbox同步git项目，不包含.git1. 改进git 了解为知笔记的同步策略，dropbox的同步策略。如何解决冲突的？如何轻客户端的？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.976Z","path":"wiki/CS/tools/同步与版本管理/git/github/-管理多个github账号/","text":"## reference方式一：https://gist.github.com/suziewong/4378434 方式二：艹，哪那么麻烦。为单个仓库设置email和username多麻烦。 最简单的方式，在仓库里设置为collaborator。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"},{"name":"github","slug":"CS/tools/同步与版本管理/git/github","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/github/"}]},{"title":"github cdn服务","date":"2018-06-20T11:22:08.975Z","path":"wiki/CS/tools/同步与版本管理/git/github/-github CDN服务/","text":"GitHub CDN服务方式一： github仓库github提供raw的方式访问源文件。(git gist 都适用) github的文件地址： https://github.com/xu-song/async-rl/blob/master/resources/episode_reward.png # blob 文件绝对地址： https://github.com/xu-song/async-rl/raw/master/resources/episode_reward.png # raw https://raw.githubusercontent.com/xu-song/async-rl/master/resources/episode_reward.png # raw的url经过 浏览器重定向后的路径 (被包了一层html标签) https://raw.githubusercontent.com/xu-song/async-rl/master/resources/episode_reward.png?sanitize=true # 浏览器重定向后的路径 (真正的文件绝对路径，可用于&lt;img src=&quot;&quot;&gt; 标签引用) https://user-images.githubusercontent.com/ # issue和comment中上传的图片 https://rawgit.com/ # 贴你github上的文件地址，就能自动变成CDN地址(而且是SSL的) 方式二： issue和comment里上传的图片存在这- https://user-images.githubusercontent.com - 文件上传的格式有限制 方式三：github release github release 这里适宜放大文件，比如模型文件，数据文件 其他 知乎: 关于连接返回的content-typegithub提供的raw链接返回的content-type都是text/plain，浏览器会拒绝执行这样的js和css的。可以用RawGit 这个网站来绕开text/plain的限制购买github的cdn服务也是可以的 TODO: 检查一下content-type，分别对js，css，py，jpg测试。即用github分别host图片，js，py试试 知乎：关于浏览器解析content-type浏览器在解析资源文件的时候会判断content-type头，这个http头定义了设备如何处理将要加载的资源，比如text/html就是让浏览器加在解析html，其中text/plain是纯文本，浏览器设备不会做任何处理，而只有application/javascript或者application/x-javascript(JavaScript 脚本)text/css(CSS样式表)这样表明是资源文件的浏览器设备才会做相应处理加在 TODO：测试一下呗 repo的raw_data VS 每次有人请求raw_data，github 都要去访问这个 repo，查找要求的数据——比起普通的静态文件和 gist，这些操作的系统开销显然要大很多。 (gist也是repo啊，跟raw无关吗？) 源码仓毕竟不同于文件服务器，请求一次的代价很大 github 的策略中，当对 raw data 的请求过于频繁时会返回 403 错误。 比如。 总结以下”12306订票助手拖垮github事件”根本归结于插件的自动更新机制 和谐期：版本自动更新，新版插件托管在任何http服务器均可 (请求压力不大) 跪了：某个版本，Chrome引入安全机制：对于一个HTTPS网站，其所有引用的资源（Script和StyleSheet之类的），也必须位于HTTPS的服务器上，否则拒绝执行。自动更新跪了 问题来了：哪里找HTTPS服务器？ Aha!：github不错，还免费 又跪了：GitHub对于第三方引用的资源，正常返回的概率是很低的。就算很少人用的时候，也几乎是每请求5-6次才肯返回一次正确的内容，其它的时候，全部返回403错误。自动更新又跪了 Aha!：如果一次数据请求失败，那么就每五秒请求一次，直到成功。 报警了：16号。于是乎，每个用户都变成了每 5s 攻击一次的“肉鸡”。被github警告了 这就是该事件，下文继续 ss： 好处 突破浏览器并发限制 动静分离、提高效率 CDN缓存更方便 问题 只存了一份吗?怎样保证数据备灾 &amp; 不同地域的访问速度-","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"},{"name":"github","slug":"CS/tools/同步与版本管理/git/github","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/github/"}]},{"title":"","date":"2018-06-20T11:22:08.974Z","path":"wiki/CS/tools/同步与版本管理/git/github/-tools for git & github/","text":"tools for git table: https://www.tablesgenerator.com/markdown_tables# editor：atom (best editor) zenhub: A better way to manage your GitHub Issue","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"},{"name":"github","slug":"CS/tools/同步与版本管理/git/github","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/github/"}]},{"title":"","date":"2018-06-20T11:22:08.972Z","path":"wiki/CS/tools/同步与版本管理/git/-git-flow 的工作流程/","text":"git-flow 是一个 git 扩展集，按 Vincent Driessen 的分支模型提供高层次的库操作。。 到底是提供了新功能，还是仅仅是git的一个封装？？ https://www.git-tower.com/learn/git/ebook/cn/command-line/advanced-topics/git-flow git flow 命令 https://danielkummer.github.io/git-flow-cheatsheet/index.zh_CN.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"","date":"2018-06-20T11:22:08.970Z","path":"wiki/CS/tools/-ebook/","text":"格式mobi, azw, azw3, epub 这几种电子书格式从本质上来说都是从 HTML 文档转换而来，大多数 HTML 标签和 CSS 样式表的特性它们都支持，它们之间的主要区别在于对排版及新特性的支持与否上。 calibre只能编辑epub和azw3格式书籍。 格式转换工具：Calibre pdf优点，编辑方便， 缺点： epubepub实际上就是一个html的打包，里面的内容都是由html来进行排版，由CSS控制样式的。因此制作epub和制作网页没有太多的区别。epub是开源格式 mobi：amazon的格式，.mobi是压缩包，里面主要包含html和资源文件 mobi是良心格式啊，能转化为htmlz。（是工具提供的还是） 编辑mobi 方式一：转化为epub 转化为epub, 然后通过sigil或jutoh修改，之后用calibre转为mobi 方式二：转化为html 转化为htmlz，解压缩， 格式转换 信息丢失 转化原理，格式A–html–格式b。如果转化成 azw3是升级版的mobi，转换成 mobi 后会产生丢失格式的问题 pdf信息量最少(比如换行)，所以不要拿pdf当做转换源 做笔记 方式一：在pdf中做笔记 优势：做笔记方便， 缺陷：pdf格式不易于操作，不易于读写 方式二：在html中，利用canvas做笔记。 不影响html源码，只是添加了一堆js 优势：做笔记方便， 缺陷： 方式三：在html中，利用标签做笔记。 优势：style可以自定义。 缺陷：图形的笔记不好做。 最推荐利用方式三","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"}]},{"title":"","date":"2018-06-20T11:22:08.968Z","path":"wiki/CS/tools/formatting/-pdf2html/","text":"Introduction如何发布pdf到web方式一：直接pdf文件方式二： convert specific pages of pdf to html. deploy the html to your blog with iframe. pdf2html toolkits: pdfkit wkhtmltopdf Reference","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"}]},{"title":"","date":"2018-06-20T11:22:08.967Z","path":"wiki/CS/tools/formatting/gitbook/-插件/","text":"gitbook serve命令能够看到加载的所有插件","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"gitbook","slug":"CS/tools/formatting/gitbook","permalink":"http://yoursite.com/categories/CS/tools/formatting/gitbook/"}]},{"title":"","date":"2018-06-20T11:22:08.965Z","path":"wiki/CS/tools/formatting/html-富文本编辑器/-为知笔记/","text":"如何把为知笔记转为简单的html元素？为知笔记的表格样式一般 每个cell都写属性，非常冗余。如何转为简单样式？ 方式一：html去除所有样式，又在线工具 方式二：","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"html-富文本编辑器","slug":"CS/tools/formatting/html-富文本编辑器","permalink":"http://yoursite.com/categories/CS/tools/formatting/html-富文本编辑器/"}]},{"title":"","date":"2018-06-20T11:22:08.963Z","path":"wiki/CS/tools/formatting/-word2html/","text":"word转为html的几种方式 word另存为html 拷贝并粘贴到ckeditor 利用Adobe Dreamweaver转换(可去除很多无用的标签)","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"}]},{"title":"","date":"2018-06-20T11:22:08.961Z","path":"wiki/CS/tools/密码管理/-LessPass/","text":"lesspass","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"密码管理","slug":"CS/tools/密码管理","permalink":"http://yoursite.com/categories/CS/tools/密码管理/"}]},{"title":"","date":"2018-06-20T11:22:08.961Z","path":"wiki/CS/tools/密码管理/-KeePassX/","text":"keeppassx竟然不开放github issue，只开放pull issue。太不爽。 能export csv，竟然不能import csv。 keeppassx VS keeppasshttps://superuser.com/questions/878902/whats-the-difference-between-keepass-and-keepassx keeppassx的存在，是为了作为linux客户端，仍然采用的keepass核心。 keeppass界面和功能更齐全。 keeppassx是山寨，import功能很弱，不支持csv等很多格式。界面也很弱。已经没有存在的意义了。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"密码管理","slug":"CS/tools/密码管理","permalink":"http://yoursite.com/categories/CS/tools/密码管理/"}]},{"title":"","date":"2018-06-20T11:22:08.955Z","path":"wiki/CS/tools/CI-持续集成/Travis CI/-examples/","text":"https://github.com/zotero/zotero/blob/master/.travis.yml","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"CI-持续集成","slug":"CS/tools/CI-持续集成","permalink":"http://yoursite.com/categories/CS/tools/CI-持续集成/"},{"name":"Travis CI","slug":"CS/tools/CI-持续集成/Travis-CI","permalink":"http://yoursite.com/categories/CS/tools/CI-持续集成/Travis-CI/"}]},{"title":"","date":"2018-06-20T11:22:08.954Z","path":"wiki/CS/tools/CI-持续集成/Travis CI/-deploy-hexo-blog-with-travis-ci/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"CI-持续集成","slug":"CS/tools/CI-持续集成","permalink":"http://yoursite.com/categories/CS/tools/CI-持续集成/"},{"name":"Travis CI","slug":"CS/tools/CI-持续集成/Travis-CI","permalink":"http://yoursite.com/categories/CS/tools/CI-持续集成/Travis-CI/"}]},{"title":"【机器翻译】Dual Learning 对偶学习","date":"2018-06-19T16:00:00.000Z","path":"wiki/machine translation/-5. 前沿-idea-冷门-专利-灌水/-对偶学习/","text":"利用翻译问题的对偶性（duality），使模型能够从源语言到目标语言（Source to Target）和从目标语言到源语言（Target to Source）这两个方向的翻译中学习。同时，这让我们能同时从有监督和无监督的源数据和目标数据中学习。具体而言，我们利用通用的对偶学习（dual learning）方法，并引入联合训练（Joint Training）算法，通过在一个统一的框架中反复提高从源语言到目标语言翻译和从目标语言到源语言翻译的模型，从而增强单语源和目标数据的效果。 如何对偶学习https://blog.csdn.net/cassiePython/article/details/74929801 这篇讲的也挺不错 横向对比对偶学习 VS 回译回译(Back-translation) 双语料 英中翻译 zh = f(en) min loss(zh, f(en)) 单语料 对偶学习： min loss(zh, f(g(zh))) 回译： min loss(zh, f(en)) 其中en=g(zh)，即回译 loss=CE 区别，对偶学习同时学 f，g。BT只学f 对偶学习 VS autoencoder对偶学习 VS 强化学习对偶学习 VS GAN扩展阅读 Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, and Wei-Ying Ma, Dual Learning for Machine Translation, NIPS 2016.","tags":[],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"-5. 前沿-idea-冷门-专利-灌水","slug":"machine-translation/5-前沿-idea-冷门-专利-灌水","permalink":"http://yoursite.com/categories/machine-translation/5-前沿-idea-冷门-专利-灌水/"}]},{"title":"【机器翻译】基于规则的机器翻译","date":"2018-06-19T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/0. 基于规则的机器翻译/-基于规则的翻译/","text":"基于规则的机器翻译基于规则的翻译过程分成6个步骤：(a) 对源语言句子进行词法分析(b) 对源语言句子进行句法/语义分析(c) 源语言句子结构到译文结构的转换(d) 译文句法结构生成(e) 源语言词汇到译文词汇的转换(f) 译文词法选择与生成","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"RNN","slug":"RNN","permalink":"http://yoursite.com/tags/RNN/"},{"name":"rule","slug":"rule","permalink":"http://yoursite.com/tags/rule/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"0. 基于规则的机器翻译","slug":"machine-translation/2-主流model-研究现状/0-基于规则的机器翻译","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/0-基于规则的机器翻译/"}]},{"title":"【机器翻译】RNN系列 - 注意力模型","date":"2018-06-19T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/-attention-seq2seq/","text":"参考","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"RNN","slug":"RNN","permalink":"http://yoursite.com/tags/RNN/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"【机器翻译】CNN系列 - convseq2seq","date":"2018-06-19T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/convseq2seq/","text":"模型简介convseq2seq 架构注意: 这里的attention是同时得到的，RNN中的attention则是依次得到的。 卷积过程 采用的全卷积网络(没有RNN) Position Embedding: 给CNN更多的“位置感” Gated Linear Units: 给CNN的输出加gate Residual Connection: 给CNN都加 Multi-step Attention: 一层attention不够那就上叠加的attention Implementation/实现细节Fairseq features: multi-GPU (distributed) training on one machine or across multiple machines fast beam search generation on both CPU and GPU large mini-batch training (even on a single GPU) via delayed updates fast half-precision floating point (FP16) training code fairseq - torch 停止更新 fairseq - pytorch 及时更新 paper A Convolutional Encoder Model for Neural Machine Translation 2016 Convolutional Sequence to Sequence Learning 2017 扩展阅读 blog | facebook https://www.zhihu.com/question/59645329/answer/167704376","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"},{"name":"attention","slug":"attention","permalink":"http://yoursite.com/tags/attention/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"【机器翻译】RNN系列 - GNMT","date":"2018-06-19T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/gnmt/","text":"2016年9月，Google机器翻译实现重大突破！Google研究团队宣布开发Google神经机器翻译系统(GNMT)。同年11月，Google翻译停止使用其自2007年10月以来一直使用的专有统计机器翻译（SMT）技术，开始使用神经机器翻译（NMT）。从此宣告， 机器翻译经过27年左右， 正式从1989年的IBM机器翻译模型(PBMT，基于短语的机器翻译)，过渡到了神经网络机器翻译模型。 GNMT是一种端到端的学习方法，不再将句子分解为词和短语独立翻译，而是翻译完整的句子，使得误差降低了 55%-85% 以上。 首先，模型对中文进行编码。整个句子编码完成后，启动decoder，进行解码。解码过程中的每一步，都需要一组attention weight，对输入序列的vector进行加权。 背景NMT虽然已经开始应用， 但 NMT 系统的训练和翻译推理的计算成本非常高，同时也难以应对罕见词，这些问题阻碍了 NMT 在实际部署和服务中的应用，因为在实际应用中，准确度和速度都很关键。而谷歌的神经机器翻译提出了带有 8 个编码器和 8 个解码器的深度 LSTM 网络组成的模型，使用了注意力和残差连接。为了提升并行性从而降低训练时间，注意机制将解码器的底层连接到了编码器的顶层。在推理计算过程中使用了低精度运算来加速翻译速度。为改善对罕见词的处理，谷歌将词分成常见子词单元（词的组件）的一个有限集合，该集合既是输入也是输出。这种方法能提供「字符」-delimited models 的灵活性和「词」-delimited models 的有效性之间的平衡、能自然地处理罕见词的翻译、并能最终提升系统的整体准确度。谷歌的波束搜索技术使用了一个长度规范化过程，并使用了一个覆盖度惩罚，其可以激励很可能能覆盖源句子中所有的词的输出句子的生成。在 WMT’ 14 英语-法语和英语-德语基准上，GNMT 实现了可与当前最佳结果媲美的结果。通过在一个单独的简单句子集合的人类对比评估中，它相比于谷歌已经投入生产的基于短语的系统的翻译误差平均降低了 60%。 模型 zero-shot翻译GNMT系统可以处理“零点翻译”，即直接将一种语言翻译成另一种语言（例如中文到日文）。以前Google翻译会先将源语言翻译成英文，然后将英文翻译成目标语言，而不是直接从一种语言翻译成另一种语言。 Result 以上可以看出 存在的问题 漏翻 错翻：特别是对于名字和稀有词(rare word) 未考虑大语境(context of the paragraph or page) 扩展阅读 GNMT: Bridging the Gap between Human and Machine Translation NTM at Production Scale | Google Blog GNMT | 维基百科 如何评价Google神经机器翻译（GNMT）系统？ | 知乎","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"RNN","slug":"RNN","permalink":"http://yoursite.com/tags/RNN/"},{"name":"attention","slug":"attention","permalink":"http://yoursite.com/tags/attention/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"个人所得税","date":"2018-06-19T16:00:00.000Z","path":"wiki/others/economy/赋税/个税上调/","text":"2018.06.19，十三届全国人大常委会第三次会议，个税修正案提请审议。这是个税法自1980年出台以后第七次大修。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"},{"name":"赋税","slug":"others/economy/赋税","permalink":"http://yoursite.com/categories/others/economy/赋税/"}]},{"title":"中朝","date":"2018-06-19T16:00:00.000Z","path":"wiki/others/politics/-朝鲜/中朝关系/","text":"金正恩，百日内三度访华- 2018-6.12 金正恩在新加坡会见特朗普 (朝鲜战争之后首次朝美首脑会晤) 牛逼呀 迈出了半岛核问题政治解决进程的重要一步。 2018.6.19-6.20，金正恩、李雪主第三次访华，钓鱼台国宾馆。（估计是朝美首脑会晤后的一个表态） 参观农业科学院 科技创新园 参观北京市轨道交通指挥中心 希望同中方一道，推动构建朝鲜半岛持久牢固和平机制 金正恩为半岛无核化 李克强、王沪宁、王岐山、丁薛祥、杨洁篪、北京市委书记蔡奇、外部部长、王毅","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"-朝鲜","slug":"others/politics/朝鲜","permalink":"http://yoursite.com/categories/others/politics/朝鲜/"}]},{"title":"","date":"2018-06-07T12:26:41.813Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-SHA-3/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"","date":"2018-06-07T12:26:41.813Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-分布式哈希和一致性哈希的概念与算法实现/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"","date":"2018-06-07T12:26:41.813Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/应用/-checksum/","text":"滚动哈希？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"},{"name":"应用","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/应用","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/应用/"}]},{"title":"","date":"2018-06-07T12:26:41.813Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/应用/-加密/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"},{"name":"应用","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/应用","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/应用/"}]},{"title":"","date":"2018-06-07T12:26:41.812Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-two-sum/","text":"时间复杂度 O(n),空间复杂度O(n) 时间复杂度O(nlogn),空间复杂度O(1)","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"}]},{"title":"","date":"2018-06-07T12:26:41.812Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/单链表排序/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"","date":"2018-06-07T12:26:41.812Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-SHA-2/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"","date":"2018-06-07T12:26:41.812Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/-SHA-1/","text":"","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"","date":"2018-06-04T09:06:41.742Z","path":"wiki/CS/web/-back-end/歧义词汇/","text":"web和website？网络编程，网站，net，web，web应用的区别？框架 架构 模板区别？见zotero/architecture web/website/webapp architecture/frameworkwebapp architure Web framework A Web framework is a collection of packages or modules which allow developers to write Web applications client-side framework server-side framework web appp framework即Web framework 关系 framework是模板，architure是实现。一套Web framework要尽量支持多种architure。(比如支持不同cache，不同database) – by xs reference Web Application Architecture – Client-Side vs. Server-Side Web application framework Web服务器, http服务器, 应用服务器严格意义上Web服务器只负责处理HTTP协议，只能发送静态页面的内容。而JSP，ASP，PHP等动态内容需要通过CGI、FastCGI、ISAPI等接口交给其他程序去处理。这个其他程序就是应用服务器。 apache+CGI: 在httpd.conf中设置CGI目录：ScriptAlias /cgi-bin/ /var/www/cgi-bin/ 服务器和CGI程序之间通信，一般是通过进程的环境变量和管道。 缺点: 1. 每次有请求，服务器都会fork and exec，每次都会有一个新的进程产生，开销还是比较大的。2. 服务进程必须要和web服务器在同一台机子上 教程 http://www.runoob.com/python/python-cgi.html apache+fastCGI+ java: httpd.conf中配置: tomcat通过8009端口与apache交互。server.xml中配置: php: apache配置： nginx配置:nginx.conf php解析器监听9000端口 python(web.py, django) 能不用framework吗？可以，见《python核心编程》P3853 apache+反向代理(应用层的url重定向) 直接重定向到其他能处理请求的服务器，比如php服务器，java服务器，文件服务器 比如Web服务器包括Nginx，Apache，IIS等。而应用服务器包括WebLogic，JBoss等。应用服务器一般也支持HTTP协议，因此界限没这么清晰。但是应用服务器的HTTP协议部分仅仅是支持，一般不会做特别优化，所以很少有见Tomcat直接暴露给外面，而是和Nginx、Apache等配合，只让Tomcat处理JSP和Servlet部分 前台接待（web服务器） 与 真正的价值服务者（应用服务器） http://z-jianwen.iteye.com/blog/889762 Apache是纯粹的web服务器，而Tomcat和IIS因为具有了解释执行服务器端代码的能力，可以称作为轻量级应用服务器 以Java EE为例，Web服务器主要是处理静态页面处理和作为 Servlet容器，解释和执行servlet/JSP，而应用服务器是运行业务逻辑的，主要是EJB、 JNDI和JMX API等J2EE API方面的，还包含事务处理、数据库连接等功能，所以在企业级应用中，应用服务器提供的功能比WEB服务器强大的多。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"}]},{"title":"","date":"2018-06-04T09:06:41.741Z","path":"wiki/CS/web/-back-end/tomcat/如何导入tomcat example到eclipse/","text":"example项目路径：apache-tomcat-9.0.4\\webapps\\examples eclipse File -&gt; new -&gt; Dynamic Web Project 输入个名字 tomcat-example 拷贝 1cp -rf example\\* tomcat-example\\WebContent 就能运行了 但是不能debug，如何debug 1mv tomcat-example\\WebContent\\WEB-INF\\classes\\ tomcat-example\\src\\ 即可","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"tomcat","slug":"CS/web/back-end/tomcat","permalink":"http://yoursite.com/categories/CS/web/back-end/tomcat/"}]},{"title":"","date":"2018-06-04T09:06:41.741Z","path":"wiki/CS/web/-back-end/tomcat/start_process/","text":"启动default servletbasic info servlet-name: default servlet-class: org.apache.catalina.servlets.DefaultServlet 线程调用栈，请求时序图启动命令：org.apache.catalina.startup.Bootstrap start (见catalina.sh) Bootstrap.main(String[]) // bootstrap.init()，主要是catalinaDaemon = new Catalina() bootstrap.load() 主要根据server.xml的配置new StandardServer() Method.invoke(Object, Object…) // 调用org.apache.catalina.startup.Catalina.load(“start”) Catalina.load(String[]) // 1. 读取server.xml 2.new StandardServer()，(server = StandardServer[8005]) 3. server.setCatalina(this) Digester.parse(InputSource) line: 1536Catalina.load() Bootstrap.load(String[]) // 主要 Tomcat admin port 8005catalina实例是什么时候new的？ 123456789101112StandardWrapper.initServlet(Servlet) //StandardWrapper.loadServlet() // 1. servlet = newInstance(servletClass) 2. initServlet(servlet) 3.StandardWrapper.load() //StandardContext.loadOnStartup(Container[]) //StandardContext.startInternal() //StandardContext(LifecycleBase).start()ContainerBase$StartChild.call() // child.start(); 其中StandardContext child=StandardEngine[Catalina].StandardHost[localhost].StandardContext[]ContainerBase$StartChild.call() // 这是个inner classFutureTask&lt;V&gt;.run()ThreadPoolExecutor.runWorker(ThreadPoolExecutor$Worker)ThreadPoolExecutor$Worker.run()Thread.run() 疑问： 这里为什么没看到engine、host、connector、service的影子 启动 jsp servlet servlet-name: jsp servlet-class: org.apache.jasper.servlet.JspServlet 启动 HelloWorldExample访问 HelloWorldExamplestart log12345678910111213141516171819202122232425262728293031七月 25, 2016 6:56:04 下午 org.apache.catalina.core.AprLifecycleListener init信息: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: C:\\Program Files\\java\\jdk1.7.0_67\\bin;C:\\windows\\Sun\\Java\\bin;C:\\windows\\system32;C:\\windows;C:/Program Files/java/jdk1.7.0_67/bin/../jre/bin/server;C:/Program Files/java/jdk1.7.0_67/bin/../jre/bin;C:/Program Files/java/jdk1.7.0_67/bin/../jre/lib/amd64;C:\\Python27\\Lib\\site-packages\\PyQt4;C:\\windows\\system32;C:\\windows;C:\\windows\\System32\\Wbem;C:\\windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\IBM\\Infoprint Select;C:\\Program Files\\java\\jdk1.7.0_67\\bin;C:\\Program Files\\java\\jdk1.7.0_67\\jre\\bin;C:\\Python27;C:\\texlive\\2015\\bin\\win32;C:\\Program Files\\nodejs\\;C:\\Program Files\\apache-maven-3.3.9\\bin;C:\\Program Files (x86)\\Skype\\Phone\\;C:\\Program Files\\TortoiseSVN\\bin;C:\\Users\\IBM_ADMIN\\Anaconda2;C:\\Users\\IBM_ADMIN\\Anaconda2\\Scripts;C:\\Users\\IBM_ADMIN\\Anaconda2\\Library\\bin;C:\\Users\\IBM_ADMIN\\AppData\\Roaming\\npm;C:\\Wind\\Wind.NET.Client\\WindNET\\bin\\;C:\\Program Files\\Git\\cmd;;E:\\software\\eclipsejavaee;;.七月 25, 2016 6:56:04 下午 org.apache.tomcat.util.digester.SetPropertiesRule begin警告: [SetPropertiesRule]&#123;Server/Service/Engine/Host/Context&#125; Setting property &apos;source&apos; to &apos;org.eclipse.jst.jee.server:tomcat-example&apos; did not find a matching property.// 上一行的原因来自于server.xml中的配置// &lt;Context docBase=&quot;tomcat-example&quot; path=&quot;/tomcat-example&quot; reloadable=&quot;true&quot; source=&quot;org.eclipse.jst.jee.server:tomcat-example&quot;/&gt;// 这个配置是由eclipse自动生成的，不用管七月 25, 2016 6:56:04 下午 org.apache.coyote.AbstractProtocol init信息: Initializing ProtocolHandler [&quot;http-bio-8080&quot;]七月 25, 2016 6:56:04 下午 org.apache.coyote.AbstractProtocol init信息: Initializing ProtocolHandler [&quot;ajp-bio-8009&quot;]七月 25, 2016 6:56:04 下午 org.apache.catalina.startup.Catalina load信息: Initialization processed in 1026 ms七月 25, 2016 6:56:04 下午 org.apache.catalina.core.StandardService startInternal信息: Starting service Catalina七月 25, 2016 6:56:04 下午 org.apache.catalina.core.StandardEngine startInternal信息: Starting Servlet Engine: Apache Tomcat/7.0.47七月 25, 2016 6:56:05 下午 org.apache.catalina.util.SessionIdGenerator createSecureRandom信息: Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [217] milliseconds.七月 25, 2016 6:56:17 下午 org.apache.catalina.core.ApplicationContext log信息: ContextListener: contextInitialized()七月 25, 2016 6:56:17 下午 org.apache.catalina.core.ApplicationContext log信息: SessionListener: contextInitialized()七月 25, 2016 6:56:25 下午 org.apache.catalina.core.ApplicationContext log信息: ContextListener: attributeAdded(&apos;org.apache.jasper.compiler.TldLocationsCache&apos;, &apos;org.apache.jasper.compiler.TldLocationsCache@44608238&apos;)七月 25, 2016 6:56:25 下午 org.apache.coyote.AbstractProtocol start信息: Starting ProtocolHandler [&quot;http-bio-8080&quot;]七月 25, 2016 6:56:25 下午 org.apache.coyote.AbstractProtocol start信息: Starting ProtocolHandler [&quot;ajp-bio-8009&quot;]七月 25, 2016 6:56:25 下午 org.apache.catalina.startup.Catalina start信息: Server startup in 21375 ms","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"tomcat","slug":"CS/web/back-end/tomcat","permalink":"http://yoursite.com/categories/CS/web/back-end/tomcat/"}]},{"title":"","date":"2018-06-04T09:06:41.741Z","path":"wiki/CS/web/-back-end/tomcat/websocket/","text":"## WebSocket 是web客户端和服务器之间新的通讯方式， 依然架构在HTTP协议之上。使用WebSocket连接， web应用程序可以执行实时的交互， 而不是以前的poll方式。 参考http://colobu.com/2015/02/27/WebSockets-tutorial-on-Wildfly-8/","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"tomcat","slug":"CS/web/back-end/tomcat","permalink":"http://yoursite.com/categories/CS/web/back-end/tomcat/"}]},{"title":"","date":"2018-06-04T09:06:41.740Z","path":"wiki/CS/web/-back-end/cache/","text":"关键词CDN网络缓存技术Cache服务器网页缓存数据缓存 百度登录主页背景图片, Status Code:200 OK (from memory cache) 有些 Status Code:200 OK (from disk cache) (ctrl+f5也是同样的response) 1Cache-Control:max-age=86400 bluescanhttp://9.186.100.11:8080/bluescan/ Status Code:304 Not Modified ctrl+f5, 变成了 Status Code:200 OK","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"}]},{"title":"","date":"2018-06-04T09:06:41.740Z","path":"wiki/CS/web/-back-end/disqus/","text":"云端评论中心..可以将你对一篇文章的评论存储在disqus的中心,然后通过js脚本调用这些评论. disqus评论存储在哪？云存储，存在disqus网站， disqus怎样将评论和相应的页面进行绑定? 为什么加载有问题？被墙了 如何加载disqus评论？ 调用api https://disqus.com/api/3.0/discovery/listTopPost.json? 如何导入，导出评论？ 如何安装？ 说是安装，其实就是把一段js迁入到网页 嵌入到哪？对于一般的博客来说，评论都是放在文章页面的。嗯。你懂的。 对于 GitHub Page 来说，你可以把上面这段代码，嵌入到你的 layout 里面的 post.html 里面，放在最后就好了 ## 需要填写的地方分别是：Site URL，Site Name，Site Shortname。 注意：这3个都是必须要填写的，而且，短域名将会在最后的 install 中使用到。 为什么必填URL?本地双击打开的html不可以评论吗？","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"}]},{"title":"","date":"2018-06-04T09:06:41.740Z","path":"wiki/CS/web/-back-end/cookie/","text":"材料http://blog.csdn.net/collonn/article/details/5698906http://www.jianshu.com/p/1361d578035d https://www.kancloud.cn/digest/dcluster/130514http://blog.csdn.net/qh_java/article/details/45955923http://www.cnblogs.com/joeliu/archive/2008/01/10/1033232.htmlhttp://zhanjia.iteye.com/blog/871021 Jsessionid只是tomcat的对sessionid的叫法，其实就是sessionid；在其它的容器也许就不叫jsessionid了。 ——————-最新更新——– Terry_Huang 回复： 给你举个更生动的例子，以前大学的时候，经常去大卡司去喝奶茶，每喝一杯，都可以得到一个印花（第一次喝的时候他会给你个积分卡片)，集齐6个印花之后，就可以免费获得一杯奶茶。这样子，印花的信息是保存在客户的积分卡上，你如果不怀好意的话，就自己搞几个神似的印花去骗奶茶喝吧。哈哈，这样子是不是更符合在客户端端保持状态。而拿银行卡去银行取钱，我们的卡只需要保存一个卡号，更多的信息是保存在服务器中，这样也比较符合服务器端保持状态。 示例12306登录界面 首次访问 https://kyfw.12306.cn/otn/ 请求1： https://kyfw.12306.cn/otn response返回了Set-Cookie:BIGipServerotn=904921610.50210.0000; path=/请求2： https://kyfw.12306.cn/otn/ request携带了一个cookie: BIGipServerotn， response返回了：Set-Cookie:JSESSIONID=0A02F035C45CDC859EBDE34EEF3022176D1CAB3240; Path=/otn 浏览器存储了两个cookie: BIGipServerotn, JSESSIONID后面再访问domain: kyfw.12306.cn默认都会携带这两个cookie吗？ 貌似有些不携带 登陆页面https://kyfw.12306.cn/otn/login/init请求1：https://kyfw.12306.cn/otn/login/init request携带以上两个cookie，response返回Set-Cookie:__NRF=D448883EA47A42ADFF201315C5A47B59; Path=/otn 请求2： https://kyfw.12306.cn/otn/passcodeNew/getPassCodeNew?module=login&amp;rand=sjrand&amp;0.5879014782091059 response返回Set-Cookie:current_captcha_type=Z; Path=/作用获取验证码图片+刷新验证码 请求3： 比较神奇https://kyfw.12306.cn/otn/resources/js/newpasscode/captcha.pngrequest header中携带了 Cookie:JSESSIONID=0A02F00DFC2165793ED24D3E6A322D73BB663555CD; __NRF=87982EA902E055A62B34594F412D6FD4; _jc_save_detail=true; _jc_save_fromStation=%u5FB7%u5DDE%2CDZP; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_fromDate=2017-02-05; _jc_save_toDate=2017-02-03; _jc_save_wfdc_flag=dc; BIGipServerotn=233832970.64545.0000 浏览器存储了四个cookie: BIGipServerotn, JSESSIONID， __NRF， current_captcha_type 验证码输入错误。 请求1： https://kyfw.12306.cn/otn/passcodeNew/checkRandCodeAnsynSet-Cookie:JSESSIONID=0A01D967C46F93749DA8E343362706EA493AB0274E; Path=/otnSet-Cookie:BIGipServerotn=1742274826.50210.0000; path=/ 请求2：https://kyfw.12306.cn/otn/passcodeNew/getPassCodeNew?module=login&amp;rand=sjrand&amp;0.8915860204592649刷新验证码，请求中携带刷新后的cookie。 登陆成功 浏览器中仍然是4个cookie。Cookie:__NRF=F178222DE155029CE8311D24270DABF5; JSESSIONID=0A01D95CFCA56AD5853ADCBFADD0263D7273CB784F; BIGipServerotn=1557725450.64545.0000; current_captcha_type=Z 实现检查浏览器，发现kyfw.12306.cn包含6个cookie(不包含JSESSIONID) https://kyfw.12306.cn/otn/ request header:Cookie:JSESSIONID=0A02F00DFC2165793ED24D3E6A322D73BB663555CD; _jc_save_detail=true; _jc_save_fromStation=%u5FB7%u5DDE%2CDZP; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_fromDate=2017-02-05; _jc_save_toDate=2017-02-03; _jc_save_wfdc_flag=dc; BIGipServerotn=233832970.64545.0000 response header: Set-Cookie:__NRF=87982EA902E055A62B34594F412D6FD4; Path=/otn — 后面再访问，就会看到cookie多了个属性__NRF Cookie:JSESSIONID=0A02F00DFC2165793ED24D3E6A322D73BB663555CD; __NRF=87982EA902E055A62B34594F412D6FD4; _jc_save_detail=true; _jc_save_fromStation=%u5FB7%u5DDE%2CDZP; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_fromDate=2017-02-05; _jc_save_toDate=2017-02-03; _jc_save_wfdc_flag=dc; BIGipServerotn=233832970.64545.0000 ##http://localhost:8080/bluescan/ username: “Composer2”,psw: “1c8bd771b24c16738eb467f35920949c”,","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"}]},{"title":"","date":"2018-06-04T09:06:41.740Z","path":"wiki/CS/web/-back-end/tomcat/jsp/","text":"test.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;%@ page contentType=\"text/html;charset=UTF-8\" %&gt;&lt;%out.print(\"将该文件编译，作为一个servlet\");out.println(this.getClass().getName() + \"&lt;br&gt;\"); // org.apache.jsp.test_jsp (文件名是test.jsp)out.println(request.getClass().getName() + \"&lt;br&gt;\"); // org.apache.catalina.connector.RequestFacade 跟 servlet中的一样(这是org.apache.catalina.connector.Request的门面，org.apache.coyote.Request的wrapper)out.println(response.getClass().getName() + \"&lt;br&gt;\"); // org.apache.catalina.connector.ResponseFacade 跟 servlet中的一样// 注意区分这三种输出方式out.println(response.getWriter().getClass().getName() + \"&lt;br&gt;\"); // org.apache.catalina.connector.CoyoteWriterout.println(out.getClass().getName() + \"&lt;br&gt;\"); // org.apache.jasper.runtime.JspWriterImplresponse.getWriter().println(\"print from response.getWriter()\" + \"&lt;br&gt;\");//response.getWriter().close();// response.getOutputStream().write(\"print from response.getOutputStream() &lt;br&gt;\".getBytes()); // 这个输出会覆盖掉其他的输出，而且不能喝getWriter()同时出现//out.println(request.getSession().getClass().getName() + \"&lt;br&gt;\");out.println(session.getClass().getName() + \"&lt;br&gt;\"); // org.apache.catalina.session.StandardSessionFacade =request.getSession()out.println(request.getServletContext().getClass().getName() + \"&lt;br&gt;\");out.println(application.getClass().getName() + \"&lt;br&gt;\"); // org.apache.catalina.core.ApplicationContextFacade =request.getServletContext()out.println(config.getClass().getName() + \"&lt;br&gt;\"); // org.apache.catalina.core.StandardWrapperFacadeout.println(pageContext.getClass().getName() + \"&lt;br&gt;\"); // org.apache.jasper.runtime.PageContextImplout.println(page.getClass().getName() + \"&lt;br&gt;\"); // org.apache.jsp.test_jsp//out.println(Exception.getClass().getName() + \"&lt;br&gt;\");out.println(\"&lt;br&gt;methods:&lt;br&gt;\");for(java.lang.reflect.Method m:this.getClass().getMethods()) &#123; out.println(m.getName() + \"&lt;br&gt;\");&#125;out.println(\"&lt;br&gt;fields:&lt;br&gt;\");for(java.lang.reflect.Field f:this.getClass().getFields()) &#123; out.println(f.getName() + \"&lt;br&gt;\");&#125;out.println(\"&lt;br&gt;DeclaredFields:&lt;br&gt;\");for(java.lang.reflect.Field f:this.getClass().getDeclaredFields()) &#123; out.println(f.getName() + \"&lt;br&gt;\");&#125;String a=\"this is a string variable\";for(int i=0;i&lt;10;i++) &#123; out.println(i+\" in loop\\n\\n\");&#125;%&gt;Date:&lt;%=new java.util.Date()%&gt; dd","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"},{"name":"tomcat","slug":"CS/web/back-end/tomcat","permalink":"http://yoursite.com/categories/CS/web/back-end/tomcat/"}]},{"title":"","date":"2018-06-04T09:06:41.739Z","path":"wiki/CS/web/-back-end/REST设计风格/","text":"远程调用API 分布式对象（Distributed Objects，简称DO） CORBA/RMI/EJB/DCOM/.NET Remoting 远程过程调用（Remote Procedure Call，简称RPC） SOAP/XML-RPC/JSON-RPC/Hessian/Burlap/Flash AMF/Dubbo RPC 基于Google Protocol Buffer数据交换格式的各种RPC协议 基于Apache Thrift的各种RPC协议，例如唯品会的OSP 表述性状态移交（Representational State Transfer，简称REST） 将HTTP协议真正作为一种 应用协议 来使用，不再需要基于HTTP的各种RPC协议 RESTful API——符合REST架构风格要求的API 对于HTTP的常见误解 浏览器只支持GET/POST方法 HTML表单仅支持GET/POST方法，但是可以通过附加参数(例如_method)的方式模拟PUT/DELETE请求 XMLHttpRequest对象GET/POST/PUT/DELETE 4种方法均可支持 未遵循HTTP协议的指导误用HTTP方法 GET方法：安全的、幂等的 POST方法：不安全的、不幂等的 PUT/DELETE方法：不安全的、幂等的 过度使用GET方法 敏感信息位于URL中，不够安全 容易受到爬虫的伤害 过度使用POST方法 例子：SOAP等RPC风格的调用协议 一个方法承担了过多职责 没有充分利用HTTP的优势 HTTP是一种RPC风格的协议 事实：HTTP其实是一种REST风格的协议 统一接口是REST与RPC两种风格协议的主要区别 HTTP是一种“传输”协议（transport protocol） 被错误翻译为“超文本传输协议” 事实：HTTP其实是一种“移交”协议（transfer protocol）。TCP才是传输协议，对传输这件工作已经做的很好了。 传输协议和移交协议的区别 传输协议做的是底层搬运比特之类的苦力活，不包含操作的语义 移交协议做的事情比传输协议更高级，包含了操作的语义 HTTP不具备互操作性 因此需要在HTTP之上设计SOAP这种“简单”的协议（事实上很复杂） 事实：充分利用好HTTP，已经能够得到足够好的互操作性，在很多场合甚至比使用SOAP更好 对于REST的常见误解 REST只适用于面向机器的Web API，不适用于面向人类的Web App 事实：REST在Web上是普遍适用的 直接使用HTTP的API就是RESTful API 事实：在SOAP与真正的RESTful API之间还有广大的中间地带 只达到Richardson成熟度模型第0级的API不是RESTful API REST只不过是更漂亮的URI设计 事实：这仅仅是REST的一个外在特征而已 HATEOAS并不重要 事实：这两个方面都是REST架构风格的核心特征 至少需要实现统一接口，否则可以确定是冒牌的RESTful API 统一接口只能使用HTTP实现 事实：HTTP仅仅是实现REST架构风格的一种方式 其他符合REST统一接口的例子：扩展了HTTP协议的WebDAV协议 示例solr的api设计1234/select?/update/core? tomcat example的url设计http://127.0.0.1:8983/solr/admin/form.jsp bluescan的设计 一点都不restful 资源有什么？manager get docs?docid= &amp; userid= post docs? //add或者upload操作 get clauses?docid= users, database, 引入delete 问题集注意区分url设计和api设计。restful指的api。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"-back-end","slug":"CS/web/back-end","permalink":"http://yoursite.com/categories/CS/web/back-end/"}]},{"title":"【机器翻译】字符级机器翻译 - BPE","date":"2018-05-31T16:00:00.000Z","path":"wiki/ML/app/nlp/trick/trick-nlp/OOV-字符级机器翻译/","text":"2016 Neural Machine Translation of Rare Words with Subword Units 解决的问题OOV问题 中文也存在OOV问题。比如分词以后 核心思想其核心思想是语料库中的高频词作为整体出现的可能性大，因此不对其进行切分，而对低频词进行切分，由此增加稀疏词中子词的共现次数。 encoding rare and unknown words as sequencesof subword units. 本文讨论了subword的不同分割技巧： 直接采用char，信息损失较多 character n-gram models segmentation based on the byte pair encoding compression algorithm 规避大词典。原来都是先把一个数据集中所有单词找出来，把最常用的一些（如90%）做成一个大词典，显然这是冗余的，words和word完全没必要区分。动不动就是50K的单词表，非常耗内存，在像Czech这类语言上更加不行。关键是冗余不优雅。很多研究者都注意到这个问题： subword，就是统计一下符号的频率，如“est”可能是一个符号，能组成“w est,b est”等词，因此称为subword。我觉得还是不够自然，而且效果并不是很好。 Hybrid Word-Character Models，相当于把未知的词训练成RNN小单元，据说华为很早就申请专利了。我表示，不能有word。 Junyoung Chung提出的不需要显式分隔的模型。提出bi-scale的RNN，我觉得很有意思，但我有个疑问，这跟base的RNN有什么区别？论文中也显示，确实差不多。我不知道为什么性能那么好。由于没有训练时间、训练所用内存等更多信息我无法作出判断。 还有Wang Ling提出的，但是完全不是NMT，需要借助IBM model来对齐和分层训练，而且效果不好。 related work 2016 年，Rico Sennrich 和 Barry Haddow 等人提出了 Byte Pair Encoding (BPE)的方法，将原有的单词拆解成了更小单元的高频词进行翻译。 BPE 方法在多大程度上解决了未登录词翻译的问题。对未登录词的翻译精准度达到了 45%左右， 参考 subword-nmt | github","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"trick","slug":"ML/app/nlp/trick","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/"},{"name":"trick-nlp","slug":"ML/app/nlp/trick/trick-nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/trick/trick-nlp/"}]},{"title":"音频文件压缩","date":"2018-05-30T16:00:00.000Z","path":"wiki/-audio/基础知识/音频压缩/","text":"压缩时域压缩8000采样不就好了 频域压缩","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"基础知识","slug":"audio/基础知识","permalink":"http://yoursite.com/categories/audio/基础知识/"}]},{"title":"启动引导程序 grub","date":"2018-05-28T16:00:00.000Z","path":"wiki/CS/OS/-linux/linux kenel/1.内核引导/grub/","text":"前言Boot Loader 是电脑启动时运行的第一个程序,它负责装载内核并将控制权转交。内核再初始化操作系统的其它部分。官方所称的 GRUB 是软件的第二版,即 GRUB2 GRUB 命名约定GRUB 对于硬盘和分区自有一套命名规则（hdN,M），其中 N 是硬盘数，M 是分区号。硬盘数 N 从 0 开始计数，分区数需要区别对待——主分区从 1 开始计数而扩展分区从 5 开始计数。 磁盘编号Grub在表示方式上并不区分IDE硬盘、SATA硬盘和SCSI硬盘等，所有硬盘会被识别为hd#，”#”是从0开始的硬盘编号，而软盘被类似地识别为fd#。 分区编号通常情况下，在使用MBR格式的分区表的电脑中，最多有四个主分区，其中一个可以是扩展分区，内含若干逻辑分区。装有Windows的硬盘中，通常C盘是主分区，其它盘是扩展分区下的逻辑分区。 Grub 2的分区编号从1开始。如(hd0)的第一个主分区(hd0, msdos1)，而第一个逻辑分区从(hd0, msdos5)开始计数。 为什么这里扩展分区从 5 计数，可以查看 mbr 的相关知识。早期版本的 GRUB 是什么计算磁盘和分区数，我忘记了，不过，大家就记住新的就好啦。 Grub配置文件GRUB 会将一些数据写入硬盘的第一个物理扇区。这一部分不属于任何一个操作系统，在启动时，该部分数据激活，然后寻找 Grub 的模块，Grub 模块的默认位置为 /boot/grub/。 既然不属于任何一个操作系统，为何操作系统有权限修改grub配置文件？ 1cat /etc/default/grub 1234567891011121314151617181920212223242526272829303132333435# If you change this file, run 'update-grub' afterwards to update# /boot/grub/grub.cfg.# For full documentation of the options in this file, see:# info -f grub -n 'Simple configuration'GRUB_DEFAULT=0#GRUB_HIDDEN_TIMEOUT=0#GRUB_HIDDEN_TIMEOUT_QUIET=trueGRUB_TIMEOUT=15GRUB_RECORDFAIL_TIMEOUT=60GRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`GRUB_CMDLINE_LINUX_DEFAULT=\"nomodeset net.ifnames=0\"GRUB_CMDLINE_LINUX=\"\"# Uncomment to enable BadRAM filtering, modify to suit your needs# This works with Linux (no patch required) and with any kernel that obtains# the memory map information from GRUB (GNU Mach, kernel of FreeBSD ...)#GRUB_BADRAM=\"0x01234567,0xfefefefe,0x89abcdef,0xefefefef\"# Uncomment to disable graphical terminal (grub-pc only)#GRUB_TERMINAL=console# The resolution used on graphical terminal# note that you can use only modes which your graphic card supports via VBE# you can see them in real GRUB with the command `vbeinfo'#GRUB_GFXMODE=640x480# Uncomment if you don't want GRUB to pass \"root=UUID=xxx\" parameter to Linux#GRUB_DISABLE_LINUX_UUID=true# Uncomment to disable generation of recovery mode menu entries#GRUB_DISABLE_RECOVERY=\"true\"# Uncomment to get a beep at grub start#GRUB_INIT_TUNE=\"480 440 1\" Grub加密与字符界面分辨率调整重启后进入grub rescue什么原因？怎样解决？参考 archlinux - grub GNU GRUB 使用 GRUB 设置启动过程 | 《Linux From Scratch》第八章","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"OS","slug":"CS/OS","permalink":"http://yoursite.com/categories/CS/OS/"},{"name":"-linux","slug":"CS/OS/linux","permalink":"http://yoursite.com/categories/CS/OS/linux/"},{"name":"linux kenel","slug":"CS/OS/linux/linux-kenel","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/"},{"name":"1.内核引导","slug":"CS/OS/linux/linux-kenel/1-内核引导","permalink":"http://yoursite.com/categories/CS/OS/linux/linux-kenel/1-内核引导/"}]},{"title":"常见的比特币命令","date":"2018-05-28T16:00:00.000Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-bitcoin-cli命令/","text":"钱包的概要信息1234567891011121314$ bitcoin-cli getwalletinfo&#123; \"walletname\": \"wallet.dat\", \"walletversion\": 159900, \"balance\": 0.00000000, # 已确认的账户余额，使用BTC单位 \"unconfirmed_balance\": 0.00000000, # 支付到该钱包，但尚未确认的交易的总额 \"immature_balance\": 0.00000000, # 挖矿奖励金额需要等待100次确认后才能使用，在此之前，这部分金额都是immature状态。 \"txcount\": 0, # 钱包里涉及的交易总个数 \"keypoololdest\": 1527560439, # 是指最早生成的key的unix时间戳 \"keypoolsize\": 1000, # 允许预先生成的公钥、私钥对的个数。私钥参与交易的目的是提升安全性和反跟踪。 \"keypoolsize_hd_internal\": 1000, # 用于内部使用（如找零）的钱包地址个数。 \"paytxfee\": 0.00000000, \"hdmasterkeyid\": \"3850de05ae997e53dc5271f4e889aa5f2a6b213b\"&#125; getblockchaininfo这个命令用来显示比特币网络概览 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758$ bitcoin-cli getblockchaininfo&#123; \"chain\": \"main\", \"blocks\": 373185, # 已经下载了329136个block，下载进度=373185/524904=71%。 # 截止2018/05/29 11:30，一共挖了524904个block。 # 可以在该地址查看最新数据。https://blockexplorer.com/api/status?q=getBlockCount \"headers\": 524904, # 当前最可信区块的ID，即当前最长链的最后一个有效区块。它可能是被挖掘出来的最新块，也可能不是—这取决于被挖掘出来的最新块是否在正确的分叉上。 \"bestblockhash\": \"0000000000000000056ff4b4bb1579533f3e901e90f6f4966104811df4705823\", \"difficulty\": 56957648455.01001, # 当前块的难度值 # 每个区块都包含着一个unix time时间戳。只有当这个时间戳大于mediantime，并且小于某个调整后的网络时间[1]时，这个区块才会被确认。 \"mediantime\": 1441481425, # 过去11个区块的中值时间。注意这里引用的区块是最长链上已确认的区块。 # 在一个新安装的Full Node上，由于区块首先要下载完成才能进行确认，而确认时间较快，所以可以把这个比例当成区块下载完成进度。 # 为什么这个比例不等于blocks/headers？ \"verificationprogress\": 0.2479860418344433, # 已确认的交易占比，为何这么低？ \"initialblockdownload\": true, \"chainwork\": \"00000000000000000000000000000000000000000009e65a3d8485126dc3d47a\", \"size_on_disk\": 50381675110, # \"pruned\": false, # 如果处于pruned模式，则下载的区块可以被删除以节省磁盘空间。 \"softforks\": [ # 比特币分叉信息 &#123; \"id\": \"bip34\", \"version\": 2, \"reject\": &#123; \"status\": true &#125; &#125;, &#123; \"id\": \"bip66\", \"version\": 3, \"reject\": &#123; \"status\": true &#125; &#125;, &#123; \"id\": \"bip65\", \"version\": 4, \"reject\": &#123; \"status\": false &#125; &#125; ], \"bip9_softforks\": &#123; \"csv\": &#123; \"status\": \"defined\", \"startTime\": 1462060800, \"timeout\": 1493596800, \"since\": 0 &#125;, \"segwit\": &#123; \"status\": \"defined\", \"startTime\": 1479168000, \"timeout\": 1510704000, \"since\": 0 &#125; &#125;, \"warnings\": \"\"&#125; 未验证的交易存在哪？存在局部节点验证后的交易存在哪？被广播，并加入全局block chain getblockhash每个区块是通过其id来标识的，每个id都是一个256位的hash。这个id非常不方便交流。同时我们知道，每一个区块都有一个高度值，而对于主链来说，每一个高度值都对应着惟一一个区块。 我们可以通过这个命令来查找创世块、第一个区块（由中本聪在赫尔辛基的一个服务器上挖出）和其它任意高度的区块的id，并进而得到该区块的信息。 1234$ bitcoin-cli getblockhash 0000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f$ bitcoin-cli getblockhash 100000000000c937983704a73af28acdec37b049d214adbda81d7e2a3dd146f6ed09 getblock根据区块的ID，可以查看其详细信息。一般有一下三种方式； bitcoin-cli getblock命令 web api的方式，例如 https://blockchain.info/rawblock/00000000839a8e6886ab5951d76f411475428afc90947ee320161bbf18eb6048 web界面的方式，例如 https://www.blockchain.com/zh-cn/btc/block/000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f 创世区块（高度为0）创世区块指区块链上的第⼀个区块，⽤来初始化相应的加密货币。 123456789101112131415161718192021222324252627$ bitcoin-cli getblock 000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f&#123; \"hash\": \"000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f\", # 哈希值，也是区块id，256字节。上一区块是000...000 \"confirmations\": 384844, # 该区块已经过多少次确认。如果该区块属于best chain，则此值等于全链高度，也是本块的深度。 \"strippedsize\": 285, \"size\": 285, # 本块的大小，0.285 kB \"weight\": 1140, \"height\": 0, # 高度为0 \"version\": 1, \"versionHex\": \"00000001\", \"merkleroot\": \"4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b\", # 默克尔树，一种用来表达链上历史交易记录的数据结构，32 Bytes。 \"tx\": [ \"4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b\" ], # 交易记录 \"time\": 1231006505, # 时间戳，2009-01-03 18:15:05 \"mediantime\": 1231006505, \"nonce\": 2083236893, # 随机数，也就是 PoW 要计算的数 \"bits\": \"1d00ffff\", # 网络难度 \"difficulty\": 1, # 难度系数。2018.09.01的难度已经是 6,727,225,469,722.53 \"chainwork\": \"0000000000000000000000000000000000000000000000000000000100010001\", # 这是什么鬼？ \"nextblockhash\": \"00000000839a8e6886ab5951d76f411475428afc90947ee320161bbf18eb6048\" # 最后一个block的next为空&#125;# 1. 为什么没保存上一个区块 previousblockhash？只保存了下一个的？# 2. 新区块奖励: 50BTC。记录在哪？# 3. 计算目标 486604799。记录在哪？# 4. 重量: 0.896 kWU。记录在哪？# 5. 总输出量、预计交易量、保存在哪？ 也可以通过浏览器查看 对应的交易记录 https://www.blockchain.com/zh-cn/btc/tx/4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b 12 没有输入(新生成的比特币)新区块奖励 0 区块#1https://www.blockchain.com/zh-cn/btc/block/00000000839a8e6886ab5951d76f411475428afc90947ee320161bbf18eb6048 最新区块可以在 https://www.blockchain.com/zh-cn/explorer 查看 这样得到的信息并不包含交易信息，也即我们得到的是区块的头。要得到全部的信息，需要传入verbosity参数，当参数值为2时，即可得到全部信息：","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"gpu挖矿","date":"2018-05-28T16:00:00.000Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-gpu挖矿/","text":"挖矿算法目前的挖矿机理都是基于 PoW（proof-of-work, 工作量证明）的，它通过大量简单的重复运算产出一个符合要求的结果，并且这个结果很容易验证。 举个例子，为了通过考试不挂科，你需要不断地大量练习，才能解出一道题，然而对于阅卷而言只需和标准答案对比一下就完了，几乎不需要成本。PoW 的技术原理主要通过 hash 实现，这里先不讨论。 由于挖矿过程是分别在全球各地执行，而网络同步有延时，有可能出现多个矿工同时抢到了某一高度（可理解为区块序号）的区块，在全网同步时就会出现冲突，这时有个规则是，谁后面接的区块多就以谁的为准，其它的作废。 挖矿设备挖矿的过程，简单地说，就是不断的执行HASH算法，类似穷举的方式去碰答案。这个过程完全是个烧CPU的过程。 挖矿设备主要经历了从 CPU -&gt; GPU -&gt; FPGA -&gt; ASIC 的变化，挖矿效率也是越来越强大。 与 GPU 相比，CPU 包含多数（对于挖矿计算而言）无用的控制单元等结构，因此性价比很低。这就好比让两个大学教授和 100 个小学生一起计算一些 10 以内的加减法，显然小学生们计算的更快，教授就是大材小用了。 FPGA 的芯片生产困难，因此生存时间很短。在将 FPGA 中不需要的逻辑实现删掉后， ASIC 矿机问世。 ASIC 矿机（也就是目前我们所说的矿机）是为挖矿量身定制的，因此挖矿速度非常快（价格也比较高），除了挖矿什么都做不了。一旦遇上“矿难”，那你面对的就是一堆废铁，而显卡至少还有其他用处。 矿池现在致力于挖矿的组织都要使用专业的挖矿机器（一个装满显卡的机器），而且是千台以上的矿机组成矿场来挖矿。但是这么多机器各自挖效率低，还容易自已抢自已生意，咋办呢？于是出现了一个新的挖矿模式–矿池。矿池是一个统筹算力的服务组织，挖矿机可以加入矿池来挖矿，相当于N台矿机都在算同一个区块，这样就避免了冲突，加快了挖矿的速度。 加入矿池相当于选择组队挖矿，因为一个人可能很难挖到一个币，但是在矿池中就可以按照你的算力占全矿池的算力比例来给你分配收益。这就好比一个人买彩票几乎没啥希望，但是如果规定一亿个人一起买，中奖的平分的话，这样收益就稳定多了。当然，矿池会收取一定的费用 挖矿客户端用比特币钱包就可以挖矿，只要简单地打开其中的挖矿开关就可以，这也是最原始的挖矿工具 我采用的https://github.com/tpruvot/ccminer 参考https://www.jianshu.com/p/d0f69961e7f9","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"区块链数据文件","date":"2018-05-28T16:00:00.000Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/-数据文件/","text":"在Linux中bitcoind的数据存在.bitcoin目录下，该目录下有以下的文件。 123456789101112131415161718192021222324252627282930313233343536$ cd .bitcoin$ tree|-- banlist.dat|-- bitcoind.pid # bitcoind运行的进程文件|-- blocks # 区块链数据文件 181G| |-- blk00000.dat...| |-- blk01271.dat| |-- index| | |-- 000197.ldb| | |-- 000198.ldb...| | |-- CURRENT| | |-- LOCK| | -- MANIFEST-000412| |-- rev00000.dat| |-- rev00001.dat...|-- chainstate # 区块链状态的数据库使用LevelDB存储 2.8G| |-- 147873.ldb...| |-- 151713.ldb| |-- CURRENT| |-- LOCK| -- MANIFEST-151563|-- debug.log # 运行时的日志文件|-- fee_estimates.dat|-- mempool.dat|-- peers.dat -- wallets # 钱包文件 1.4M |-- database | -- log.0000000001 |-- db.log -- wallet.dat5 directories, 4196 files","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"比特币挖矿教程 - ubuntu","date":"2018-05-28T16:00:00.000Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/挖矿实战-linux/","text":"下载比特币核心钱包(Bitcoin Core wallet)123sudo add-apt-repository ppa:bitcoin/bitcoinsudo apt updatesudo apt install bitcoin-qt bitcoind core只是个钱包，不是挖矿的， 比特币钱包的图形界面1bitcoin-qt 首次运行下载整个链，有些人要一两周。我运行在下载超快，4个小时。美国服务器。 为什么这么快？性能好？网络好？bitcoin进行过优化？ GPU: Tesla K80 * 4，单卡显存12205MiB 12345678topTasks: 335 total, 1 running, 334 sleeping, 0 stopped, 0 zombie%Cpu(s): 3.9 us, 0.5 sy, 0.0 ni, 95.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 65859336 total, 4927116 free, 1657532 used, 59274688 buff/cacheKiB Swap: 1998844 total, 1997836 free, 1008 used. 63587368 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND13981 root 20 0 3299756 1.189g 120768 S 119.6 1.9 30:05.16 bitcoin-qt 非图形化运行也可以非图形化运行1234# 前台运行bitcoind# 后台运行bitcoind --daemon 运行的时候我们可以使用命令查看bitcoind的运行情况: 比特币网络也可以直接查看debug.log,监控当前运行情况。 12cd $HOME/.bitcointail -f debug.log 备份钱包这三个很重要 比特币钱包地址 比特币私钥 比特币公钥 这三个存储在wallet.dat中，这个文件丢失了，比特币也就没了。 三者关系钱包生成私钥→私钥生成公钥→公钥生成公钥哈希→公钥哈希生成地址→地址用来接受比特币。（公钥不能推导出私钥） 地址可以公开，因为它是用来接受比特币的，公钥和公钥哈希也可以公开，没啥问题。私钥绝对不能公开，因为有了它本质上就取得了对应比特币的所有权。 比特币钱包地址比特币地址是一串由26位到34位字母和数字字符串组成的。看上去像一堆乱码一样，说白了这个就像你的银行卡卡号一样，可以有N个这样的账户。通过区块链查可以查每个比特币地址的所有转账记录，公开透明。 如果购买的比特币数额较大，建议大家提到自己的钱包里，不要长期放在交易所里。对于新手建议还是创建一个比特币钱包比较安全。 如何获得比特币地址？点击【收币】就可以看到自己的地址了。 在“接收”(Receive)选项卡，我们可以获取自己的钱包地址。直接点击“请求付款”(Request Payment)，将生成一个新的地址。你可以将这个地址发送给别人，让他们向你支付比特币。 我的地址 1aa 每次点击“请求付款”都会重新生成新的地址。 尚未请求地址，挖到的矿会存在哪？钱包地址删除或丢失，钱包的钱就没了吗？还能找到。只要你用过的地址 那还是你的。 一个私钥可以对应很多公钥。公钥就是你的钱包地址，它是两个大质数的乘积。私钥就是其中的一个大质数。所以私钥和任何其它大质数的乘积都可以作为你的公钥，就是你的地址。它们都可以被你的私钥打开。 私钥掉了，钱包的钱就消失了吗？消失是没消失，但永远不会流通了。所以比特币会通缩。 根据钱包地址，能查到所有者吗？能查到国家吗？钱包没有国家的属性，你在任何国家都可以使用任何地址。 如果地址有过交易，可以查这笔交易是从哪里广播的。如果主人没有隐藏自己，这个广播的ip就是他的地址。 比特币密码忘了怎么办？ 钱包地址、公钥掉了，无所谓 私钥忘了，永久丢失 钱包加密的密码丢失，永久丢失 if you encrypt your wallet and lose your passphrase, you will lose all of your bitcoins 假如我找到一个私钥，有很多币，拿去卖钱是不是也没有任何人能去告我偷或者不当得利之类的？采用违法行为所得肯定会遭遇调查。但是由于加密货币的匿名性，无法查找到你头上。但是你通过黑客方式获取密钥，那还是可以追踪到你的 fbi已经收缴过一次大额比特币了 比特币匿名性较弱，追踪起来有难度，但是还是可以尝试追踪的，利益关系大的话，追到的可能性也大。 “比特币这么贵了，我一个都买不起呀？”实际上，比特币最小单位并不是 1，而是“聪”，没错，就是中本聪的“聪”。1 BTC = 1 亿聪，也就是说最小单位是十的负八次方 私钥 公钥导入已有钱包 或区块链1mv ~/.bitcoin ~/.bitcoin.backup 没看懂的Regular people don’t run a full node. regular people just want to maintain a bitcoin wallet. it doesn’t need the full blockchain to be downloaded. 参考 Install Bitcoin Wallet on Ubuntu","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"比特币挖矿攻略","date":"2018-05-28T16:00:00.000Z","path":"wiki/block-chain/虚拟货币/币种/比特币-BTC/-挖矿/比特币挖矿攻略/","text":"比特币矿池比特币挖矿的用户数量非常庞大，而每10分钟产出的比特币又十分有限，形成了千万人抢1个区块的情况出现，所以，如果你用个人电脑单独挖矿，有可能一整年也抢不到一个区块，在这种情况下，人们就想出了一种组队挖矿的方法，所谓的组队挖矿，就是我们现在要讲述的矿池(mining pool)。 矿池是一个通过特定算法而设计的服务器，所有连接到矿池服务器的用户，会组队进行挖矿，个人电脑的性能虽然渺小，但是成千上万的人进行组队挖矿，总体性能就会变得十分强大，在这种情况，挖矿的成功率会大大提升，一旦矿池中的队伍成功制造了一个区块，那么所有队伍中的人会根据每个人的电脑性能进行分红。比如：1000人在同一个矿池中挖矿，挖出一个区块后，这个区块产生的N个比特币的报酬，会根据这1000个人的电脑性能进行分红。如果你的电脑性能强劲，也许会分到100分之1，如果性能落后，也可能会分到10000分之1。 在这种情况，矿池的开发者一般会对每个用户收取1%~3%的费用作为手续费，但由于这种方法让大家更稳定得获得比特币，几乎所有人都会选择矿池挖矿，而不是单独挖矿。 在上文挖矿教程中讲到的比特时代免费提供的矿池，采用P2Pool技术架构，不向用户收取任何费用，是主流矿池中的一个，另外还有BTC Guild和deepbit等矿池，人气也是非常旺的。虽然每个矿池的设计都不太一样，但是使用方法基本上是雷同并且简单的，因此本教程不再做进一步的讲述，大家可以自行摸索。即使小编在前面的教程中已经默认给大家配置了比特时代提供的矿池和端口，但为了让大家对矿池有更深入的了解，这里再给大家介绍几个主流的矿池供大家选择： 比特矿池(免费，小编推荐) | BitCoin.CZ(适合新手) | BTC Guild(最老牌) | deepbit(稳定高效) | f2pool(国内) # 只要电脑性能越好，挖矿的效率就越高。而由于比特币的算法原因，其实就是显卡核心的性能越好，挖矿的效率越高。下面本教程给大家罗列一下经过测试以后，主流显卡核心的挖矿效率进行对比： ATI系列显卡HD 6570 | 速率 78.5 MHash/SHD 6670 | 速率 96.9 MHash/SHD 6750 | 速率 156.3 MHash/SHD 6770 | 速率 182.3 MHash/SHD 6790 | 速率 182.5 MHash/SHD 5870 | 速率 343.2 MHash/SHD 6950 | 速率 299.3 MHash/SHD 6970 | 速率 355.1 MHash/SHD 6990 | 速率 714.8 MHash/SHD 7950 | 速率 453.7 MHash/SHD 7970 | 速率 566.2 MHash/SHD 7990 | 速率 1073.5 MHash/SNVIDIA系列显卡GTX 285 | 速率 56.1 MHash/SGTX 460 | 速率 71.1 MHash/SGTX 570 | 速率 124.2 MHash/SGTX TITAN | 速率 302.4 MHash/S 挖矿的效率对比上，同样价格的N系列显卡完全比不上A系列显卡，这是由显卡的设计架构决定的 职业挖矿1：显卡集装矿机职业挖矿2：专用工业矿机参考http://www.btc38.com/newbie.html","tags":[],"categories":[{"name":"block-chain","slug":"block-chain","permalink":"http://yoursite.com/categories/block-chain/"},{"name":"虚拟货币","slug":"block-chain/虚拟货币","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/"},{"name":"币种","slug":"block-chain/虚拟货币/币种","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/"},{"name":"比特币-BTC","slug":"block-chain/虚拟货币/币种/比特币-BTC","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/"},{"name":"-挖矿","slug":"block-chain/虚拟货币/币种/比特币-BTC/挖矿","permalink":"http://yoursite.com/categories/block-chain/虚拟货币/币种/比特币-BTC/挖矿/"}]},{"title":"【数据分析篇】thchs30（清华大学中文语料库）","date":"2018-05-27T16:00:00.000Z","path":"wiki/-audio/dataset/thchs30/","text":"简介THCHS-30的特点 这部分我们介绍THCHS-30语音库。这个数据库是在2000-2001年记录的，第一个作者是Prof.Xiaoyan Zhu的一个研究生。这个语音库设计的目的是作为863数据库的补充，尽可能提高中文发音的涵盖率。这个新数据库叫TCMSD(清华大学连续普通话数据库），而且变得 更加开放。。我们15年前发布了这个数据库，其所有权为Prof.Zhu。后来又更名为THCHS-30，代表清华大学30小时中文语音库。THUYG-30也用了相同的命名规则，这个数据库将会在不就发布。 统计 这个数据集包含以下内容： 数据集 音频时长(h) 句子数 词数 train 25 10000 198252 dev 2:14 893 17743 test 6:15 2495 49085 还有训练好的语言模型word.3gram.lm和phone.3gram.lm以及相应的词典lexicon.txt。 概述 data_thchs30.tgz [6.4G] ( speech data and transcripts ) test-noise.tgz [1.9G] ( standard 0db noisy test data ) resource.tgz [24M] ( supplementary resources, incl. lexicon for training data, noise samples ) 解压后:12 thchs30数据量比较小，不需要GPU集群就可以快速完成训练 resourceresource/dict/lexicon.txt 12345678910111213141516SIL sil&lt;SPOKEN_NOISE&gt; sil啊 aa a1啊 aa a2啊 aa a4啊 aa a5啊啊啊 aa a2 aa a2 aa a2啊啊啊 aa a5 aa a5 aa a5阿 aa a1阿 ee e1阿尔 aa a1 ee er3阿根廷 aa a1 g en1 t ing2阿九 aa a1 j iu3阿克 aa a1 k e4阿拉伯数字 aa a1 l a1 b o2 sh u4 z iy4阿拉法特 aa a1 l a1 f a3 t e4 resource/dict/lexiconp.txt 12345678910111213141516SIL 1.0 sil&lt;SPOKEN_NOISE&gt; 1.0 sil啊 1.0 aa a1啊 1.0 aa a2啊 1.0 aa a4啊 1.0 aa a5啊啊啊 1.0 aa a2 aa a2 aa a2啊啊啊 1.0 aa a5 aa a5 aa a5阿 1.0 aa a1阿 1.0 ee e1阿尔 1.0 aa a1 ee er3阿根廷 1.0 aa a1 g en1 t ing2阿九 1.0 aa a1 j iu3阿克 1.0 aa a1 k e4阿拉伯数字 1.0 aa a1 l a1 b o2 sh u4 z iy4阿拉法特 1.0 aa a1 l a1 f a3 t e4 resource/dict/extra_questions.txt1234567sila1 ai1 an1 ang1 ao1 e1 ei1 en1 eng1 i1 ia1 ian1 iang1 iao1 ie1 in1 ing1 iong1 iu1 ix1 iy1 o1 ong1 ou1 u1 ua1 uai1 uan1 uang1 ueng1 ui1 un1 uo1 v1 van1 ve1 vn1a2 ai2 an2 ang2 ao2 e2 ei2 en2 eng2 er2 i2 ia2 ian2 iang2 iao2 ie2 in2 ing2 iong2 iu2 ix2 iy2 o2 ong2 ou2 u2 ua2 uai2 uan2 uang2 ui2 un2 uo2 v2 van2 ve2 vn2a3 ai3 an3 ang3 ao3 e3 ei3 en3 eng3 er3 i3 ia3 ian3 iang3 iao3 ie3 in3 ing3 iong3 iu3 ix3 iy3 o3 ong3 ou3 u3 ua3 uai3 uan3 uang3 ueng3 ui3 un3 uo3 v3 van3 ve3 vn3a4 ai4 an4 ang4 ao4 e4 ei4 en4 eng4 er4 i4 ia4 ian4 iang4 iao4 ie4 in4 ing4 iong4 iu4 ix4 iy4 iz4 o4 ong4 ou4 u4 ua4 uai4 uan4 uang4 ueng4 ui4 un4 uo4 v4 van4 ve4 vn4a5 ai5 an5 ang5 ao5 e5 ei5 en5 eng5 er5 i5 ia5 ian5 iang5 iao5 ie5 in5 ing5 iong5 iu5 ix5 iy5 iz5 o5 ong5 ou5 u5 ua5 uai5 uan5 uang5 ueng5 ui5 un5 uo5 v5 van5 ve5 vn5aa b c ch d ee f g h ii j k l m n oo p q r s sh t uu vv x z zh resource/dict/nonsilence_phones.txt12345678910111213a1a2a3a4a5aaai1ai2ai3ai4ai5an1an2 resource/dict/optional_silence.txt1sil resource/dict/silence_phones.txt1sil 数据ss2.1 语音信号 THCHS-30是在安静的办公室环境下，通过单个碳粒麦克风录取的，总时长超过30个小时。大部分参与录音的人员是会说流利普通话的大学生。采样频率16kHz，采样大小16bits。 THCHS-30的文本选取自大容量的新闻，目的是为了扩充863语音库。我们选取1000句来录音。表1展示了双音素和三音素的涵盖率，从表中可以看出来THCHS-30的确提高了863数据库的发音涵盖率。 、 这些录音根据其文本内容分成了四部分，A（句子的ID是1~250），B（句子的ID是251~500），C（501~750），D（751~1000）。ABC三组包括30个人的10893句发音，用来做训练，D包括10个人的2496句发音，用来做测试。详细信息如下表： 2.2 附加资源 为了帮助构建一个实用的中文ASR系统，一些附加的资源也随着THCHS-30发布了。这些资源包括发音词典，语言模型，训练方法和一些其他有用的工具。另外还有一些噪声条件下的语音可供使用。 2.2.1 Lexicon 和 LM（发声词典和语言模型） 我们发布了两个语言模型和配套的发声词典。基于词汇的LM包括48k个词汇，而且是基于三音素的。词汇LM的训练用的是一个从中文Gigaword语料库中随机选取的文本集合，训练内容包括772000个句子，总计一千八百万个词汇，一亿一千五百万个汉字。phone LM用了一个比较小的、包括两百万字符的数据集做训练。用一个小的文本数据做训练是因为我们想尽可能少的保留语言信息，这样结果的性能就直接与声学模型的质量有关了。这两种LM用SRILM来训练。","tags":[],"categories":[{"name":"audio","slug":"audio","permalink":"http://yoursite.com/categories/audio/"},{"name":"dataset","slug":"audio/dataset","permalink":"http://yoursite.com/categories/audio/dataset/"}]},{"title":"A星寻路算法","date":"2018-05-23T16:00:00.000Z","path":"wiki/Math/-运筹学-动态规划/常见问题/A星寻路算法/","text":"很多游戏特别是rts，rpg类游戏，都需要用到寻路。寻路算法有深度优先搜索（DFS），广度优先搜索(BFS)，A星算法等，而A星算法是一种具备启发性策略的算法，效率是几种算法中最高的，因此也成为游戏中最常用的寻路算法。","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"常见问题","slug":"Math/运筹学-动态规划/常见问题","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/常见问题/"}]},{"title":"冒泡排序","date":"2018-05-23T16:00:00.000Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-1.sorting-排序/-冒泡排序/","text":"简介冒泡排序是一种流行但低效的排序算法，它的作用是反复交换相邻的未按次序排列的元素。 BUBBLESORT(A)1234for i = 1 to A.length -1 for j = A.length downto i + 1 if A[j] &lt; A[j - 1] exchange A[j] with A[j - 1] # 假设$ A^{‘}$表示BUBBLESORT(A)的输出。为了证明BUBBLESORT正确，我们必须证明它将终止并且有：$ A^{‘}[1] $ 其中n=A.length。 # 冒泡排序的最坏情况运行时间是多少？与插入排序的运行时间相比，其性能如何？参考 《算法导论 - 第三版》 P23","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-1.sorting-排序","slug":"CS/programing/algorithm-数据结构与算法/1-sorting-排序","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/1-sorting-排序/"}]},{"title":"Dropbox差异同步算法rsync及其改进算法原理","date":"2018-05-23T16:00:00.000Z","path":"wiki/CS/tools/同步与版本管理/云存储-dropbox/dropbox-增量同步原理/","text":"打个比方，你一共在两台电脑上（A,B）用同一个帐号的Dropbox，一共有三个文件（C，D，E），你在A电脑上删了（或者任意操作后保存）C，只要同步，B上面的C就会执行自行同步你在A上对C 的操作。至于Ipad上的同步，原理是一样。 yskin说eDonkey2000（好吧，就是大家说的电驴）是这样实现的：把文件按固定大小分成几段，然后每段生成一个Hash码，然后再把所有Hash码合并成一个Hash码表，再对其生成一个Hash码，于是就成为了ed2k链接。下载的时候，先拿ed2k链接找人要到Hash码表，然后再根据码表分别下载每个片段。 Dropbox的增量同步也一样，每4M生成一个Hash码，然后更新的时候把码表和隐藏目录里存储的原码表做一下比较，发现1-10、12-20段都没有改变，只有11段不一样了，于是就只上传了第11段的数据。 dunning说dropbox最初是采用了类似rsync的技术，但后来好像还是采用了Fix Sized Chunk进行。一个10MB的文档我曾经试过，修改1个字基本也有50%~70%左右的部分会被重新上传。 疑问是否有版本记录功能？跟git什么区别？ 是否是增量同步？ 如何解决冲突问题？ 参考 Dropbox的同步方式是怎样的？ | v2ex 云存储或笔记的增量同步是如何实现的？ | 知乎 gist 基于rsync的文件增量同步方案 | 美团 详解rsync算法–如何减少同步文件时的网络传输量","tags":[{"name":"同步","slug":"同步","permalink":"http://yoursite.com/tags/同步/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"云存储-dropbox","slug":"CS/tools/同步与版本管理/云存储-dropbox","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/云存储-dropbox/"}]},{"title":"MD5","date":"2018-05-23T16:00:00.000Z","path":"wiki/CS/programing/algorithm-数据结构与算法/-2.searching-查找/hash/md5/","text":"MD5消息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。MD5由美国密码学家罗纳德·李维斯特（Ronald Linn Rivest）设计，于1992年公开，用以取代MD4算法。这套算法的程序在 RFC 1321 中被加以规范。 将数据（如一段文字）运算变为另一固定长度值，是散列算法的基础原理。 1996年后被证实存在弱点，可以被加以破解，对于需要高度安全性的数据，专家一般建议改用其他算法，如SHA-2。2004年，证实MD5算法无法防止碰撞（collision），因此不适用于安全性认证，如SSL公开密钥认证或是数字签名等用途。 要解决的问题有多个不同的源串经过MD5签名后结果相同的情况。但这不影响MD5的使用。MD5的作用并不是加密而是“签名”（Signature） MD5的核心 不易破解。运算不可逆，根据结果串非常难反推源串 减少碰撞。签名后的结果分布比较均匀，发生重复的几率最小 特别微小改动的两个数据，一定不要碰撞。Key值只有轻微变化，Value值也会发生很大地变化 “试探法”来破解MD5，付出的代价要特别高 不考虑还原 （有别于压缩算法） 算法MD5的容量，128-bits， java对string的哈希， 碰撞概率如果是两个随机的值，碰撞率大概在2的-128次方。 md5的组成为32位十六进制数字，共有16^32 = 3.4 * 10^38种可能 将26个英文字母组合成32位字符串将有 26^32 = 1.9 * 10^45 种可能，很显然用英文字母组合的32位字符串的可能性要远多于md5的可能性 https://stackoverflow.com/questions/8852668/what-is-the-clash-rate-for-md5 破解文件校验在文件大小、属性不变的前提下伪造一份MD5值一样的文件 现在MD5也不是很安全了，早几年的碰撞算法已经可以伪造一份第三方修改过的资料，当然代价还是颇高的 在网上可以下到一个叫fastcoll的小工具，这个工具可以轻松创建两个md5相同的文件，所以md5重复的概率是很大的，大到你随手就可以这样造出来一个。 加密伪造一份MD5值一样的字符串 因为密码一般位数比较短，可以采用逆向法破解。 md5的设计思想MD5是一种散列值，就好比你手中有一把砂子，面前有一排瓶子，你要把砂子放到瓶子里，如何才能既随机又均匀？ 其设计思想是使Key集合中的任意关键字能够尽可能均匀的变换到Value空间中，不同的Key对应不同的Value。通过建立Hash的方式我们能够得到O(1)的查找时间性能，其中关键在于选取一个hash function(md5就是一致hash function)。 md5这种hash函数通常情况下，Key值只有轻微变化，Value值也会发生很大地变化。 LSH正好相反， 参考 维基百科","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"algorithm-数据结构与算法","slug":"CS/programing/algorithm-数据结构与算法","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/"},{"name":"-2.searching-查找","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/"},{"name":"hash","slug":"CS/programing/algorithm-数据结构与算法/2-searching-查找/hash","permalink":"http://yoursite.com/categories/CS/programing/algorithm-数据结构与算法/2-searching-查找/hash/"}]},{"title":"手机通信原理","date":"2018-05-22T16:00:00.000Z","path":"wiki/others/通信/-手机通信原理/","text":"寻呼 广播 由于基站空闲的话音信道是有限的， 有多少部收发信机就有多少空闲的话音信道。 当同时呼叫的用户数超出话音信道数时， 会因信道占满而接续不上， 这时用户会得到“ 请稍候再挂”的提示音， 这种情况相当于电话占线。 移动通信系统的多址接入技术频分多址 FDMA 频分多路复用依靠不同的频率来区分信道，一个信道容纳一个用户。 在频分多址方式中， 由于多个移动台进行通信时占用数量众多的频点， 浪费频率资源， 频带利用率不高。 为了在有限的频段中增加信道数量， 希望系统中的信道间隔越窄越好。 目前， 模拟手机TACS制采用FDMA方式。 其信道带宽25kHz ，频段带宽 25MHz，整个频段可容纳 25M/25k＝1000 个用户 。 由于信道带宽的压缩是有限度的， 而用户数却不断增加， 因此FDMA 无力解决有限频段和众多用户的矛盾。 随着移动通信的迅猛发展， 很快就显示出容量不足的缺点。 而且由于信道频带窄，语音失真大，通话质量差。这也正是模拟制TACS 被淘汰的一个重要原因。 时分多址 TDMA 时分多路复用不同的移动台共用一个频率。 但是各个移动台占用的时间不同， 即各移动台占用不同的“时隙” ， 分时通信。 因此一个信道可供多个用户同时通信使用而不会造成“混台”。在信道数相同的情况下，用TDMA 技术的系统比FDMA 系统的容量高几倍。 数字移动通信GSM 制广泛采用时分多址TDMA 和频分多址FDMA 相结合的方式。这是在一个宽带的无线载波上，按时间 （ 称为时隙）划分为若干个时分信道，每个用户占用不同的时隙，在指定时隙内收、发信号。 码分多址 CDMA - 3G 码分多路复用FDMA和TDMA为了扩大通信用户容量， 都尽力压缩信道带宽， 但这种压缩是有限度的， 因为这将导致通话质量下降。而CDMA却独辟另一途径，大幅度地增加信道带宽，这就是扩频通信技术。 在CDMA移动通信中，将话音频号转换为数字信号，给每组数据话音分组增加一个地址，进行扰码处理，然后将它发射到空中。CDMA最大的优点就是相同的带宽下可以容纳更多的呼叫，而且它还可以随话音传送数据信息。 有点类似计算机网络中的数据包分组(分帧)，这样信息流的传输就不会混乱了。要携带分组信息，序列标号信息 采用扩频通信， 如何解决通信用户容量问题呢？ 办法是不同的移动台都分配一个独特的、 随机的码序列来实现多址方式。对于不同用户的信号， 用相互正交的不同扩频码序列（ 或称为伪随机码） 来填充。这样的信号可在同一载波上发射， 接收时只要采用与发端相同的码序列进行相关接收， 即可恢复信号。 也就是说， 数量众多的用户可以共用一个频率， 使系统的通信容量增加。 这时， 可将CDMA看成一个蜂窝系统，整个系统使用一个频率，即各蜂窝同频， 而根据扩频码来区分用户。这样的信号可在同CDMA中，可用带宽为12.5MHz 的整个频带去发射，亦可以12.5MHz的整个频带去接收。 CDMA的关键是所用扩频码有多少个不同的互相正交的码序列， 就有多少个不同的地址码， 也就有多少个码分信道。 为了扩大系统容量， 人们正在致力于这种正交码序列的编码研究。 细节见 https://zh.wikipedia.org/wiki/%E5%88%86%E7%A2%BC%E5%A4%9A%E9%87%8D%E9%80%B2%E6%8E%A5 CDMA是3G技术，电信用的多。 波分多路复用（WDM）移动是没有3G牌照？搞的G3是什么鬼？CDMA出现之前，使用模拟信号传输的？CDMA之后都改用数字信号传输了？是吗？长期演进技术 LTE - 4GTDDFDD疑问单cpu计算要实现并行，一般采用时分复用TDMA，这里是否有频段的说法？ 貌似不是一个东西。 这里讲的是模拟信号的信息流传输，瓶颈是带宽。对于数字信号的信息流传输 3G第三代手机显然具备这样几个特点： 采用码分多址 技术， 扩展了通信频带， 不但能传送语言信号， 也为传递图像信号奠定了基础。 手机中可加装微型摄像头，可实时地拍摄景物，使可视通信成为可能，可随意拨打可视电话。 由于通频带拓宽，通过无线电网络技术，能轻松地上网，能浏览网页，接收电子邮件，能下载网上文件和图片， 实现多媒体通信。 因此具有掌上电脑之称。 手机与商务通混然一体，能以手写体录入文字。 第三代手机有超大显示屏，触摸式键盘，具有摄像头，备有微机接口 4G第四代手机的蓝图 美国AT&amp;T 实验室正在研究第四代移动通信技术， 其研究的目标是提高移动手机访问互联网的速率。 目前， 手机上网的连接速率大约为调制解调器的1/4 ，而采用4G 技术的连接速率一开始就达到拨号调制解调器的十几倍。","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"通信","slug":"others/通信","permalink":"http://yoursite.com/categories/others/通信/"}]},{"title":"RRC（Radio Resource Control）无线资源控制","date":"2018-05-21T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/5. 第三层 网络层/-无线资源控制/","text":"光光 做这个，通信里的L3。 移动通信中的无线资源管理无线资源管理（Radio Resource Management，RRM）是通信基站结构里非常重要，也是最庞大的一个子系统。 目标是在有限带宽的条件下，为网络内无线用户终端提供业务质量保障，其基本出发点是在网络话务量分布不均匀、信道特性因信道衰弱和干扰而起伏变化等情况下，灵活分配和动态调整无线传输部分和网络的可用资源，最大程度地提高无线频谱利用率，防止网络拥塞和保持尽可能小的信令负荷。无线资源管理(RRM)的研究内容主要包括以下几个部分：功率控制、信道分配、调度、切换、接入控制、负载控制、端到端的QoS和自适应编码调制等。 简单的来说，RRM的功能就像是政府一样，负责把硬件软件整合在一起形成的处理能力进行分割，然后分配给每一个用户，用户成功接入取决于有没有被RRM接纳并且分配了资源。RRM在通信协议模型里对应着庞大的层2，也就是MAC和RLC层，MAC层在物理层之上以2层的传输间隔（如果是3G，这个间隔一般是10ms或者2ms）为单位进行调度， RLC在MAC层之上进行错误校验。 RRC处理UE(User Equipment)和eNodeB(Evolved Node-B)之间控制平面的第三层信息。 https://baike.baidu.com/item/RRC/1560254 https://www.zhihu.com/question/30293207","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"5. 第三层 网络层","slug":"CS/network/网络协议-OSI七层模型/5-第三层-网络层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/5-第三层-网络层/"}]},{"title":"python编码","date":"2018-05-21T16:00:00.000Z","path":"wiki/CS/programing/lan/python/编码/-python编码/","text":"文档 https://docs.python.org/2/howto/unicode.html dddPython获取系统编码参数的几个函数1234567系统的缺省编码(一般就是ascii): sys.getdefaultencoding() （系统自动解码会采用这种类型）系统当前的编码: locale.getdefaultlocale()系统代码中临时被更改的编码（通过locale.setlocale(locale.LC_ALL,“zh_CN.UTF-8″)）: locale.getlocale()文件系统的编码: sys.getfilesystemencoding()终端的输入编码: sys.stdin.encoding （这个类似文件系统的编码）终端的输出编码: sys.stdout.encoding代码的缺省编码: 文件头上# -*- coding: utf-8 –*- 头部编码文件头部编码声明决定了python解析源码中的str的编码选择方式，比如头部声明的是utf-8编码，则代码中s=&quot;中文&quot;python就会按照utf-8编码格式来解析，通过repr(s)可以看到字符编码是\\xe4\\xb8\\xad\\xe6\\x96\\x87，如果头部声明的编码是gbk编码，则python会对s采用gbk编码解析，结果是\\xd6\\xd0\\xce\\xc4。 需要注意的是，文件本身的编码要跟文件头部声明编码一致，不然就会出现问题。文件本身的编码在Linux下面可以在vim下用命令set fenc来查看。如果文件本身编码是gbk，而源码文件头部声明的编码是utf-8，这样如果源码中有中文就会有问题了，因为本身中文str存储是按照gbk编码来的，而python在解析str的时候又以为是utf-8编码，这样就会报SyntaxError: (unicode error) &#39;utf8&#39; codec can&#39;t decode byte错误。 ###文件编码 text file encoding eclipse中设置： project /resouce / text file encoding ###默认编码问题 ###读写文件编码 string byte由一系列不可改变的Unicode字符组成的叫string。而一系列不可改变的介于0-255之间的数字被称为bytes对象。 ###编码示例 123&gt;&gt;&gt; a=u'中国 abc' # u'\\u4e2d\\u56fd abc' type: unicode len(a)=6 空格也占一个长度，一个汉字占1个长度&gt;&gt;&gt; a='中国 abc' # '\\xd6\\xd0\\xb9\\xfa abc' type: str len(a)=8 空格也占一个长度，一个汉字占2个长度&gt;&gt;&gt; a=u'中国abc'.encode('utf8') #'\\xe4\\xb8\\xad\\xe5\\x9b\\xbdabc' type: str len(a)=9 一个汉字占3个长度（URL中就是采用的这种编码） ###问题 http://jingyan.baidu.com/article/e75aca85440f01142edac636.html中修改的是什么编码？ mobaxterm中修改的是什么编码？ eclipse中的很多项，分别修改的是什么编码？ textstudio中分别修改的是什么编码？ ###windows cmd的默认显示编码是GBK， 如果改成utf-8编码，需要输入命令 CHCP 65001，并修改字体。见 http://jingyan.baidu.com/article/e75aca85440f01142edac636.html 对str按照文件编码或者终端的输入编码进行解码 ###Linux中 我的Ubuntu中的默认编码 对str按照文件编码或者终端的输入编码进行解码 因为a是str，自动的先将 s 解码为 unicode ，然后再编码成 gb18030。因为解码是python自动进行的，我们没有指明解码方式，python 就会使用 sys.defaultencoding 指明的方式来解码。实际应该按照文件编码或者终端的输入编码进行解码，因此会出现错误。 系统无关 python安装时，默认编码是ascii， sys.getdefaultencoding() 。当程序中出现非ascii编码时，python的处理常常会报这样的错UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0x?? in position 1: ordinal not in range(128)，python没办法处理非ascii编码的，此时需要自己设置将python的默认编码，一般设置为utf8的编码格式。 靠尼玛， cmd和eclipse中都是 sys.getdefaultencoding() = ascii， 为什么 转码 实例BERT实例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# https://github.com/google-research/bert/blob/master/tokenization.py#L27import sixdef convert_to_unicode(text): \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\" if six.PY3: if isinstance(text, str): return text elif isinstance(text, bytes): return text.decode(\"utf-8\", \"ignore\") else: raise ValueError(\"Unsupported string type: %s\" % (type(text))) elif six.PY2: if isinstance(text, str): return text.decode(\"utf-8\", \"ignore\") elif isinstance(text, unicode): return text else: raise ValueError(\"Unsupported string type: %s\" % (type(text))) else: raise ValueError(\"Not running on Python2 or Python 3?\")def printable_text(text): \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\" # These functions want `str` for both Python2 and Python3, but in one case # it's a Unicode string and in the other it's a byte string. if six.PY3: \"\"\" python3分string类型和bytes类型？ python2呢？string类型，unicode类型，，，，？ \"\"\" if isinstance(text, str): return text elif isinstance(text, bytes): return text.decode(\"utf-8\", \"ignore\") else: raise ValueError(\"Unsupported string type: %s\" % (type(text))) elif six.PY2: if isinstance(text, str): return text elif isinstance(text, unicode): return text.encode(\"utf-8\") # 这里只支持utf-8解码，太弱了 else: raise ValueError(\"Unsupported string type: %s\" % (type(text))) else: raise ValueError(\"Not running on Python2 or Python 3?\") tensor2tensor实例 语种判断12345678910111213141516171819202122# https://github.com/google-research/bert/blob/master/tokenization.py#L201def _is_chinese_char(self, cp): \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\" # This defines a \"chinese character\" as anything in the CJK Unicode block: # https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block) # # Note that the CJK Unicode block is NOT all Japanese and Korean characters, # despite its name. The modern Korean Hangul alphabet is a different block, # as is Japanese Hiragana and Katakana. Those alphabets are used to write # space-separated words, so they are not treated specially and handled # like the all of the other languages. if ((cp &gt;= 0x4E00 and cp &lt;= 0x9FFF) or # (cp &gt;= 0x3400 and cp &lt;= 0x4DBF) or # (cp &gt;= 0x20000 and cp &lt;= 0x2A6DF) or # (cp &gt;= 0x2A700 and cp &lt;= 0x2B73F) or # (cp &gt;= 0x2B740 and cp &lt;= 0x2B81F) or # (cp &gt;= 0x2B820 and cp &lt;= 0x2CEAF) or (cp &gt;= 0xF900 and cp &lt;= 0xFAFF) or # (cp &gt;= 0x2F800 and cp &lt;= 0x2FA1F)): # return True return False","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"python","slug":"CS/programing/lan/python","permalink":"http://yoursite.com/categories/CS/programing/lan/python/"},{"name":"编码","slug":"CS/programing/lan/python/编码","permalink":"http://yoursite.com/categories/CS/programing/lan/python/编码/"}]},{"title":"【北大人工智能讲座系列】人工智能与量子计算 - 施尧耘","date":"2018-05-20T16:00:00.000Z","path":"wiki/CS/-量子计算/阿里-施尧耘/","text":"主讲老师简介施尧耘 - 阿里巴巴接触的工程师和量子技术首席科学家/架构师。阿里云量子实验室(AQL)创始董事。 1997年在北大获得计算机科学学士学位 雷鸣大学同学。貌似不是北大毕业的2001年在普林斯顿大学获得计算机科学博士学位 2017年9月，辞去密西根大学终身教授，加入阿里，任阿里云首席量子技术科学家/架构师 导师-姚期智 AI基础设施 - 雷鸣硬件和平台技术 硬件 GPU、TPU FPGA ASIC芯片 (目前大部分的AI芯片属于ASIC，算法固化，大部分创业公司的方向) 神经网络芯片 (仍在研究阶段) 光计算 (MIT等，用光学方法加速AI计算速度，比GPU上百倍提升) 量子计算 (一旦在通用计算突破，将会很厉害) 平台 TensorFlow、Caffe等 Amazon、Google等AI云计算平台 商汤也有独立的AI平台 AUTOML，给定数据，自动选算法。牛逼牛逼啊 硬件的应用发展 通用AI计算芯片的发展 NVIDIA引领 谷歌、Intel、amazon等不断发起挑战 (google-TPU、Intel收购mobieye) ASIC的发展 针对高频场推出 要求及时反馈的场景、端计算 手机、摄像头、自动驾驶汽车等 未来的发展：光计算和量子计算 ARM是端上高性能芯片 AI计算软基础设施发展 开源AI计算平台，竞争激烈 AI云端化正在推进 AI工具型创业公司 提供多种AI工具(和AI云会有竞争) AI服务型创业公司 主要ToB，帮助企业AI解决实际问题 AI+云。一体化还是两种方案并存？因为云自身提供云存储、云计算，如果独立的AI则不易融合。一般性需求走云通道，而不用定制化。 量子计算 - 施尧耘什么是量子计算利用量子物理 非..性质的计算，有别于经典计算。 发展史 vacuum tube transistor 图灵机我勒个去，这块视频听不清啊 来自雷鸣 &amp; 施尧耘的报告","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"-量子计算","slug":"CS/量子计算","permalink":"http://yoursite.com/categories/CS/量子计算/"}]},{"title":"alpha-go","date":"2018-05-17T16:00:00.000Z","path":"wiki/ML/app/Reinforcement Learning/alpha-go/","text":"占坑","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"Reinforcement Learning","slug":"ML/app/Reinforcement-Learning","permalink":"http://yoursite.com/categories/ML/app/Reinforcement-Learning/"}]},{"title":"维特比算法","date":"2018-05-17T16:00:00.000Z","path":"wiki/ML/ml 传统方法/supervised/hmm-viterbi/","text":"动态规划 这是个递归问题递归思想就是：把问题分解成规模更小，但和原问题有着相同解法的问题。但是递归低效递归：1-T的最优，依赖2-T最优,…依赖T-1到T的最优。但是T-1到T的最优是无法 要解决的问题top1路径：很简单，所有候选到当前帧的cost，M*N的矩阵。topN路径: 不仅仅考虑跳到当前点的最有路径，全局保留。存在的问题是有些点被剪掉了。可以考虑 HMM 示例模型 全连接 - 指数级 - 朴素递归法重复计算子问题 &lt;script src=https://www.gstatic.com/charts/loader.js&gt;function drawSimpleNodeChart(){var a=new google.visualization.arrayToDataTable([[“id”,”childLabel”,”parent”,”ss”,{role:”style”}],[0,”初始状态”,-1,322,”black”],[1,”1”,0,111,”black”],[2,”2”,0,5,”black”],[3,”3”,0,1,”blue”],[11,”1”,1,1,”black”],[12,”2”,1,1,”black”],[13,”3”,1,1,”black”],[111,”1”,11,1,”black”],[112,”2”,11,1,”black”],[113,”3”,11,1,”black”],[121,”1”,12,1,”black”],[122,”2”,12,1,”black”],[123,”3”,12,1,”black”],[131,”1”,13,1,”black”],[132,”2”,13,1,”black”],[133,”3”,13,1,”black”],[21,”1”,2,1,”black”],[22,”2”,2,1,”black”],[23,”3”,2,1,”black”],[211,”1”,21,1,”black”],[212,”2”,21,1,”black”],[213,”3”,21,1,”black”],[221,”1”,22,1,”black”],[222,”2”,22,1,”black”],[223,”3”,22,1,”black”],[231,”1”,23,1,”black”],[232,”2”,23,1,”black”],[233,”3”,23,1,”black”],[31,”1”,3,1,”black”],[32,”2”,3,1,”red”],[33,”3”,3,1,”blue”],[311,”1”,31,1,”black”],[312,”2”,31,1,”black”],[313,”3”,31,1,”black”],[321,”1”,32,1,”black”],[322,”2 — line1 贪婪路径”,32,1,”red”],[323,”3”,32,1,”black”],[331,”1”,33,1,”black”],[332,”2”,33,1,”black”],[333,”3 — line0 全局最优路径”,33,1,”blue”]]);new google.visualization.WordTree(document.getElementById(“wordtree_explicit”)).draw(a,{wordtree:{format:”explicit”,type:”suffix”}})}google.charts.load(“current”,{packages:[“wordtree”]}),google.charts.setOnLoadCallback(drawSimpleNodeChart) 复杂度 $ O(N^{T}) $ 这里N=3，T=3。 注意 总路径数：$ N^{T}=3^{3}=9 $ 边的数目：$ N \\times N \\times T=3 \\times 3 \\times 3=9 $ 维特比算法只是对边进行了复用。 最优路径 - 维特比算法&lt;script src=https://www.gstatic.com/charts/loader.js&gt;function drawChart(){var n=new google.visualization.DataTable;n.addColumn(“number”,”时间”),n.addColumn(“number”,”line0”),n.addColumn({type:”string”,role:”annotation”}),n.addColumn(“number”,”line1”),n.addColumn({type:”string”,role:”annotation”}),n.addColumn(“number”,”line2”),n.addColumn({type:”string”,role:”annotation”}),n.addColumn(“number”,”line3”),n.addColumn({type:”string”,role:”annotation”}),n.addColumn(“number”,”line4”),n.addColumn({type:”string”,role:”annotation”}),n.addColumn(“number”,”line5”),n.addColumn({type:”string”,role:”annotation”}),n.addColumn({type:”string”,role:”legend”}),n.addRows([[1,3,”0.28”,3,””,3,””,3,””,2,”0.16”,1,”0.1”,”none”],[2,3,”0.42”,2,”0.0504”,2,””,1,”0.028”,null,””,null,””,”none”],[3,3,”0.0147”,2,”0.01008”,1,”0.00756”,null,””,null,””,null,””,”none”]]),new google.visualization.LineChart(document.getElementById(“visualization”)).draw(n,{legend:{position:”bottom”},pointSize:7,vAxis:{title:”状态”,titleTextStyle:{fontName:”Times-Roman”,bold:!0,italic:!1},ticks:[0,1,2,3],viewWindow:{max:4},maxValue:0},hAxis:{title:”时间”,ticks:[1,2,3],viewWindow:{max:4},maxValue:0,gridlines:{color:”transparent”,count:0}}})}google.charts.load(“current”,{packages:[“corechart”]}),google.charts.setOnLoadCallback(drawChart),google.load(“visualization”,”1”,{packages:[“corechart”]}),google.setOnLoadCallback(drawChart) 全局最优：line0贪心算法会找到 line1 维特比是少计算了？剪枝了？还是并未少计算，只是复用了前面的计算结果。 维特比并未少计算，只是去除了冗余计算量而已。 例如路径 1 7 10 k-best 维特比通常的维特比算法，如果要取top-k最优路径，那么只能在最后一层取topk，前面默认只缓存top-1。 这样导致所取的top-k并非全局最优top-k。 剪枝算法top1问题维特比算法复杂度是 NNT T上不能缩减，我们只能在N上做手脚。 时间点t，只取top N 累积路径，只取 路径总数上限 topK问题为了和N区分，这里采用topM。 通常的做法： 剪枝的做法： FAQbeambeam=4指的是n还是似然值。还是当前点的路径数目，剪纸。当前帧剪纸，比如top 15. log似然当前最优是100，100-12. 平滑有些转移概率为0的，是否需要平滑？ 看具体情况。有些状态根本调不到下一个状态。音素上的跳转概率并没平滑。 每帧出top 60，那么就是60^N的路径，但是有top_thresho. lattice free什么鬼？ lattice freee是和传统的鉴别训练区分。latice 网格，传统只给top1。鉴别性，音素错误率，等准则在训练中要体现。全局性的错误率，softmax只提供了单帧错误率。","tags":[{"name":"hmm","slug":"hmm","permalink":"http://yoursite.com/tags/hmm/"},{"name":"viterbi","slug":"viterbi","permalink":"http://yoursite.com/tags/viterbi/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"}]},{"title":"模拟退火","date":"2018-05-17T16:00:00.000Z","path":"wiki/Math/-运筹学-动态规划/启发式算法/-模拟退火算法/","text":"说文解字模拟退火来自冶金学的专有名词退火。退火是将材料加热后再经特定速率冷却，目的是增大晶粒的体积，并且减少晶格中的缺陷。材料中的原子原来会停留在使内能有局部最小值的位置，加热使能量变大，原子会离开原来位置，而随机在其他位置中移动。退火冷却时速度较慢，使得原子有较多可能可以找到内能比原先更低的位置。 讲得真好啊。 模拟退火的原理也和金属退火的原理近似：我们将热力学的理论套用到统计学上，将搜寻空间内每一点想像成空气内的分子；分子的能量，就是它本身的动能；而搜寻空间内的每一点，也像空气分子一样带有“能量”，以表示该点对命题的合适程度。算法先以搜寻空间内一个任意点作起始：每一步先选择一个“邻居”，然后再计算从现有位置到达“邻居”的概率。 可以证明，模拟退火算法所得解依概率收敛到全局最优解。 退火、正火、淬火和回火 淬火硬化 淬cuì火，俗称蘸（zhàn）火，金属和玻璃的一种热处理工艺。把合金制品或玻璃加热到一定温度，随即在含有矿物质的水、油或空气中急速冷却，一般用以提高合金的硬度和强度。淬火可增强钢与铸铁的强度和硬度。急速冷却的速率也会影响物质表面硬度和心部硬度。淬火后物质会变脆，所以通常会再进行回火处理，目的是降低物质的脆度。螺丝、齿轮、转动轴、金属块等物品常使用淬火处理。淬火后得到马氏体，组织变硬，也就是晶粒变得粗大。 回火可以稍微降低硬度和强度，使钢不太脆 淬火后，钢变硬但是太脆了，动不动就断，那么好，我们在加热它，这个温度要温和的多了，然后再慢慢冷却下来，目的是组织变得细小，记住，晶粒细小的组织性能好，放在钢上，就是硬度高、强度大、塑形好。 退火 将钢加热、保温后缓慢冷却 为什么不模拟淬火呢？急速冷却一下。 简介模拟退火算法以一定的概率来接受一个比当前解要差的解，因此有可能会跳出这个局部的最优解，达到全局的最优解。以图1为例，模拟退火算法在搜索到局部最优解A后，会以一定的概率接受到E的移动。也许经过几次这样的不是局部最优的移动后会到达D点，于是就跳出了局部最大值A。 模拟退火算法描述： 若J( Y(i+1) )&gt;= J( Y(i) ) (即移动后得到更优解)，则总是接受该移动 若J( Y(i+1) )&lt; J( Y(i) ) (即移动后的解比当前解要差)，则以一定的概率接受移动，而且这个概率随着时间推移逐渐降低（逐渐降低才能趋向稳定） 随着温度T的降低，P(dE)会逐渐降低。 我们将一次向较差解的移动看做一次温度跳变过程，我们以概率P(dE)来接受这样的移动。 参考https://www.cnblogs.com/heaad/archive/2010/12/20/1911614.html","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"启发式算法","slug":"Math/运筹学-动态规划/启发式算法","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/启发式算法/"}]},{"title":"路径搜索算法","date":"2018-05-17T16:00:00.000Z","path":"wiki/Math/-运筹学-动态规划/常见问题/路径搜索问题/","text":"算法 en 简介 时间复杂度 全局最优解 缺陷 应用场合 全搜索 ( N^T ) √ 指数级 维特比算法 Viterbi T*N^2 √ 深度T影响不大，N影响比较大。比如seq2seq中的N是词典大小。因此可采用近似算法 常用于HMM模型，分词、中文输入法 束搜索 beam search 属于贪心算法思想 beam search是一种启发式搜索，没有条件限制，都可以用，利用定义好的代价来剪枝，需要创建一个搜索树，因此每一个结点都与前面所有的父亲结点连接，生成很多结点在搜索树上，而DP是计算最优子问题的结果，保存在一个中间表中。 TNbeam_size 当beam_size=N时，就是Viterbi算法 × seq2seq， 贪心 greedy search T*N × 全局最优Viterbi算法 近似算法 贪心，每一步都贪心。 束搜索（beam search）就是引入了类似贪心的策略（每一步都贪心的保留一部分当前最好的结果）","tags":[{"name":"viterbi","slug":"viterbi","permalink":"http://yoursite.com/tags/viterbi/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"常见问题","slug":"Math/运筹学-动态规划/常见问题","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/常见问题/"}]},{"title":"启发式算法","date":"2018-05-17T16:00:00.000Z","path":"wiki/Math/-运筹学-动态规划/启发式算法/启发式算法/","text":"说文解字Heuristic 启发式的；探索的。 启发法(Heuristics):是凭经验的解题方法,也可称经验规则。 人在解决问题时所采取的一种根据经验规则进行发现的方法。其特点是在解决问题时,利用过去的经验,选择已经行之有效的方法，而不是系统地、以确定的步骤去寻求答案 看上去有点类似streaming，有点像markov 特点:不能保证问题一定得到解决,但却常常有效解决问题。 来源 定位 在算法中的位置决方法， 有2类， 分别是 确定方式和近似方式（ Exact Method， Approximate Method） 对于优化问题的解决方法， 有2类， 分别是 确定方式和近似方式（ Exact Method， Approximate Method） 对于优化问题. 根据条件，和限制， 可以描绘出一个解集空间（Solution Space）， 确定算法， 只可用在解集空间很小的问题， 但对于NP hard 问题， 可行时间内在个空间中找到 全局最优解（Global Optimum ） 的可能性很小 （ 几乎不可能）。 故需要使用近似算法（Approximate Method） 在有限时间内来寻找一个近似最优解。 近似方法分为两种 分别为 近似算法（Approximate Algorithms） 和启发式算法（ Heuristic Algorithms)。 近似算法通常可得到一个有质量保证的解。 然而 启发式算法通常可找到在传统解决问题的经验中找到寻求一种面向问题的策略， 之后用这种策略来在可行时间内寻找一个相对比较好的解，但对解的质量没有保证。 https://www.zhihu.com/question/28874818/answer/67504126 简介启发式就是能快速出结果的算法，出来的结果一般是可用的，但是不能保证全局最优，也不能保证算法的完备性。全局最优容易理解，完备性是说能这个算法能不能找到所有的解，或者干脆判定此问题无解。 启发式方法（试探法）是一种帮你寻求答案的技术，但它给出的答案是具有偶然性的（subject to chance），因为启发式方法仅仅告诉你该如何去找，而没有告诉你要找什么。它并不告诉你该如何直接从A 点到达B 点，它甚至可能连A点和B点在哪里都不知道。实际上，启发式方法是穿着小丑儿外套的算法：它的结果不太好预测，也更有趣，但不会给你什么30 天无效退款的保证。 启发式方法 VS 算法启发式解决问题的方法是与算法相对立的。算法是把各种可能性都一一进行尝试，最终能找到问题的答案，但它是在很大的问题空间内，花费大量的时间和精力才能求得答案。启发式方法则是在有限的搜索空间内，大大减少尝试的数量，能迅速地达到问题的解决。但由于这种方法具有尝试错误的特点，所以也有失败的可能性。科学家的许多重大发现，常常是利用极为简单的启发式规则。 驾驶汽车到达某人的家，写成算法是这样的：沿167 号高速公路往南行至Puyallup；从South Hill Mall 出口出来后往山上开4.5 英里；在一个杂物店旁边的红绿灯路口右转，接着在第一个路口左转；从左边褐色大房子的车道进去，就是North Cedar 路714 号。 用启发式方法来描述则可能是这样：找出上一次我们寄给你的信，照着信上面的寄出地址开车到这个镇；到了之后你问一下我们的房子在哪里。这里每个人都认识我们——肯定有人会很愿意帮助你的；如果你找不到人，那就找个公共电话亭给我们打电话，我们会出来接你。 算法和启发式方法之间的差别很微妙，两个术语的意思也有一些重叠。就本书的目的而言，它们之间的差别就在于其距离最终解决办法的间接程度：算法直接给你解决问题的指导，而启发式方法则告诉你该如何发现这些指导信息，或者至少到哪里去寻找它们。 ss对于优化问题. 根据条件，和限制， 可以描绘出一个解集空间（Solution Space）， 确定算法， 只可用在解集空间很小的问题， 但对于NP hard 问题， 可行时间内在个空间中找到 全局最优解（Global Optimum ） 的可能性很小 （ 几乎不可能）。 故需要使用近似算法（Approximate Method） 在有限时间内来寻找一个近似最优解。 近似方法分为两种 分别为 近似算法（Approximate Algorithms） 和启发式算法（ Heuristic Algorithms)。 近似算法通常可得到一个有质量保证的解。 然而 启发式算法通常可找到在传统解决问题的经验中找到寻求一种面向问题的策略， 之后用这种策略来在可行时间内寻找一个相对比较好的解，但对解的质量没有保证。 启发式算法的发展启发式算法的计算量都比较大，所以启发式算法伴随着计算机技术的发展，取得了巨大的成就。 40年代：由于实际需要，提出了启发式算法（快速有效）。 50年代：逐步繁荣，其中贪婪算法和局部搜索 等到人们的关注。 60年代: 反思，发现以前提出的启发式算法速度很快，但是解得质量不能保证，而且对大规 模的问题仍然无能为力（收敛速度慢）。 70年代：计算复杂性理论的提出，NP问题。许多实际问题不可能在合理的时间范围内找到全局最优解。发现贪婪算法和局部搜索算法速度快，但解不好的原因主要是他们只是在局部的区域内找解，等到的解没有全局最优性。由此必须引入新的搜索机制和策略………..Holland的遗传算法出现了（GEnetic Algorithm）再次引发了人们研究启发式算法的兴趣。 80年代以后：模拟退火算法（SiMUlated Annealing Algorithm），人工神经网络（Artificial Neural Network），禁忌搜索（Tabu Search）相继出现。 最近比较热或刚热过去的：演化算法（Evolutionary Algorithm）, 蚁群算法（Ant Algorithms）， 拟人拟物算法，量子算法等。 各个算法的思想这就不再详细给出，为什么要引出启发式算法，因为NP问题，一般的经典算法是无法求解，或求解时间过长，我们无法接受。这里要说明的是：启发式算法得到的解只是近似最优解（近似到什么程度，只有根据具体问题才能给出）. 二十一世纪的最大的数学难题NP？=P，如果NP=P启发式算法就不在有存在的意义。 群体智能算法就是启发式算法；研究的重点就是如何平衡局部搜索与全局搜索；有效逃离局部最优解； 近几年比较活跃的算法有如下： 仿动物类的算法：粒子群优化，蚂蚁优化，鱼群算法，蜂群算法等； 仿植物类的算法：向光性算法，杂草优化算法，等等；仿人类的算法有： 和声搜索算法是较好的算法；近年开始研究情感计算的人较多。 实际应用时差分进化算法较有优势。关于粒子群算法，理论成熟，应用广泛。 Shi Cheng: 上面提到的算法，应该属于元启发式算法 meta-heuristics algorithms 疑问那，梯度下降是贪心算法吗？ 贪心算法是启发式算法吗？贪心算法是一种启发式算法，它企图寻求局部最优解，容易陷入局部最优的困境。 梯度下降法也是启发式咯？启发式搜索与传统基于梯度信息的方法 启发式搜索在机器学习优化中的研究有哪些？什么算法不是启发式算法？启发式方法并不告诉你该如何直接从A 点到达B 点，而是仅仅告诉你该如何去找。按照这个意思，梯度下降法、神经网络、机器学习算法 是不是 基本都是启发式方法？ 决策树不是启发式的吧， 哪些机器学习算法 是启发式算法咯？# 所以后来有了元启发式算法，如蚁群算法，模拟退火算法，禁忌算法等等，这类算法通过一些策略，某种程度上可以跳出局部最优解，从而寻求更好的全局最优解。 各类启发式算法概述优胜劣汰是大自然的普遍规律，它主要通过选择和变异来实现。选择是优化的基本思想，变异（多样化）是随机搜索或非确定搜索的基本思想。“优胜劣汰”是算法搜索的核心，根据“优胜劣汰”策略的不同，可以获得不同的超启发式算法。超启发式算法的主要思想来自于人类经过长期对物理、生物、社会的自然现象仔细的观察和实践，以及对这些自然现象的深刻理解，逐步向大自然学习，模仿其中的自然现象的运行机制而得到的。 遗传算法：是根据生物演化，模拟演化过程中基因染色体的选择、交叉和变异得到的算法。在进化过程中，较好的个体有较大的生存几率。 模拟退火：是模拟统计物理中固体物质的结晶过程。在退火的过程中，如果搜索到好的解接受；否则，以一定的概率接受不好的解（即实现多样化或变异的思想），达到跳出局部最优解得目的。 神经网络：模拟大脑神经处理的过程，通过各个神经元的竞争和协作，实现选择和变异的过程。 禁忌搜索：模拟人的经验，通过禁忌表记忆最近搜索过程中的历史信息，禁忌某些解，以避免走回头路，达到跳出局部最优解的目的。 蚂蚁算法：模拟蚂蚁的行为，拟人拟物，向蚂蚁的协作方式学习。 这几种超启发式算法都有一个共同的特点：从随机的可行初始解出发，才用迭代改进的策略，去逼近问题的最优解。他们的基本要素： （1）随机初始可行解； （２）给定一个评价函数（常常与目标函数值有关）； （３）邻域，产生新的可行解； （４）选择和接受解得准则； （５）终止准则。 其中（４）集中反映了超启发式算法的克服局部最优的能力。 启发式算法的不足和如何解决方法：参考 https://tuotiansudai.com/cms/fund/jijingongsi/57939.html http://www.cnblogs.com/p2pstream/archive/2009/04/09/1432270.html","tags":[],"categories":[{"name":"Math","slug":"Math","permalink":"http://yoursite.com/categories/Math/"},{"name":"-运筹学-动态规划","slug":"Math/运筹学-动态规划","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/"},{"name":"启发式算法","slug":"Math/运筹学-动态规划/启发式算法","permalink":"http://yoursite.com/categories/Math/运筹学-动态规划/启发式算法/"}]},{"title":"肩周炎","date":"2018-05-16T16:00:00.000Z","path":"wiki/others/医疗/肩周炎/","text":"什么是肩周炎又称粘连性肩关节囊炎 如何鉴定肩周炎如何治疗如何保养黏连，就要解黏连。正确锻炼、拉伸 最好有个打印版经典视频-","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"医疗","slug":"others/医疗","permalink":"http://yoursite.com/categories/others/医疗/"}]},{"title":"AlphaGo背后的搜索算法：蒙特卡罗树搜索","date":"2018-05-16T16:00:00.000Z","path":"wiki/ML/app/Reinforcement Learning/AlphaGo-tree-search/","text":"深度学习 + 增强学习 启发式算法蒙特卡洛树搜索“蒙特卡洛树搜索”是一种启发式的搜索策略，能够基于对搜索空间的随机抽样来扩大搜索树，从而分析围棋这类游戏中每一步棋应该怎么走才能够创造最好机会。 一位名叫苏椰的知乎用户举了这样一个例子，以通俗的语言进行了解释：假如筐里有100个苹果，让我每次闭眼拿1个，挑出最大的。于是我随机拿1个，再随机拿1个跟它比，留下大的，再随机拿1个……我每拿一次，留下的苹果都至少不比上次的小。拿的次数越多，挑出的苹果就越大，但我除非拿100次，否则无法肯定挑出了最大的。这个挑苹果的算法，就属于蒙特卡罗算法：尽量找好的，但不保证是最好的。 需要说明的是，蒙特卡罗树搜索并不是只有一种算法，而是一类算法。其中最流行的算法之一就是UCT（upper confidence bounds applied to trees）。 占坑 alphago为什么不采用维特比算法？因为alphago的路径搜索，跟markov不同。 markov有个状态转移矩阵，有限状态。围棋的状态空间太大，没办法用状态转移矩阵来衡量吧？ alpha-zero","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"Reinforcement Learning","slug":"ML/app/Reinforcement-Learning","permalink":"http://yoursite.com/categories/ML/app/Reinforcement-Learning/"}]},{"title":"星际争霸","date":"2018-05-16T16:00:00.000Z","path":"wiki/ML/app/Reinforcement Learning/星际争霸/","text":"游戏简介三种种族，多兵种协同(海陆空)，包围、埋伏、多地形(坡) 战争迷雾 金钱 deep mind 策略# 计算机优势apm高，即使计算机胜了，也并非表示策略更优。 所以需要在apm&lt;=人的情况下，与人公平竞争。 缺陷现在的计算机，能耗太高。人只需要一碗饭。芯片能耗。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"Reinforcement Learning","slug":"ML/app/Reinforcement-Learning","permalink":"http://yoursite.com/categories/ML/app/Reinforcement-Learning/"}]},{"title":"jupyter notebook嵌入到博客","date":"2018-05-15T16:00:00.000Z","path":"wiki/CS/web/blog-framework/-jupyter-notebook/","text":"内嵌式 采用gist 采用nbviewer.jupyter.org 自己转化为html pelican 集成html render","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"}]},{"title":"对比不同的loss funtion","date":"2018-05-11T16:00:00.000Z","path":"wiki/ML/ml 传统方法/loss function/summary/","text":"分类 loss 参考 http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html 0-1 losslogistic losshinge-loss也叫SVM loss max(0, 1-py) h(x)=max(1−x,0) 平滑的hinge-lossE = ln (1 + exp(−ty)) y log p 回归 lossL1 对应拉普拉斯分布MSEL2 对应高斯分布 (p-y)^2 RMSE","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"loss function","slug":"ML/ml-传统方法/loss-function","permalink":"http://yoursite.com/categories/ML/ml-传统方法/loss-function/"}]},{"title":"利用hmm实现输入法","date":"2018-05-09T16:00:00.000Z","path":"wiki/ML/ml 传统方法/supervised/-hmm-输入法/","text":"简介pypinyin使用文档 dictword 写成 pyall.tr，是一个词典，保存的 首字母–汉字词组的映射 参考 GodTian_Pinyin - code - blog这个实现的是，bi-gram。 https://github.com/letiantian/Pinyin2Hanzi TODO利用lstm实现看看。","tags":[{"name":"hmm","slug":"hmm","permalink":"http://yoursite.com/tags/hmm/"},{"name":"viterbi","slug":"viterbi","permalink":"http://yoursite.com/tags/viterbi/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"}]},{"title":"CNN网路结构可视化","date":"2018-05-08T16:00:00.000Z","path":"wiki/ML/deep learning/可视化/CNN-visualization/","text":"简介可视化方法 传统CNN可视化 对kernel可视化 对中间feature map可视化 对全连接weight可视化 反卷积网络 可视化 传统CNN可视化单层sparse autoencoder在的可视化对autoencoder的参数W进行可视化。(训练数据STL-10) 通过可视化可以看到，autoencoder学习到的参数类似边缘检测器(a set of edge detectors)不同的隐藏单元学会了在图像的不同位置和方向进行边缘检测。 以上来自ufldl 这里sparse autoencoder是在图片88的patch上学习得到的，学到**参数W类似CNN中的88的卷积核**。因此UFLDL的教程中直接把w当做cnn的卷积核，效果也不错。 cnn的可视化 传统CNN可视化的缺陷： 传统CNN可视化的一个缺陷是，不能够还原图片，只能单向可视化。例如，给定一个hidden feature。 反卷积网络 可视化反卷积网络与传统CNN网络采用同样的结构，只不过训练方法不同。反卷积网络采用非监督学习，类似autoencoder的思想。 这样 deep dream 详解见参考中的deep dream源码 # todo 可视化梯度消失、梯度爆炸 可视化ReLU对梯度消失的影响 可视化LSTM对梯度消失的影响 借鉴deep-dream，可视化lstm lstm可视化 https://medium.com/asap-report/visualizing-lstm-networks-part-i-f1d3fa6aace7 参考paper Visualizing and Understanding Convolutional Networks | 2014 Zeiler ECCV CNN领域可视化理解的开山之作- 博客 Deep Visualization:可视化并理解CNN | 知乎 feature-visualization | distill code deep-dream | tensorflow官方","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"可视化","slug":"ML/deep-learning/可视化","permalink":"http://yoursite.com/categories/ML/deep-learning/可视化/"}]},{"title":"反卷积 逆卷积(Deconvolution)  - CNN的逆过程","date":"2018-05-08T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/生成模型/Deconvolution/","text":"背景众所周知，神经网络分为有向网络，无向网络。典型的无向网络有CRF、Autoencoder、RBM等。由于Autoencoder和RBM是层级结构，也叫双向网络。这种是专门设计的双向网络，具有很好的理论依据(特别是RBM)。用的更多的网络，比如NN、CNN等都是单向网络。 PGM理论好，实践弱 概率图模型，又称有向图模型。实际上我们是可以通过后验概率，计算图模型的反向。 但是 PGM中的后验概率计算一般都很复杂，特别是对于深层PGM，要算很多层叠的微积分。没有 模型的求解难 深层模型要用EM算法， 由于后验求不出来，大家就采用很多近似方法(比如变分)以及基于采样的方法。 得益于漂亮的理论基础，PGM也曾大放异彩，占领学术界和工业界高地。比如曾经风靡的HMM，LDA。涌现了Jordan Blei Daffni Ng一大批牛人。但是PGM的深层扩展性较差，常见的比较深层的PGM就是Blei大神的LDA了。然而神经网络已经动不动上百层了。随着大数据来临，PGM越来越力不从心，渐渐被神经网络取代。 RBM理论漂亮，实践，大家还是用autoencoder，而不用RBM。 复杂性 CRF条件随机场，又叫概率无向图， NN首先我们来看一下，RBM和autoencoder是怎样可逆的？ autoencoder强制学习双向的全连接参数W。 deconv神奇的CNN逆过程。 在我的世界观里，CNN是用来特征学习的，网络是单向的，特别是卷积层和pooling层是不可逆的。然而竟然听说有deconv network。 实际上就是类似autoencoder的思想。 反池化过程反激活在Alexnet中，relu函数是用于保证每层输出的激活值都是正数，因此对于反向过程，我们同样需要保证每层的特征图为正值，也就是说这个反激活过程和激活过程没有什么差别，都是直接采用relu函数。 反卷积信号里的卷积是不可逆的，比如高通滤波，难道还能把高频还原？显然是行不通的。 这里只是采用autoencoder的思想，强制学习双向的卷积kernel。 反全连接应用deconvolutional network相关文章，其实deconv的用处还挺广的，涉及到visualization/pixel-wiseprediction/unsupervised learning/image generation都会用到deconv的结构。比如Deconvolutional Network[1][2]做图片的unsupervised feature learning，ZF-Net论文中的卷积网络可视化[3]，FCN网络中的upsampling[4]，GAN中的Generative图片生成[5]。 参考 How does a deconvolutional neural network work? | Quora 如何理解深度学习中的deconvolution networks？ | 知乎 可视化理解卷积神经网络 | CSDN Adaptive deconvolutional networks for mid and high level feature learning","tags":[{"name":"卷积","slug":"卷积","permalink":"http://yoursite.com/tags/卷积/"},{"name":"反卷积","slug":"反卷积","permalink":"http://yoursite.com/tags/反卷积/"},{"name":"cnn","slug":"cnn","permalink":"http://yoursite.com/tags/cnn/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"生成模型","slug":"ML/deep-learning/model-basic/生成模型","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/生成模型/"}]},{"title":"图像风格迁移-Image Style Transfer","date":"2018-05-08T16:00:00.000Z","path":"wiki/ML/app/vision/app/style-transfer/style-transfer/","text":"简介图片1中的内容 + 图片2中的风格 = 新图片 难点 怎样提取出content信息？ 怎样提取出style信息？ 怎样融合content和style？ 大佬们围绕这几个点，绞尽脑汁，各显神通。 核心思想分解我们先从简单问题的入手，问题1看上去好像比较简单。 怎样提取出content信息？怎样提取出style信息？这几年CNN挺火，据说CNN的不同层能学习到不同级别的特征。是不是也能学习到style信息呢？带着这个疑问，我们先来看看CNN学到的是什么。 https://distill.pub/2017/feature-visualization/ 细节网络的高层特征一般是关于输入图像的物体和布局等信息，低层特征一般表达输入图像的像素信息。也就是说在提取content特征时，不同层的表达效果是不一样的，本文在后面提取图像的content特征时采用高层特征。 参考文献 | 发展史2015 A Neural Algorithm of Artistic Style2016年的CVPR Image Style Transfer Using Convolutional Neural Networks","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"style-transfer","slug":"ML/app/vision/app/style-transfer","permalink":"http://yoursite.com/categories/ML/app/vision/app/style-transfer/"}]},{"title":"【数据分析篇】imageNet","date":"2018-05-05T16:00:00.000Z","path":"wiki/ML/app/vision/dataset/-imageNet/","text":"22K categories and 14M images","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"dataset","slug":"ML/app/vision/dataset","permalink":"http://yoursite.com/categories/ML/app/vision/dataset/"}]},{"title":"mean field","date":"2018-05-04T16:00:00.000Z","path":"wiki/ML/PGM/-bayesian-inference/mean-field/","text":"mean field method，一句话，就是后验概率用fully factorized approximation，即后验概率的每个维度都相互独立。见图MLAPP P740 但是这一个假设太强，很多时候近似效果不好，因此采用structured mean field","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"-bayesian-inference","slug":"ML/PGM/bayesian-inference","permalink":"http://yoursite.com/categories/ML/PGM/bayesian-inference/"}]},{"title":"exact inference","date":"2018-05-04T16:00:00.000Z","path":"wiki/ML/PGM/-bayesian-inference/exact-inference/","text":"","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"PGM","slug":"ML/PGM","permalink":"http://yoursite.com/categories/ML/PGM/"},{"name":"-bayesian-inference","slug":"ML/PGM/bayesian-inference","permalink":"http://yoursite.com/categories/ML/PGM/bayesian-inference/"}]},{"title":"分词","date":"2018-05-04T16:00:00.000Z","path":"wiki/ML/app/nlp/app/分词/readme/","text":"简介 分句 用户词典 NER 新词识别 模型/算法 开源 结巴分词 开源 哈工大LTP 根据中文标点里的句号、问号、感叹号、分号、省略号。 C++ 中科院NLPIR 计算所ICTCLAS CHMM(层叠形马尔可夫模型)。进行原子切分,然后在此基础上进行N-最短路径粗切分,找出前N个最符合的切分结果,生成二元分词表,然后生成分词结果,接着进行词性标注并完成主要分词步骤 C/C++ IKAnalyzer 轻量级 结合词典分词和文法分析算法 java 参考 https://www.zhihu.com/question/19578687","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"分词","slug":"ML/app/nlp/app/分词","permalink":"http://yoursite.com/categories/ML/app/nlp/app/分词/"}]},{"title":"前后端渲染之争","date":"2018-05-03T16:00:00.000Z","path":"wiki/CS/web/前后端渲染之争/","text":"简介前端渲染是在客户端完成字符串替换，后端渲染当然在服务器完成 -「后端渲染」指传统的 ASP、Java 或 PHP 的渲染机制；以及最初的CGI-「前端渲染」指使用 JS 来渲染页面大部分内容，代表是现在流行的 SPA 单页面应用； 前端渲染前端渲染的优势 局部刷新。无需每次都进行完整页面请求 懒加载。如在页面初始时只加载可视区域内的数据，滚动后rp加载其它数据，可以通过 react-lazyload 实现 富交互。使用 JS 实现各种酷炫效果 节约服务器成本。省电省钱，JS 支持 CDN 部署，且部署极其简单，只需要服务器支持静态文件即可 天生的关注分离设计。服务器来访问数据库提供接口，JS 只关注数据获取和展现 JS 一次学习，到处使用。可以用来开发 Web、Serve、Mobile、Desktop 类型的应用 坏处： 占用（一部分、少部分）客户端运算资源（解析模板）。前端代码多点，毕竟包含模板代码了么。脚本是不是首次下就慢点了（看你在意不在意这个毕竟能304和CDN啥的）。可能造成前后两份模板的情况，总归要后端吐出个首屏啥的先让用户看见吧。那这部分页面模板不就是后端拼好了吐出来的么 mathjax.js angualr vue bootstrap也是吧 后端渲染后端渲染的优势 服务端渲染不需要先下载一堆 js 和 css 后才能看到页面（首屏性能） SEO 服务端渲染不用关心浏览器兼容性问题（随着浏览器发展，这个优点逐渐消失） 对于电量不给力的手机或平板，减少在客户端的电量消耗很重要 python flask，django java jsp- 参考 [精读前后端渲染之争 | 知乎]https://zhuanlan.zhihu.com/p/26366128 Here’s Why Client-side Rendering Won | freecodecamp | 中文翻译 前后端渲染之争 精读前后端渲染之争 后端渲染html、前端模板渲染html，jquery的html，各有什么区别？","tags":[{"name":"render","slug":"render","permalink":"http://yoursite.com/tags/render/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"}]},{"title":"深度学习中的梯度爆炸  梯度消失","date":"2018-05-03T16:00:00.000Z","path":"wiki/ML/deep learning/存在的问题/梯度消失-爆炸/","text":"梯度消失随着网络深度的加深，梯度消失问题会愈加明显。无论cnn，rnn 什么形式会爆炸 f_{t+1} 累加的形式不消失$f_{t+1} = w * f_{t} + w f_{t-1} + …$ CNN。设输入数据为 $x$ ，对 $x$ 的卷积操作就可以看做是 $Wx+b$ 我们设第一层卷积的参数为$W_1, b_1$ ，第二层卷积的参数是$W_2, b_2$，依次类推。又设激活函数为$f$ ，每一层卷积在经过激活函数前的值为$a_i$，经过激活函数后的值为$f_i$。 按照上面的表示，在CNN中，输入$x$ ，第一层的输出就是$f_1=f[W_1x+b_1]$，第二层的输出就是$f_2= f[W_2f[W_1x+b_1]+b_2]$ ，第三层的输出就是$f_3= f[W_3f[W_2f[W_1x+b_1]+b_2]+b_3]$。设最终损失为$L$ ，我们来尝试从第三层开始，用BP算法推导一下损失对参数$W_1$的偏导数，看看会发生什么。 为了简洁起见，略过求导过程，最后的结果为$\\frac{\\partial{L}}{\\partial{W_1}}=\\frac{\\partial{L}}{\\partial{f_3}}\\frac{\\partial{f_3}}{\\partial{a_3}}W_3\\frac{\\partial{f_2}}{\\partial{a_2}}W_2\\frac{\\partial{f_1}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{W_1}}$。我们常常说原始神经网络的梯度消失问题，这里的$\\frac{\\partial{f_3}}{\\partial{a_3}}$、$\\frac{\\partial{f_2}}{\\partial{a_2}}$ 就是梯度消失的“罪魁祸首”。 例如sigmoid的函数，它的导数的取值范围是(0, 0.25]，也就是说对于导数中的每一个元素，我们都有$0&lt;\\frac{\\partial{f_3}}{\\partial{a_3}}\\le0.25$，$0&lt;\\frac{\\partial{f_2}}{\\partial{a_2}}\\le0.25$，小于1的数乘在一起，必然是越乘越小的。这才仅仅是3层，如果10层的话， 根据$0.25^{10}\\approx0.000000954$，第10层的误差相对第一层卷积的参数 $W_1$的梯度将是一个非常小的值，这就是所谓的“梯度消失”。 ReLU函数的改进就是它使得 $\\frac{\\partial{f_3}}{\\partial{a_3}}\\in{0,1}$ ， $\\frac{\\partial{f_2}}{\\partial{a_2}}\\in{0,1}$ ， $\\frac{\\partial{f_1}}{\\partial{a_1}}\\in{0,1}$ ，这样的话只要一条路径上的导数都是1，无论神经网络是多少层，这一部分的乘积都始终为1，因此深层的梯度也可以传递到浅层中。 那为什么同样的方法在RNN中不奏效呢？其实这一点Hinton在它的IRNN论文里面（arxiv：[1504.00941] A Simple Way to Initialize Recurrent Networks of Rectified Linear Units）是很明确的提到的： 也就是说在RNN中直接把激活函数换成ReLU会导致非常大的输出值。为了讲清楚这一点，我们先用同上面相似的符号把原始的RNN表示出来： $$a_i=Wf_{i-1}+Ux_{i}+b_i$$，$$f_i=f[a_i]$$ 在这个表示中，RNN每个阶段的输入是 $x_i$，和CNN每一层使用独立的参数$W_i$不同，原始的RNN在每个阶段都共享一个参数 $W$。如果我们假设从某一层开始输入 $x_i$ 和偏置 $b_i$ 都为0，那么最后得到的输出就是 $f[W…[Wf[Wf[Wf_i]]]]$ ，这在某种程度上相当于对参数矩阵 $W$ 作连乘，很显然，只要 $W$ 有一个大于1的特征值，在经过若干次连乘后都会导致结果是一个数值非常庞大的矩阵。 另外一方面，将激活函数换成ReLU也不能解决梯度在长程上传递的问题。同样考虑 $f_3$ 对 $W$ 的导数。在CNN中，每一层的参数 $W_1,W_2,W_3……$ 是互相独立的，然而RNN中 W 参与了每个时间段的运算，因此 $f_3$ 对 $W$ 导数更复杂，写出来是 $\\frac{\\partial{f_3}}{\\partial{W_1}}=\\frac{\\partial{f_3}}{\\partial{a_3}}f_2+\\frac{\\partial{f_3}}{\\partial{a_3}}W\\frac{\\partial{f_2}}{\\partial{a_2}}f_1+\\frac{\\partial{f_3}}{\\partial{a_3}}W\\frac{\\partial{f_2}}{\\partial{a_2}}W\\frac{\\partial{f_1}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{W_1}}$ 。我们可以看下最后 $\\frac{\\partial{f_3}}{\\partial{a_3}}W\\frac{\\partial{f_2}}{\\partial{a_2}}W\\frac{\\partial{f_1}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{W_1}}$这部分，使用ReLU后，当梯度可以传递时，有$\\frac{\\partial{f_3}}{\\partial{a_3}}=\\frac{\\partial{f_2}}{\\partial{a_2}}=\\frac{\\partial{f_3}}{\\partial{a_1}}=1$ ，但这个式子中还是会有两个 $W$ 的连乘。在更长程上，就会有更多 $W$ 的连乘。对于CNN来说，这个部分是 $W_1,W_2,W_3…..$ 进行连乘，一方面它们都是稀疏矩阵，另一方面 $W_1,W_2,W_3….$ 互不相同，很大程度上都能抵消掉梯度爆炸的影响。 最后，IRNN在RNN上使用了ReLU，取得了比较好的结果，其中的原因在于，它对 $W$ 和 $b_i$ 取了比较特殊的初值： $W=I$ , $b_i=0$ 。这样在梯度的式子 $\\frac{\\partial{f_3}}{\\partial{a_3}}W\\frac{\\partial{f_2}}{\\partial{a_2}}W\\frac{\\partial{f_1}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{W_1}}$ 中W尽管会连乘，但是会类似于单位矩阵 $I$ 的连乘，不会引起太明显的梯度数值变化。另外一方面，也不会引起非常大的输出值 RNNLSTM梯度爆炸 策略梯度爆炸问题其实不是什么麻烦。 因为现在大家都会做某种形式的Gradient clipping（也就是限定一下梯度绝对值的上限，超过就截断）来避免梯度爆炸。觉得Gradient clipping很糙？其实一点都不糙，因为用SGD训练深度模型数学上本身就已经糙的不能再糙了。觉得LSTM不需要这种东西？No。如果查查主流工具包，或者看看比较实际的LSTM应用论文，应该都至少这么做了。 SGD为什么糙？只有GD才不糙？一切近似算法都糙？ saizheng: relu确实容易explode，除非加大很tricky的clipping，因为clipping多了，优化就做不好了为什么？？ saizheng: 普通rnn做超长memory一般就用quoc le的那个trick，identity init，我猜你看过那个paper，但是那个东西的tradeoff就是损失了短时间段内fit复杂nonlinearty的能力 参考 RNN中为什么要采用tanh而不是ReLu作为激活函数？","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"存在的问题","slug":"ML/deep-learning/存在的问题","permalink":"http://yoursite.com/categories/ML/deep-learning/存在的问题/"}]},{"title":"java的正则表达式","date":"2018-05-03T16:00:00.000Z","path":"wiki/CS/programing/lan/java/java正则表达式/","text":"正则表达式实例Java 正则表达式和 Perl 的是最为相似的。 java.util.regex 包主要包括以下三个类： Pattern 类pattern 对象是一个正则表达式的编译表示。Pattern 类没有公共构造方法。要创建一个 Pattern 对象，你必须首先调用其公共静态编译方法，它返回一个 Pattern 对象。该方法接受一个正则表达式作为它的第一个参数。 Matcher 类Matcher 对象是对输入字符串进行解释和匹配操作的引擎。与Pattern 类一样，Matcher 也没有公共构造方法。你需要调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。 PatternSyntaxException：PatternSyntaxException 是一个非强制异常类，它表示一个正则表达式模式中的语法错误。 参考 菜鸟教程","tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://yoursite.com/tags/正则表达式/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"}]},{"title":"【数据分析篇】SemEval-2018-阅读理解","date":"2018-05-03T16:00:00.000Z","path":"wiki/ML/app/nlp/app/阅读理解/-dataset/SemEval-2018/","text":"https://competitions.codalab.org/competitions/17184","tags":[{"name":"dataset","slug":"dataset","permalink":"http://yoursite.com/tags/dataset/"},{"name":"数据分析","slug":"数据分析","permalink":"http://yoursite.com/tags/数据分析/"},{"name":"阅读理解","slug":"阅读理解","permalink":"http://yoursite.com/tags/阅读理解/"},{"name":"SemEval","slug":"SemEval","permalink":"http://yoursite.com/tags/SemEval/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"阅读理解","slug":"ML/app/nlp/app/阅读理解","permalink":"http://yoursite.com/categories/ML/app/nlp/app/阅读理解/"},{"name":"-dataset","slug":"ML/app/nlp/app/阅读理解/dataset","permalink":"http://yoursite.com/categories/ML/app/nlp/app/阅读理解/dataset/"}]},{"title":"【数据分析篇】SNLI数据集","date":"2018-05-03T16:00:00.000Z","path":"wiki/ML/app/nlp/app/entailment/dataset/snli/","text":"Stanford自然语言推理(SNLI)数据集，全称The Stanford Natural Language Inference (SNLI) Corpus。 https://nlp.stanford.edu/projects/snli/ 简介SNLI1.0包含570，000的人工手写英文句子对。针对 推理前提(premise)与推理假设(hypothesis)之间是否存在逻辑关系，人工标注了以下三种标签： entailment) 蕴含、推理 \\(p \\Rightarrow h \\) contradiction 矛盾、对立 \\(p \\bot h \\) neutral 中立、无关 \\(p \\nLeftrightarrow h \\) 用于自然语言推理 (Natural language inference,NLI), 也称为 (recognizing textual entailment, RTE)。 数据示例数据 Text Judgments Hypothesis A man inspects the uniform of a figure in some East Asian country. contradictionC C C C C The man is sleeping An older and younger man smiling. neutralN N E N N Two men are smiling and laughing at the cats playing on the floor. A black race car starts up in front of a crowd of people. contradictionC C C C C A man is driving down a lonely road. A soccer game with multiple males playing. entailmentE E E E E Some men are playing a sport. A smiling costumed woman is holding an umbrella. neutralN N E C N A happy woman in a fairy costume holds an umbrella. snli_1.0/snli_1.0_train.jsonl的第一行 1234567891011121314&#123; \"annotator_labels\":[ \"neutral\" ], \"captionID\":\"3416050480.jpg#4\", \"gold_label\":\"neutral\", \"pairID\":\"3416050480.jpg#4r1n\", \"sentence1\":\"A person on a horse jumps over a broken down airplane.\", \"sentence1_binary_parse\":\"( ( ( A person ) ( on ( a horse ) ) ) ( ( jumps ( over ( a ( broken ( down airplane ) ) ) ) ) . ) )\", \"sentence1_parse\":\"(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN on) (NP (DT a) (NN horse)))) (VP (VBZ jumps) (PP (IN over) (NP (DT a) (JJ broken) (JJ down) (NN airplane)))) (. .)))\", \"sentence2\":\"A person is training his horse for a competition.\", \"sentence2_binary_parse\":\"( ( A person ) ( ( is ( ( training ( his horse ) ) ( for ( a competition ) ) ) ) . ) )\", \"sentence2_parse\":\"(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) (VP (VBG training) (NP (PRP$ his) (NN horse)) (PP (IN for) (NP (DT a) (NN competition))))) (. .)))\"&#125; 疑问 为什么有好几个judgement？ 最终标签是综合了5个专家的意见，根据少数服从多数的原则得到的。 还额外提供了句子的两种解析树表示。 自然语言推理（NLI）数据在构造的过程中存在一系列的人工模式，这种模式的直接后果是模型可以在不需要知道推理前提（premise）的条件下就可以以 67%的准确率判断推理假设（hypothesis）是否是蕴含（entailment）中立（neural）或对立（contradiction） 数据统计 &amp;分析 premise hypothesis label a person on a horse jumps over a broken down airplane. a person is training his horse for a competition. neutral 原句没有体现training和competition a person on a horse jumps over a broken down airplane. a person is at a diner, ordering an omelette. contradiction 这种关系，是否要借助外界数据？ a person on a horse jumps over a broken down airplane. a person is outdoors, on a horse. entailment children smiling and waving at camera they are smiling at their parents neutral children smiling and waving at camera there are children present entailment there are属于stop word，最好。但是又要和there are not相反 children smiling and waving at camera the kids are frowning contradiction a boy is jumping on skateboard in the middle of a red bridge. the boy skates down the sidewalk. contradiction a boy is jumping on skateboard in the middle of a red bridge. the boy does a skateboarding trick. entailment a boy is jumping on skateboard in the middle of a red bridge. the boy is wearing safety equipment. neutral an older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background. an older man drinks his juice as he waits for his daughter to get off work. neutral an older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background. a boy flips a burger. contradiction an older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background. an elderly man sits in a small shop. neutral two blond women are hugging one another. some women are hugging on vacation. neutral two blond women are hugging one another. the women are sleeping. contradiction two blond women are hugging one another. there are women showing affection. entailment a few people in a restaurant setting, one of them is drinking orange juice. the people are eating omelettes. neutral a few people in a restaurant setting, one of them is drinking orange juice. the people are sitting at desks in school. contradiction a few people in a restaurant setting, one of them is drinking orange juice. the diners are at a restaurant. entailment an older man is drinking orange juice at a restaurant. a man is drinking juice. entailment an older man is drinking orange juice at a restaurant. two women are at a restaurant drinking wine. contradiction premis比较具体，hyposies 简洁，抽象(比如male抽象成man，苹果抽象成苹果) contradiction通常有反义词，比如 up down 数据读取","tags":[{"name":"dataset","slug":"dataset","permalink":"http://yoursite.com/tags/dataset/"},{"name":"数据分析","slug":"数据分析","permalink":"http://yoursite.com/tags/数据分析/"},{"name":"entailment","slug":"entailment","permalink":"http://yoursite.com/tags/entailment/"},{"name":"自然语言推理","slug":"自然语言推理","permalink":"http://yoursite.com/tags/自然语言推理/"},{"name":"SNLI","slug":"SNLI","permalink":"http://yoursite.com/tags/SNLI/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"entailment","slug":"ML/app/nlp/app/entailment","permalink":"http://yoursite.com/categories/ML/app/nlp/app/entailment/"},{"name":"dataset","slug":"ML/app/nlp/app/entailment/dataset","permalink":"http://yoursite.com/categories/ML/app/nlp/app/entailment/dataset/"}]},{"title":"【数据分析篇】百度竞赛 - 2018 - 阅读理解","date":"2018-05-03T16:00:00.000Z","path":"wiki/ML/app/nlp/app/阅读理解/-dataset/baidu-2018/","text":"简介 竞赛主页 http://mrc2018.cipsc.org.cn 数据下载 百度阅读理解数据集 DuReader是迄今为止规模最大的中文公开领域阅读理解数据集。数据集基于真实应用需求，所有问题都来源于百度搜索用户的真实问题，文档来自全网真实采样的网页文档和百度知道 UGC 文档，答案基于问题与文档由人工撰写生成。数据集标注了问题类型、实体和观点等丰富信息，弥补了现有主流数据集对于观点类问题覆盖不足的问题。首批发布的阅读理解数据集包含20万问题、100万文档及42万人工撰写的优质答案，并提供开源基线系统。DuReader 将为阅读理解技术研究提供有力支撑，希望加速相关技术和应用的发展。 室外场景理解数据集是世界范围内第一个带像素级语义标签的室外3D图像数据，来源于百度自动驾驶事业部。该数据集试图将感知能力从物体级感知升级到像素级感知，进而了解图片中所有像素的属性和来源，目标实现更精准、安全的自动驾驶。 视频精彩片段数据集主要来源于爱奇艺。视频类型为综艺节目，目前囊括近1500个长视频，视频总时长约1200小时，还从中手动收取出18000个精彩小视频，同时能够提供视频帧的图片特征序列，是全球首创的公开精彩片段标注数据集。 数据样例 1raw/trainset/zhidao.train.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123;\"documents\": [ &#123; \"bs_rank_pos\": 1, \"is_selected\": false, \"paragraphs\": [ \"VPN技术对机构和很多远程用户来说，是极端有用的，但在设定上，它可能有些复杂。下面的指南将手把手的教你如何建立VPN，它包含各个步骤详细的操作流程。 第一步：系统需求 VPN分为两种，一种是硬件解决方案，一种是软件解决方案，在这个手把手的指南中，我将介绍一种软件解决方案，即使用Microsoft产品建立VPN. 为了架设VPN，你将需要三个独立的Windows 2003服务器和至少一个远程用户，远程用户的机器上需要运行Windows XP操作系统。 你的VPN需要的第一台Windows 2003服务器是一台基本的基础设施服务器，它必须作为一台域控制器（domain controller），DHCP服务器（DHCP server），DNS服务器（DNS Server）和认证中心（certificate authority）。如果你的网络中已经有一台Windows 2003服务器，你就不需要去购买一台服务器担当此角色。 任何Windows 2003域都至少有一台域控制器和一台作为DNS的服务器，多数Windows 2003网络同时运行DHCP服务。如果你所有的这些服务已经到位，你所关心的唯一的事情就是设置一个认证中心（我将在第三步为你说明如何做这件事情）。下载，你只需知道作为认证中心的那台服务器必需运行Windows Server 2003 Enterprise Edition操作系统。 你需要的第二台服务器将是VPN服务器（VPN server），Windows Server 2003 Standard Edition和Enterprise Edition都提供了VPN服务器的必要软件，因此，你不需要在这台服务器上安装任何特别的软件。唯一特别的是硬件上，这台服务器需要双网卡，一块网卡连接Internet，另一块网卡则连接你的专用企业网络。 第二步：实施DHCP服务 1.打开服务器的控制面板，选择“添加或删除程序”。 2.当“添加或删除程序”对话框出现时，点击“添加/删除Windows组件”按钮。 3.在弹出的窗口中，选择“网络服务”，按下“详细信息”。 4.现在从网络服务列表中选择“动态主机配置协议（DHCP）”，然后单击“确定”，进行下一步操作。 Windows现在将安装DHCP服务，安装结束后，你将要创建一个地址范围，并且启动DHCP服务器，在你的网络上运行。 5.为了做到这些，请在控制面板――管理工具中选择动态主机配置协议（DHCP）配置，打开DHCP管理器。 6.在DHCP管理器中你的服务器上单击右键，选择启动（Authorize）。 7.启动DHCP服务器后，在DHCP管理器的服务器列表窗口中单击右键，选择“新建作用域（New Scope）”，这将启动新建作用域向导。 8.点击下一步略过向导的欢迎界面。 9.输入你正在创建的作用域的名称，并且点击下一步。（你可以输入任何你想到的名称，但在这个教程中，我将命名此作用域为“Corporate Network”。） 10.现在你将需要填入IP地址范围。在这里只需输入你已经使用的起始IP地址和结束IP地址，但注意不要与已经存在的IP地址冲突。长度和子网掩码部分则会自动输入，不需要你的干涉，当然，你也可以手动调节这两者的值。 11.接下来的三个画面包括一些你不必关心的设置，连续三次点击下一步，直到你进入“路由（默认网关）（Router （Default Gateway））”界面。 12.输入你网络网关的IP地址，点击添加，然后下一步。 13.输入你的域的名称和你的DHCP服务器的IP地址（IP address of your DHCP server），然后点击下一步。 14.单击下一步略过WINS配置窗口。 15.最后，根据提示选“是，我想激活作用域（Yes， I Want To Activate The Scope Now）”再点击“完成”即可结束最后设置。 第三步：创建一个企业认证中心 在我向你讲述如何创建一个企业认证中心之前，我将告诉你几个必需注意的事项。安装认证中心并不是一个轻松的过程，如果一个未经授权的用户进入了你的认证中心，他将几乎控制你的所有网络。同样，如果认证中心服务器当机，它可能对给你的网络带来毁灭性的破坏。 所以，一定要像保护原子弹一样保护你的认证中心，确保认证中心尽可能的安全，并频繁的做好全系统的备份，你还需要保护这些备份，以防止它们偶然地出现问题。下面是创建企业认证中心的具体过程。\" ], \"title\": \"如何架设vpn服务器\" &#125;, &#123; \"bs_rank_pos\": 2, \"is_selected\": true, \"paragraphs\": [ \"步骤：1、点击开始，依次点击程序、管理工具、路由和远程访问，打开后右键你的主机名，选择\\\"配置和启用。2、选择\\\"自定义配置，下一步，选上\\\"VPN访问，下一步、完成、然后启动服务3、打开IP路由选择，在常规上面按右键选择\\\"新增路由协议，选择\\\"NAT/基本防火墙。4、在新显示的NAT/基本防火墙上面按右键，选择\\\"新增接口\\\"，然后选择你的网络连接(一般是\\\"本地连接\\\")连接的属性里面选择\\\"公用接口连接到INTERNET\\\".选上\\\"在此接口启用NAT\\\".然后确定。5、设置用户部分在WINDOWS的用户和组里面新建用户，给新用户配置远程拨入的权限，(在用户的属性里面默认是按策略设置，改为\\\"允许访问\\\")、建立完成。\", \"占坑关注\", \"你说的PC Anywhere只是一个远程监控软件啊！我不知道你是想远程控制家里的机器还是想将公司的机器和家里的机器连成一个局域网的类型？VPN是个虚拟专网，可以用windows server 系统来直接完成不需要装别的软件！这个阿~我先写吧，太复杂了！不是一句两句能说清楚的！你看一下这个，很详细，而且图文并茂~http://blog.sina.com.cn/u/494f9a6b0100052l\", \"&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; Windows 7下架设VPN服务器的5大步骤：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 1、打开“网络和共享中心”，选择“更改适配器设置”&lt;/p&gt;&lt;p&gt;&lt;img src=\\\"28765673001\\\" /&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 这里快速打开网络和共享中心&lt;/p&gt;&lt;p&gt;&lt;img src=\\\"28765660417\\\" /&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 2、在“菜单栏”点击“文件”，然后选择“新建传入连接”&lt;/p&gt;&lt;p&gt;&lt;img src=\\\"28765674840\\\" /&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 3、选择允许使用VPN连接到本机的帐户，可以从列表中勾选，也可以“添加用户”&lt;/p&gt;&lt;p&gt;&lt;img src=\\\"28765665635\\\" /&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 选择允许VPN连接到本机的账户&lt;/p&gt;&lt;p&gt;&lt;img src=\\\"28765699912\\\" /&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 接下来选择其他用户连接VPN的方式，一般来说是选择“通过Internet”。当然，如果显示的连接方式是多项的话，那么请根据需要请选择正确的方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 4、这一步就到了设置网络参数环节了，如果对方连接后可以使用本地网络的DHCP服务器，那么可以跳过此设置。如果本地网络没有DHCP服务器的话就要先进行一下设置了，具体步骤如下：&lt;/p&gt;&lt;p&gt;&lt;img src=\\\"28765716220\\\" /&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 选中“Internet 协议版本 4(TCP/IP)”， 点击“属性”按钮，选择“指定IP地址”（这里是根据用户自身的IP地址而设定，设置一个没有被使用的IP段即可），设置后请按确定， 然后点击“允许访问”就大功告成了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 5、到这里VPN服务器已经架设完毕了，其他用户已经可以利用上面的帐号以及设置的IP地址通过VPN连接到网络了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 关于防火墙和内网用户的两点特别说明：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 1、如果你有防火墙请允许1723和1701端口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; 2、如果是内网用户请在路由器上做1723和1701端口的映射，一般做1723就行了。&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;\" ], \"title\": \"vpn服务器如何建立\" &#125;, &#123; \"bs_rank_pos\": 3, \"is_selected\": false, \"paragraphs\": [ \"在Windows服务器上架设VPN可以如下操作：第一步，打开控制面板-&gt;管理工具-&gt;服务项目，禁用Windows防火墙服务。第二步，打开控制面板-&gt;管理工具，双击“路由和远程访问”。然后右键点击服务器图标，再点击“配置并启用路由和远程访问”。第三步，在“路由和远程服务器安装向导”中，选择“自定义配置”。第四步，勾选“VPN访问”和“NAT和基本防火墙”。第五步， 点击“完成”。系统提示“要开始服务吗？”，选择“是”。第六步，接下来开始配置路由和远程访问，我们先点击本地服务旁边的+按钮，把左侧菜单展开，再点击IP路由选择旁边的+按钮。第七步，下面配置静态IP地址。右键点击本地服务，点击属性，再点击IP选项卡。第八步，点选“静态地址池”，点击“添加”。输入一个起始IP地址和结束IP地址范围，推荐输入192.168.1.100到192.168.1.254这个范围，因为192.168段属于本地保留IP段。最后点击“确定”。第九步，右键点击“静态路由”，再点击“新建静态路由”。第十步，目标和网络掩码都输入0，网关请和TCP/IP属性中的默认网关保持一致。第十一步，删除“DHCP中继代理程序”中的“内部”项目。第十二步，然后右键点击“DHCP中继代理程序”，再点击“新增接口”。第十三步，选择“本地连接”，再点击“确定”，然后在弹出的对话框中点击“确定”。第十四步，右键点击“NAT/基本防火墙”，再点击“新增接口”，然后选择“本地连接”，点击“确定”。第十五步，在弹出的对话框中先点选“公共接口连接到Internet”，再勾选“在此接口上启用NAT”，最后点击“确定”。第十六步，至此在路由和远程访问中的配置就完成了。下面是添加VPN用户的步骤，到计算机管理中添加一个用户，作为VPN连接的用户，把这个用户放到Guest组下面，并在用户属性-&gt;拨入-&gt;远程访问权限中设置成“允许访问”。 然后就是在你自己电脑上新建VPN连接，进行拨号测试了。要确定是否连接成功，请访问IP查询网站，看是否显示的是国外服务器的IP即可。\", \"详细设置方法你可以参考酷盛帮助中心里面的图文攻略。\" ], \"title\": \"如何在自己电脑上搭建vpn服务器\" &#125;, &#123; \"bs_rank_pos\": 4, \"is_selected\": true, \"paragraphs\": [ \"1、看路由器里面带不带VPN功能，如果有可以直接在路由器里面设置VPN，当然你可以去买一个带有VPN功能的路由器；2、用windows server系统架构一个VPN！不过家里需要是静态IP地址！\" ], \"title\": \"公司要建vpn服务器,该怎么搭建\" &#125;, &#123; \"bs_rank_pos\": 5, \"is_selected\": true, \"paragraphs\": [ \"XP本身就可以做VPN的 不过只能支持一个用户。\", \"第一，申请ddns，比如3322.org、花生壳什么的，让其他人能够通过动态域名找到你，因为使用adsl等拨号软件时，每次拨号ip地址都会变动，总不能每次都人工通知人家你ip地址是什么吧；第二，路由器中配ddns账号、域名等信息，让路由器自动通知整个互联网，你申请的域名现在的ip地址是多少；第三，路由器中配端口转发，你vpn要使用哪个端口就设定进去，这样当别人访问路由器这个端口时，你在路由器中就可以指定转发到那台机器，例如80端口指定到192.168.1.2（你在上面放www网站），3389端口指定到192.168.1.10（例如做为管理机器）上，你就可以用远程桌面连接到这台机器，8080端口指定到192.168.1.5（例如放BBS论坛），你就通过你申请的域名http://sdf.3322.org:8080访问到BBS论坛了。你家里面路由器后面的VPN想开什么服务，把端口转发设定一下即可。\", \"上面不是有XP的教程么，我就把Win7的教程给你写一份，你都可以试试。 1.右键点击桌面的“网络”-&gt;“属性”后出现 2.单击“设置新的连接或网络”出现 3.选种“连接到工作区”点下一步。 4.单击“使用我的Internet连接（VPN）”，马上就转跳到5.在“Internet 地址（I）”填上VPN提供的IP地址，再下一步6.这里是填VPN的用户名和密码，点“连接”7.到这里就完成的连接设置导向。点击“关闭”。8.回到桌面右键点击“网络”-&gt;“属性” 9.点击一下左边的“更改适配器设置”。10.找到我们刚才建好的“VPN 连接”双击打开。11.填上VPN提供的VPN用户名和密码，“域”可以不用填写。12.整个Windows7 VPN过程都设置完成了。现在点击“连接（C）”就可以上游戏、上网冲浪了、浏览网页了 还有不明白的可以联系幺五幺二五零八四试试，这个网站的教程比较全面\", \"&lt;p&gt;&lt;img src=\\\"37250702446\\\" /&gt;&lt;/p&gt;\" ], \"title\": \"家用vpn服务器如何搭建\" &#125;],\"question\": \"如何搭建vpn服务器\",\"answers\": [ \"1、打开“网络和共享中心”，选择“更改适配器设置”2、在“菜单栏”点击“文件”，然后选择“新建传入连接”3、选择允许使用VPN连接到本机的帐户，可以从列表中勾选，也可以“添加用户”4、这一步就到了设置网络参数环节了，如果对方连接后可以使用本地网络的DHCP服务器，那么可以跳过此设置。如果本地网络没有DHCP服务器的话就要先进行一下设置了。5、到这里VPN服务器已经架设完毕了，其他用户已经可以利用上面的帐号以及设置的IP地址通过VPN连接到网络了。\", \"1、看路由器里面带不带VPN功能，如果可以就直接在路由器里面设置VPN，也可以买带VPN功能路由器；2、用windows server系统架构一个VPN。\", \"家用：第一，申请ddns，比如3322.org、花生壳什么的，让其他人能够通过动态域名找到；第二，路由器中配ddns账号、域名等信息，让路由器自动通知整个互联网，申请的域名现在的ip地址是多少；第三，路由器中配端口转发，vpn要使用哪个端口就设定进去，这样当别人访问路由器这个端口时，在路由器中就可以指定转发到那台机器，最后路由器后面的VPN想开什么服务，把端口转发设定一下即可。\"],\"question_type\": \"DESCRIPTION\",\"fact_or_opinion\": \"FACT\",\"question_id\": 91210&#125; 数据样例2raw/trainset/search.train.json1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&#123;\"documents\": [ &#123; \"bs_rank_pos\": 0, \"is_selected\": true, \"paragraphs\": [ \"导读:绣眉有哪几种方法?小编带来绣眉的基本方法,喜欢绣眉的MM看看吧。\", \"绣眉可以让MM的五官看起来更加的清秀有立体感,绣眉有哪几种方法?绣眉的基本方法分享给大家。\", \"绣眉有哪几种方法?\", \"绣眉的五种基本方法:\", \"1、雕润眉 2、平面绣眉 3、点状绣眉 4、立体绣眉\", \"5、仿真立体绣眉\", \"绣眉的基本方法:\", \"1、雕润眉 雕润眉是完美医学纹绣为载体,根据人的眉毛生长而雕刻出来的眉形,根据肤色来选料,这样的眉形看起来很靓丽好看,与传统的绣眉方法相比,雕润眉是如丝发般的精细雕刻眉毛,具有三维立体感,而且纹眉后不痛不肿,不脱色,不变色,不晕色,一般半个小时就能完成的绣眉。》》》99.99%人都关注的绣眉结痂问题 2、平面绣眉 平面绣眉是传统的绣眉方式,是通过过将复合自身形象的图案纹绘在眉毛上,经过改良而形成的平面绣眉,是标准眉型图案,颜色深浅平均,跟一般的眉形没太大区别。 3、点状绣眉 点状绣眉是独具设计性的绣眉,是一种改良的损伤最小的平面绣眉,需要用针点上药水刺其眉毛的毛囊口着色,稍微比较痛,看上去的眉毛比较粗,适合眉形好,眉毛少的女生。 4、立体绣眉 立体绣眉是利用排针,一排12只,运用不同的针法衔接在眉毛上,绣出二种深浅不一的咖啡色,这样的眉形看起来很自然立体,具有长短不齐、粗细不一的毛发线条特点,,让MM看起来更秀气漂亮。 5、仿真立体绣眉 仿真立体绣眉是比较流行的绣眉方式哦,是利用排针,一排12只,运用不同的针法进行绣眉,以咖啡色为基础,这样的眉形看起来很自然动态美。\", \"绣眉的五种基本方法,选择适合自己的绣眉方法,打造出秀气漂亮的眉形哦。\", \"(想知道自己适合什么发型吗?微信添加公众号爱靓网,发型师为您解答!)\" ], \"title\": \"绣眉有哪几种方法?绣眉的基本方法_绣眉_妆美扮靓_爱靓网\" &#125;, &#123; \"bs_rank_pos\": 1, \"is_selected\": false, \"paragraphs\": [ \"2016-09-30 10:04\", \"对于美的追求是很多人的天性,对于爱美的女生来说好看的眉型不但能提升气质,还能修饰脸型,绣眉也早已成为女生完善美化眉形的一种方式。绣眉有哪几种常见方法?一般绣眉得花多少钱?一起和小编了解一种吧。\", \"绣眉有哪几种常见方法?一起来了解下:\", \"A、平面绣眉:这是一款传统的绣眉方式,是以标准的眉型为图案,通过绣眉技术纹绘在眉毛上,色泽均匀上色,给人的感觉就好像刚刚画完眉毛一样。 B、点状绣眉:点状绣眉相对来说,会更有设计性。通过药水的渗透,将有色的染料对这眉毛的毛囊口进行点刺上色,还能按照眉毛的整体轮廓勾勒出眉型,不过眉毛过粗的美眉们则不适合点状绣眉喔! C、仿真立体绣眉:这种绣眉方式是利用排针和不同的针法衔接在眉毛上,出来的眉形效果是一把一把的形状,而且常用的色料是深浅不一的咖啡色来呈现,在着色上后的眉形效果就会像自己长出来的眉毛一样自然好看。 D、立体绣眉:立体绣眉也是利用排针来进行纹绣,采取了由浅至深的形式绣出眉形,而整体的效果会呈现出雾状,非常地有立体感。\", \"绣眉一般要多少钱?\", \"一般来说,绣眉的价钱在800到5000元之间,每家的医美诊所价格都是不同,会因规模以及技术相互关联。绣眉使用的材料也是决定价格的高低,一般分为有机色料及无机色料,以及绣眉的方式也是能决定价格的关键喔!由于绣上的眉型都是因人而异的,也会导致绣眉价格的差异。\", \"想必经过了小编的介绍,大家都对绣眉有哪几种常见方法?以及其价格有了一定的了解!如果你也想眉形好看也不妨尝试一下绣眉,选择好的技术以及医美医院才能保证绣眉的完美效果喔!(图片来源:视觉中国)\", \"(责任编辑:陆薇)\", \"全世界都在安利的“举重妖精”李圣经,凭什么成为男神收割机? 同是新疆美女 为啥迪丽热巴观众缘最好? 从晴儿到楚乔 赵丽颖是怎么越来越美的? 滨崎步发福or水肿?3分钟快速消水肿 学刘诗诗掀起刘海 气场2米8一点也不难\", \"梦幻的粉嫩无瑕肌 怎能不被吸引? 怀疑自己画了个假妆?那是用错了气垫 水润透亮 让肌肤呼吸一整天 伊夫黎雪植物焕颜抚纹系列 倒春寒 给肌肤加个完整的保湿屏障\", \"周末好心情 慵懒 露天趴音乐节妆容\", \"六月护肤爱用品 春季护肤五款高颜值萌物 开启焕肤撩春模式 实用百搭口罩妆容\", \"包贝尔新剧曝光表情冷 姜至鹏出轨被曝私密图 咘咘公园跳钢管舞萌翻 白百何学龅牙兔神表情 黄晓明胖了一圈曝真相 周冬雨再出表情包搞笑\" ], \"title\": \"绣眉有哪几种常见方法?绣眉一般要多少钱【图】_彩妆资讯百科_美容_\" &#125;, &#123; \"bs_rank_pos\": 2, \"is_selected\": false, \"paragraphs\": [ \"平面绣眉 平面绣眉是最为传统的绣眉方法。这种方法起源于古代,古时候人们将符合自身形象的图案描绘在眉毛和额头之间,最为有名的就是杨贵妃在眉毛和额头之间绘上了花朵。平面绣眉就是采用的这种方法。经过现代人的改良之后,平面绣眉出来的效果就像是刚刚画好的眉毛,还是比较逼真的。 点状绣眉 相对于平面绣眉来说,点状绣眉是比较疼的,不过这种方式更具有独特的设计性。点状绣眉适合眉毛细而且淡的人选择,它是采用针沾上药水有粗有细的对毛囊进行着色。采用这种方法能够绣出更加自然逼真的眉毛。 仿真立体绣眉 这种绣眉方法有点类似于点状绣眉,不过这种方法使用的是排针。目前比较常见的是使用一排十二根针。由于针的排布原因,使用这种方法绣出来的眉毛是一把一把的。而且美容院会采用深浅不同的颜色来表现眉毛的特点,因此,绣\", \"有平面绣眉,点状绣眉,仿真立体绣眉,立体绣眉\" ], \"title\": \"绣眉有哪几种_百度知道\" &#125;, &#123; \"bs_rank_pos\": 3, \"is_selected\": false, \"paragraphs\": [ \"有平面绣眉,点状绣眉,仿真立体绣眉,立体绣眉\" ], \"title\": \"绣眉有几种,哪种比较好看?_百度知道\" &#125;, &#123; \"bs_rank_pos\": 4, \"is_selected\": false, \"paragraphs\": [ \"有线条眉,就是跟真的眉毛很像,一根一根的;还有那种雾状眉,像化妆了一样;还有一种就是线条加雾的感觉。\", \"1、平面绣眉:传统的绣眉方式。在古代,绣眉技术是通过将复合自身形象的图案纹绘在眉额之间。后经过现代美容师的改良而形成如今的平面绣眉。以标准的眉型为图案,色泽均匀,宛如刚刚画完眉。 2、点状绣眉:此种方法相对于平面绣眉更加具有设计性,但是人体疼痛感要稍微强烈一点。在针点上通过药水的浸透,再对眉毛的毛囊口进行点刺并着色。可以按照眉毛的粗细变化,从而勾勒出漂亮的眉型。但是对于眉毛相对比较粗、浓者来说,是不适合进行点状绣眉的。 3、仿真立体绣眉:这种绣眉的方法利用排针,一排12只,运用不同的针法衔接在眉毛上,所绣出来的眉型现出一把一把的,而且须用二种深浅不一的咖啡色来表现色差,就像自己长的眉毛一样立体自然。 4、立体绣眉:这种绣眉的方法利用排针单一颜色由浅至深,绣出雾状,表现出立体\" ], \"title\": \"绣眉分哪几种_百度知道\" &#125;],\"question\": \"绣眉有哪几种\",\"answers\": [ \"绣眉的五种基本方法：1、雕润眉；2、平面绣眉；3、点状绣眉；4、立体绣眉；5、仿真立体绣眉。\"],\"entity_answers\": [ [ \"雕润眉\", \"平面绣眉\", \"点状绣眉\", \"立体绣眉\", \"仿真立体绣眉\" ]],\"question_type\": \"ENTITY\",\"fact_or_opinion\": \"FACT\",\"question_id\": 0&#125;","tags":[{"name":"dataset","slug":"dataset","permalink":"http://yoursite.com/tags/dataset/"},{"name":"数据分析","slug":"数据分析","permalink":"http://yoursite.com/tags/数据分析/"},{"name":"阅读理解","slug":"阅读理解","permalink":"http://yoursite.com/tags/阅读理解/"},{"name":"baidu","slug":"baidu","permalink":"http://yoursite.com/tags/baidu/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"阅读理解","slug":"ML/app/nlp/app/阅读理解","permalink":"http://yoursite.com/categories/ML/app/nlp/app/阅读理解/"},{"name":"-dataset","slug":"ML/app/nlp/app/阅读理解/dataset","permalink":"http://yoursite.com/categories/ML/app/nlp/app/阅读理解/dataset/"}]},{"title":"推荐系统架构","date":"2018-05-02T16:00:00.000Z","path":"wiki/ML/recommender-system/架构/","text":"架构 模型训练层 服务层 推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。 召回：初始推荐结果推荐引擎的构建来源于不同的数据源(也就是用户的特征有很多种类，例如统计的、行为的、主题的)+不同的推荐模型算法，推荐引擎的架构可以试多样化的(实时推荐的+离线推荐的)，然后融合推荐结果（人工规则+模型结果），融合方式多样的，有线性加权的或者切换式的等 多个引擎一般也称为多路召回： 新鲜度召回 热度召回 质量分召回 个性化 基于用户CF召回 基于itemCF召回 随机提取，每路召回1000个item。10路就10000 item。 优点： 支持多种模型，以及自定义模型- 可以方便地增加/删除引擎，控制不同引擎对推荐结果的影响。对于绝大多数需求，只需要通过不同的引擎组合实现。 可以实现推荐引擎级别的用户反馈 粗排精排通常采用LR模型，或者LR的变种。 最上层线上推荐服务、中层各个推荐数据召回集（数据主题、分类池子）、底层各种推荐模型。 推荐系统有哪些坑？ | 知乎 将“推荐”理解为“推送 高估算法作用 推荐系统中，按照影响效果：用户交互界面(UI) &gt; 数据 &gt; 算法。 技术点、难点、瓶颈 online/offline streaming 推荐，比如滑来滑去小视频 参考 《推荐系统实践》 项亮 QQ大数据推荐系统的架构演进 推荐系统的架构","tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"http://yoursite.com/tags/推荐系统/"},{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"recommender-system","slug":"ML/recommender-system","permalink":"http://yoursite.com/categories/ML/recommender-system/"}]},{"title":"hexo中如何支持公式 mathjax","date":"2018-05-02T16:00:00.000Z","path":"wiki/demo/hexo/hexo-math/","text":"UPDATE: 2018-08-08: github markdown已经支持公式， 简介MathJax 和 Katex mathjax Beautiful math in all browsersA JavaScript display engine for mathematics that works in all browsers. —— 来自www.mathjax.org MathJax是一款运行在浏览器中的开源的数学符号渲染引擎，使用MathJax可以方便的在浏览器中显示数学公式，不需要使用图片。目前，MathJax可以解析Latex、MathML和ASCIIMathML的标记语言。 MathJax项目于2009年开始，发起人有American Mathematical Society, Design Science等，还有众多的支持者。 无损缩放，支持多种方式的公式渲染(math-render)。(不采用图片、Flash) CSS引擎：采用CSS生成数学公式 SVG引擎：采用SVG生成数学公式 MathML引擎： 源码拷贝。可以拷贝LaTeX、wiki等； 输入形式可以是MathML、TeX或者ASCIImath html中使用mathjaxmathjax就是个前端渲染引擎。 也可以借鉴 https://kexue.fm/latex.html 或者拷贝以上代码，保存为math.html，双击打开就能看到渲染好的公式。 hexo中使用mathjax同样很简单，仅需两步。 加载mathjax的cdn 博客中按照tex语法写公式即可 示例markdown中书写：1$$x = &#123;-b \\pm \\sqrt&#123;b^2-4ac&#125; \\over 2a&#125;.$$ 会被自动渲染成以下公式： $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ 1234# 其他方式：\\[x = &#123;-b \\pm \\sqrt&#123;b^2-4ac&#125; \\over 2a&#125;.\\]# 如果存在转义问题，可以采用以下方式\\\\[x = &#123;-b \\pm \\sqrt&#123;b^2-4ac&#125; \\over 2a&#125;.\\\\] hexo中支持公式的markdown插件 hexo-renderer-marked这是hexo默认的markdown渲染插件，其调用的marked.js渲染引擎。 hexo-math插件。不推荐，竟然还支持math 的标签，画蛇添足 markdown渲染引擎 marked 轻量级 demo jupyter、google-colab、hexo默认采用的marked.js作为渲染引擎 hexo模块: hexo-renderer-marked pandoc 重量级 demo pandoc -f markdown+tex_math_single_backslash –mathjax test.md -o test.html 以上参数的命令可以解决问题 hexo模块: hexo-renderer-pandoc kramdowndemo cs231n 等采用的kramdown hexo模块: hexo-renderer-kramed 存在的问题公式的转义问题有时会遇到公式渲染失败，有时也会遇到很多不同的公式写法，比如： $、$$ \\(和\\)、\\[和\\] \\\\(和\\\\)、\\\\[和\\\\]，示例tensorflow 、cs231n 公式渲染失败，一般是由于不同的markdown引擎的渲染方式不同引起的，以上的\\\\(这种写法也是为了和markdown渲染引擎作斗争，以致于写个公式变得这么复杂。 举个例子 1\\[ x=1 \\] 经过marked引擎解析成以下html:1&lt;p&gt;[ x=1 ]&lt;/p&gt; 注意: 这里的反斜线\\[经过marked引擎后转义丢失，只剩下[。因此mathjax无法识别，以致于公式无法正常显示。 怎么办？既然反斜线丢失，那就多加个反斜线，写成\\\\[ x=1 \\\\]。这样就渲染成功了 常见的markdown渲染引擎 marked 轻量级 demo) pandoc 重量级 也存在同样的问题，demo&amp;from=markdown&amp;to=) pandoc -f markdown+tex_math_single_backslash –mathjax test.md -o test.html 以上参数的命令可以解决问题 kramdown也存在同样的问题，demo 多加个反斜线，比如\\[要写成\\\\[ 麻烦 修改marked源码，取消了对\\\\,\\{,\\}的转义(escape) 麻烦 采用其他markdown引擎，比如kramdown (比如cs231n就采用的kramdown) 发现也不work 把所有\\[替换成$$ 我目前是这样做的 建议: 不要采用 \\[ 或 \\(的格式书写公式，尽量用$$ 或 $ 很多引擎不支持\\[或 \\( (比如github) \\[中的反斜线经常会被解释成转义符号，造成符号丢失 疑问 `theme-next`为什么要限定markdown引擎？不应该和markdown引擎无关吗？ ... 参考 theme-next中使用mathjax | next官方文档 Hexo下mathjax的转义问题 使Marked.js与MathJax共存","tags":[{"name":"前端渲染","slug":"前端渲染","permalink":"http://yoursite.com/tags/前端渲染/"},{"name":"mathjax","slug":"mathjax","permalink":"http://yoursite.com/tags/mathjax/"},{"name":"公式","slug":"公式","permalink":"http://yoursite.com/tags/公式/"}],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"RNN研究现状以及发展趋势，LSTM的变种 (variants of LSTM)","date":"2018-05-02T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/RNN/3. RNN-next/","text":"训练算法，如Back Propagation Through Time(BPTT)、Real-time Recurrent Learning(RTRL)、Extended Kalman Filter(EKF)等学习算法，以及梯度消失问题(vanishing gradient problem) 详细介绍Long Short-Term Memory(LSTM，长短时记忆网络)； 详细介绍Clockwork RNNs(CW-RNNs，时钟频率驱动循环神经网络)； 基于Python和Theano对RNNs进行实现，包括一些常见的RNNs模型。 # GRU - gated recurrent unitIt combines the forget and input gates into a single “update gate.” Italso merges the cell state and hidden state, and makes some other changes. The resulting model is simpler thanstandard LSTM models, and has been growing increasingly popular. SRNN -上海交通大学的Zeping Yu 和Gongshen Liu，在论文“Sliced Recurrent Neural Networks”中，提出了全新架构“切片循环神经网络”（SRNN）。SRNN可以通过将序列分割成多个子序列来实现并行化。SRNN能通过多个层获得高级信息，而不需要额外的参数。 SRU - simple recurrent unitlightRNN","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"深度学习中的注意力机制 原理 及 代码","date":"2018-04-30T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/attention-model/","text":"seq2seq缺陷：无论之前的context有多长，包含多少信息量，最终都要被压缩成一个几百维的vector。这意味着context越大，最终的state vector会丢失越多的信息。 Attention based model的核心思想: 一个模型完全可以在decode的过程中利用context的全部信息，而不仅仅是最后一个state。 ss global attention local attention ewrw soft hard 各种各样的attention 2014年google mind团队的这篇论文《Recurrent Models of Visual Attention》，他们在RNN模型上使用了attention机制来进行图像分类。 Bahdanau等人在论文《Neural Machine Translation by Jointly Learning to Align and Translate》中，使用类似attention的机制在机器翻译任务上将翻译和对齐同时进行，他们的工作算是第一个将attention机制应用到NLP领域中。 接着attention机制被广泛应用在基于RNN/CNN等神经网络模型的各种NLP任务中。 2017年，google机器翻译团队发表的《Attention is all you need》中大量使用了自注意力（self-attention）机制来学习文本表示。 什么是attention，attention的起源广义的attention见google得transformer。 Attention函数的本质可以被描述为一个查询（query）到一系列（键key-值value）对的映射， self attention什么是self-attention，下面这个图就是self-attention。 可以理解为没有target的attention，也可以理解为自己把自己当做target进行attention。 Multi-Head AttentionStructured Self-attention参考 A Structured Self-attentive Sentence Embedding Self-Attention with Relative Position Representations - google brain 2018Self-Attention with Relative Position Representations（基于相对位置表示的子注意力模型） Reinforced Self-AttentionReinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling（增强的自注意力网络:一种对序列建模的硬和软注意力的混合） Distance-based Self-Attention NetworkDistance-based Self-Attention Network for Natural Language Inference（基于距离的自注意力网络的自然语言推理） sparse attentionhierarchical attentioinHierarchical Attention Networks for Document Classification 采用了word-level和sentent-level的attention。 a word sequence encoder 采用的GRU。Document Modeling with Gated Recurrent Neural Network… 这篇文章提到，在文本分类领域 GRU比LSTM效果好。 也可以采用CNN a word-level attention layer a sentence encoder a sentence-level attention layer 可视化分析 ## ## 参考 Attention and Augmented Recurrent Neural Networks | Distill- 深度学习中的注意力机制 | 张俊林 2017 自然语言处理中的自注意力机制（Self-attention）| cnblogs 知乎 注意力机制和PyTorch实现机器翻译 【论文推荐】最新七篇自注意力机制(Self-attention)相关论文 《Attention is All You Need》浅读（简介+代码）| kexue.fm","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"【机器翻译】transformer","date":"2018-04-30T16:00:00.000Z","path":"wiki/machine translation/2. 主流model-研究现状/2. NMT/transformer/","text":"简介在2017年5月Facebook发布了ConvSeq2Seq模型吊打了GNMT一个月之后，Google发出了最强有力的反击，发表了一篇论文Attention is all you need，文中提出了一种新的架构叫做Transformer，用以来实现机器翻译。它抛弃了传统的CNN、RNN，只采用attention，取得了很好的效果，激起了工业界和学术界的广泛讨论。 背景，motivation如何获取context信息常用的模型架构有RNN、CNN（见 related work）。trick方面，常见的是position-encoding transformer横空出世Transformer避开了recurrence，只用attention，便可以刻画出输入和输出的依赖关系。 对比RNN的决策步骤太长问题，transformer可单步决策。通过一层self-attention，bank能够直接attend到river上。 ConvS2S是线性时间复杂度，ByteNet是log时间复杂度。而Transformer则是常数时间复杂度(前提是the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention)。 核心点 创新点 亮点 trick 对attention的抽象对attention的抽象 q k v When $a \\ne 0$, there are two solutions to $ax^2 + bx + c = 0$ and they are$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ 前面给出的是一般化的框架形式的描述，事实上Google给出的方案是很具体的。首先，它先把Attention的定义给了出来：$$ Attention(\\boldsymbol{Q},\\boldsymbol{K},\\boldsymbol{V}) = softmax\\left(\\frac{\\boldsymbol{Q}\\boldsymbol{K}^{\\top}}{\\sqrt{d_k}}\\right)\\boldsymbol{V} $$ 这里用的是跟Google的论文一致的符号，其中$ \\boldsymbol{Q}\\in\\mathbb{R}^{n\\times d_k}, \\boldsymbol{K}\\in\\mathbb{R}^{m\\times d_k}, \\boldsymbol{V}\\in\\mathbb{R}^{m\\times d_v} $。如果忽略激活函数softmax的话，那么事实上它就是三个$ n\\times d_k,d_k\\times m, m\\times d_v $的矩阵相乘，最后的结果就是一个$ n\\times d_v $的矩阵。于是我们可以认为：这是一个Attention层，将n$ n\\times d_k $的序列Q编码成了一个新的$ n\\times d_v $的序列。 并行其实就是encoder的时候可以，速度上来说transformer并不占优势 这里将attention抽象成 q k v attention 可以不只是用于 decoder 里每步输入一个符号，而是可以用在网络中的任意一层，把一个序列转换成另一个序列。这个作用与 convolutional layer、recurrent layer 等是类似的，但有一个好处就是不再局限于局域性。attention是直接去capture dependency structure，摆脱了局限性魔咒 attention 可以一般地描述为在一个 key-value mapping 中进行检索，只不过 query 跟 key 可以进行模糊匹配，检索结果是各个 key 对应的 value 的加权平均。 Query, key, value 其实并不是专门针对翻译的概念。不过可以举一些翻译中的例子。例如，当刚刚翻译完主语之后，attention 的内部状态就会想要去找谓语，这时它就把「想找谓语」这件事编码成 query。然后句子里本身是谓语的地方，会有一个 key，表明「我这里可以提供谓语」，它跟 query 一拍即合。这个 key 对应的 value 就是谓语本身的 embedding。 机器翻译中的特例ssQ: 在LSTM+attention模型里，query就是上一个时间单元的隐状态，容易理解，即你所谓的对[想找谓语]编码，但是all attention模型不再使用LSTM，这个query编码是什么？谢谢A: all attention model 只不过不再用 lstm 计算隐状态，而是用 attention 计算得出。一层 attention 计算出的结果就是下一层的 query Multi-Head Attention以Q为例，单个head的计算 code-t2t code-Kyubyong code-keras 将输入向量切成8份，这每一份可以看成一个local partial，然后再分别attnetion最终再concat成一个context向量。如果将本文multi-head attention的V输入切成八份后的向量类比关注不同local paritial的卷积核的话，我们可以看到CNN和这里multi-head attention异曲同工 优势：能在encode的时候并行化，(convS2S同样可以，但是transformer只用attention） Multiple attention layers (heads) in parallel Each head uses different linear transformations. Different heads can learn different relationships. 思考self attention遗漏了什么？位置信息self attention中的k, q, v分别指代什么？self attention是否可逆向？ FFN层FFN(Position-wise Feed-Forward Network)。 Position-wise: 顾名思义，就是对每个position采用相同的操作。 Feed-Forward Network: 就是最普通的全连接神经网络，这里采用的两层，relu作为激活函数 FFN层对接multi-head attention层，那么该层的输入 $x \\in \\mathbb{R}^{batchsize \\times length \\times d_{model}}$。 https://github.com/tensorflow/tensor2tensor/blob/v1.9.0/tensor2tensor/models/transformer.py#L1373 $$FFN(x)=max(0,x W_1+b_1)W_2+b_2$$ 其中输入和输出的维度都是$d_{model}=512$，中间维度是$d_{ff}=2048$。对于单个position$$x \\in \\mathbb{R}^{512}, W_1 \\in \\mathbb{R}^{512 \\times 2048}, W_2 \\in \\mathbb{R}^{2048 \\times 512}$$ 与卷积的等价性这里的全连接层，一种替代方案就是采用kernel size为1的卷积，即 tensor2tensor中有两种实现dense_relu_dense 和 conv_relu_conv，默认采用的前者。 其中卷积的维度是123input.shape = [batch_size, length, 512]kernel_1 = [2048,1] kernel_2 = [512, 1] tensor2tensor实现中，conv1d中的kernel_size如果为1，默认返回dense。源码1234def tpu_conv1d(inputs, filters, kernel_size, padding=\"SAME\", name=\"tpu_conv1d\"): if kernel_size == 1: return dense(inputs, filters, name=name, use_bias=True) ... 逗比，conv到底比dense会不会加速？ 为什么我觉得kernel_size=512才等价于全连接？ 实际上，kernel_size没必要一定是1的。 层数与维度设计 - 很精妙很自然，我们有两个疑问。 为什么要两层？ 为什么要先升维再降维？ ResNet等网络通常采用bottleNeck架构，先降维再升维(减小计算量)。这里是什么思想 小结为什么要设置全连接层？全连接层一般占用参数比较多，比如常用的CNN架构里很少在中间层放全连接。 这里在中间层大量使用FFN的思想是什么呢？ 仅仅是为了故意避开CNN？答：FFN的设计初衷是: 1. 增加非线性变换; 2. 维度变换。同时尽量减少参数量、计算量。如果不采用FFN呢？有什么更好的设计？conv层: 单个position的conv无意义。可以考虑跨position的conv！！！pooling层全连接参数多，在多数CNN架构里只在最后一层加FC层。为什么叫强调position-wise？不就是普通的ReLU激活函数的神经网络吗？解释一: 这里FFN层是每个position进行相同且独立的操作，所以叫position-wise。对每个position独立做FFN。解释二：从卷积的角度解释，这里的FFN等价于kernel_size=1的卷积，这样每个position都是独立运算的。如果kernel_size=2，或者其他，position之间就具有依赖性了，貌似就不能叫做position-wise了paper中强调：applied to each position separately and identically 既想增加非线性，又不像增加计算量？ Positional Encoding回顾一下Transformer的整个架构，不难发现Transformer模型本身并不能捕捉序列的顺序。换句话说，如果将K,V按行打乱顺序（相当于句子中的词序打乱），那么Attention的结果还是一样的。这就表明了，到目前为止，Attention模型顶多是一个非常精妙的“词袋模型”而已。 Sinusoid Positional Encoding code 1、以前在RNN、CNN模型中其实都出现过Position Embedding，但在那些模型中，Position Embedding是锦上添花的辅助手段，也就是“有它会更好、没它也就差一点点”的情况，因为RNN、CNN本身就能捕捉到位置信息。但是在这个纯Attention模型中，Position Embedding是位置信息的唯一来源，因此它是模型的核心成分之一，并非仅仅是简单的辅助手段。 2、在以往的Position Embedding中，基本都是根据任务训练出来的向量。而Google直接给出了一个构造Position Embedding的公式：$$\\left{\\begin{aligned}&amp;PE_{2i}(p)=\\sin\\Big(p/10000^{2i/{d_{pos}}}\\Big)\\&amp;PE_{2i+1}(p)=\\cos\\Big(p/10000^{2i/{d_{pos}}}\\Big)\\end{aligned}\\right.$$ 这里的意思是将id为$p$的位置映射为一个$d_pos$维的位置向量，这个向量的第$i$个元素的数值就是$PE_{i}(p)$。Google在论文中说到他们比较过直接训练出来的位置向量和上述公式计算出来的位置向量，效果是接近的。因此显然我们更乐意使用公式构造的Position Embedding了。 3、Position Embedding本身是一个绝对位置的信息，但在语言中，相对位置也很重要，Google选择前述的位置向量公式的一个重要原因是：由于我们有 $\\sin(\\alpha+\\beta)=\\sin\\alpha\\cos\\beta+\\cos\\alpha\\sin\\beta$以及$\\cos(\\alpha+\\beta)=\\cos\\alpha\\cos\\beta-\\sin\\alpha\\sin\\beta$，这表明位置$p+k$的向量可以表示成位置$p$的向量的线性变换，这提供了表达相对位置信息的可能性。 小结Transformer并没有在结构上突破传统的LSTM和CNN，只是采用了position encoding的方式取巧。如何在结构上突破CNN和LSTM的缺陷，达到获取position(时序)信息、任意长度依赖、易并行的效果？其他方案拼接: 起来作为一个新向量，也可以把位置向量定义为跟词向量一样大小，然后两者加起来。FaceBook的论文和Google论文中用的都是后者。直觉上相加会导致信息损失，似乎不可取multi-channel: 其他layer normResult## 可视化经过测试，列了以下可视化结果。 TODO，+动态可视化 维度设计在NLP的很多网络里，一般 hidden_dim和embedding_dim 相等- 每层的维度都是相同的维度，(只在FFN层进行了局部升维)。 这与传统的 参数量 &amp; 计算量code TensorFlow https://github.com/Kyubyong/transformer 简易版，bucket、lr、decay等都没有实现 https://github.com/tensorflow/models/tree/master/official/transformer TF官方code，基本不更新 https://github.com/tensorflow/tensor2tensor#translation 官方code，产品级，更新频繁 代码解析： https://blog.csdn.net/mijiaoxiaosan/article/details/74909076 Pytorch 缺陷ssAttention层的好处是能够一步到位捕捉到全局的联系，因为它直接把序列两两比较（代价是计算量变为$\\mathscr{O}(n^2)$)，当然由于是纯矩阵运算，这个计算量相当也不是很严重）；相比之下，RNN需要一步步递推才能捕捉到，而CNN则需要通过层叠来扩大感受野，这是Attention层的明显优势。 扩展阅读 Transformer | Google-blog 《Attention is All You Need》浅读（简介+代码）| kexue.fm 很多还没看懂，后面继续看 从convS2S到transformer | 知乎","tags":[{"name":"机器翻译","slug":"机器翻译","permalink":"http://yoursite.com/tags/机器翻译/"},{"name":"seq2seq","slug":"seq2seq","permalink":"http://yoursite.com/tags/seq2seq/"},{"name":"attention","slug":"attention","permalink":"http://yoursite.com/tags/attention/"}],"categories":[{"name":"machine translation","slug":"machine-translation","permalink":"http://yoursite.com/categories/machine-translation/"},{"name":"2. 主流model-研究现状","slug":"machine-translation/2-主流model-研究现状","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/"},{"name":"2. NMT","slug":"machine-translation/2-主流model-研究现状/2-NMT","permalink":"http://yoursite.com/categories/machine-translation/2-主流model-研究现状/2-NMT/"}]},{"title":"【政治风云人物系列】褒贬不一 朱镕基","date":"2018-04-28T16:00:00.000Z","path":"wiki/others/politics/china/人物/-朱镕基/","text":"简介因铁腕作风，于风雨飘摇中导演中国经济“软着陆”，一时间举世瞩目，人称“经济沙皇”。接着导演中国经济史上最著名的分锐制、国企改革、金融体制改革等等。大开大阖间毁誉参半，国家既得其利也受其弊。利弊得失是怎样的一笔账，这是争论不下的最大焦点。 “铁面总理”、“大炮总理” 个性鲜明 这是共和国历史上唯一一位没有获得连任的总理 他是形式上没有连任，1992年起作为第一副总理就代替大鸟全面负责经济工作了。 历史朱先生在担任上海市长、市委书记时，给上海官场面貌及风气的震动是极大的。他从来不陪客人吃饭，极少参加各种庆典仪式活动，从不题字，说话绝少官腔，疾恶如仇，且批评疾言厉色。 1993年调任国务院担任主管经济的副总理后，首先的任务就是“灭火”，即煞住因伟人南巡讲话而在全国掀起的又一轮经济热，特别是开发区热和海南房地产热。这特别地表现了他的清醒与勇气，好在点燃这把火的邓小平先生给予了他坚决的支持。朱的做法也在某些方面是和当时的官场逆向而行的，特别是此时成型的官僚阶级已经从经济增长和改革开放中看到了以权谋私的最大机遇：既有政绩，又有租金。朱先生要在这时搞整顿是格外地费力的，不但要讲经济，而且要讲政治，与官僚集团作战。 【牛逼】 他亲自兼任央行行长，以从根儿上控制住银行的货币泛滥和贷款腐败。他力挽狂澜，将几个省的人行行长撤职。朱先生的壮举得罪了金融系统的传统势力，而且他的许多做法太超出官场规矩，给人不近人情之感。有一个故事，能说明这一点。某省人行行长也是被朱撤职的，某省政府随即任命此人为省政府主管金融工作的副秘书长。不久，国务院在天津召开金融工作会议，该副秘书长赴会。不料开幕式上，竟被朱先生点名起立并轰出会场，理由是“你连一个银行都管不好，怎么能管好一个省的金融工作”。 改革朱镕基当年的工作，从三角债到技术升级，从转变政府工作职能到重大项目国产化，从银行金融管理效率到税制改革，方方面面对二十年后的中国经济各项红利的开发，无人能与之相比。 搞经济1992年4月邓小平在视察首钢时讲到，朱镕基懂经济，不服气不行。 国企改革在朱镕基的时代，他进行了令他自己引以为傲的国企改革。在没有建立任何最低生活保障的情况下让几千万工人下岗。东北的工人占了很大一部分。这些工人突然没有了任何生活来源，很多妇女找不到工作，要么从事性工作，要么死亡。面临这种情况的妇女是如此之多，于是中国有了很多性工作者，而且也只能如此廉价。 网评： 朱镕基：中国逼良为娼最多的人 金融体制改革行政体制改革朱一口将国务院系统从70部门压缩为28个部门，工作人员减少了近一半，近乎奇迹。 反腐子弟王岐山是朱鎔基培养的得意门生。(中共十九大后王岐山退出政治局常委) 右派经历有分析认为，1955年反右的直接后果是引发了饿死3700余万人的大灾难。 有记者追问他一九五八年当右派的事。他闪烁其词地回答：“这一段经历对我的教育是很深刻的，但是也是很不愉快的。因此我也不想再提这件事了。”党内高层右派的态度类似朱镕基，不愿再揭疮疤。而中共官方也竭力掩饰这段内斗历史。 ## 朱镕基严于律己，举世皆知。他不题词、不受礼、不吃请、不剪彩、不批条子。但我们发现，他也曾破例题词。 2002年朱镕基在两会期间答记者问时，面对全世界的新闻媒体说出这样的话语：我只希望在我卸任以后，全国人民能说一句，他是个清官，不是贪官，我就很满意了。如果他们再慷慨一点，说朱镕基还是办了一点实事，我就谢天谢地了。 1998年10月7日下午，朱镕基到中央电视台视察(焦点访谈)，破例题写16个大字：“舆论监督，群众喉舌，政府镜鉴，改革尖兵。” 横向比较纵向比较VS 温家宝朱鎔基近年对其继任人温家宝的经济政策颇有微辞，如认为温不懂经济，对控制楼价不力等等。 新浪网友就称之为“改革开放后最不懂经济的总管” “朱时代时大卖国企，可谓国退民进，而现时代则正好相反，缓过神来的国企，大肆扩张，国进民退，与民争利”。 没有及时调整分税制弊端，使土地财政成为地方的主要财源 VS 李克强网友评价影帝看来粉丝还真多 论外交他任上搞什么消气之旅,拉二胡唱小曲,也没哄得洋大人开心,人还没回国给美国兜屁股踢了一脚, 大使馆被炸,建国以来最大的奇耻大辱 论反腐,金融口大案频发,张恩照等巨贪在他任上被提上去 论民生,农民真苦农业真危险在他任上爆发.血汗工厂在他任上最为猖獗 搞国企改革,搞跨了千万国企 论清廉,自个家儿子女儿都在其主管口成了富豪. 论作秀是一流的 参考 王霄：朱镕基功过之一瞥 从朱镕基讲话中我们知道了什么？ | 知乎","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"人物","slug":"others/politics/china/人物","permalink":"http://yoursite.com/categories/others/politics/china/人物/"}]},{"title":"【读图识政治】党史","date":"2018-04-28T16:00:00.000Z","path":"wiki/others/politics/china/党的机构/-党史/","text":"","tags":[{"name":"国家领导","slug":"国家领导","permalink":"http://yoursite.com/tags/国家领导/"},{"name":"总书记","slug":"总书记","permalink":"http://yoursite.com/tags/总书记/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"党的机构","slug":"others/politics/china/党的机构","permalink":"http://yoursite.com/categories/others/politics/china/党的机构/"}]},{"title":"【读图识政治】中国最高领导人","date":"2018-04-28T16:00:00.000Z","path":"wiki/others/politics/china/国家领袖/最高领导人/","text":"最高领导人中华人民共和国最高领导人是指中华人民共和国政治中具有最终决定和最高地位的政治领导人，是一个“非官方”的称谓。最高领导人在中国共产党和中华人民共和国的权力机构中不一定拥有最高职衔，但均曾担任中共中央军委主席，能有效控制其三大党政军机构——中国共产党、政府和解放军等武装力量。 目前中国官方称呼毛泽东、邓小平、江泽民、习近平为第一、二、三、五代中央领导集体的核心，称呼第四代胡锦涛为以他为总书记的党中央。党主席兼总理华国锋则是过渡时期的领导人。 2017年中共十九大之后，中共中央政治局全体委员和常委都被规定要向总书记述职，形成“总书记绝对领导制”，习近平作为总书记不再只是集体领导的一员，其权威已经达到毛泽东时期中央委员会主席的程度，成为全党全国的最高领袖。 历代领导人 代 姓名 肖像 党职 时间 备注 1 毛泽东 中共中央委员会主席中共中央军事委员会主席 1949-1976 党主席，一直都是最高领导人 华国锋 中共中央委员会主席中共中央军事委员会主席 1976-1978 毛泽东钦点的接班人，党内斗争失势后退休 2 邓小平 中共顾问委员会主任中共中央军事委员会主席 1978-1992 1978年复出做元老代表，主持改革开放政策 3 江泽民 中共中央总书记中共中央军事委员会主席 1992-2002 六四事件之后取代赵紫阳做中共中央总书记 4 胡锦涛 中共中央总书记中共中央军事委员会主席 2002-2012 邓小平于1992年就已经隔代钦点的接班人 5 习近平 中共中央总书记中共中央军事委员会主席 2012- 革命元老习仲勋儿子，中共党内协商产生 领导班子google.charts.load(“current”,{packages:[“timeline”]}); google.charts.setOnLoadCallback(drawChart); function drawChart(){var container=document.getElementById(‘timeline-china’); var chart=new google.visualization.Timeline(container); var dataTable=new google.visualization.DataTable(); dataTable.addColumn({type: ‘string’, id: ‘Position’}); dataTable.addColumn({type: ‘string’, id: ‘Name’}); dataTable.addColumn({type: ‘date’, id: ‘Start’}); dataTable.addColumn({type: ‘date’, id: ‘End’}); dataTable.addRows([ [ ‘国家主席’, ‘毛泽东’, new Date(1949, 10, 1), new Date(1959, 4, 27)], [ ‘国家主席’, ‘刘少奇’, new Date(1959, 4, 27), new Date(1968, 10, 31)], [ ‘国家主席’, ‘宋庆龄、董必武(代理)’, new Date(1968, 10, 31), new Date(1972, 2, 24)], [ ‘国家主席’, ‘董必武(代理)’, new Date(1972, 2, 24), new Date(1975, 1, 17)], [ ‘国家主席’, ‘宋庆龄’, new Date(1981, 5, 16), new Date(1981, 5, 29)], [ ‘国家主席’, ‘李先念(名誉主席)’, new Date(1983, 6, 18), new Date(1988, 4, 8)], [ ‘国家主席’, ‘杨尚昆’, new Date(1988, 4, 8), new Date(1993, 3, 27)], [ ‘国家主席’, ‘江泽民’, new Date(1993, 3, 27), new Date(2003, 3, 15)], [ ‘国家主席’, ‘胡锦涛’, new Date(2003, 3, 15), new Date(2013, 3, 14)], [ ‘国家主席’, ‘习近平’, new Date(2013, 3, 14), new Date()], [ ‘中共总书记’, ‘毛泽东’, new Date(1945, 6, 19), new Date(1976, 9, 9)], [ ‘中共总书记’, ‘华国锋’, new Date(1976, 10, 7), new Date(1981, 6, 28)], [ ‘中共总书记’, ‘胡耀邦’, new Date(1981, 6, 29), new Date(1987, 1, 16)], [ ‘中共总书记’, ‘赵紫阳’, new Date(1987, 1, 16), new Date(1989, 6, 2)], [ ‘中共总书记’, ‘江泽民’, new Date(1989, 6, 24), new Date(2002, 11, 14)], [ ‘中共总书记’, ‘胡锦涛’, new Date(2002, 11, 15), new Date(2012,11, 14)], [ ‘中共总书记’, ‘习近平’, new Date(2012, 11, 15), new Date()], [ ‘军委主席’, ‘毛泽东’, new Date(1949, 10, 1), new Date(1976, 8)], [ ‘军委主席’, ‘华国锋’, new Date(1976, 10, 7), new Date(1981, 6)], [ ‘军委主席’, ‘邓小平’, new Date(1981, 6), new Date(1989, 11)], [ ‘军委主席’, ‘江泽民’, new Date(1989, 11), new Date(2004, 9)], [ ‘军委主席’, ‘胡锦涛’, new Date(2004, 9), new Date(2012, 11)], [ ‘军委主席’, ‘习近平’, new Date(2012, 11), new Date()], [ ‘国务院总理’, ‘周恩来’, new Date(1949, 10, 1), new Date(1976, 1, 8)], [ ‘国务院总理’, ‘华国锋’, new Date(1976, 2, 2), new Date(1980, 9, 10)], [ ‘国务院总理’, ‘赵紫阳’, new Date(1980, 9, 10), new Date(1987, 11, 24)], [ ‘国务院总理’, ‘李鹏’, new Date(1987, 11, 24), new Date(1998, 3, 17)], [ ‘国务院总理’, ‘朱镕基’, new Date(1998, 3, 17), new Date(2003, 3, 16)], [ ‘国务院总理’, ‘温家宝’, new Date(2003, 3, 16), new Date(2013, 3, 15)], [ ‘国务院总理’, ‘李克强’, new Date(2013, 3, 15), new Date()]]); var options={‘title’:’中国最高领导人’, ‘height’:220, ‘language’: ‘ja’}; chart.draw(dataTable,options);} 邓小平一生未担任国家元首、政府首脑，或党内最高领导职务，但从1978年12月（中共十一届三中全会）至1989年11月辞去中共中央军委主席（中共十三届五中全会）一职前，普遍认为他是实际的最高领导人，并写入《中国共产党章程》予以确认。 1976-1981 华国锋任国家主席。1978年实权逐渐转移至邓小平。1981-1982 胡耀邦任国家主席。由邓小平为首的中共元老掌握实权。1982-1987 胡耀邦 总书记 在职期间由中共元老邓小平担任实际最高领导人。1987-1989 赵紫阳 总书记 在职期间由中共元老邓小平担任实际最高领导人。 军委主席因此形式上存在两个中央军事委员会，即中国共产党中央军事委员会和中华人民共和国中央军事委员会，但是两个委员会的最高负责人（又分别称中共中央军委主席和国家军委主席）和副主席除了过渡时期外均为相同的人选。 国家主席 邓小平指出：“还是要设国家主席，有国家主席代表国家比较好，但是对国家主席的职权可以规定得虚一点，不要管具体工作，不要干涉具体政务。” 1981年5月16日，第五届全国人民代表大会常务委员会第十八次会议决定，授予病危的宋庆龄“中华人民共和国名誉主席”荣誉称号。 1983年开始，中华人民共和国“主席”的官方英文译名由“Chairman”（直译为“主席”）改为“President”（可译为“总统”）。 参考 维基百科","tags":[{"name":"国家领导","slug":"国家领导","permalink":"http://yoursite.com/tags/国家领导/"},{"name":"总书记","slug":"总书记","permalink":"http://yoursite.com/tags/总书记/"},{"name":"国家元首","slug":"国家元首","permalink":"http://yoursite.com/tags/国家元首/"},{"name":"国家主席","slug":"国家主席","permalink":"http://yoursite.com/tags/国家主席/"},{"name":"军委主席","slug":"军委主席","permalink":"http://yoursite.com/tags/军委主席/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家领袖","slug":"others/politics/china/国家领袖","permalink":"http://yoursite.com/categories/others/politics/china/国家领袖/"}]},{"title":"【深度学习-模型系列】Inception","date":"2018-04-27T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/CNN/inception/","text":"简介 [v1 - 2014] Going Deeper with Convolutions [v2 - 2015] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift 加了BatchNormalization正则，去除55卷积，用两个33代替 [v3 - 2015] Rethinking the Inception Architecture for Computer Vision 77卷积又拆成71+1*7 [v4 - 2016] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning 加入了残差结构 code-tensorflow 尽管Inception v3与Inception-ResNet-v2都很擅长识别每一条狗所属的类别，这种新模型的性能更为显著。例如，旧模型可能会错误地将右边的图片识别为阿拉斯加雪橇犬，新模型Inception-ResNet-v2能够准确地识别两个图片中狗的类别。 创新点codehttps://github.com/tensorflow/models/tree/master/research/inception","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"【Hexo插件系列】hexo-reference","date":"2018-04-27T16:00:00.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/2/hexo-reference/","text":"12345678910111213141516var renderFootnotes = require('./src/footnotes'); util = require('hexo-util');// Register footnotes filterhexo.extend.filter.register('before_post_render', function(data) &#123; data.content = renderFootnotes(data.content); return data;&#125;);// Add CDN CSS resourceshexo.extend.filter.register('after_post_render', function(data) &#123; data.content = util.htmlTag('link', &#123;rel: 'stylesheet', type: 'text/css', href: 'https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css'&#125;) + data.content; return data;&#125;); 是不是应该叫filter","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"2","slug":"CS/web/blog-framework/nodejs-hexo/plugin/2","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/2/"}]},{"title":"【java源码系列】random的源码实现","date":"2018-04-27T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/-lang/Math.random/","text":"API介绍 Math.random()方法来产生一个随机数，这个产生的随机数是0-1之间的一个double- 用法生成从1到10的int型随机数12345// 方式一：int i = (int)(1+Math.random()*(10-1+1))// 方式二:int i = random.nextInt(99)+1; 主要涉及的类java.util.Random 其他Random从Jdk 1.0开始就有了，而ThreadLocalRandom是Jdk1.7才新增的。简单从命名和类所在的包上看，两者的区别在于对并发的支持。","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"java源码","slug":"java源码","permalink":"http://yoursite.com/tags/java源码/"},{"name":"random","slug":"random","permalink":"http://yoursite.com/tags/random/"},{"name":"随机数","slug":"随机数","permalink":"http://yoursite.com/tags/随机数/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"-lang","slug":"CS/programing/lan/java/jdk/rt/lang","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/lang/"}]},{"title":"【数据分析篇】aspect-level 数据分析","date":"2018-04-24T16:00:00.000Z","path":"wiki/ML/app/nlp/app/text_classification/datasets/aspect/aspect/","text":"SemEval 2014 Task 4 Read train 2990, test 973 长度 20以下的，Trimmed to train 2124, test 692 数据量好少， 123456789101112131415161718192021222324252627282930313233343536373839and cheap !price1the staff is n&apos;t the friendliest or most competent , and i am stickler for service , but everything else about this place makes up for it .service-1the service is always bad though , do n&apos;t expect much of anything from your server , and i would not recommend bringing a date here either .service-1i absolutely love this place ! ! !miscellaneous1a restaurant that does n&apos;t try to do anything except serve great food with great service in a pleasant atmosphere .ambience1this place was not all that !miscellaneous-1the food is great .food1highly recommended ! ! ! ! !miscellaneous1the food was really good , i had the onion soup and it was one of the best ever .food1a++ the service was good to excellent along with the attitude .service1we had a 3 hour brunch- they definitely do not rush you- and they kept the unlimited mimosas flowing the whole time .service1i &apos;ve been eating at taj mahal for over twenty years and have found them to be the most excellent of the indian eateries on this block of indian restaurants .miscellaneous1anyway , the food is good , the price is right and they have a decent wine list .price1 基于aspect的情感分析指的是挖掘句子中涉及的aspect，以及对每个aspect表现出来的情感。 现有的工作一般把这个任务分成两个部分：aspect识别，可以是aspect term提取或者aspect分类；aspect的情感识别 aspect term提取待阅读 http://zhaoxueli.win/2017/03/06/%E5%9F%BA%E4%BA%8E-Aspect-%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/ https://www.jianshu.com/p/227053b4a85c","tags":[{"name":"dataset","slug":"dataset","permalink":"http://yoursite.com/tags/dataset/"},{"name":"数据分析","slug":"数据分析","permalink":"http://yoursite.com/tags/数据分析/"},{"name":"文本分类","slug":"文本分类","permalink":"http://yoursite.com/tags/文本分类/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"text_classification","slug":"ML/app/nlp/app/text-classification","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-classification/"},{"name":"datasets","slug":"ML/app/nlp/app/text-classification/datasets","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-classification/datasets/"},{"name":"aspect","slug":"ML/app/nlp/app/text-classification/datasets/aspect","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-classification/datasets/aspect/"}]},{"title":"【深度学习-trick系列】batch、batch_size、batch normalization","date":"2018-04-23T16:00:00.000Z","path":"wiki/ML/trick/-标准化-batchNorm/","text":"简介“you want zero-mean unit-variance activations? just make them so.” 采用强制归一化，而不通过小心翼翼的设计激活函数，实现中间层的N(0,1)分布。 # 为什么要在激活前做BN？ 因为我们期望的是激活函数的输入服从N(0,1)，而不是激活函数的output服从N(0,1)。 有了BN，是否还需要对输入数据归一化处理？ 不用了 # Train mode: 𝜇, 𝜎 are functions of 𝑥; backprop gradients Test mode: 𝜇, 𝜎 are pre-computed on training set (by running average, or post-processing after training) DNN中的normalization 白化（whitening）- ResNet采用了Batch Normalization 实例resnet中的BN123x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)x = Activation('relu')(x) RNN中的BNrnn中 transformer中没有BN，只有LN。为什么？ batch_size为了充分利用大规模集群算力以达到提升训练速度的目的，人们不断的提升batch size大小，这是因为更大的batch size允许我们在扩展GPU数量的同时不降低每个GPU的计算负载。 调参经验难以捉摸的batch size 通常的经验: 速度: batch size越大，速度越快(每小时处理的样本数越多)。 速度有上限，计算资源会饱和 精度: batch size越大，泛化能力却变差（在测试集上效果差） batch size极小(比如1, SGD)，模型可能会收敛困难，甚至发散 实测语言模型我的测试 Batch_size Emb_size N_unit Epoch Elapse min/epoch TrainPPL TestPPL wps (train) 显存 comments 512 512 512 20 11h 33 213 363,313 90k-150k 2G 2048 512 512 20 6.5h 19.5 350,208 514,300 170k-220k 4G 大batch能提速，测试集上的收敛情况不不确定 4096 512 512 20 6h 18 438,208 687,332 170k-220k 8G 速度达到上限，也许计算资源饱和 512 1024 2048 13 23h 106 190,105 236,185 30k-35k 4G emb_size和num_unit增大，效果提升 2048 1024 2048 15 23.5h 94 229,102 284,185 35k-40k 8G 大batch，微弱提速 验证了经验 1.1、1.2 并未验证经验2 机器翻译 - transformerpaper中的测试，来自training tips for transformer: base model: 大batch size不仅速度快，而且收敛快。所以transformer中batch size越大越好，不OOM就行。 验证了经验1，与经验2.1相抵触 big model: batch_size=1450效果挺好，1400在2小时候突然效果变差。可能是因为，batch太小导致较大误差，从而训练变得发散。这种发散可能是临时的(1400)，也可能是不可恢复的(1000)。另一部分原因可能是 big model有可能比较比较难初始化。 验证了经验1，2 推荐: transformer中batch size能设置多大就多大 我的测试 … 总结 - 面临的挑战大batch size带来精度损失过度增大batch size会带来明显的精度损失！这是因为在大batch size（相对于训练样本数）情况下，样本随机性降低，梯度下降方向趋于稳定，训练就由SGD向GD趋近，这导致模型更容易收敛于初始点附近的某个局部最优解，从而抵消了计算力增加带来的好处。如何既增大batch size，又不降低精度，是机智团队面临的首要挑战。 TODO: 测试大batch_size的影响 解决办法 为了提升大batch size情况下的可扩展性，机智团队将训练数据和参数采用半精度浮点数的方式来表示，以减少计算量的同时降低带宽需求。但半精度浮点数的表示方式不可避免的会降低模型收敛精度。 我的测试 - 机器翻译 接口1keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,...) 参数 123456789101112131415axis: Integer, the axis that should be normalized (typically the features axis). For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.momentum: Momentum for the moving mean and the moving variance.epsilon: Small float added to variance to avoid dividing by zero.center: If True, add offset of beta to normalized tensor. If False, beta is ignored.scale: If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.beta_initializer: Initializer for the beta weight.gamma_initializer: Initializer for the gamma weight.moving_mean_initializer: Initializer for the moving mean.moving_variance_initializer: Initializer for the moving variance.beta_regularizer: Optional regularizer for the beta weight.gamma_regularizer: Optional regularizer for the gamma weight.beta_constraint: Optional constraint for the beta weight.gamma_constraint: Optional constraint for the gamma weight. 实例 2018年6月25日，OpenAI在其Dota2 5v5中取得一定成绩后介绍，其在训练中batch size=100W，而1v1的训练batch_size=800W；训练时间则是以周计。 腾讯内部的游戏AI也面临大batch size收敛精度和低训练速度慢的问题；目前batch_size超过10K则收敛不到基准精度 腾讯在ImageNet数据集上，6.6分钟训练好ResNet-50，batch_size=65536 transformer翻译模型，batch_size=2048、4096 百万级的batch_size是用GPU训的？显存够吗？要多大显存啊？ 。。。。 显存不够情况下，能否把单卡放一部分参数？ ... 源码实现 keras实现 tensorflow实现 参考 Batch normalization layer (Ioffe and Szegedy, 2014) Batch Normalization: Accelerating Deep Network.. 2015 4分钟训练ImageNet！腾讯创纪录 | 机器之心 LARS算法与batch_size相关 Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour - Facebook ImageNet Training in 24 Minutes - UC Berkeley ImageNet Training by CPU: AlexNet in 11 Minutes and ResNet-50 in 48 Minutes 科普文 | 搜狐","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"【深度学习-trick系列】Dropout","date":"2018-04-23T16:00:00.000Z","path":"wiki/ML/trick/-过拟合-dropout/","text":"alex 2012 首次采用 能够防止过拟合 学习到的feature更鲁棒 Bagging 是通过结合多个模型降低泛化误差的技术，主要的做法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。而 Dropout 可以被认为是集成了大量深层神经网络的 Bagging 方法，因此它提供了一种廉价的 Bagging 集成近似方法，能够训练和评估值数据数量的神经网络。 Dropout 指暂时丢弃一部分神经元及其连接。随机丢弃神经元可以防止过拟合，同时指数级、高效地连接不同网络架构。神经元被丢弃的概率为 1 − p，减少神经元之间的共适应。隐藏层通常以 0.5 的概率丢弃神经元。使用完整网络（每个节点的输出权重为 p）对所有 2^n 个 dropout 神经元的样本平均值进行近似计算。Dropout 显著降低了过拟合，同时通过避免在训练数据上的训练节点提高了算法的学习速度。 Drop ConnectDrop Connect 是另一种减少算法过拟合的正则化策略，是 Dropout 的一般化。在 Drop Connect 的过程中需要将网络架构权重的一个随机选择子集设置为零，取代了在 Dropout 中对每个层随机选择激活函数的子集设置为零的做法。由于每个单元接收来自过去层单元的随机子集的输入，Drop Connect 和 Dropout 都可以获得有限的泛化性能 [22]。Drop Connect 和 Dropout 相似的地方在于它涉及在模型中引入稀疏性，不同之处在于它引入的是权重的稀疏性而不是层的输出向量的稀疏性。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"trick","slug":"ML/trick","permalink":"http://yoursite.com/categories/ML/trick/"}]},{"title":"【深度学习-模型系列】word2vec","date":"2018-04-23T16:00:00.000Z","path":"wiki/ML/app/nlp/app/word-vector/model/word2vec/word2vec/","text":"简介单词在计算机看来只是个符号而已，如何让计算机理解词义？ 为什么要学习word embedding图像和音频处理系统使用丰富的高维数据集，这些数据集被编码为图像数据的单个原始像素强度的向量，或者音频数据的功率谱密度系数。对于物体或语音识别这一类的任务，我们所需的全部信息已经都存储在原始数据中（显然人类本身就是依赖原始数据进行日常的物体或语音识别的）。 然而，NLP通常将单词视为离散的原子符号(atomic symbol)，因此“cat”可以表示为Id537，“dog”表示为Id143。这些编码是任意的，并且没有为系统提供关于个别符号之间可能存在的关系的有用信息。这意味着，当该模型处理有关“狗”的数据(比如它们既是动物、四条腿的、宠物等)时，它对“猫”的了解很少。将单词表示为惟一的、离散的id会导致数据稀疏，这通常意味着我们可能需要更多的数据来成功地训练统计模型。使用向量表示可以克服其中一些障碍。 向量空间模型(VSMs)表示连续向量空间中的词(嵌入)，其中语义相似的词映射到附近的点(“彼此嵌入在一起”)。VSMs在NLP领域有着悠久而丰富的历史，但所有的方法都以某种方式依赖于分布假设，即出现在相同上下文中的单词具有相同的语义。利用这一原理的不同方法可以分为两类: 基于计数的方法 基于计数的方法计算某个单词与相邻单词在大型文本语料库中共存的频率的统计数据，然后将这些统计数据映射到每个单词的一个小而密集的向量。 即对one-hot的降维 如潜在语义分析、LDA、PCA，等传统降维方法 lda中的p(w|z)跟softmax什么关系？ 基于预测的方法(如神经概率语言模型) 预测模型直接尝试根据学习到的小而密集的嵌入向量(考虑到模型的参数)来预测邻居的单词 以上参考tensorflow tutorial 简而言之，就是one-hot编码不能体现语义，单词间相似度是0 embedding可以看成sparse one-hot的降维，也可以看成id的升维。我觉得视为前者更好。 分布式假设词向量的模型和求解都是基于同一种假设，Distributional Hypothesis (D.H.) (Harris, 1954):“words are characterised by the company that they keep” 基于以上假设可以得出，上下文相似的词所表达的词义也是相似的。 D.H. : the meaning of “cat” is captured by the probabilitydistribution P(\u0001|cat). word2vec只是利用分布式假设的方法之一。 word2vec的起源word2vec builds on existing researcharchitecture is essentially that of Minh and Hinton’s log-bilinearmodelchange of focus: vectorization, not language modelling. 模型skipgram VS cbow字面意思呢？ skipgram: 重在skip这个词，并非连续的，而是跳跃的（predict the target using a random close‑by word） cbow: continuous‑bag‑of‑words，重在continuous 优化目标分类。词典大小是N，那么就是N分类。 弊端： 【策略一】转化为二叉树，多个二分类。即Hierarchical Softmax 【策略二】直接视为二分类：中心词w和context(w)相关，是正例，其他word都是负例 负例太多，所以采用Negative Sampling FS、 HS、 NCEfull softmax神经网络语言模型通常采用极大似然估计(MLE)的方式，会采用softmax来计算$P(w_t | h) $。 $$\\begin{align}P(w_t | h) &amp;= \\text{softmax} (\\text{score} (w_t, h)) \\ &amp;= \\frac{\\exp { \\text{score} (w_t, h) } } {\\sum_\\text{Word w’ in Vocab} \\exp { \\text{score} (w’, h) } }\\end{align}$$ 其中$\\text{score} (w_t, h)$ log似然，要最大化以下的函数$$\\begin{align} J_\\text{ML} &amp;= \\log P(w_t | h) \\ &amp;= \\text{score} (w_t, h) - \\log \\left( \\sum_\\text{Word w’ in Vocab} \\exp { \\text{score} (w’, h) } \\right).\\end{align}$$ 但是这里的第二项(full probabilistic model)计算量较大。 在word2vec，并不需要计算full probabilistic model。 CBOW and skip-gram 是采用二分类 $$J_\\text{NEG} = \\log Q_\\theta(D=1 |w_t, h) + k \\mathop{\\mathbb{E}}{\\tilde w \\sim P\\text{noise}} \\left[ \\log Q_\\theta(D = 0 |\\tilde w, h) \\right]$$ HS12345// 默认采用cbow模型cbow = 1;// 默认不用`Hierarchical Softmax`int hs = 0, negative = 5; 基于Hierarchical Softmax的CBOW模型 源码 基于Hierarchical Softmax的Skip-Gram模型 源码 两者能同时都用吧。即采样负例后，再HS，可以减少HS的编码吗？ Use Hierarchical Softmax; default is 0 (not used) 为什么层次 SoftMax 能加速？ Softmax 大部分的计算量在于分母部分，它需要求出所有分量的和 而层次 SoftMax 每次只需要计算两个分量，因此极大的提升了速度 NCENoise-Contrastive Training Negative Sampling 层次 Softmax 还不够简单，于是提出了基于负采样的方法进一步提升性能负采样（Negative Sampling）是 NCE(Noise Contrastive Estimation) 的简化版本 如果不使用负采样，即 N-gram 神经语言模型中的做法，就是对整个词表 Softmax 和交叉熵 负采样相当于选取所有负例中的一部分作为负样本，从而减少计算量 基于Negative Sampling的CBOW模型 源码 基于Negative Sampling的Skip-Gram模型 源码 比如我们有一个训练样本，中心词是w,它周围上下文共有2c个词，记为context(w)。由于这个中心词w,的确和context(w)相关存在，因此它是一个真实的正例。通过Negative Sampling采样，我们得到neg个和w不同的中心词wi,i=1,2,..neg，这样context(w)和$$w_i$就组成了neg个并不真实存在的负例。利用这一个正例和neg个负例，我们进行二元逻辑回归，得到负采样对应每个词$w_i$对应的模型参数$\\theta_{i}$，和每个词的词向量。 Negative Sampling由于没有采用霍夫曼树，每次只是通过采样neg个不同的中心词做负例，就可以训练模型，因此整个过程要比Hierarchical Softmax简单。 Negative Sampling可否也用霍夫曼树？貌似还真不能？HS和NS貌似是冲突的。 负采样算法 - Negative Sampling assigns high probabilities to the real words, and low probabilities to noise words 计算复杂度大大减小(注意分母，也就是log的第二项)。 scales only with the number of noise words that we select (k), and not all words in the vocabulary (V). 损失函数采用noise-contrastive estimation (NCE) loss tf.nn.nce_loss() 负采样算法，即对给定的 w ，生成相应负样本的方法 最简单的方法是随机采样，但这会产生一点问题，词表中的词出现频率并不相同 如果不是从词表中采样，而是从语料中采样；显然，那些高频词被选为负样本的概率要大于低频词 在词表中采样时也应该遵循这个 因此，负采样算法实际上就是一个带权采样过程 这里还有很多细节，参考imhuay的github 一些源码细节σ(x) 的近似计算，类似带权采样的策略，用查表来代替计算。 具体计算公式如下 $$\\sigma(x)=\\left {\\begin{array}{ll} 0, &amp;x6 \\end{array}\\right.$$ 因为 σ(x) 函数的饱和性，当 x &lt; -6 || x &gt; 6 时，函数值基本不变了 低频词的处理对于低频词，会设置阈值（默认 5），对于出现频次低于该阈值的词会直接舍弃，同时训练集中也会被删除 高频词的处理 高频词提供的信息相对较少，为了提高低频词的词向量质量，有必要对高频词进行限制 高频词对应的词向量在训练时，不会发生明显的变化，因此在训练是可以减少对这些词的训练，从而提升速度 Sub-sampling 技巧 源码中使用 Sub-sampling 技巧来解决高频词的问题，能带来 2~10 倍的训练速度提升，同时提高低频词的词向量精度 给定一个词频阈值 t，将 w 以 p(w) 的概率舍弃，p(w) 的计算如下 $$\\begin{aligned} &amp;p(w)=1-\\sqrt\\frac{t}{\\mathrm{len}(w)}\\ \\text{where}\\quad\\ &amp;\\mathrm{len}(w)=\\frac{\\mathrm{count}(w)}{\\sum_{u\\in V}\\mathrm{count}(u)} \\end{aligned}$$ Word2Vec 中的Sub-sampling 显然，Sub-Sampling 只会针对 出现频次大于 t 的词 特别的，Word2Vec 使用如下公式计算 p(w)，效果是类似的 $$p(w)=1-\\left ( \\sqrt\\frac{t}{\\mathrm{len}(w)} + \\frac{t}{\\mathrm{len}(w)} \\right )$$ 自适应学习率 预先设置一个初始的学习率 η_0（默认 0.025），每处理完 M（默认 10000）个词，就根据以下公式调整学习率 随着训练的进行，学习率会主键减小，并趋向于 0 为了方式学习率过小，Word2Vec 设置了一个阈值 η_min（默认 0.0001 * η_0）；当学习率小于 η_min，则固定为 η_min。 参数初始化 词向量服从均匀分布 [-0.5/m, 0.5/m]，其中 m 为词向量的维度 所有网络参数初始化为 0 word2vec的不足 基于上文的分布式假设，会出现“好”和“不好”相似度很高(因为这两个词的上下文大部份都是一样的) “好”和”不好”更多的是相似，差异的细微的，人们认为它们是反义词。word2vec认为它俩相近是正常的，反而人是不客观的。 要想学出它俩的区别来，需要用到情感分类的标签 HS树的构建 采用的是平衡二叉树。n叉树呢？ 二叉树，是较多二分类，不适宜GPU。所以word2vec的相关代码都是采用的cpu，(google官方源码、fastText、gensim) 树的深度，霍夫曼的最优性？ NCE的采样数目 可以同时采样多个负样本，这样就适合GPU了吧？ 长依赖？需要这个东西吗？ 多义词 每个词学多个vector（word2tensor）: Improving Word Representations via Global Context and Multiple Word Prototypes; A Scalable Probabilistic Model for Learning Multi-Prototype Word Embeddings oov FAQIs “embedding” an action or a thing? Bothembedding words in a vector space (action)producing word embeddings (things).为什么层次 SoftMax 能加速?为什么叫CBOW（ Continuous Bag-Of-Words，即连续的词袋模型） 和 Skip-Gram？ 参考 word2vec 中的数学原理详解 | CSDN Word2vec数学原理全家桶 imhuay的面试笔记 - 很赞 word2vec | tensorflow fastText word2vec | gensim live demohttps://demo.eson.org/projector TODO：扩展demo word2vec的可视化 给定word1 出word2 显示vector向量 一个word与一组word的相似度。用attention可视化。 向量计算，比如king - man + woman = queen","tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"},{"name":"word2vec","slug":"word2vec","permalink":"http://yoursite.com/tags/word2vec/"},{"name":"hierarchical softmax","slug":"hierarchical-softmax","permalink":"http://yoursite.com/tags/hierarchical-softmax/"},{"name":"negative sampling","slug":"negative-sampling","permalink":"http://yoursite.com/tags/negative-sampling/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"word-vector","slug":"ML/app/nlp/app/word-vector","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/"},{"name":"model","slug":"ML/app/nlp/app/word-vector/model","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/"},{"name":"word2vec","slug":"ML/app/nlp/app/word-vector/model/word2vec","permalink":"http://yoursite.com/categories/ML/app/nlp/app/word-vector/model/word2vec/"}]},{"title":"【java源码系列】导读","date":"2018-04-22T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/java源码阅读/","text":"背景知识 JCP:JCP（Java Community Process）成立于1998年，是使有兴趣的各方参与定义Java的特征和未来版本的正式过程。- 关于版本号7是指jdk版本 7.0版本 u是update 更新的意思 45 是第45次更新 为什么要新建u开头的project？http://openjdk.java.net/projects/jdk8u/qanda.html b07是不是发布JDK6u1时，JDK6作为开发分支的最后一个buid号？每个release（无论是大版本的第一个release还是后面小版本的update release）在真的发布前都会经过很多次build。开发过程中通常是每周一build来做整合测试，临发布前会选择一个build作为候选版本跑更完整的测试，当这些测试都通过之后就发布。所以6u18b07的意思就是针对JDK 6 update 18这个release，这是第07个build。每个release的build number都是独立递增的，从1开始。 实现OpenJDK 是一个自由开放源始码软件实现在Java Platform, Standard Edition (Java SE)。在OpenJDK之前，许多各式各样不同的公司和组织推出好几个免费的Java实现。其中一个例子是ApacheHarmony。 IBM也有提供Java实现，而RedHat则是通过IcedTea项目提供它：一个用于OpenJDK的架构和集成项目。 历史 版本 年份 new feature 其他 JDK Beta 1994 JDK 1.0 1996 几百个类 JDK 1.1 1997 内部类、JDBC、RMI J2SE 1.2 1998 collections框架 - 作者Joshua Bloch J2SE 1.3 2000 HotSpot JVM J2SE 1.4 2002 仿照perl的正则、NIO J2SE 5.0 2005 大量语法糖: 泛型、自动封装、枚举等 三千多个类 Java SE 6 2006 Java SE 7 2011 Java SE 8 2014 Java SE 9 JDK源码openJDK 官方源码：http://hg.openjdk.java.net/ 采用Mercurial(Hg)管理，类似git Github镜像：https://github.com/dmlloyd/openjdk 这是对官方Git仓库的实时同步。很赞。怎么做到的？用的github插件？ 阅读笔记 Jdk1.8源码解析 https://github.com/wupeixuan/JDKSourceCode1.8 JDK源码阅读笔记 https://github.com/seaswalker/JDK https://github.com/codefollower/OpenJDK-Research 参考 java 1.0.2 源码 - 第一个稳定版JDK java 1.4 源码 对比1.5来看 java 1.5 源码 java 7 源码 对比8来看 java 8 源码 Oracle JDK","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"java源码","slug":"java源码","permalink":"http://yoursite.com/tags/java源码/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"}]},{"title":"文本分类 - 综述","date":"2018-04-22T16:00:00.000Z","path":"wiki/ML/app/nlp/app/text_classification/text-classification/","text":"任务 短文本分类 长文本分类 超短文本(一个word)分类 特定领域的文本分类 aspect-level classification ss methods: word-level tfidf + svm/lr fastText facebook (只是作为baseline而已) lstm bilstm lstm + attention cnn code1 code2 gated cnn rcnn char-level char的作用？ 见NLP.md char cnn (Zhang and LeCun, 2015) char rnn char-CRNN (Xiao and Cho, 2016) char-rnn + word rnn (Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation) char-cnn + word rnn Hierarchical: char + word: word + sentence: Hierarchical Attention char + word + sentence: datasets &amp;paper &amp; implementation[TextCNN]: Convolutional Neural Networks for Sentence Classification[TextCNN-code]: https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/ [TextRNN]: Recurrent Neural Network for Text Classification with Multi-Task Learning[TextRNN-code]: [RNN+Attention]: Hierarchical Attention Networks for Document Classificationhttp://www.jianshu.com/p/4fbc4939509f[RNN+Attention-code]: https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-RNN/ [RNN+CNN]: Recurrent Convolutional Neural Networks for Text Classification. AAAI. 2015.[RNN+CNN-code]: https://github.com/knok/rcnn-text-classification [fastText]: three papers. https://github.com/facebookresearch/fastText in C++ [1] P. Bojanowski, E. Grave, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information [2] A. Joulin, E. Grave, P. Bojanowski, T. Mikolov, Bag of Tricks for Efficient Text Classification [3] A. Joulin, E. Grave, P. Bojanowski, M. Douze, H. Jégou, T. Mikolov, FastText.zip: Compressing text classification models https://github.com/scharmchi/char-level-cnn-tf !!!!!! char-level deep learning https://offbit.github.io/how-to-read/ https://github.com/offbit/char-models tutorial &amp; survey &amp; bloghttp://www.jeyzhang.com/cnn-apply-on-modelling-sentence.htmlhttps://zhuanlan.zhihu.com/p/25928551 web service1. watson NLC: https://www.ibm.com/watson/developercloud/natural-language-classifier/api/v1 2. songfang NLC code 模型汇总 https://github.com/brightmart/text_classification","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"text_classification","slug":"ML/app/nlp/app/text-classification","permalink":"http://yoursite.com/categories/ML/app/nlp/app/text-classification/"}]},{"title":"【java源码系列】HashMap","date":"2018-04-22T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/util/HashMap/","text":"历史 java 1.0 中没有HashMap，有HashTable java 1.2 引入HashMap java 7 基于哈希表的实现 java 8 采用的 hash数据结构12transient Node&lt;K,V&gt;[] table;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; hash过程流程 对key计算hashcode 将hashcode映射到有限bucket空间 在相应的bucket内，存储或查询相应的key 计算hashcodejava7 123456789final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); // 麻蛋 &#125; h ^= k.hashCode(); // 按位异或 h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); // “扰动函数”。Java 8中这步已经简化了，只做一次16位右位移异或混合，而不是四次，但原理是不变的。 return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); // &gt;&gt;&gt; 无符号右移运算符&#125; 基础知识: hashSeed 随机数的种子，详见.. ^ 按位异或。作用: &gt;&gt;&gt; 无符号右移运算符左移的规则：丢弃高位，0补低位右移的规则：丢弃低位，高位的空位补符号位，即正数补零，负数补1 右移的偏移量20，12，7，4是怎么来的呢？因为Java中对象的哈希值都是32位的，所以这几个数应该就是把高位与低位做异或运算， 再看一下String类中hashcode的计算1234567891011public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; // 为什么取素数？为什么取31？ &#125; hash = h; &#125; return h;&#125; 在存储数据计算hash地址的时候，我们希望尽量减少有同样的hash地址，所谓“冲突”。如果使用相同hash地址的数据过多，那么这些数据所组成的 hash链就更长，从而降低了查询效率！所以在选择系数的时候要选择尽量长的系数并且让乘法尽量不要溢出的系数，因为如果计算出来的hash地址越大，所 谓的“冲突”就越少，查找起来效率也会提高。 使用31的原因可能是为了更好的分配hash地址，并且31只占用5bits！ 在java乘法中如果数字相乘过大会导致溢出的问题，从而导致数据的丢失.而31则是素数（质数）而且不是很长的数字，最终它被选择为相乘的系数的原因不过与此！ 分配hashcode到buckethashcode的取值空间太大，不能作为直接存储地址。因此要把hashcode分配到一定数量的bucket中，取值[0, capacity‐1]。 为了使每个key都能在冲突最小的情况下映射到[0,capacity)，通常有两种做法： capacity为素数，index = hashCode(key) mod capacity capacity为2的倍数，index = hashCode(key) &amp; (capacity‐1) java7中 12int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 16index = hashCode(key) &amp; (capacity‐1); // 映射到0,capacity-1之间(类似mod) 普通的哈希算法（也称硬哈希）采用简单取模的方式，将机器进行散列，这在cache环境不变的情况下能取得让人满意的结果，但是当cache环境动态变化时，这种静态取模的方式显然就不满足单调性的要求（当增加或减少一台机子时，几乎所有的存储内容都要被重新散列到别的缓冲区中）。 存储或查询 (get put)java7的get 123456789101112131415final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; java7的put 123456789101112131415161718192021public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null;&#125; rehashjava7的rehash 1234567891011121314151617181920212223void resize(int newCapacity) &#123; Entry[] newTable = new Entry[newCapacity]; // 创建新的entry array transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;// Transfers all entries from current table to newTable.void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 复杂度？ 一致性？ 其他1234 // 默认的平衡因子为0.75。过高的因子会降低存储空间但是查找的时间就会增加。int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 哈希表容量（也就是buckets或slots大小）float DEFAULT_LOAD_FACTOR = 0.75f; NUll keys always map to hash 0, thus index 0 横向对比 Hashtable LinkedHashMap TreeMap EnumMap VS HashtableHashMap 不是线程安全的 HashMap 是 HashTable 的轻量级实现，他们都完成了Map 接口，主要区别在于 HashMap 允许 null key 和 null value，由于非线程安全，效率上可能高于 Hashtable。 VSrevisit设计 参考 HashMap.java | java7 HashMap.java | java8 思考题 hashcode的计算？ Null key的处理？为什么 常量 modCount的作用？ loadFactor的作用？ 为什么容量必须为2的指数倍（默认为16）？ 超容后，reshash的复杂度是多少？怎样降低复杂度？怎样保证一致性？ 容量超过Integer.MAX_VALUE怎么办？ hashSeed的影响？ 并发的影响？见 如何做到key的排序？见 为什么放到util呢？ Map类的操作对象是其他类，所以也属于工具类。当然也可以理解为普通类(封装类、组合类) 答案在文中寻找","tags":[{"name":"java源码","slug":"java源码","permalink":"http://yoursite.com/tags/java源码/"},{"name":"hash","slug":"hash","permalink":"http://yoursite.com/tags/hash/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"util","slug":"CS/programing/lan/java/jdk/rt/util","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/util/"}]},{"title":"机器学习中的正则化约束 - 结构风险","date":"2018-04-19T16:00:00.000Z","path":"wiki/ML/ml 传统方法/正则约束-结构风险/","text":"简介 结构风险（structural risk）：描述模型与训练样本的拟合程度，以及模型的复杂程度。 正则化的由来 有几种角度来看待正则化(Regularization)，它符合奥卡姆剃刀(Occam’s razor)原理：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的才是最好的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。还有个说法就是，正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项(regularization term)或惩罚项(penalty term)或权重衰减项(weight decay term)。 高维统计分析模型通常都是稀疏模型，即真正有效的变量只占一小部分，绝大多数变量都是噪声数据。因此当模型的参数过多时，不仅无法提高模型的解释力，反而会降低模型的解释力。 在这个背景下，统计学家提出了各种各样的变量选择方法来筛选模型中重要的解释变量，从而防止过拟合问题。其中正则化是最常用的一种方法，而正则化方法中最常见的就是L0, L1 和L2范数。 正则化方法的思想：处理最优化函数问题时，在目标函数中加入对参数的约束惩罚项，从而达到简化模型的目的。 常见的结构风险L0范数：就是指矩阵中非零元素的个数，很显然，在损失函数后面加上L0正则项就能够得到稀疏解，但是L0范数很难求解，是一个NP问题，因此转为求解相对容易的L1范数（l1能够实现稀疏性是因为l1是L0范数的最优凸近似） L1L1正则化使得模型更加稀疏， L1范数：矩阵中所有元素的绝对值的和。损失函数后面加上L1正则项就成了著名的Lasso问题（Least Absolute Shrinkage and Selection Operator），L1范数可以约束方程的稀疏性，该稀疏性可应用于特征选择：比如，有一个分类问题，其中一个类别Yi(i=0,1),特征向量为Xj（j=0,1~~~1000），那么构造一个方程Yi = W0X0+W1X1···WjXj···W1000X1000+b;其中W为权重系数，那么通过L1范数约束求解，得到的W系数是稀疏的，那么对应的X值可能就是比较重要的，这样就达到了特征选择的目的 L1 正则化在零点不可微，因此权重以趋近于零的常数因子增长。很多神经网络在权重衰减公式中使用一阶步骤来解决非凸 L1 正则化问题。 elastic net 的提出 是为了 可以解决feature之间的 高相关性 问题，单纯Lasso 一般会在一个 高相关性 的 特征group 里面选取一个显著特征， zou 的paper 里面有相关证明。 当然解决 高相关性的方法还有 group lasso ， general fused lasso 等从几何解释来讲 elastic net 很像 L1 到 L2 之间一个 penalty， 但不同之处在于 elastic net 具有 L1 的特性，sparsity， 函数并不是smooth 的。这个具体可以参考 Element of statistical learning 的第三章。 https://www.zhihu.com/question/38081976 L2二范数，等价于Gauss共轭先验 L2使得模型参数更趋近于0，提高泛化能力 稀疏约束普通参数的稀疏约束一范数，等价于Laplace共轭先验 归一化后的参数稀疏$$P=(p_1,p_2…p_n)$$ 共轭先验是狄利克雷分布，可通过先验参数控制稀疏程度。 可用二范数 可用1范数。 其他约束 正交约束：AA’ = 对角阵 单位正交约束：AA’ = I 另外sum=1 + 平方和=1这就是稀疏约束。 AA’为对角阵 |AA’-E|_2 参考http://www.cnblogs.com/stevenlk/p/6247992.html","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"spiking neural network 脉冲神经网络","date":"2018-04-19T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/spiking/","text":"生物学背景神经科学（英语：neuroscience），又称神经生物学，是专门研究神经系统的结构、功能、发育、演化、遗传学、生物化学、生理学、药理学及病理学的一门科学。对行为及学习的研究都是神经科学的分支。 对人脑研究是个跨领域的范畴，当中涉及分子层面、细胞层面、神经小组、大型神经系统，如视觉神经系统、脑干、脑皮层。 最高层次的研究就是结合认知科学成为认知神经科学，其专家被称为认知心理学家。一些研究人员相信认知神经科学提供对思维及知觉的全面了解，甚至可以代替心理学。 神经元结构树突细胞体轴突细胞核兰氏结突触施旺细胞髓鞘典型神经元的结构(来自wikipedia) 树突为神经元的输入通道，其功能是将自其他神经元所接收的动作电位（电信号）传送至细胞本体。其他神经元的动作电位借由位于树突分支上的多个突触传送至树突上。与长度可达约1米的轴突相比，树突通常较短。 轴突（Axon）由神经元组成，即神经细胞之细胞本体长出突起，功能为传递细胞本体之动作电位至突触。 生物学功能 陈述性记忆：对事件、人物等有意识回忆，相对容易记住和忘记 非陈述性记忆：对抽象、感知、动作和习惯等无意识操作 突触可塑性（Synaptic plasticity）指神经细胞间的连接，即突触，其连接强度可调节的特性。突触可塑性的产生有多种原因，例如：突触中释放的神经递质数量的变化，细胞对神经递质的反应效率。突触可塑性被认为是构成记忆和学习的重要神经化学基础。 脉冲 Biological neurons use short and sudden increases in voltage to send information.action potentials, spikes or pulses. SNN 脉冲神经网络 信息承载SNN的信息承载，仅仅是靠脉冲频率吗？等价于二值的普通编码吗？ neurons encode information in the timing of single spikes, and not only just in their averagefiring frequency. 独特之处 they can encode temporal information in their signals, but therefore do also need different and biologically more plausible rules for synaptic plasticity. 疑问SNN的图像分类等常见任务上效果怎样？ SNN的优势是什么，独特之处是什么？ 一个image怎样转化成脉冲作为网络输入？ firing rate表示信号强弱，单个脉冲有什么意义？","tags":[{"name":"SNN","slug":"SNN","permalink":"http://yoursite.com/tags/SNN/"},{"name":"spiking neural network","slug":"spiking-neural-network","permalink":"http://yoursite.com/tags/spiking-neural-network/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"【对话系统】之ChatterBot","date":"2018-04-19T16:00:00.000Z","path":"wiki/ML/app/nlp/app/conversation/系统/ChatterBot/","text":"快速搭建1$ pip install chatterbot 123456789101112from chatterbot import ChatBotchatbot = ChatBot( 'Ron Obvious', trainer='chatterbot.trainers.ChatterBotCorpusTrainer')# Train based on the english corpuschatbot.train(\"chatterbot.corpus.chinese\")# Get a response to an input statementchatbot.get_response(\"你是谁\") 后台算法https://chatterbot.readthedocs.io/en/stable/faq.html#what-kinds-of-machine-learning-does-chatterbot-use 基于搜索和分类 搜索 分类 利用朴素贝叶斯 判断是否 an input statement meets a particular set of criteria that warrant a response 说的好模糊","tags":[{"name":"聊天机器人","slug":"聊天机器人","permalink":"http://yoursite.com/tags/聊天机器人/"},{"name":"对话系统","slug":"对话系统","permalink":"http://yoursite.com/tags/对话系统/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"nlp","slug":"ML/app/nlp","permalink":"http://yoursite.com/categories/ML/app/nlp/"},{"name":"app","slug":"ML/app/nlp/app","permalink":"http://yoursite.com/categories/ML/app/nlp/app/"},{"name":"conversation","slug":"ML/app/nlp/app/conversation","permalink":"http://yoursite.com/categories/ML/app/nlp/app/conversation/"},{"name":"系统","slug":"ML/app/nlp/app/conversation/系统","permalink":"http://yoursite.com/categories/ML/app/nlp/app/conversation/系统/"}]},{"title":"倒排索引的分布式存储","date":"2018-04-18T16:00:00.000Z","path":"wiki/ML/retrieval/倒排索引/倒排索引的分布式存储/","text":"倒排索引又叫反向索引 背景索引数据的规模为TB级。TB相当于1 000 GB，一个1 000 GB的文件是不可想象的。因此将全部索引文件存放在一台主机上，不仅是不合适的，而且是不安全的。这样一旦这个倒排文件损坏，全部服务就会受到很大影响，因此倒排索引的分布式存储技术应运而生了。 大数据遇到的问题单机的瓶颈 存储：索引数据大 网络：传输瓶颈(网络负载)，尽量减少网络开销 磁盘I/O： 多机需要解决的问题 (集群或分布式) 数据倾斜问题 可靠性 网络 查询速度，memory db？如何 策略如何解决以上各种问题？ 没什么特别好的办法…就是各种切分索引，然后把结果合并之类的 常见操作 重建索引 周期性重建索引 基于主索引的前提下，构建辅助索引，用于储存新文档，维护于内存中，当辅助索引达到一定的内存占用时，写入磁盘与主索引进行合并； 种切分索引，然后把结果合并之类的 服务功能的分布式拆分 尽量减少网络开销 各个子服务应该是无状态的 每个子服务都应该是可横向扩展的 分布式 VS 集群数据的分布式拆分 搜索引擎索引分片 Log 参考 https://juejin.im/entry/58abf9432f301e006bdbc373 常见疑问切分索引多机分布式索引一般按照文档编号(docId)或者按照索引词编号(wordId)进行划分。按照DocId划分的结果称为局部倒排文件（Local inverted file）；按照WordId划分的结果称为全局倒排文件（Global inverted file） 1234567apple -&gt; 1, 13, 24, 33, 46, 52, 77banana -&gt; 4, 8, 33, 34, 52, 66, 88grapes -&gt; 7, 22, 46, 77, 89pineapple -&gt; 15, 37, 52delicious -&gt; 24, 34, 46, 77, 89rotten -&gt; 8, 66exotic -&gt; 37 按照docid来切分，比如1-100和101-200分在不同的服务器。 按照wordid来切分，比如apple banana分在不同的服务器。 group_by term (全局方案) index (局部倒排文件) index的获取 并行度=term数 并行度不限 网络负载 单点压力大 分布式结点分担网络负载 磁盘IO 节约磁盘I/O (如果只检索一个单词，那么只需要在一个索引结点中检索即可) 可靠性 单点故障很危险 单点故障影响不大 索引的存储结果我们人为能看到的就是segment文件，其实索引文件segment的下层结构就是field域（类似于数据库里面的列名，但是这两个概念区别还是蛮大的，只是拿过来类比），对于每一个field里面存储的就是倒排文件，而我们进行查询的过程时，为了加快查询效率就会制定field域去查询，对于每一个term来说会·去查找字典的一种结构（现在存储结构有FST（英文字典存储结构），前缀树等），因为字典是已经排好序的了，所以这里只需要进行二分查找就可以了，对于每一个term查找到的倒排链进行交集或者并集的合并，在合并的过程若要是按照文本相关性排序（不指定排序股则），就会在合并的过程中会进行相关的score分数计算（例如BM25，或者TF-IDF等一些算法），计算出来的文档会存储在一个top-N的小根堆里面，最后返回给用户。对于倒排链的合并过程交集是一个比较消耗性能的操作，比如lucene对于OR操作的优化比较多，比如说把现在N条倒排链按照长度排序（短的文档在前，长的在后），然后分成两组最短的1条一个组，剩下的N-1条一组，然后对于这两个组进行合并。在OR的合并过程中，可以指定最少有几个term满足要求，这样在前N-1中要是没有满足要求，这样最后一条就不需要在进行合并了。 ## 倒排索引，当有100台server，要把索引表 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/*An inverted index is used to support text search. The inverted index has a record for each term. Each record has the list of documents that the term appears in. Documents are identified by an integer document ID. The list of document IDs is sorted in ascending order. For the purpose of this problem, assume that the only operation performed on the inverted index is intersection to find the documents that contain all terms in the search query.For example, the inverted index could have the following data.TermDocument IDsapple -&gt; 1, 13, 24, 33, 46, 52, 77banana -&gt; 4, 8, 33, 34, 52, 66, 88grapes -&gt; 7, 22, 46, 77, 89pineapple -&gt; 15, 37, 52delicious -&gt; 24, 34, 46, 77, 89rotten -&gt; 8, 66exotic -&gt; 37Expected results from intersections are as follows:Terms intersectedDocument IDs with all termsdelicious apple -&gt; 24, 46, 77delicious apple grapes -&gt; 46, 77apple banana -&gt; 33, 52We have an inverted index that is very large and requires N servers to \"fit\". Assume N is 100.*//* This class will be given a list of words (such as might be tokenized * from a paragraph of text), and will provide a method that takes two * words and returns the shortest distance (in words) between those two * words in the provided text. * Example: * WordDistanceFinder finder = new WordDistanceFinder(Arrays.asList(\"the\", \"quick\", \"brown\", \"fox\", \"quick\")); * assert(finder.distance(\"fox\", \"the\") == 3); * assert(finder.distance(\"quick\", \"fox\") == 1); * * \"quick\" appears twice in the input. There are two possible distance values for \"quick\" and \"fox\": * (3 - 1) = 2 and (4 - 3) = 1. * Since we have to return the shortest distance between the two words we return 1. */public class WordDistanceFinder &#123; public WordDistanceFinder (List&lt;String&gt; words) &#123; Map&lt;String, List&lt;Integer&gt;&gt; map = new HashMap&lt;String, List&lt;Integer&gt;&gt;(); for(int i = 0; i &lt; words.size(); i++) &#123; if(!map.contains(word)) map.put(word, new ArrayList&lt;Integer&gt;()); map.get(word).add(i); &#125; &#125; public int distance (String wordOne, String wordTwo) &#123; List&lt;Integer&gt; index1 = map.get(wordOne); List&lt;integer&gt; index2 = map.get(wordTwo); int i = 0; j = 0; int min_distance = map.size(); while(i &lt; index1.size() &amp;&amp; j &lt; index2.size()) &#123; ind1 = index1[i]; ind2 = index[j]; current_distance = math.abs(ind1 - ind2); min_distance = current_distance&gt;min_distance?min_distance:current_distance; if(ind1 &lt; ind2) &#123; i++; &#125; else &#123; j++; &#125; &#125; return min_distance; // implementation here &#125;&#125;","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"retrieval","slug":"ML/retrieval","permalink":"http://yoursite.com/categories/ML/retrieval/"},{"name":"倒排索引","slug":"ML/retrieval/倒排索引","permalink":"http://yoursite.com/categories/ML/retrieval/倒排索引/"}]},{"title":"【深度学习】基础篇","date":"2018-04-11T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/basic/","text":"基础概念 NN 前馈网络: 前馈是相对反馈(backward)，带反馈的网络就构成了环，即有环网络。通常所用到的网络都是前馈网络。 感知机 多层感知机 autoencoder RBM 答疑梯度爆炸 梯度消失12345678910111213141516171819202122Q: 梯度消失就是0.9^30≈0.04？梯度爆炸就是1.1的n次方？ 怎样不消失，不爆炸呢？就是1的n次方吗？A: 是的，ReLU就是这么干的Q: 那sigmoid和tanh，是不是就彻底被淘汰了？A: 网络不深可以用，具体情况具体分析 再说了batch normalization的作用对于mitigate这种情况效果不错Q: 除了ReLU，还有什么能防止梯度爆炸、梯度消失的策略？A: 还有一些特殊的网络结果诸如resnet LSTM，也可以防止梯度小时或者爆炸，但不能根本解决Q: 为什么BN能起到一定的作用？A: 避免了梯度非常小，或者非常大。将梯度归一化到一个固定范围，相当于他说的消除了柔性 通过mini-batch来对相应的activation做规范化操作，使得结果（输出信号各个维度）的均值为0，方差为1Q: 为什么resnet LSTM，能防止梯度爆炸 梯度消失？A: 因为避免了连乘。Q: 可以理解bn是集中到标准正态分布范围内，但是网络里用的ReLU抑制负数所以有损失吗？A:Q: RNN 为什么会出现 Gradient Vanish？LSTM为什么能防止梯度消失？ 激活函数 (activation function)VGG ResNet都采用ReLU ##","tags":[{"name":"nn","slug":"nn","permalink":"http://yoursite.com/tags/nn/"},{"name":"gradient vanish","slug":"gradient-vanish","permalink":"http://yoursite.com/tags/gradient-vanish/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"}]},{"title":"github issue","date":"2018-04-10T16:00:00.000Z","path":"wiki/CS/tools/同步与版本管理/git/github/github-issue/","text":"每一次commit都可以选择性的与某个issue关联。比如在 message中添加#n，就可以与第n个 issue 进行关联。commit message title, #1 官方doc： https://guides.github.com/features/issues/ https://help.github.com/articles/closing-issues-using-keywords/ By prefacing your commits with: fix fixes: 例如提交messeage为Fixes #45，当commit被merge到master上时，会自动关闭issue 45 fixed close closes closed resolve resolves resolved when the commit is merged into master, it will also automatically close the issue. 同时操作多个issueThis closes #34, closes #23, and closes example_user/example_repo#42 常用标签Labels，标签。包括 enhancement、bug、invalid 等，表示 issue 的类型，解决的方式。除了自带的以外，也可以去自定义。 Milestone，里程碑。几经修改后，它现在已经与git tag和Github release区分开来，仅仅作为issue的一个集合。通常用来表示项目的一个阶段，比如demo、release等，保护达成这些阶段需要解决的问题。有时候，也会与版本计划重合，比如v1.0、v2.0等。issue不能设置截止时间，但是milestone可以。 Assignee，责任人。指定这个 issue 由谁负责来解决。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"},{"name":"github","slug":"CS/tools/同步与版本管理/git/github","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/github/"}]},{"title":"logistic regression","date":"2018-04-10T16:00:00.000Z","path":"wiki/ML/ml 传统方法/supervised/广义线性模型/对数线性模型/-lr-FAQ/","text":"常见疑问Logistic什么意思？对数？逻辑？ Regression明明是Classification的算法，为什么叫Regression LR是线性分类器还是非线性的？误区一：逻辑回归的模型引入了sigmoid函数映射，所以是非线性分类器 逻辑斯蒂的sigmoid是似然函数，即一种loss，跟是不是线性模型没关系。所有的似然函数都是非线性函数，照这个逻辑，所有的分类器就都是非线性分类器了。 判断一个分类器是不是线性，要看分界面。比如加kernel后的分界面就是非线性。logistic的分界面是 y=wx+b, 是线性的。 神经网络中间层的sigmoid是映射，跟逻辑斯蒂回归的sigmoid不是一个东西。最后一层softmax才是LR分类器。 总结LR可以看成 “只有一层softmax层的神经网络”。增加隐层数，就是增加了非线性映射。 如何用LR解决非线性分类的问题 自己定义这个非线性映射 这样也就不叫LR了 https://zhuanlan.zhihu.com/p/20545718 用kernel 和svm是不一样的，svm使用kernel不容易过拟合，而lr更容易过拟合。因为在lr里面vc dimension是随变量数线性增长的，而在svm中vc dimension随变量数对数级增长 (没看懂，知乎小活泼) 通常使用的kernel都是隐式的，也就是找不到显式地把数据从低维映射到高维的函数，而只能计算高维空间中数据点的内积。https://www.zhihu.com/question/29385169","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"},{"name":"supervised","slug":"ML/ml-传统方法/supervised","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/"},{"name":"广义线性模型","slug":"ML/ml-传统方法/supervised/广义线性模型","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/广义线性模型/"},{"name":"对数线性模型","slug":"ML/ml-传统方法/supervised/广义线性模型/对数线性模型","permalink":"http://yoursite.com/categories/ML/ml-传统方法/supervised/广义线性模型/对数线性模型/"}]},{"title":"【卷积】2. 深度学习中的卷积进化史","date":"2018-04-08T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/CNN/2.深度学习中的卷积综述/","text":"卷积在深度学习中的应用 Convolutional neural networks therefore constitute a very useful tool for machine learning practitioners. However, learning to use CNNs for the first time is generally an intimidating experience. CNN为什么work？ 局部连接代替全连接，&amp; 权值共享 pooling层， 是 发展 2012年， 基于深度学习CNN网络的AlexNet在ILSVRC竞赛的ImageNet上大放异彩 检测: 2014年Ross Girshick利用CNN成功取代了HOG、DPM等特征提取， ross等人把目标检测分成了三个步骤，首先是对图像提取detection proposal，其实就是图像中一些可能是检测物体的区域，然后使用cnn对这些proposal进行特征提取，最后用svm对这些提取到的特征进行分类，从而完成检测的任务，这是 Two-stage object detectors鼻祖。 卷积的类型简单卷积 卷积核为3、步幅为1和带有边界扩充的二维卷积结构 卷积核大小（Kernel Size）：定义了卷积操作的感受野。在二维卷积中，通常设置为3，即卷积核大小为3×3。 步幅（Stride）：定义了卷积核遍历图像时的步幅大小。其默认值通常设置为1，也可将步幅设置为2后对图像进行下采样，这种方式与最大池化类似。 边界扩充（Padding）：定义了网络层处理样本边界的方式。当卷积核大于1且不进行边界扩充，输出尺寸将相应缩小；当卷积核以标准方式进行边界扩充，则输出数据的空间尺寸将与输入相等。 输入与输出通道（Channels）：构建卷积层时需定义输入通道I，并由此确定输出通道O。这样，可算出每个网络层的参数量为I×O×K，其中K为卷积核的参数个数。例，某个网络层有64个大小为3×3的卷积核，则对应K值为 3×3 =9。 group conv对channel 分group，然后各group独立，最后再合并。 关于group之间是否共享卷积核？以及影响？实例AlexNet中采用group conv的初衷是为了利用多GPU。为了减少GPU之间的交互带来的速度影响，只在特定的层才有共享权重 最小 卷积核最小的卷积核，在1维卷积中是kernel size为1的卷积，二维卷积中是kernel size为1*1的卷积。 这种卷积又叫Pointwise convolution，即feature map上的每个point采用相同的卷积操作。 作用 在channel上升维、降维。 1*1 卷积 (二维卷积)针对[w,h,in_channel]的输入，进行 1,1二维卷积 $$[w,h,in] \\xrightarrow[1 \\times 1 \\times in \\times out]{conv2d} [w,h,out]$$ 1*1卷积并未对图像尺寸进行调整，仅仅是channel之间的融合。 当$out_channel &gt; in_channel$时，起到升维的作用；反之，则起到降维的作用。 1*1kernel广泛用于NIN、GoogLeNet、ResNet 注意 缺陷: 1*1卷积并未考虑空间邻域的信息，仅仅是channel之间的整合。所以一般会配合 优势: 计算量小，参数少 实战架构: 构造bottleneck架构: 由于1*1卷积方便维度变换，很多网络构造bottleneck架构，即高维的IO，低维的middle，目的是在低维下进行复杂运算，减少计算量。 实例: NIN, GoogLeNet, ResNet 卷积的分解 所有的depthwise seprable convolution 对应一维卷积，就是kernel_size 为1卷积 最大卷积核 - 全卷积全卷积(FCN) Transposed Convolutions 可分离卷积、分解卷积Separable Convolution，Factorized Convolutions应该是一个意思吧？ Separable 即分离(split)的意思，将传统的一层conv分离为两层，一层用于filtering，一层用于combining 不可分离呢？ 很自然我们会有两个疑问：为什么要分解？为什么能分解？ 要解答这两个疑问，首先我们要搞清楚以下这件事情 卷积，就是局部的全连接，即矩阵乘法[w,h,in] * [k,k,in,out]这样的卷积，可以视为输入图像一个[k,k]局部的全连接。 conv([k,k,in], [k,k,in,out]) 等价于 [k*k*in] * [k*k*in*out]的一个全连接。就是个矩阵乘法。 当k*k*in比较大时，仍然计算量很大。 如何减小计算量 - 矩阵分解上面我们看到了，卷积就是局部的全连接。那么一个最简单的减小计算量方式，就是矩阵分解(张量分解)。 [kkin] [kkinout]我们需要对Tensor[in,k*k,out]进行分解，只需要保持[in,out]不变即可。卷积核张量可以变成尺寸为$(whc) \\times n)$的二维矩阵。比如使用秩为$d$的SVD分解，因此每层的卷积核被分解成两个卷积核 $w \\times h \\times c \\times d$ 和 $1 \\times 1 \\times d \\times n$。这就是depthwise-conv + pointwise-conv吗？ 回顾张量分解123[I,J,K] = [I,R] [J,R] [K,R] [R,R,R] # 最后一项可以省略，相当于降维到R，R要小于IJK。如果R较大，则是升维了。 = [I*J,R] [R,K] # 视为矩阵分解 = [I,R] [R,J*K] # 视为矩阵分解 张量分解，维度乱了，不再是conv形式了。既想矩阵分解，又想保持卷积形式，那么还是采用矩阵分解吧。123[in,k*k,out] = [in, k*k, R] [R, out] # 维度不够，1来凑 = [in, k*k, R] [R, 1*1, out] # # [depthwise] [pointwise] 通常情况下R怎么取值？既然是降低运算量，那么R的取值要小于in和out咯？ 这里看到，这里的depthwise中，每个channel并不是independently，而是进行了R的交叉。 UV分解，USV分解。 为什么要分解？要了解为什么要分解 为什么能分解？深度可分离卷积深度可分离卷积结构（depthwise separable convolution） Depthwise depth: channel数 depthwise: 顾名思义，就是对所有input channel采用相同的操作。channel之间的操作是独立的，不交互的。 DSC是分解卷积(factorized convolutions)的一种，它将常规的卷积分解为一个depthwise conv与一个1*1 conv。 depthwise conv: 用于channel内的filtering pointwise conv(1*1): 用于channel间的combining 定义: DepthSepConv defines kxk depthwise convolution followed by 1x1 convolution 因为depthwise卷积是channel间独立的，所以一般会后接1*1卷积，做channel间的融合 优势: Depthwise separable convolutions reduce the number of parameters and computation used in convolutional operations while increasing representational efficiency. 传统卷积 (这里不关心$[w,h]$)$$[w, h,in] \\xrightarrow[k \\times k \\times in \\times out]{conv2d} [w,h,out]$$ 卷积参数量: $k \\times k \\times in \\times out$ 计算量: 参数 depth_multiplier:- 历史 &amp; 应用 Rigid-motion scattering for image classification 2014 首次提出 Inception models在前几层用到了，用于减小模型复杂度 MobileNet 2017 首次 SliceNet 2017 | 机器翻译, s factorized convolutions是什么鬼？ Factorized Networks Xception network Squeezenet 为什么能降低参数量，同时还能保持精度？ 类似矩阵分解的思想。 Group conv是一种channel分组的方式，Depthwise +Pointwise是卷积的方式，只是ShuffleNet里面把两者应用起来了。因此Group conv和Depthwise +Pointwise并不能划等号。 而group卷积只是单纯的通道分组处理，降低复杂度。 Dilated Convolutions空洞卷积（atrous convolutions）又名扩张卷积（dilated convolutions），向卷积层引入了一个称为 “扩张率(dilation rate)”的新参数，该参数定义了卷积核处理数据时各值的间距。 一个扩张率为2的3×3卷积核，感受野与5×5的卷积核相同，而且仅需要9个参数。你可以把它想象成一个5×5的卷积核，每隔一行或一列删除一行或一列。 在相同的计算条件下，空洞卷积提供了更大的感受野。空洞卷积经常用在实时图像分割中。当网络层需要较大的感受野，但计算资源有限而无法提高卷积核数量或大小时，可以考虑空洞卷积。 扩展阅读 Andrew Ng 的UFLDL教程 各种卷积结构原理及优劣 | Medium 比较新 一文了解各种卷积结构原理及优劣 | Medium &amp; 中文翻译|知乎 理解深度学习中的卷积 | Tim Dettmers &amp; 中文翻译 | 码农场 Understanding Convolutions | colah 卷积为什么叫「卷」积？ | 知乎 如何通俗易懂地解释卷积？ | 知乎 A guide to convolution arithmetic for deep learning","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"残差网络ResNet","date":"2018-04-07T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/CNN/-Resnet/","text":"简介Is learning better networks as easy as stacking more layers?深层网络会遭遇退化问题(degradation): 随着网络层数的增加，精度会到达饱和区，而后迅速下降。 作者在CIFAR-10数据进行实验，采用3x3 卷积层的简单堆叠来测试网络深度的影响。发现当层数增加到20层的时候网络进入饱和区(即使再增加网络的深度，精度也不会提高)。不仅如此，继续增加深度还会导致模型退化，训练精度和测试精度迅速下降。这说明当网络变得很深以后，深度网络就变得更加难以训练了。(注意：这不是过拟合。过拟合是训练误差小，测试误差大) (难以训练，训练误差) 随着网络层级的不断增加，模型精度不断得到提升。而当网络层级增加到一定的数目以后， “Overly deep” plain nets have higher training error 【问题来了】为什么随着网络层级越深，训练误差越大了？ 模型如何又能加深网络层数、又能解决梯度消失问题、又能提升模型精度呢？ 那么我们作这样一个假设：假设现有一个比较浅的网络（Shallow Net）已达到了饱和的准确率，这时在它后面再加上几个恒等映射层（Identity mapping，也即y=x，输出等于输入），这样就增加了网络的深度，并且起码误差不会增加，也即更深的网络不应该带来训练集上误差的上升。而这里提到的使用恒等映射直接将前一层输出传到后面的思想，便是著名深度残差网络ResNet的灵感来源。 这里没看懂。恒等映射层是 y=x, 还是y=f(x)+x ? 创新点Residual Learning 普通网络中：$H(x)$ is any desired mapping,hope the 2 weight layers fit $H(x)$ 残差网络：$H(x)$ is any desired mapping,hope the 2 weight layers fit 𝐻(𝑥)hope the 2 weight layers fit $F(x)$let $H(x)=F(x)+x$ 恒等映射Identity Mapping by Shortcuts bottle neck 右侧是bottleneck连接，左右两个网络具有相似的复杂度，但是右侧的bottlenect设计能够用于更深层的网络。 疑问为什么不能简单地增加网络层数？对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸。 对于该问题的解决方法是正则化初始化和中间的正则化层（Batch Normalization），这样的话可以训练几十层的网络。 虽然通过上述方法能够训练了，但是又会出现另一个问题，就是退化问题，网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。退化问题说明了深度网络不能很简单地被很好地优化。作者通过实验：通过浅层网络+ y=x 等同映射构造深层模型，结果深层模型并没有比浅层网络有等同或更低的错误率，推断退化问题可能是因为深层的网络并不是那么好训练，也就是求解器很难去利用多层网络拟合同等函数。 怎么解决退化问题？深度残差网络。如果深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络。那现在要解决的就是学习恒等映射函数了。 但是直接让一些层去拟合一个潜在的恒等映射函数H(x) = x，比较困难，这可能就是深层网络难以训练的原因。但是，如果把网络设计为H(x) = F(x) + x,如下图。我们可以转换为学习一个残差函数F(x) = H(x) - x. 只要F(x)=0，就构成了一个恒等映射H(x) = x. 而且，拟合残差肯定更加容易。 维度设计 从上到下： 整体的feature_map变小 整体的channel数目在增大 源码 官方实现 | KaimingHe caffe keras 强调identity_block，恒等映射 pytorch 强调bottlenect resnet示例-pytorch 依赖 resnet模型-pytorch 另外一个resnet版本 https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py resnet-tensorflow 提供cifar10 imagenet的示例 ResNet可视化参考 SGD在两层神经网络上是怎么收敛的？ | 知乎 ResNet及其多种变体 https://www.jianshu.com/p/e58437f39f65","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"CNN模型之AlexNet","date":"2018-04-06T16:00:00.000Z","path":"wiki/ML/deep learning/model-basic/CNN/-AlexNet/","text":"Alex 2012使用了一些改良CNN方法去解决普适物体识别难题。开创性地使用了CUDA来加速神经网络训练，并且开放了Cuda-Convnet和绝秘CNN结构，群众反响热烈。又名ConvNet、AlexNet。 模型结构 由于早期GPU显存的限制，最早的AlexNet包括了two stream的设计，以让网络中一半的节点能存入一个GPU。 5层卷积层详情如下：(max pooling: kernel_size=3, stride=2) 层数 input size kernel size # kernels stride padding output size max pooling 1 224×224×3 11×11 96 4 2 55×55×96 yes 2 27×27×96 5×5 256 1 2 27×27×256 yes 3 13×13×256 3×3 384 1 1 13×13×384 no 4 13×13×384 3×3 384 1 1 13×13×384 no 5 13×13×384 3×3 256 1 1 13×13×256 yes AlexNet的pytorch实现https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py 12 为什么跟 https://zhuanlan.zhihu.com/p/31717727 不同 多GPU训练由于早期GPU显存的限制，AlexNet使用了双数据流的设计，以让网络中一半的节点能存入一个GPU。这两个数据流，也就是说两个GPU只在一部分层进行通信，这样达到限制GPU同步时的额外开销的效果。有幸的是，GPU在过去几年得到了长足的发展，除了一些特殊的结构外，我们也就不再需要这样的特别设计了。 Overlapping Pooling重叠的池化层 池化操作提取的是一小部分的代表性特征，减少冗余信息。传统的卷积层中，相邻的池化单元是不重叠的。如果stride=kernel_size，我们得到不重叠的池化。如果stride&lt;kernel_size，我们得到重叠的池化。在AlexNet中使用了最大池，stride=2，kernel_size=3。 论文指出，这种池化能“稍微”减轻过拟合。 ReLU见激活函数-ReLU 学习使用基于动量的梯度下降算法 batch_size = 128 momentum=0.9 weight_decay=0.0005 codehttps://code.google.com/p/cuda-convnet/ tensorflow中的tutorial/cnn也是AlexNet的实现 参考 参数量: https://zhuanlan.zhihu.com/p/40791280 https://my.oschina.net/u/876354/blog/1633143","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"CNN","slug":"ML/deep-learning/model-basic/CNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/CNN/"}]},{"title":"rsync 原理","date":"2018-04-04T16:00:00.000Z","path":"wiki/CS/tools/同步与版本管理/rsync/","text":"简介rsync是Unix下的一款应用软件，它能同步更新两处计算机的文件与目录，并适当利用差分编码以减少数据传输量。rsync中的一项同类软件不常见的重要特性是每个目标的镜像只需发送一次。rsync可以拷贝／显示目录内容，以及拷贝文件，并可选压缩以及递归拷贝。 在常驻模式（daemon mode）下，rsync默认监听TCP端口873，以原生rsync传输协议或者通过远程shell如RSH或者SSH提供文件。SSH模式下，rsync客户端运行程序必须同时在本地和远程机器上安装。 rsync使用所谓的“rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 需要解决的问题 如何判断文件是否变更？ 如何找到变更的部分？ 对于二进制文件怎样处理？ 对于大文件怎样处理？ rsync算法 按固定大小将A分为多块，每块都计算出一个32位的滚动哈希值和一个128位的MD4（有些也用MD5），发给B一端。 B一端从位置0开始按的同样块大小的滚动哈希值，查找看是否命中A给的某个滚动哈希值，若匹配，则表明B文件中的这块内容与对应的A中的那块内容很可能是一致的，但由于32位的哈希值强度不够，因此再计算MD4，若还是匹配，则确认是一致内容，这时B发给A端匹配的段号。对于那些不能匹配的内容，则发给A端原始内容。 A端得到B端给的匹配信息，构造一个与B一致的复本，若是匹配的块，则拷贝原A文件中对应的块，若是不匹配内容则追加之。 分块Checksum算法首先，我们会把fileDst的文件平均切分成若干个小块，比如每块512个字节（最后一块会小于这个数），然后对每块计算两个checksum， 一个叫rolling checksum，是弱checksum，32位的checksum，其使用的是Mark Adler发明的adler-32算法， 另一个是强checksum，128位的，以前用md4，现在用md5 hash算法。 为什么要这样？因为若干年前的硬件上跑md4的算法太慢了，所以，我们需要一个快算法来鉴别文件块的不同，但是弱的adler32算法碰撞概率太高了，所以我们还要引入强的checksum算法以保证两文件块是相同的。也就是说，弱的checksum是用来区别不同，而强的是用来确认相同。（checksum的具体公式可以参看这篇文章） 传输算法同步目标端会把fileDst的一个checksum列表传给同步源，这个列表里包括了三个东西，rolling checksum(32bits)，md5 checksume(128bits)，文件块编号。 我估计你猜到了同步源机器拿到了这个列表后，会对fileSrc做同样的checksum，然后和fileDst的checksum做对比，这样就知道哪些文件块改变了。 但是，聪明的你一定会有以下两个疑问： 如果我fileSrc这边在文件中间加了一个字符，这样后面的文件块都会位移一个字符，这样就完全和fileDst这边的不一样了，但理论上来说，我应该只需要传一个字符就好了。这个怎么解决？如果这个checksum列表特别长，而我的两边的相同的文件块可能并不是一样的顺序，那就需要查找，线性的查找起来应该特别慢吧。这个怎么解决？很好，让我们来看一下同步源端的算法。 checksum查找算法比对算法源码基于rsync的应用 Rclone Back In Time … 都没听过 基于rsync的改进算法基于rsync的改进算法主要有多轮rsync和本地rsync两个。 疑问参考 维基百科 RSYNC 的核心算法 | 酷壳 Dropbox差异同步算法rsync及其改进算法原理","tags":[{"name":"checksum","slug":"checksum","permalink":"http://yoursite.com/tags/checksum/"},{"name":"同步","slug":"同步","permalink":"http://yoursite.com/tags/同步/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"}]},{"title":"数组","date":"2018-04-01T16:00:00.000Z","path":"wiki/CS/programing/lan/array/","text":"概述数组 VS 列表 优缺点优点 代码优化：它使代码优化，可以轻松地检索或排序数据。 随机访问：可以获取任何位于任何索引位置的数据。 缺点 大小限制：只能在数组中存储固定大小的元素。 它在运行时不会增长其大小。 为了解决这个问题，在Java中使用了集合框架。 不同语言的实现CC++Java Java数组在内存中如何储存的Java的数组是存在函数栈中？还是存堆中？为什么这个图里，像是存在堆中？ 数组引用变量是存放在栈内存(stack)中，数组元素本质是一个对象，是存放在堆内存(heap)中。通过栈内存中的指针指向对应元素的在堆内存中的位置来实现访问。 基本数据类型的数组在内存分配情况 从图中可看出数组元素直接存放在堆内存中，当操作数组元素时，实际上是操作基本类型的变量。 引用类型数组在内存中如何储存元素为引用类型的数组，在内存中的存储与基本类型完全不一样。 此时数组元素存放引用，指向另一块内存，在其中存放有效的数据。如图： 在数组参数传递的时候，数组是作为引用参数，传递的是数组的引用指针，将数组引用传递给另一数组引用，但仍然不能改变数组长度(仅仅只是调整数组引用指针的指向)。 疑问 Java在堆中分配数组，能否保证连续性？是等价于C++中的malloc分配数组吗？ Java分配数组的源码在哪？ python对比C的数组存储在stack中，Java的数组是对象，存储在堆中。 参考 http://www.dczou.com/viemall/220.html-","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"【Hexo插件系列】日志的自动分类插件 hexo-auto-category","date":"2018-03-31T16:00:00.000Z","path":"wiki/demo/hexo/hexo-auto-category/","text":"简介 Hexo写日志，通常我们都需要维护一个front-matter信息，包括title、date。博客多了，为了方便日志分类，一般还需要设置categories。比如下面的例子：12345678---title: Hexo简介date: 2008-08-08categories: - web开发 - 前端 - 博客框架--- 久而久之，就会发现很多问题： 工作繁琐：大量的category是重复性工作 容易出错：大小写和中英文目录有可能混杂。比如有个web目录，偶尔我们写成了Web，造成了目录树中冗余的节点。 可维护性差：如果要更改目录树中的节点，就要手动更改每个日志的categories变量。 本文介绍一种自动生成categories的插件 hexo-auto-category官方地址。 自动生成 categories最常用的文件管理策略，就是利用文件系统目录结构(树形结构 directory-tree)。同样，为了便于管理大量的日志文件，采用目录结构是一种简便可行的方案。hexo-auto-category根据日志文件(Markdown)所在文件目录自动分类，即自动生成markdown的front-matter中的categories变量。 示例 对于博客 source/_post/web/framework/hexo.md，该插件会自动生成以下categories123categories: - web - framework 安装1$ npm install hexo-auto-category --save 配置在站点根目录下的_config.yml添加： 123456# Generate categories from directory-tree# Dependencies: https://github.com/xu-song/hexo-auto-category# depth: the depth of directory-tree you want to generate, should &gt; 0auto_category: enable: true depth: 编译 &amp; 部署1$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 高级配置如果只想生成第一级目录分类，可以设置depth属性，比如： 123auto_category: enable: true depth: 1 如有任何疑问，可在Github Issue提出","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"plugin","slug":"plugin","permalink":"http://yoursite.com/tags/plugin/"},{"name":"category","slug":"category","permalink":"http://yoursite.com/tags/category/"},{"name":"hexo-auto-category","slug":"hexo-auto-category","permalink":"http://yoursite.com/tags/hexo-auto-category/"}],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"关于Monkey Patch猴子补丁","date":"2018-03-31T16:00:00.000Z","path":"wiki/CS/programing/lan/monkey-patching/","text":"简介定义以下是维基百科对猴子补丁的定义 The term monkey patch refers to dynamic modifications of a class or module at runtime, motivated by the intent to patch existing third-party code as a workaround to a bug or feature which does not act as desired. 所谓的猴子补丁，是指在运行时修改类或模块，而不去改变源码，达到hot patch的目的。 猴补丁（英语：Monkey patch）是一种很脏的编程技巧，用拼凑代码的方法修改程序逻辑。 Monkey patching 只能在动态语言中实现。比如Python类的方法其实也只是一个属性，方便运行时修改，所以用Python做猴子补丁非常方便。 Changing a method at runtime instead of updating the object definition is one example。 名字来源 这个词原来为Guerrilla Patch，杂牌军、游击队，说明这部分不是原装的，在英文里guerilla发音和gorllia(猩猩)相似，再后来就写了monkey(猴子)。 还有一种解释是说由于这种方式将原来的代码弄乱了(messing with it)，在英文里叫monkeying about(顽皮的)，所以叫做Monkey Patch。 示例/应用场景维基百科总结了4种应用场景 Replace methods / attributes / functions at runtime, e.g. to stub out a function during testing; Modify/extend behaviour of a third-party product without maintaining a private copy of the source code; Apply a patch at runtime to the objects in memory, instead of the source code on disk; Distribute security or behavioural fixes that live alongside the original source code (an example of this would be distributing the fix as a plugin for the Ruby on Rails platform). 简单示例对属性 打补丁以下来自wikpedia示例。利用猴子补丁，动态修改math标准库中Pi的默认值。(这里仅修改了attributes，也可以对某些method进行重写) 12345678910&gt;&gt;&gt; import math&gt;&gt;&gt; math.pi3.141592653589793&gt;&gt;&gt; math.pi = 3 # 给标准库打补丁，即运行时修改math的pi属性&gt;&gt;&gt; math.pi3&gt;&gt;&gt; ================================ RESTART ================================&gt;&gt;&gt; import math&gt;&gt;&gt; math.pi3.141592653589793 对方法 打补丁12345678910class Foo(object): def bar(self): print 'Foo.bar'def bar(self): # 这是补丁 print 'Modified bar'Foo().bar()Foo.bar = bar # 给Foo的bar方法打补丁，即运行时修改类的方法Foo().bar() 由于Python中的名字空间是开放，通过dict来实现，所以很容易就可以达到patch的目的。 实际应用案例socket的热补丁用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了. SQL注入攻击网页和数据库 Zope、Plone中的安全补丁 In Zope and Plone, security patches are often delivered using dynamic class modification, but they are called hot fixes.– wikipedia 很多安全补丁也是一种猴子补丁，只不过叫法不同而已。 Eventlet Patcher现在我们先来看一下eventlet中的Patcher的调用代码吧，这段代码对标准的ftplib做monkey patch，将eventlet的GreenSocket替换标准的socket。 123456from eventlet import patcher # *NOTE: there might be some funny business with the \"SOCKS\" module # if it even still exists from eventlet.green import socket patcher.inject('ftplib', globals(), ('socket', socket)) del patcher Eventlet中大量使用了该技巧，以替换标准库中的组件，比如socket。 未完待续，参考 https://blog.csdn.net/seizef/article/details/5732657 从Gevent学习猴子补丁的设计异步协程工具Gevent是python上面最有名也支持面最广通用性最好的协程工具,它底层基于greenlet,而且可以通过使用猴子补丁将标准库中的同步模块自动的转换成异步.同时他也提供了方便的并发模型和常用的web服务器工具. gevent能够 修改标准库里面大部分的阻塞式系统调用，包括socket、ssl、threading和 select等模块，而变为协作式运行。 12345678910111213141516&gt;&gt;&gt; import socket&gt;&gt;&gt; print(socket.socket) # monkey patch前&lt;class 'socket._socketobject'&gt;&gt;&gt;&gt;&gt;&gt;&gt; from gevent import monkey # monkey patch后&gt;&gt;&gt; monkey.patch_socket()&gt;&gt;&gt; print(socket.socket)&lt;class 'gevent._socket2.socket'&gt; # 改变了标准socket库&gt;&gt;&gt; import select # monkey patch前&gt;&gt;&gt; print(select.select) # select()轮询的阻塞调用&lt;built-in function select&gt;&gt;&gt;&gt;&gt;&gt;&gt; monkey.patch_select() # monkey patch后&gt;&gt;&gt; print(select.select) # select()轮询的异步调用&lt;function select at 0x7fb8a7239d70&gt; 例如，Redis的python绑定一般使用常规的tcp socket来与redis-server实例通信。 通过简单地调用gevent.monkey.patch_all()，可以使得redis的绑定协作式的调度 请求，与gevent栈的其它部分一起工作。 这让我们可以将一般不能与gevent共同工作的库结合起来，而不用写哪怕一行代码。 虽然猴子补丁仍然是邪恶的(evil)，但在这种情况下它是“有用的邪恶(useful evil)”。 patch_all除了socket外,gevent还可以为其他的模块打补丁,一起打补丁可以使用1patch_all(socket=True, dns=True, time=True, select=True, thread=True, os=True, ssl=True, httplib=False,subprocess=True, sys=False, aggressive=True, Event=False, builtins=True, signal=True) 函数。 我们可以看到像socket,dns,time,selectthread,os, ssl, httplib,subprocess, sys, aggressive, Event, builtins, signal模块都可以打上补丁,打上以后,他们就是非阻塞的了. 核心协程模块greenlet12345678910111213141516import geventdef foo(): print('Running in foo') gevent.sleep(0) # 这行的作用是什么？ print('Explicit context switch to foo again')def bar(): print('Explicit context to bar') gevent.sleep(0) # print('Implicit context switch back to bar')gevent.joinall([ gevent.spawn(foo), gevent.spawn(bar),]) 输出12345Running in fooExplicit context to barExplicit context switch to foo againImplicit context switch back to bar[&lt;Greenlet at 0x7fb8a72c3eb0&gt;, &lt;Greenlet at 0x7fb8a72c3a50&gt;] 上述例子能看到，执行顺序是 foo--&gt;bar--foo--bar，来回切换。即gevent.sleep()并不会真正的阻塞整个线程，而是将cpu的控制权显式的交给未被gevent.sleep()阻塞的协程使用。 协程是单线程程序（从上述例子来讲），如果我们使用time.sleep()，那么整个线程都会被阻塞。 gevent.sleep与time.sleep的区别 gevent is a cooperative analog to the threading module. When using gevent.sleep it you would never use time.sleep. So no example is needed. time.sleep would suspend the entire process, blocking all greenlet threads. 来源。 以上说法针对的是协程(单线程程序)。而对于多线程，time.sleep仅仅阻塞当前线程，不阻塞其他线程，来源。 猴子补丁 与 SocketIO用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了. 我看到猴子补丁，是从Gevent中看到的。SocketIO服务器发送数据，浏览器端并非实时接收，而是批量接收 (跟过马路有点像，凑够一波发送一次)。 这里涉及到buffer和flush。 https://github.com/miguelgrinberg/Flask-SocketIO/issues/106 https://github.com/miguelgrinberg/Flask-SocketIO/issues/141 没看懂的部分，后面再看。 That is really the only way to make this work when you use gevent, threading is cooperative so you have to release the CPU so that other tasks associated with the server get a chance to run and flush the messages. Any chance you haven’t monkey patched the standard library?— Flask-SocketIO的作者miguelgrinberg link 这里说的意思是，socketio.emit(message) 默认会加缓存(buffer)。需要主动flush才能立即发送。而gevent.sleep(是flush的一种方式，因为它会 将cpu的控制权显式的交给未被gevent.sleep()阻塞的协程使用，切换之前会先flush一下。 socketio.emit默认会有个buffer（为了高效），为什么gevent.sleep会flush这个buffer？让我们重新梳理一下思路： gevent.sleep会释放cpu控制权，即切换协程，从而不阻塞其他协程运行。 gevent切换协程的源码 gevent进行协程切换前，需要flush当前协程。 gevent进行flush的源码 flush当前协程导致socket.emit中的缓存立即发送 猴子补丁与 import json,之前做的一个游戏服务器,很多地方用的import json,后来发现ujson比自带json快了N倍,于是问题来了,难道几十个文件要一个个把import json改成import ujson as json吗?其实只需要在进程startup的地方monkey patch就行了.是影响整个进程空间的.同一进程空间中一个module只会被运行一次. 习题猴子补丁是动态语言的专利么？使用猴子补丁的条件主要是可以打开类、可以重定义现有属性、方法。修改类方法的指针，或者属性 CC++C++ 类有哪个方法是编译时确定好的, 没法打开类, 对象属于哪个类是 new 对象的代码确定好的, 既然 new 的代码在编译时确定了, 再载入补丁库也修改不了 (除非搞缓冲区溢出攻击…) 比如python中可以math.Pi=3。 javajava强大的反射，即使属性或方法被设置为了private final也可以动态更改。讲道理也可以动态补丁。 总结不是脚本语言的专利……是语言设计留不留口的问题？ 猴子补丁的坑参考 Monkey patch | wikipedia what-is-monkey-patching | StackOverflow 待看 《松本行弘的程序世界》专门有一章讲了猴子补丁的设计 猴子补丁是动态语言的专利么？ | ruby-china 猴子补丁和热更新 | 网络博客","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"}]},{"title":"【Angular系列】 Angular 2 入门","date":"2018-03-27T16:00:00.000Z","path":"wiki/CS/web/front-end/framework/Angular/angular2-quickstart/","text":"runoob教程链接 首先是不掺杂typescript，更能熟悉angular其工作原理。 运行 下载源码 npm install 双击html即可。无须借助node server，更容易理解前端框架 执行顺序 npm start启动lite-server，默认加载index.html。或直接双击index.html 浏览器加载index.html 浏览器依次加载并执行 app.component.js、app.module.js、main.js 执行app.component.js，将app.component匿名函数加入到window.app中。并未调用constructor 执行app.module.js，将app.module匿名函数加入到window.app中 执行main.js， main.js调用app.AppModule，即调用app.module匿名函数。其中会调用constructor app.module调用app.AppComponent，即调用app.component匿名函数，返回template 细节index.html123456789101112131415161718192021222324252627282930313233343536&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Angular 2 实例 - 菜鸟教程(runoob.com)&lt;/title&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;link rel=\"stylesheet\" href=\"styles.css\"&gt; &lt;!-- 1. 载入库 --&gt; &lt;!-- IE 需要 polyfill --&gt; &lt;script src=\"node_modules/core-js/client/shim.min.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/zone.js/dist/zone.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/reflect-metadata/Reflect.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/rxjs/bundles/Rx.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/@angular/core/bundles/core.umd.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/@angular/common/bundles/common.umd.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/@angular/compiler/bundles/compiler.umd.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/@angular/platform-browser/bundles/platform-browser.umd.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/@angular/platform-browser-dynamic/bundles/platform-browser-dynamic.umd.js\"&gt;&lt;/script&gt; &lt;!-- 2. 载入 'modules' 顺序不能乱，因为main.js依赖app.module.js，app.module.js依赖app.component.js --&gt; &lt;script src='app/app.component.js'&gt;&lt;/script&gt; &lt;script src='app/app.module.js'&gt;&lt;/script&gt; &lt;script src='app/main.js'&gt;&lt;/script&gt; &lt;/head&gt; &lt;!-- 3. 显示应用 --&gt; &lt;body&gt; &lt;my-app&gt;Loading...&lt;/my-app&gt; &lt;/body&gt;&lt;/html&gt; main.js定义了一个匿名函数，参数为app 第二个括号用于调用该匿名函数，并传入参数。 1234567(function(app) &#123; document.addEventListener('DOMContentLoaded', function() &#123; ng.platformBrowserDynamic .platformBrowserDynamic() .bootstrapModule(app.AppModule); // 依赖AppModule类 &#125;);&#125;)(window.app || (window.app = &#123;&#125;)); app.module.js定义了一个匿名函数，参数为app。1234567891011(function(app) &#123; app.AppModule = // // 创建一个Angular Module对象，并赋值给对app ng.core.NgModule(&#123; imports: [ ng.platformBrowser.BrowserModule ], declarations: [ app.AppComponent ], bootstrap: [ app.AppComponent ] &#125;) .Class(&#123; constructor: function() &#123;&#125; &#125;);&#125;)(window.app || (window.app = &#123;&#125;)); app.component.js定义了一个匿名函数，参数为app 12345678910(function(app) &#123; app.AppComponent = // 创建一个Angular Component对象 ng.core.Component(&#123; selector: 'my-app', template: '&lt;h1&gt;我的第一个 Angular 应用&lt;/h1&gt;' &#125;) .Class(&#123; constructor: function() &#123;&#125; &#125;);&#125;)(window.app || (window.app = &#123;&#125;)); package.json用于npm install的依赖和npm start的脚本。 1234567891011121314151617181920212223242526272829303132&#123; \"name\": \"angular2-quickstart\", \"version\": \"1.0.0\", \"scripts\": &#123; \"start\": \"npm run lite\", \"lite\": \"lite-server\" &#125;, \"license\": \"ISC\", \"dependencies\": &#123; \"@angular/common\": \"2.0.0\", \"@angular/compiler\": \"2.0.0\", \"@angular/core\": \"2.0.0\", \"@angular/forms\": \"2.0.0\", \"@angular/http\": \"2.0.0\", \"@angular/platform-browser\": \"2.0.0\", \"@angular/platform-browser-dynamic\": \"2.0.0\", \"@angular/router\": \"3.0.0\", \"@angular/upgrade\": \"2.0.0\", \"core-js\": \"^2.4.1\", \"reflect-metadata\": \"^0.1.3\", \"rxjs\": \"5.0.0-beta.12\", \"zone.js\": \"^0.6.23\", \"angular2-in-memory-web-api\": \"0.0.20\", \"bootstrap\": \"^3.3.6\" &#125;, \"devDependencies\": &#123; \"concurrently\": \"^2.0.0\", \"lite-server\": \"^2.2.0\" &#125;&#125;","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"framework","slug":"CS/web/front-end/framework","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/"},{"name":"Angular","slug":"CS/web/front-end/framework/Angular","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/Angular/"}]},{"title":"单页应用","date":"2018-03-26T16:00:00.000Z","path":"wiki/CS/web/front-end/SPA-单页应用/","text":"单页应用（英语：single-page application，缩写SPA）是一种网络应用程序或网站的模型，它通过动态重写当前页面来与用户交互，而非传统的从服务器重新加载整个新页面。这种方法避免了页面之间切换打断用户体验，使应用程序更像一个桌面应用程序。在单页应用中，所有必要的代码（HTML、JavaScript和CSS）都通过单个页面的加载而检索，或者根据需要（通常是为响应用户操作）动态装载适当的资源并添加到页面。尽管可以用位置散列或HTML5历史API来提供应用程序中单独逻辑页面的感知和导航能力，但页面在过程中的任何时间点都不会重新加载，也不会将控制转移到其他页面。[2]与单页应用的交互通常涉及到与网页服务器后端的动态通信。– wikipedia 就是基于ajax技术交互的动态页面呗。 诸如AngularJS、Ember.js、Meteor.js、ExtJS和React等面向网页浏览器的JavaScript框架采纳了单页应用（SPA）原则。 这句话怎么理解？这些框架是为了单页应用设计的？为什么这么说？ 汇总参考自掘金 https://juejin.im/post/5a0ea4ec6fb9a0450407725c 单页面应用（SPA） 多页面应用（MPA） 组成 一个外壳页面和多个页面片段组成 多个完整页面构成 资源共用(css,js) 共用，只需在外壳部分加载 不共用，每个页面都需要加载 刷新方式 页面局部刷新或更改 整页刷新 url 模式 a.com/#/pageone a.com/pageone.html 用户体验 页面片段间的切换快，用户体验良好 页面切换加载缓慢，流畅度不够，用户体验比较差 转场动画 容易实现 无法实现 数据传递 容易 依赖 url传参、或者cookie 、localStorage等 搜索引擎优化(SEO) 需要单独方案、实现较为困难、不利于SEO检索 可利用服务器端渲染(SSR)优化 实现方法简易 试用范围 高要求的体验度、追求界面流畅的应用 适用于追求高度支持搜索引擎的应用 开发成本 较高，常需借助专业的框架 较低 ，但页面重复代码多 维护成本 相对容易 相对复杂 疑问为什么SPA不利于SEO？单页页面，数据在前端渲染。爬虫一般只抓取静态页面，不会调用js来动态生成新页面。 为什么SPA要首次加载大量资源？前端渲染，肯定前端需要很多js。SPA一定要前端渲染吗，后端可以渲染好html部分元素返回前台吧？ SPA首次加载大量的静态资源，是前端渲染任务重造成的？ 加载顺序首屏渲染速度除了受js文件大小的影响，还有HTML的解析时机。为了提早加载完document，最好将没有用到的其他文件的下载往后推或者异步下载（不要让他阻塞document的加载）。这里给这些js文件添加了 defer属性。 参考 单页应用 | wikipedia 单页应用有那些优缺点？ | 知乎 单页应用开发基础","tags":[{"name":"单页应用","slug":"单页应用","permalink":"http://yoursite.com/tags/单页应用/"},{"name":"angular","slug":"angular","permalink":"http://yoursite.com/tags/angular/"},{"name":"react","slug":"react","permalink":"http://yoursite.com/tags/react/"},{"name":"ajax","slug":"ajax","permalink":"http://yoursite.com/tags/ajax/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"}]},{"title":"OCR","date":"2018-03-26T16:00:00.000Z","path":"wiki/ML/app/vision/app/OCR/OCR/","text":"OCR文字识别用的是什么算法？–知乎 流程General OCR一般包含: detection–&gt;找到包含文字的区域(proposal); 接着利用radon hough变换 等方法 进行文本校正。 通过投影直方图分割出单行的文本的图片。 classification–&gt;识别区域中的文字。 framework是: CNN + LSTM + CTC。这个framework加上residue network + stn可以把通用的数据集刷的非常高。 detection先说detection models, 近两年比较热门的object detection model有 faster-rcnn(https://arxiv.org/pdf/1506.01497.pdf) 和 yolo(http://pjreddie.com/media/files/papers/yolo.pdf), 两个模型都是基于CNN给出proposed regions 同时对object region进行分类。 其中yolo比faster-rcnn的速度更快，但是在accuracy上有些损失。 比较著名的是Ian goodfellow在13年提出的multi-digit number classification 另一类比较常用的方法是RNN/LSTM/GRU + CTC, 开源工具&amp;代码https://github.com/tesseract4java/jtesseract 开源包: tesseract 很赞 最好的模型，竟然是lstm？https://github.com/tesseract-ocr/tessdata_best","tags":[{"name":"OCR","slug":"OCR","permalink":"http://yoursite.com/tags/OCR/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"OCR","slug":"ML/app/vision/app/OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/"}]},{"title":"文件管理工具 - Everthing原理 之 还没看懂","date":"2018-03-25T16:00:00.000Z","path":"wiki/CS/tools/文件管理/everything/everything/","text":"简介Everything is an Awesome Utility that Locates Files and Folders Instantly in Windows Everything仅支持windows系统的NTFS硬盘格式(不支持FAT、FAT32)。Everything默认对文件名、文件大小、日期以及其它某些meta data建索引，可关闭某些字段索引来加速。 建索引很快 数据库文件 Everything.db。 这是什么类型的数据库？自定义的吗？ 搜索超快 怎样建的索引？咋这么快？建了个hash索引？倒排索引？ 实时性好 怎样获取的新文件列表？大量的临时文件要不要索引？ Everything功能如此强大，让人不禁对其工作原理产生强烈的好奇心。但是，Everthing官方未开源，这对想学习其工作原理的程序员来说是个bad news。官方提供SDK不知能否看出一些原理逻辑。待看 啊哈，有相关开源项目微软某成员(疑似轮子哥)在codeplex开源了一个类似everything的个人项目everythingSZ。以下介绍EverythingSZ的原理。 原理Everything搜索文件很快，是利用的NTFS分区的USN功能. 原理： 读取NTFS下的USN日志文件 UsnOperator类源码 根据USN继续查询； 根据文件编号继续查询； 创建USN（激活USN状态）； NTFS的Change Journal（更改日志）的方法实现监控功能 未采用 FileSystemWatcher 监听文件变化。(everthing不是采用的这个window api) 如何建索引如何监听文件变化这属于操作系统 &amp; 文件系统的范畴。 Windows即利用windows api。 以下几种方式： FindFirstChangeNotification 无法获取是哪一个文件发生了改变。 ReadDirectoryChangesW 据说变化量大又密集时，丢失通知现象很严重 FileSystemWatcher 貌似是对ReadDirectoryChangesW的封装 NTFS的Change Journal（更改日志） Change Journal是标卷上一个特殊的文件，系统将其隐藏，所以用资源管理器或者CMD Shell都看不到，当文件系统中的文件或者目录发生改变时，就会向日志中追加记录。参考 通过读取和监控USN（后面会讲）而不是扫描文件来构建索引，所以搜索速度飞快 Everything采用了第四种方式，即利用了NTFS系统的Change Journal特性。 Linux inotify 命令 是Linux自带的监控inode变动的函数 文档 man 7 inotify 其它疑问linux下有没有类似的工具比linux下的find命令快，比locate命令实时性好。 见stackexchange 参考 &amp; 待看 EverythingSZ源码 - 轮子哥推荐 | Github C# 探索Everything背后的技术（USN和MFT）| Github NTFS系列 密切关注你的NTFS驱动器 | CSDN-","tags":[{"name":"Everthing","slug":"Everthing","permalink":"http://yoursite.com/tags/Everthing/"},{"name":"文件管理","slug":"文件管理","permalink":"http://yoursite.com/tags/文件管理/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"文件管理","slug":"CS/tools/文件管理","permalink":"http://yoursite.com/categories/CS/tools/文件管理/"},{"name":"everything","slug":"CS/tools/文件管理/everything","permalink":"http://yoursite.com/categories/CS/tools/文件管理/everything/"}]},{"title":"如何debug typescript","date":"2018-03-25T16:00:00.000Z","path":"wiki/CS/web/front-end/framework/Angular/angular-debug/","text":"Debugging TypeScript in Visual StudioDebugging TypeScript in Firefox or Chrome在ts中写个console.info(“ds”)然后浏览器 原理浏览器默认是不认识typescript的，如何做到在浏览器debug typescript的呢？ 参考https://blogs.msdn.microsoft.com/jtarquino/2016/01/24/debugging-typescript-in-visual-studio-code-and-chrome/","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"framework","slug":"CS/web/front-end/framework","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/"},{"name":"Angular","slug":"CS/web/front-end/framework/Angular","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/Angular/"}]},{"title":"【Angular系列】Angular 快速入门教程 - Hello Angular","date":"2018-03-25T16:00:00.000Z","path":"wiki/CS/web/front-end/framework/Angular/angular-quickstart/","text":"简介Angular 是由谷歌开发与维护一个开发跨平台应用程序的框架，同时适用于手机与桌面。 其模板基于双向UI数据绑定。数据绑定是一种自动方法，在模型改变时更新视图，以及在视图改变时更新模型。 以下代码来自https://github.com/angular/quickstart 流程简介 https://github.com/angular/quickstart (本文代码的来源) https://angular.io/guide/quickstart 浏览器默认请求index.html index.html调用main.js main.js调用app.component.js app.component.js扫描html，发现有my-app标签，将字符串&lt;h1&gt;Hello &lt;/h1&gt;动态插入到my-app元素里。 angular的js扫描html，发现了，向后台发送一个动态请求 (好像是在js中的hard code) 实际node后台顺序貌似是反向的。 流程分解入口 index.html以下是index.html，其中调用了main.js 123456789101112131415161718192021222324252627&lt;!-- src/index.html --&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Angular QuickStart&lt;/title&gt; &lt;base href=\"/\"&gt; &lt;!-- 如果想双击运行html的话，需要去掉这行，并加入angular依赖 --&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;link rel=\"stylesheet\" href=\"styles.css\"&gt; &lt;!-- IE 需要 polyfill --&gt; &lt;script src=\"node_modules/core-js/client/shim.min.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/zone.js/dist/zone.js\"&gt;&lt;/script&gt; &lt;script src=\"node_modules/systemjs/dist/system.src.js\"&gt;&lt;/script&gt; &lt;!-- 这里是Angular的入口js文件 --&gt; &lt;script src=\"systemjs.config.js\"&gt;&lt;/script&gt; &lt;script&gt; System.import('main.js').catch(function(err)&#123; console.error(err); &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 使用 AppComponent 组件 --&gt; &lt;my-app&gt;Loading AppComponent content here ...&lt;/my-app&gt; &lt;/body&gt;&lt;/html&gt; 在main.ts中设置断点，会看到页面是这样子的。 main.tsmain.ts调用 AppModule模块，会创建AppModule类。(由Angular的NgModuleFactory创建)1234// src/main.tsimport &#123; platformBrowserDynamic &#125; from '@angular/platform-browser-dynamic';import &#123; AppModule &#125; from './app/app.module';platformBrowserDynamic().bootstrapModule(AppModule); AppModule 模块AppModule模块的声明如下。其中调用了AppComponent组件，即首先创建AppComponent类。(由Angular的ComponentFactory创建)123456789101112// src/app/app.module.tsimport &#123; NgModule &#125; from '@angular/core';import &#123; BrowserModule &#125; from '@angular/platform-browser';import &#123; AppComponent &#125; from './app.component';// NgModule指令实现数据的双向绑定@NgModule(&#123; imports: [ BrowserModule ], declarations: [ AppComponent ], bootstrap: [ AppComponent ]&#125;)export class AppModule &#123; &#125; AppComponent 组件AppComponent 组件会对html中的my-app标签进行渲染，返回template中指定的元素。 以下是AppComponent组件的声明 12345678910// src/app/app.component.tsimport &#123; Component &#125; from '@angular/core';// 通过 Component 装饰器和自定义组件类来创建自定义组件@Component(&#123; // 定义组件的元信息 selector: 'my-app', // 用于定义组件在HTML代码中匹配的标签 template: `&lt;h1&gt;Hello &#123;&#123;name&#125;&#125;&lt;/h1&gt;`, // 定义组件内嵌视图。利用 &#123;&#123;&#125;&#125; 插值表达式实现数据绑定。这是单向绑定吧？ // 双向绑定：&lt;input [(ngModel)]=\"todo.text\"&gt;&#125;)// 定义组件类export class AppComponent &#123; name = 'Angular'; &#125; 其中变量是在浏览器端渲染。 值得注意的是这里的template。Angular模板基于双向UI数据绑定。在模型改变时自动更新视图，以及在视图改变时自动更新模型。其HTML模板在浏览器中编译。比如这里的&lt;h1&gt;Hello &lt;/h1&gt;。 工作流程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&#123; \"name\": \"angular-quickstart\", \"version\": \"1.0.0\", \"description\": \"QuickStart package.json from the documentation, supplemented with testing support\", \"scripts\": &#123; \"build\": \"tsc -p src/\", # 采用的tsc编译器，node自带的ts编译器。也可以采用webpack， \"build:watch\": \"tsc -p src/ -w\", \"build:e2e\": \"tsc -p e2e/\", # end-to-end tests. \"serve\": \"lite-server -c=bs-config.json\", # 轻量级node静态文件服务器，默认会读取当前目录下的bs-config.js或者bs-config.json文件做为配置导入 \"serve:e2e\": \"lite-server -c=bs-config.e2e.json\", \"prestart\": \"npm run build\", \"start\": \"concurrently \\\"npm run build:watch\\\" \\\"npm run serve\\\"\", # runs the compiler and a server at the same tim \"pree2e\": \"npm run build:e2e\", \"e2e\": \"concurrently \\\"npm run serve:e2e\\\" \\\"npm run protractor\\\" --kill-others --success first\", \"preprotractor\": \"webdriver-manager update\", \"protractor\": \"protractor protractor.config.js\", \"pretest\": \"npm run build\", \"test\": \"concurrently \\\"npm run build:watch\\\" \\\"karma start karma.conf.js\\\"\", \"pretest:once\": \"npm run build\", \"test:once\": \"karma start karma.conf.js --single-run\", \"lint\": \"tslint ./src/**/*.ts -t verbose\" &#125;, \"keywords\": [], \"author\": \"\", \"license\": \"MIT\", \"dependencies\": &#123; \"@angular/common\": \"~4.3.4\", \"@angular/compiler\": \"~4.3.4\", \"@angular/core\": \"~4.3.4\", \"@angular/forms\": \"~4.3.4\", \"@angular/http\": \"~4.3.4\", \"@angular/platform-browser\": \"~4.3.4\", \"@angular/platform-browser-dynamic\": \"~4.3.4\", \"@angular/router\": \"~4.3.4\", \"angular-in-memory-web-api\": \"~0.3.0\", \"systemjs\": \"0.19.40\", \"core-js\": \"^2.4.1\", \"rxjs\": \"5.0.1\", \"zone.js\": \"^0.8.4\" &#125;, \"devDependencies\": &#123; \"concurrently\": \"^3.2.0\", \"lite-server\": \"^2.2.2\", \"typescript\": \"~2.1.0\", \"canonical-path\": \"0.0.2\", \"tslint\": \"^3.15.1\", \"lodash\": \"^4.16.4\", \"jasmine-core\": \"~2.4.1\", \"karma\": \"^1.3.0\", \"karma-chrome-launcher\": \"^2.0.0\", \"karma-cli\": \"^1.0.1\", \"karma-jasmine\": \"^1.0.2\", \"karma-jasmine-html-reporter\": \"^0.2.2\", \"protractor\": \"~4.0.14\", \"rimraf\": \"^2.5.4\", \"@types/node\": \"^6.0.46\", \"@types/jasmine\": \"2.5.36\" &#125;, \"repository\": &#123;&#125;&#125; 疑问 这个project，如何不依赖node，直接双击在浏览器运行？ 这里的是绑定的js中写死的静态变量。如何绑定后台的一个动态变量？ 其他angular入门教程 首推教程 Angular 2 教程 http://www.runoob.com/angularjs2/angularjs2-tutorial.html 可直接双击html执行 Angular 4 教程 https://www.w3cschool.cn/angular/","tags":[{"name":"angular","slug":"angular","permalink":"http://yoursite.com/tags/angular/"},{"name":"front-end","slug":"front-end","permalink":"http://yoursite.com/tags/front-end/"},{"name":"前端架构","slug":"前端架构","permalink":"http://yoursite.com/tags/前端架构/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"framework","slug":"CS/web/front-end/framework","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/"},{"name":"Angular","slug":"CS/web/front-end/framework/Angular","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/Angular/"}]},{"title":"【Angular系列】 基本概念","date":"2018-03-25T16:00:00.000Z","path":"wiki/CS/web/front-end/framework/Angular/angular2-basic/","text":"运行环境由于目前各种环境（浏览器或 Node）暂不支持ES6的代码，所以需要一些shim和polyfill（IE需要）让ES6写的代码能够转化为ES5形式并可以正常运行在浏览器中。 从上图可以看出在 Es5 浏览器下需要以下模块加载器： systemjs - 通用模块加载器，支持AMD、CommonJS、ES6等各种格式的JS模块加载。 es6-module-loader - ES6模块加载器，systemjs会自动加载这个模块。 traceur - ES6转码器，将ES6代码转换为当前浏览器支持的ES5代码，systemjs会自动加载 这个模块。 组件和模块的区别组件(Component)和模块(Module)又是一对容易混淆的名词，也常常被用来相互替换。 模块模块相当于是一个namespace，或者package，表示的是一堆功能单元的集合。 Angular应用都是模块化的， 命名空间：在JavaScript中，最高级别的函数外定义的变量都是全局变量（这意味着所有人都可以访问到它们）。也正因如此，当一些无关的代码碰巧使用到同名变量的时候，我们就会遇到“命名空间污染”的问题。 可维护性：命名空间的隔离实现了每个模块的独立性。良好设计的模块会尽量与外部的代码撇清关系，以便于独立对其进行改进和维护。可复用性也好 组件一般来说，一个组件就是一个用于控制视图模板的JavaScript类。 从设计上来看，组件强调复用，模块强调职责(内聚、分离)，或者说组件是达到可复用要求的模块。 习题原生javascript(ES5)不支持模块化，类难道不起到了隔离作用吗？原生JavaScript并不支持类，虽然最新的ES6里引入了Class不过还不普及。 没有内置的模块化系统，可以使用第三方模块系统。 疑问，angular4 是否有cdn？cdn只看到了1 和 2。 参考JavaScript 模块化入门Ⅰ：理解模块","tags":[{"name":"angular","slug":"angular","permalink":"http://yoursite.com/tags/angular/"},{"name":"front-end","slug":"front-end","permalink":"http://yoursite.com/tags/front-end/"},{"name":"前端架构","slug":"前端架构","permalink":"http://yoursite.com/tags/前端架构/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"framework","slug":"CS/web/front-end/framework","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/"},{"name":"Angular","slug":"CS/web/front-end/framework/Angular","permalink":"http://yoursite.com/categories/CS/web/front-end/framework/Angular/"}]},{"title":"2018 - 中美贸易战","date":"2018-03-24T16:00:00.000Z","path":"wiki/others/economy/2018-中美贸易战/","text":"背景据中方统计，最近10年间美国对中国出口年均增长11%，几乎是同期中国对美国出口年均增速的两倍。美国62%的大豆、14%的棉花、25%的波音飞机、17%的汽车、15%的集成电路都出口到中国。 而据美国官方数据，2016年中国是美国农产品第二大出口市场；每个美国农民平均向中国出口农产品约1.2万美元。 时间线 宣战 回应 结束，中国提出把部分从韩国和台湾采购的半导体转而向美国购买，以减少中国对美国的贸易顺差 2018-04-16: 美国商务部下令禁止美国公司向中兴出售元器件等产品，为期7年 如何评价 2018 年 4 月中兴通讯同时遭英美两国制裁？| 知乎 华为年底退出美国市场 2018.04.25，据《华尔街日报》消息称，美国司法部正在对华为是否违反了美国对伊朗的制裁规定进行调查除了中兴、华为外，特朗普还准备对阿里下手了！阿里在美国提供的云端运算服务可能会被禁止。 2018.06.15 美国发布了加征关税商品清单，将对从中国进口的约500亿美元商品加征25%的关税 2018.06.19 特朗普通过白宫发布声明，“考虑对额外2000亿美元的中国商品加征10%的关税。如果中国仍拒绝改变其贸易行为，美国将在法律程序完成后正式对这批中国商品开证关税。此外，如果中国再次出台对等措施，还将考虑再对2000亿美元的中国商品征税。” 4500亿美元的商品占对美出口的90% 2018.06.19 中国A股暴跌，千股跌停。黑色星期二。暴跌的主要原因就是今早7点半，特朗普的白宫声明 2018.06.19 商务部发表声明：如果美方失去理性，中方将不得不采取数量型和质量型相结合的综合措施，做出强有力的反制。因为美国对华出口额仅1300亿，因此提出来质量型 2018.7.6 经国务院批准，对原产于美国的659项约500亿美元进口商品加征25%的关税。主要包括 牛猪鸡鸭鱼虾蟹、植物、越野车小汽车、化学医疗等。美方发表声明称，如果中国采取报复性措施，美国将继续追加额外关税。 中美贸易领域贸易战这个东西我觉得要考虑双方的进出口情况：美国：进口的主要是日常消费品，比如服装、玩具等，数量规模大，和老百姓生活相关度高，打贸易战会造成美国人民日常消费成本大幅度增加，会造成美国人民反对该政策； 出口的主要是粮食作物和芯片等技术类产品，会造成部分高科技公司的收入减少，部分农业受到冲击，鉴于美国农业的大规模种植水平，受到影响的人不会太多。中国：进口粮食（主要是大豆），食用油价格预期会上涨，芯片类科技产品推进国产化，这点题主已经提到了，台湾很可能会跟着美国走，所以电子产品预计会价格上涨； 出口的日常消费品受影响这方面才是危险的，因为失掉美国市场后，过剩产能如果不能及时消化，会造成上述行业大量的滞销、停产以及人员失业，这个影响的人会很多，国民收入减少会导致内需萎缩，对国内经济冲击会比较大。 依赖性分析 中国是美国飞机和大豆的第一大出口市场，也是汽车和棉花的第二大出口市场 中美贸易逆差 以往，中国的集成电路主要从韩国、日本和中国台湾进口，也正因此，在中国与多国的双边贸易中，韩国、日本与中国台湾是难得的几个与中国大陆保持顺差纪录的地区。 宣战美国总统特朗普当地时间22日中午在白宫签署针对中国的总统备忘录，宣布基于“301调查”结果，将对约600亿美元进口自中国的商品加征关税，并对中资投资美国设限等。 中国随即作出回应。中国驻美大使馆发表声明说，中方不希望打贸易战，但绝不惧怕贸易战，有信心、有能力应对任何挑战。如果美方执意要打，我们将奉陪到底，并采取所有必要措施坚决捍卫自身合法权益。 几个小时后，中国商务部公布针对美国进口钢铁和铝产品232措施的中止减让产品清单，拟对约30亿美元自美进口商品加征关税。 针对美国特朗普总统指责中国，“窃取美国知识产权和技术”等，崔大使回应：美国应该意识到，现在世界变化了。很多国家都在发展创新。如果美国觉得技术都是自己一家的，这种态度就是“歧视他国”，是无知的表现。 美国想干什么川普究竟是谈判策略还是真要打一场贸易战？贸易战是个杀敌一千自损八百的手段。 想捞点钱- 这次贸易战开打，结果必是中国忍痛让美国剪点羊毛 中国底气如何 底气之一，在于中国有巨大的市场 底气之二，在于中国承受损失的能力更强。 屠新泉称，贸易战关键的不是损失，而是承受损失的能力。“中国承受损失的能力强于美国。” 中国能打什么牌第一张牌，是限制进口美国商品。 限制进口美国农产品和高端制成品将是中国的一大“王牌”。 完整清单 - 中国拟对这些美国进口产品加征关税 囧，中国并未对美国高端产品加税吧。。。 中国目前对美国的反击，从比例上看，是选择了一个比较不痛不痒的点，谈不上是正儿八经的回击，更像是一种姿态。 第二张牌，是削减对美国出口。影响美国当地时间3月22日，在特朗普宣布对华贸易限制措施之后，资本市场出现恐慌，美国股市暴跌。 # 美国之前制裁中兴，理由是中兴向伊朗出售美国技术，双方后来达成和解，但中兴需要支付约 8.9 亿美元的刑事和民事罚金。此次，美方封杀中兴的理由是其没有严格履行和解协议，只解雇了四名高级雇员，未处罚或减少35名员工奖金，这就是所谓的“实锤”。 网评川普贸易战醉翁之意不在酒德媒指出，美国总统特朗普的关税举措首要打击目标并非中国。特朗普需要对中国做出威胁姿态，以不失去自己选民的支持。特朗普迄今宣布的对铝和钢的惩罚性措施的首要打击目标并非中国，而是巴西或日本。 看不懂系列 xon：对推动中国进一步开放是有利的，但被某些利益集团绑架的话，会使中国重走日本80年代末的老路…… xon：此次贸易战的起因是中国不遵循WTO承诺，可以对比一下，如果真正实现WTO承诺，对普通老百姓是不是有利的。未兑现的WTO承诺所保护的车企、银行、石化、医药、通讯、旅游、教育、出版物等等。都是大型国有企业盘踞的、普通老百姓怨声载道的方面。 不错，嗟，来食 说出这种话的人，不是权贵就是奴才… xon：如果当年谈判不是授权外让步，就会小概率出现如今的被动；如果当年可以不中断“十五年”的渐进式开放就不会出现如今所担忧的开闸式冲击。换句话说造成如今的局面完全是被某些金字塔顶端的人耽搁了… 有些现在才开始开放的领域（需要被保护），其实可以早一些开放？ xon：1. 有些行业可以不开放，当年入世谈判时并未被授权，当年某位谈判领导会上临时决定的。2、许诺开放的行业里在“十五年”内是在采取渐进式开放的，譬如铁道部转铁路总公司、土地“以租代征”合法化等等都是这一过程的重要节点。但是某大的换届换思路后就嘎然而止了…… 如今的被动不是外界强加给我们的，完全可以说是自己折腾的… ## | 知乎如何看待 2018 年中美贸易战打响？ | 知乎","tags":[],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"economy","slug":"others/economy","permalink":"http://yoursite.com/categories/others/economy/"}]},{"title":"javascript与typescript的对比","date":"2018-03-24T16:00:00.000Z","path":"wiki/CS/web/front-end/typescript/js和ts的区别/","text":"https://www.zhihu.com/question/25421196 js做不到的事情指的是 1：搞面向对象巨方便 2：可选的强类型可以让你在程序运行之前多发现一些错误 3：为IDE给javascript弹智能提示打下了良好的基础 除了语法糖，ts最大的特点应该是静态类型， 包括ts里类的public protected private 也只是做静态类型检查用， TypeScript 总体来讲最重要的在于 Scalable.如果只是写个两三千行的脚本 TypeScript 并不是那么重, 但如果是五六千行, 甚至是数万行, TypeScript 的优势就能发挥出来了. 至于 TypeScript 是 Scalable 的原因, 其实也很简单, 静态类型检查, 代码重构和语言服务. 这些都是 JavaScript 的弱势. 项目大了, 很多时候自己的代码怎么用都记不清楚, 当然第三发的类库就不用说了. 用了 TypeScript, 可以看清楚每一个对象的属性, 方法的参数等, 便利很多. TypeScript不是 语法上的ECMA6实现，而是以JavaScript为目标语言的，一种编译语言，并且提供向原生JavaScript转换的编译器；而Google的Traceur项目应该才算是ECMA6的语法上实现。 #","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"typescript","slug":"CS/web/front-end/typescript","permalink":"http://yoursite.com/categories/CS/web/front-end/typescript/"}]},{"title":"Webpack简介","date":"2018-03-24T16:00:00.000Z","path":"wiki/CS/web/front-end/前端构建工具/webpack/webpack/","text":"简介Webpack这个工具可以将你的所有代码和可选择地将依赖捆绑成一个单独的 .js 文件。 安装12345678# 全局安装webpack$ npm install -g webpack# webpack 已经将 webpack 命令行相关的内容都迁移到 webpack-cli，所以除了 webpack 外，我们还需要安装 webpack-cli：$ npm install webpack-cli -D -g# 查看版本$ npx webpack --version 配置文件根目录下新建webpack.config.js webpack 打包1$ sh webpack 4 引入的，有俩种模式，development 与 production，默认为 production - 其实还有一个隐藏的 none 模式 参考https://github.com/chemdemo/chemdemo.github.io/issues/13Parcel Vs Webpack","tags":[{"name":"webpack","slug":"webpack","permalink":"http://yoursite.com/tags/webpack/"},{"name":"构建工具","slug":"构建工具","permalink":"http://yoursite.com/tags/构建工具/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"前端构建工具","slug":"CS/web/front-end/前端构建工具","permalink":"http://yoursite.com/categories/CS/web/front-end/前端构建工具/"},{"name":"webpack","slug":"CS/web/front-end/前端构建工具/webpack","permalink":"http://yoursite.com/categories/CS/web/front-end/前端构建工具/webpack/"}]},{"title":"webpack原理","date":"2018-03-24T16:00:00.000Z","path":"wiki/CS/web/front-end/前端构建工具/webpack/webpack原理/","text":"webpack是一个js打包工具，不是一个完整的前端构建工具。它的流行得益于模块化和单页应用的流行。webpack提供扩展机制，在庞大的社区支持下各种场景基本它都可找到解决方案。 webpack核心概念 entry 一个可执行模块或库的入口文件。Webpack 执行构建的第一步将从 Entry 开始 Module：模块，在 Webpack 里一切皆模块，一个模块对于着一个文件。Webpack 会从配置的 Entry 开始递归找出所有依赖的模块。 chunk 多个文件组成的一个代码块，例如把一个可执行模块和它所有依赖的模块组合和一个 chunk 这体现了webpack的打包机制。 loader 文件转换器，例如把es6转换为es5，scss转换为css。 plugin 插件，用于扩展webpack的功能，在webpack构建生命周期的节点上加入扩展hook为webpack加入功能。 Webpack 启动后会从 Entry 里配置的 Module 开始递归解析 Entry 依赖的所有 Module。每找到一个 Module 就会根据配置的 Loader 规则去找出对应的转换规则立即对 Module 进行转换后，再解析出当前 Module 依赖的 Module。这些模块会以 Entry 为单位进行分组，一个 Entry 和其所有依赖的 Module 被分到一个组也就是一个 Chunk。最后 Webpack 会把所有的 Chunk 转换成文件输出。在整个流程中 Webpack 会在恰当的时候执行 Plugin 里定义的逻辑。 webpack构建流程从启动webpack构建到输出结果经历了一系列过程，它们是： 解析webpack配置参数，合并从shell传入和webpack.config.js文件里配置的参数，生产最后的配置结果。 注册所有配置的插件，好让插件监听webpack构建生命周期的事件节点，以做出对应的反应。 从配置的entry入口文件开始解析文件构建AST语法树，找出每个文件所依赖的文件，递归下去。 在解析文件递归的过程中根据文件类型和loader配置找出合适的loader用来对文件进行转换。 递归完后得到每个文件的最终结果，根据entry配置生成代码块chunk。 输出所有chunk到文件系统。 需要注意的是，在构建生命周期中有一系列插件在合适的时机做了合适的事情，比如UglifyJsPlugin会在loader转换递归完后对结果再使用UglifyJs压缩覆盖之前的结果。 webpack原理 一切皆模块正如js文件可以是一个“模块（module）”一样，其他的（如css、image或html）文件也可视作模 块。因此，你可以require(‘myJSfile.js’)亦可以require(‘myCSSfile.css’)。这意味着我们可以将事物（业务）分割成更小的易于管理的片段，从而达到重复利用等的目的。 按需加载传统的模块打包工具（module bundlers）最终将所有的模块编译生成一个庞大的bundle.js文件。但是在真实的app里边，“bundle.js”文件可能有10M到15M之大可能会导致应用一直处于加载中状态。因此Webpack使用许多特性来分割代码然后生成多个“bundle”文件，而且异步加载部分代码以实现按需加载。 example示例文件 webpack.config.js123456789101112131415161718192021/** * @author: @AngularClass *//** * Look in ./config folder for webpack.dev.js */switch (process.env.NODE_ENV) &#123; case 'prod': case 'production': module.exports = require('./config/webpack.prod')(&#123;env: 'production'&#125;); break; case 'test': case 'testing': module.exports = require('./config/webpack.test')(&#123;env: 'test'&#125;); break; case 'dev': case 'development': default: module.exports = require('./config/webpack.dev')(&#123;env: 'development'&#125;);&#125; tsconfig.webpack.json12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; \"compilerOptions\": &#123; \"target\": \"es5\", \"module\": \"es2015\", \"moduleResolution\": \"node\", \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true, \"allowSyntheticDefaultImports\": true, \"sourceMap\": true, \"noEmit\": true, \"noEmitHelpers\": true, \"importHelpers\": true, \"strictNullChecks\": false, \"lib\": [ \"es2015\", \"dom\" ], \"baseUrl\": \".\", \"paths\": &#123; \"@angular/*\": [\"node_modules/@angular/*\"] &#125;, \"typeRoots\": [ \"node_modules/@types\" ], \"types\": [ \"hammerjs\", \"node\" ] &#125;, \"exclude\": [ \"node_modules\", \"client/dist\", \"client/src/**/*.spec.ts\", \"client/src/**/*.e2e.ts\" ], \"awesomeTypescriptLoaderOptions\": &#123; \"forkChecker\": true, \"useWebpackText\": true &#125;, \"angularCompilerOptions\": &#123; \"genDir\": \"./compiled\", \"skipMetadataEmit\": true &#125;, \"compileOnSave\": false, \"buildOnSave\": false, \"atom\": &#123; \"rewriteTsconfig\": false &#125;&#125; 参考https://github.com/gwuhaolin/blog/issues/4 深入浅出 Webpack ##","tags":[{"name":"webpack","slug":"webpack","permalink":"http://yoursite.com/tags/webpack/"},{"name":"构建工具","slug":"构建工具","permalink":"http://yoursite.com/tags/构建工具/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"前端构建工具","slug":"CS/web/front-end/前端构建工具","permalink":"http://yoursite.com/categories/CS/web/front-end/前端构建工具/"},{"name":"webpack","slug":"CS/web/front-end/前端构建工具/webpack","permalink":"http://yoursite.com/categories/CS/web/front-end/前端构建工具/webpack/"}]},{"title":"行政名词 扫盲","date":"2018-03-23T16:00:00.000Z","path":"wiki/others/politics/china/职位-机构-名词解释/","text":"“部”与“委员会”有何区别？ 简单理解：“部”是一颗颗珍珠，“委”则是串起这些珍珠的链子。前者具有单一职能，重在执行，后者主要在于协调，重在推进。 比如发改委，几乎涉及了国务院组成部门大部分部级单位的部分权力。 国务院组成部门、直属机构、办事机构、直属事业单位的区别？各级机构中，尤以国务院所属机构的名称特征更加明显，包括国务院组成部门、直属机构、办事机构，都能从名称上识别。 国务院直属特设机构，只有一个，如国资委。 国务院直属机构，共16个，如国家税务总局、工商总局、安监总局、统计局、林业局等。有办事机构，共4个，如侨务办、研究室等。 直属事业单位，共17个，如新华社、中科院、银监委员会、证监委员会、保监委员会等。 部委管理的局22个，如信访局、粮食局、能源局等，其中个别的叫委，如国家语言文字工作委员会。 国务院直属机构，不属于国务院级组成部门，其负责人不属于国务院全体会议的组成人员。在国务院直属机构中，没有部的称谓，但有委员会的称谓。直属机构中的正职负责人，有的是正部级，总局的应该都是，局的不是，可能还有就是局级待遇的。事业单位的正职，一般会是正部级。 https://www.zhihu.com/question/20838877/answer/16352524 省部级：“部”、“总局”、“总署” 一般都是正部级厅局级：司 局 区别国务院部门中，为何有的叫“部(委)”，有的叫“总局(局)”？司和局有什么区别？ 在国务院部门中，“司”和“局”虽然行政级别一样，但职能有所区别。 2012年4月，事业单位改革指导意见正式公布后，不少人发现，像中国气象局、中国证监会这些从名称上看似行政机构，实际也承担行政职能的单位，竟然也被归为事业单位。不过，他们或许能借这次改革，被划入行政序列。 每个中央机关，都有诸多内设机构，每个部门都有一个办公厅(室)。除此之外，党委部门如中组部、中宣部、统战部的其他内设机构一般都叫“局”。 国务院下属行政机构的内设机构一般叫“司”，但也还有少量的“局”，如广电总局下设十多个“司”，还有一个电影局，铁道部下设多个司，还有一个运输局。 在国务院部门中，“司”和“局”虽然在行政级别上是一样的，但在职能上有所区别，文化部一位退休的司级干部用他的自身经历，向南方周末记者说明这个差别。他所在的部门现在叫文化部艺术司，过去叫艺术局。 在他看来，“司”和“局”在业务上没有太大区别，但在对外协调上有所区别。原来的文化部艺术局，除了下设业务处室之外，还有党委、人事处、计划财务处，统筹文化部在京直属单位如国家京剧院、国家话剧院、国家美术馆等的人、财、物。但变成艺术司之后，就成了一个纯业务部门，对人、财、物的统筹工作，就上交由文化部相关部门负责。 另外一个变化是，文化部艺术局是可以直接对“外”的，可以直接向各省市的文化厅(局)直接发文。但改成艺术司以后，就不能直接发文了，如需要发文，只能是起草好之后，以文化部或文化部办公厅的名义对外发。 “国家”、“中国”、“中华”、“中央”，有何差别？在日常称呼中，人们一般喜欢将国务院部门简称为“国家××部(委)”，如“国家发改委”、“国家工商总局”。 但如果你去看机构全称，就会发现，不同部门的准确名称，开头几个字是不同的。有的开头是“中华人民共和国”，如中华人民共和国发展和改革委员会，有的开头却是“中国”，如中国气象局，有的开头又是“国家”，如国家工商行政管理总局。 这里，都有什么区别和讲究呢？ “名称的开头”，其实是个外行的说法，规范的说法是“区域名”。在中国，机构名称一般都由三个部分组成，分别是区域名、矢名和格级名。 以中华人民共和国外交部为例，“中华人民共和国”是它的区域名，表明它的管理范围和隶属关系；“外交”是它的矢名，表明工作内容；“部”是它的格级名，表明了它的级别规格。 目前国务院部门，分别组成部门、直属机构、办事机构、议事协调机构、事业单位等几类。一般来说，同类机构的区域名、格级名一致，能从名称大体判断的它的机构属性。 比如，区域名为“中华人民共和国”的，大多都是国务院组成部门，如中华人民共和国教育部、文化部、公安部等。国务院27个组成部门中，只有中国人民银行例外，区域名是“中国”。除了央行和审计署之外，组成部门的格级名都是“部”、“委”。 而国务院直属机构，区域名大多都是“国家”，如国家广电总局、国家旅游局、国家统计局。国务院15个直属机构中，唯有海关总署的区域名是“中华人民共和国”。这也是唯一一个区域名是“中华人民共和国”，但不是国务院组成部门的机构。国务院直属机构的格级名一般叫“局”、“总局”、“总署”。 此外，所有部委管理的国家局中，除了2008年机构改革后的中国民航局，其他局的区域名都是“国家”，如国家信访局、国家文物局。 国务院办事机构的区域名都是“国务院”，如国务院法制办、国务院研究室。 区域名为“中国”的国务院机构中，除了央行是国务院组成部门，其他都是国务院事业单位，如中国气象局、中国地震局、中国科学院、中国证监会等。事业单位中，还有少数区域名不是“中国”的，如国家电监会、国研中心等。 国务院系统之外，党委部门区域名一般都是“中央”，人大、政协也有各自的区域名，再有一类就是人民团体，一般而言，区域名为“中华”、“全国”的都是人民团体，如中华全国总工会、中华全国妇女联合会等。","tags":[{"name":"ss","slug":"ss","permalink":"http://yoursite.com/tags/ss/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"【读图识政治】国家机构中的新面孔 - 国家监察委员会","date":"2018-03-23T16:00:00.000Z","path":"wiki/others/politics/china/国家机构/国家监察机关/2018-国家监察委员会/","text":"这是标题 afda fad fad 监察委干嘛的，跟纪委有关系没？功能冲突不？国家监察委员会是中国特色的国家反腐败机构，这个机构将与中国国务院等机构并列为正国级单位。国家监察委员会或将与现在的中纪委合署办公。 扩展阅读监察委员会，国家机构中的新面孔｜长漫画 - 中央纪委国家监委网站","tags":[{"name":"宪法","slug":"宪法","permalink":"http://yoursite.com/tags/宪法/"},{"name":"国家监察委员会","slug":"国家监察委员会","permalink":"http://yoursite.com/tags/国家监察委员会/"},{"name":"国家机构改革","slug":"国家机构改革","permalink":"http://yoursite.com/tags/国家机构改革/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家机构","slug":"others/politics/china/国家机构","permalink":"http://yoursite.com/categories/others/politics/china/国家机构/"},{"name":"国家监察机关","slug":"others/politics/china/国家机构/国家监察机关","permalink":"http://yoursite.com/categories/others/politics/china/国家机构/国家监察机关/"}]},{"title":"【读图识政治】图解 党和国家机构改革2018","date":"2018-03-22T16:00:00.000Z","path":"wiki/others/politics/china/国家机构/2018-党和国家机构改革/","text":"前言2018年两会刚刚闭幕，中共中央周三（3月21日）公布《深化党和国家机构改革方案》，进一步加强党对政府的领导。 一、统一职权，消除政出多头 一位要求匿名的内地政治学者对BBC中文表示：“此次改革强化了党的集中、统一和全面领导，具体部署是从中共执政安全角度考虑，在一些比较重要的、事关执政安全的领域强化了党的领导，如意识形态、社会控制、干部监督管理等。 机构改革国务院学者们认为，此次党的机构改革进一步强化了共产党的领导，削弱了国务院的权力。 多个国务院机构被撤销，如监察部、国家预防腐败局、国家公务员局和国务院侨务办公室。许多新组建的委员会和小组将设于国务院部门内，比如中央全面依法治国委员会办公室设在司法部，中央审计委员会办公室设在审计署，中央教育工作领导小组秘书组设在教育部。 方案称，此次改革，“着眼于健全加强党的全面领导的制度”，“确保党的领导全覆盖，确保党的领导更加坚强有力”。 国务院正部级机构减少8个，副部级机构减少7个，除国务院办公厅外，国务院设置组成部门26个。 改革后的国务院组成部门为19个，相较过去的25个为少，其中民政部、 教育部、 民族事务委员会、文化部、水利部、农业部、卫生和计划生育部、 科学技术部、国家安全部、监察部、审计署、住房和城乡建设部，都有调整合并，而民政部、国家安全部、审计署等则被取消，相关职能被合并到其他的部委中。 财政 审计 意识形态领域让中宣部统一管理新闻出版和电影，意味着“今后大陆人能够读什么看什么听什么全部由中宣部来统一口径”； 国家新闻出版广电总局原本就是国家广电总局和新闻出版署合并组建的，这次改革又恢复了国家广电总局，兜了一大圈又回到原地。而且方案中没有明确新闻出版管理职能归谁，，还有待进一步明确。() 为何拆分国家新闻出版广电总局？为何把新闻出版可能会划给中宣部？ 中宣部原有职责是？ 中国共产党中央委员会宣传部（通称中共中央宣传部，简称中央宣传部、中宣部），是中共中央直属机构。主要职能是管理中国大陆出版审查体系、中共中央宣传工作以及监管中国大陆媒体和社会舆情舆论工作。中宣部的主要职能是管控意识形态、新闻出版甚至教育方针。 “报刊是党的宣传工具，党的喉舌。”“不许一切反革命分子有言论自由，而只允许人民内部有这种自由……禁止一切反革命分子用言论自由达到他们的反革命目的。”–维基百科wikipedia这样写会不会被查水表。 1998年朱镕基总理视察中央电视台，破例题写16个大字：“舆论监督，群众喉舌，政府镜鉴，改革尖兵。” 短短16个字，尽显真正的共产党、真正的共产党员，为人民服务，坚守人民立场的本色！ 以前记得课本上有这个，现在看来写这几个字很需要勇气啊。一个电视台，本来是中央喉舌，是政府管理下的部门，你让他成为政府镜鉴，这不是本末倒置吗？ 新闻出版广电总局 中宣部是党机构 - Marx Yongso?听过党政合署的消息吗，知道顺德改革吗？ - 清新脱俗财神爷党政合属但两个牌子 - Marx Yong中宣部是共产党的中央宣传部啊，不是政府机构 - 微小de工作 社会控制方面不再设立中央社会治安综合治理委员会及办公室，职责交由中央政法委承担； 干部监督方面成立国家监察委。中国通过国家监察法 “双规”办案走向合法。国家监察委将与纪委合署办公。由于针对的还是以公权力犯罪为主的案子，检察院的反贪污贿赂、反渎职侵权以及预防职务犯罪三个部门的职能及大部分人员都将被剥离出来，转移至新成立的监察部门。 去年10月，习近平在中共十九大报告中明确提出，监察人员将用留置取代“两规”措施。留置是指留置在特定场所交代问题。 “两规”是什么？为何引发争议？“两规”又称“双规”，是中共党纪检监察机关查办案件的一种特殊措施，要求有关人员在规定的时间、地点就案件所涉及的问题作出说明。这种措施长期以来一直遭到外界批评。 中国人民大学法学院教授韩大元曾撰文指出，从监察委的三个试点地区看，监察委员会与纪委虽属于两个机构，但由于主任是纪委书记担任，副主任由副书记兼任，实质上可能导致机构合一，成为党政高度合一的机关。 姜明安则称，党政合一以后可以提高效率，是国家治理能力的现代化。 至于监察委权力过大引发的谁来监督监察委的问题，姜明安对此比较乐观，他认为人大、监察委自身、检察院、公安都能从行动上对监察委进行监督。但上述要求匿名的律师认为，在现实中，人大不可能去审查监察委，“监察委只能靠自我监督”。 参考 http://www.bbc.com/zhongwen/simp/chinese-news-43451802 国家移民管理局针对出入境人口越来越多的局面，组建国家移民管理局。将公安部的出入境管理、边防检查职责整合，建立健全签证管理协调机制，组建国家移民管理局，由公安部管理。 退役军人事务部组建退役部不是为了向美国看齐，这几年来发生了些不让报道的非访事件（大规模），引起了大佬们的重视，原来那么多老士官退役后都得不到合理的安置。 - 赵十六 税将省级和省级以下国税地税机构合并，具体承担所辖区城内各项税收、非税收入征管等职责。国税地税机构合并后，实行以国家税务总局为主与省（区、市）人民政府双重领导管理体制。这意味着分税制实施二十多年后，又重回了之前国税地部合一的局面，这一改革对地方的深远影响，尚待观察 水利部水利部多了三峡工程和南水北调的管理权。 但三峡和南水北调都修建的差不多了，水利部很多权力都被分配到其他部委了，基本被瓜分 ss当局将国安部、国家保密局、国家密码管理局合并，组建“国家安全保密总局”（加挂中央国家安全保密委牌子）。各省设国安保密局、地市设立分局、县设办事处；各级国安保密部门实行省以下垂直管理，同时接受各级政府协调。换言之，国安部被取消。 科技部 哪些部门被加强或削弱了？加强： 审计署，将国家发展和改革委员会的重大项目稽查、财政部的中央预算执行情况和其他财政收支情况的监督检查、国务院国有资产监督管理委员会的国有企业领导干部经济责任审计和国有重点大型企业监事会的职责划入审计署。 科学技术部，吸收了国家外国专家局的职能 司法部，吸收了国务院法制办的职能 削弱 民政部，民政部的老龄工作、退役军人安置工作、优抚工作、救灾、医疗救助等重要职能均被划出 国家发改委，组织编制主体功能区规划职责划入自然资源部，应对气候变化和减排职责划入生态环境部，农业投资项目划入农业农村部，重大项目稽查划入审计署，价格监督检查与反垄断执法职责划入市场监管总局，药品和医疗服务价格管理职责划入国家医保局。但这些职责多为国家层面的职能，对地方发改委、发改局的职能，影响不大。 住房和城乡建设部，划出了城乡规划管理和风景名胜区管理职能 人力资源和社会保障部划出了城镇职工和城镇居民基本医疗保险、生育保险职责 商务部划出了经营者集中反垄断执法等职责，且基本上没有新增职责，都可以看成改革中的“输家”。 发改委没裁，但是被划掉了很多职能，算是不小的削弱 扩展阅读 深化党和国家机构改革 - 维基百科 深化党和国家机构改革方案动态图 - 人民日报 如何评价2013年国务院机构改革 - 知乎 如何评价2018《国务院机构改革方案》？ - 知乎","tags":[{"name":"国家机构","slug":"国家机构","permalink":"http://yoursite.com/tags/国家机构/"},{"name":"国家机构改革","slug":"国家机构改革","permalink":"http://yoursite.com/tags/国家机构改革/"},{"name":"国务院","slug":"国务院","permalink":"http://yoursite.com/tags/国务院/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"},{"name":"国家机构","slug":"others/politics/china/国家机构","permalink":"http://yoursite.com/categories/others/politics/china/国家机构/"}]},{"title":"【读图识政治】图解中国领导团队新阵容 & 主要行政机构 --2018","date":"2018-03-21T16:00:00.000Z","path":"wiki/others/politics/china/2018中国领导团队新阵容/","text":"看图今年全国两会适逢换届，至3月19日，国家机构和全国政协新领导层均已产生，中国领导团队的新阵容已组建完毕。 人民日报客户端根据两会报道和相关公开资料，梳理绘制了一张中国领导团队新阵容思维导图 职责 分工中国领导团队，有三大分支：党、人大、政协。党选举党内领导，人大选举国家领导，政协包括各党派。一般每个分支的大boss都是政治局常委。 李克强：国务院总理 (中央人民政府) 栗战书：人大委员长 汪洋：政协主席 王沪宁：中央书记处书记，主管意识形态。 上一任刘云山 &lt;!– 王沪宁毕业后在一直中央政策研究室从事纯理论工作，一干就是二十年，“清水衙门”。 王沪宁直接参与、起草了江泽民“三个代表”重要思想、胡锦涛“科学发展观”以及习近平“新时代中国特色社会主义思想”等重大政治理论与思想，辅佐了三代总书记，是中共高层的重要理论智囊。 王沪宁有元老们的认同支持。江曾力挺，胡锦涛也有好感 栗战书、王沪宁主导了2018宪法修正案。 他是继邓力群之后，又一位理论界人士担任中央书记处书记职务。 王沪宁代表当前最高意识形态，拥有“习近平思想”解释权。–&gt; 赵乐际：纪委书记 韩正：国务院副总理 (原上海市委书记) 党2017年10月25，中共19大 选举，党内领导。 人大13届全国人大，选举国家领导。 政协2018年3月14日，第13届全国人民政治协商会议，选举政协领导。 汇总 排名 肖像姓名 党职 公职 分工 1 习近平 中共中央总书记中共中央军委主席 国家主席中央军委主席 中央国家安全委员会主席中央全面深化改革委员会主任中央全面依法治国委员会主任中央财经委员会主任中央外事工作委员会主任中央对台工作领导小组组长中央网络安全和信息化委员会主任中央军委深化国防和军队改革领导小组组长中央军委联合作战指挥中心总指挥中央军委联合作战指挥中心总指挥中央军民融合发展委员会主任 2 李克强 中共中央政治局常委国务院党组书记 国务院总理 中央国家安全委员会副主席中央全面深化改革委员会副主任中央财经委员会副主任中央机构编制委员会主任国家国防动员委员会主任国家能源委员会主任中央网络安全和信息化委员会副主任中央军民融合发展委员会副主任 3 栗战书 中共中央政治局常委全国人大常委会党组书记 全国人大常委会委员长 中央国家安全委员会副主席中央港澳工作协调小组组长 4 汪 洋 中共中央政治局常委全国政协党组书记 全国政协主席 中央西藏工作协调小组组长中央新疆工作协调小组组长中央对台工作领导小组副组长 5 王沪宁 中共中央政治局常委中央书记处书记中央文明委主任中央政策研究室主任 中央全面深化改革委员会副主任中央宣传思想工作领导小组组长中央党的建设工作领导小组组长中央党的群众路线教育实践活动领导小组组长中央机构编制委员会副主任中央网络安全和信息化委员会副主任中央财经委员会成员中央军民融合发展委员会副主任 6 赵乐际 中共中央政治局常委中共中央纪委书记 中央党的建设工作领导小组副组长中央巡视工作领导小组组长中央深化国家监察体制改革试点工作领导小组组长 7 韩 正 中共中央政治局常委国务院党组副书记 国务院副总理 中央全面深化改革委员会副主任国家能源委员会副主任国务院食品安全委员会主任中央财经委员会成员中央军民融合发展委员会副主任兼办公室主任 变动续期七大常委 习近平 李克强 其他5个都是新晋常委 原常委 王岐山 -&gt; 副主席 (2017年10月，中共十九大后，王岐山不再担任中央委员会和中纪委领导职务。)王岐山在党内排名第八位，在副总理韩正之后，仅次于七位政治局常委 对比以下链接 中国官员级别–2013 疑问中央军委是党的会议选举的吧？怎么也挂在人民代表大会下面？ 网评五年前，习近平和李克强双接班，人们按照先前的江朱体制和胡温体制的说法，称之为习李体制。但人们很快就发现，没有什么习李体制，李克强这个国务院总理的地位远远比不上先前的朱镕基和温家宝；倒是政治局常委名列第六的王岐山更重要，俨然习王体制。现在，王岐山将出任国家副主席，必将是中共建政以来权力最大的副主席。","tags":[{"name":"国家领导","slug":"国家领导","permalink":"http://yoursite.com/tags/国家领导/"},{"name":"两会","slug":"两会","permalink":"http://yoursite.com/tags/两会/"},{"name":"国家机构","slug":"国家机构","permalink":"http://yoursite.com/tags/国家机构/"},{"name":"国家机构改革","slug":"国家机构改革","permalink":"http://yoursite.com/tags/国家机构改革/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"Github Pages示例网站","date":"2018-03-21T16:00:00.000Z","path":"wiki/CS/web/建站/host/github-pages/examples/","text":"pytorch.orghttp://pytorch.org 搭建在github pages上。对应 pytorch.github.io 1234567891011121314151617181920$ dig pytorch.org; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; pytorch.org;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 32725;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4000;; QUESTION SECTION:;pytorch.org. IN A;; ANSWER SECTION:pytorch.org. 3323 IN A 185.199.108.153;; Query time: 82 msec;; SERVER: 192.168.16.101#53(192.168.16.101);; WHEN: Tue Oct 23 13:34:25 CST 2018;; MSG SIZE rcvd: 56 http://pytorch.org/tutorials 站点对应 https://github.com/pytorch/tutorials https://discuss.pytorch.org/ 则需要必须要借助后台服务器，因此是独立的主机名 国内测速，，都超时。百度收录2个网页 http://tool.chinaz.com/dns/ dns测速，都不通 测速有毛病吧，我手机都能连上 hexo.iohexo.io 采用的美国 CloudFlare公司CDN节点，外加CloudFlare的SSL证书 Issued by: Let’s Encrypt Authority X3 1234567891011121314151617181920$ dig hexo.io; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; hexo.io;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 12407;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4000;; QUESTION SECTION:;hexo.io. IN A;; ANSWER SECTION:hexo.io. 16 IN A 206.189.89.118;; Query time: 108 msec;; SERVER: 192.168.16.101#53(192.168.16.101);; WHEN: Tue Oct 23 13:36:21 CST 2018;; MSG SIZE rcvd: 52 百度仅收录了 https://hexo.io/zh-cn/ 目录。如何做到的 scikit-image.org 信息等价站点: https://scikit-image.github.iogithub pages项目: https://github.com/scikit-image/scikit-image.github.com网站源码: https://github.com/scikit-image/scikit-image-webhttps证书Issued by: Let’s Encrypt Authority X3Signature Algorithm: SHA-256 with RSA Encryption ( 1.2.840.113549.1.1.11 )Public Key Algorithm: RSA Encryption ( 1.2.840.113549.1.1.1 ) 采用的rst (ReStructuredText)格式 疑问采用jekyll模板吗？DNS解析为什么没有CNAME记录？ DNS分析 1234567891011121314151617181920212223$ dig scikit-image.org; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; scikit-image.org;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 44723;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4000;; QUESTION SECTION:;scikit-image.org. IN A;; ANSWER SECTION:scikit-image.org. 1678 IN A 185.199.108.153scikit-image.org. 1678 IN A 185.199.109.153scikit-image.org. 1678 IN A 185.199.110.153scikit-image.org. 1678 IN A 185.199.111.153;; Query time: 50 msec;; SERVER: 192.168.16.101#53(192.168.16.101);; WHEN: Tue Oct 23 13:26:48 CST 2018;; MSG SIZE rcvd: 109 scrapy.org采用jekyll模板 网站源码: https://github.com/scrapy/scrapy.org","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"},{"name":"github-pages","slug":"CS/web/建站/host/github-pages","permalink":"http://yoursite.com/categories/CS/web/建站/host/github-pages/"}]},{"title":"为静态网站提供动态服务之 统计模块","date":"2018-03-20T16:00:00.000Z","path":"wiki/CS/web/建站/plugin-for-static-site/统计模块/","text":"汇总 对比site_uv 是指访问的用户个数，一个IP记一次，多次访问不累加site_pv 是网站访问次数，多次访问累加page_pv 是文章点击次数，多次访问累加 google统计 百度统计 Leancloud.cn 不蒜子 特点 功能繁杂 轻量级，无需注册，两行代码 要注册 功能 pv uv 速度 对比不蒜子的js放在七牛，速度应该不慢，如果说速度慢，可能是七牛的原因， 初始化首次数据初始化首次数据无非就两种方式 修改服务器的数据库数据 (多数不提供该服务，因为随意篡改数据就失去了数据权威性) 仅更改本网站的显示 (so easy，也可以理解成自己欺骗自己) 首先看方式二：以不蒜子为例 在html中引入以下js1234567891011121314&lt;!-- 修正不蒜子计数初始值 --&gt; &lt;script &gt; $(document).ready(function() &#123; var int = setInterval(fixCount, 50); // 50ms周期检测函数 var countOffset = 20000; // 初始化首次数据 function fixCount() &#123; if ($(\"#busuanzi_container_site_pv\").css(\"display\") != \"none\") &#123; $(\"#busuanzi_value_site_pv\").html(parseInt($(\"#busuanzi_value_site_pv\").html()) + countOffset); // 加上初始数据 clearInterval(int); // 停止检测 &#125; &#125; &#125;); &lt;/script&gt; 这里的方法是改给自己看，并未改动busuanzi的数据库。 方式一，看各家提供的接口咯 不蒜子的方式 “不蒜子”与百度统计谷歌分析等有区别：“不蒜子”可直接将访问次数显示在您在网页上（也可不显示）；对于已经上线一段时间的网站，“不蒜子”允许您初始化首次数据。请先注册登录，自行修改阅读次数。— 来自不蒜子官网 然而，至今不蒜子尚未提供注册服务(2018年3月)，也就是不蒜子暂时也不提供 修改统计数据的接口。 实际上并未改初始化首次数据的方式。因为 单独介绍不蒜子“不蒜子”是通过页面url（或者主机名神马的）来标识一个计数值，而像localhost、index.html这样的名字早已经被像我们一样的广大程序猿在测试时用烂了，自然就累计了好多次","tags":[{"name":"静态网站","slug":"静态网站","permalink":"http://yoursite.com/tags/静态网站/"},{"name":"插件","slug":"插件","permalink":"http://yoursite.com/tags/插件/"},{"name":"动态服务","slug":"动态服务","permalink":"http://yoursite.com/tags/动态服务/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"plugin-for-static-site","slug":"CS/web/建站/plugin-for-static-site","permalink":"http://yoursite.com/categories/CS/web/建站/plugin-for-static-site/"}]},{"title":"javascript的正则表达式","date":"2018-03-20T16:00:00.000Z","path":"wiki/CS/web/front-end/js/regular-expression/","text":"简介匹配到的字符串 字符 替换文本 $&amp; 与正则相匹配的字符串 $` 匹配字符串左边的字符 $’ 匹配字符串右边的字符 $1,$2,$3,…,$n 匹配结果中对应的分组匹配结果 回调函数匹配的正则表达式 字符 含义 \\ 匹配将依照下列规则：在非特殊字符之前的反斜杠表示下一个字符是特殊的，不能从字面上解释。例如，没有前面’\\’的’b’通常匹配小写’b’，无论它们出现在哪里。如果加了’\\’,这个字符变成了一个特殊意义的字符，意思是匹配一个字符边界。反斜杠也可以将其后的特殊字符，转义为字面量。例如，模式 /a/ 代表会匹配 0 个或者多个 a。相反，模式 /a\\/ 将 ‘‘ 的特殊性移除，从而可以匹配像 “a“ 这样的字符串。使用 new RegExp(“pattern”) 的时候不要忘记将 \\ 进行转义，因为 \\ 在字符串里面也是一个转义字符。 ^ 匹配输入的开始。如果多行标志被设置为true，那么也匹配换行符后紧跟的位置。例如，/^A/ 并不会匹配 “an A” 中的 ‘A’，但是会匹配 “An E” 中的 ‘A’。当 ‘^’ 作为第一个字符出现在一个字符集合模式时，它将会有不同的含义。补充字符集合 一节有详细介绍和示例。 $ 匹配输入的结束。如果多行标示被设置为true，那么也匹配换行符前的位置。例如，/t$/ 并不会匹配 “eater” 中的 ‘t’，但是会匹配 “eat” 中的 ‘t’。 * 匹配前一个表达式0次或多次。等价于 {0,}。例如，/bo*/会匹配 “A ghost boooooed” 中的 ‘booooo’ 和 “A bird warbled” 中的 ‘b’，但是在 “A goat grunted” 中将不会匹配任何东西。 + 匹配前面一个表达式1次或者多次。等价于 {1,}。例如，/a+/匹配了在 “candy” 中的 ‘a’，和在 “caaaaaaandy” 中所有的 ‘a’。 ? 匹配前面一个表达式0次或者1次。等价于 {0,1}。例如，/e?le?/ 匹配 “angel” 中的 ‘el’，和 “angle” 中的 ‘le’ 以及”oslo’ 中的’l’。如果紧跟在任何量词 *、 +、? 或 {} 的后面，将会使量词变为非贪婪的（匹配尽量少的字符），和缺省使用的贪婪模式（匹配尽可能多的字符）正好相反。例如，对 “123abc” 应用 /\\d+/ 将会返回 “123”，如果使用 /\\d+?/,那么就只会匹配到 “1”。还可以运用于先行断言，如本表的 x(?=y) 和 x(?!y) 条目中所述。 . （小数点）匹配除换行符之外的任何单个字符。例如，/.n/将会匹配 “nay, an apple is on the tree” 中的 ‘an’ 和 ‘on’，但是不会匹配 ‘nay’。 (x) 匹配 ‘x’ 并且记住匹配项，就像下面的例子展示的那样。括号被称为 捕获括号。模式/(foo) (bar) \\1 \\2/中的 ‘(foo)’ 和 ‘(bar)’ 匹配并记住字符串 “foo bar foo bar” 中前两个单词。模式中的 \\1 和 \\2 匹配字符串的后两个单词。注意 \\1、\\2、\\n 是用在正则表达式的匹配环节。在正则表达式的替换环节，则要使用像 $1、$2、$n 这样的语法，例如，’bar foo’.replace( /(…) (…)/, ‘$2 $1’ )。 (?:x) 匹配 ‘x’ 但是不记住匹配项。这种叫作非捕获括号，使得你能够定义为与正则表达式运算符一起使用的子表达式。来看示例表达式 /(?:foo){1,2}/。如果表达式是 /foo{1,2}/，{1,2}将只对 ‘foo’ 的最后一个字符 ’o‘ 生效。如果使用非捕获括号，则{1,2}会匹配整个 ‘foo’ 单词。 x(?=y) 匹配’x’仅仅当’x’后面跟着’y’.这种叫做正向肯定查找。例如，/Jack(?=Sprat)/会匹配到’Jack’仅仅当它后面跟着’Sprat’。/Jack(?=Sprat\\ Frost)/匹配‘Jack’仅仅当它后面跟着’Sprat’或者是‘Frost’。但是‘Sprat’和‘Frost’都不是匹配结果的一部分。 x(?!y) 匹配’x’仅仅当’x’后面不跟着’y’,这个叫做正向否定查找。例如，/\\d+(?!.)/匹配一个数字仅仅当这个数字后面没有跟小数点的时候。正则表达式/\\d+(?!.)/.exec(“3.141”)匹配‘141’但是不是‘3.141’ x y \\ 匹配‘x’或者‘y’。例如，/green\\ red/匹配“green apple”中的‘green’和“red apple”中的‘red’ {n} n是一个正整数，匹配了前面一个字符刚好发生了n次。比如，/a{2}/不会匹配“candy”中的’a’,但是会匹配“caandy”中所有的a，以及“caaandy”中的前两个’a’。 {n,m} n 和 m 都是整数。匹配前面的字符至少n次，最多m次。如果 n 或者 m 的值是0， 这个值被忽略。例如，/a{1, 3}/ 并不匹配“cndy”中的任意字符，匹配“candy”中得a，匹配“caandy”中的前两个a，也匹配“caaaaaaandy”中的前三个a。注意，当匹配”caaaaaaandy“时，匹配的值是“aaa”，即使原始的字符串中有更多的a。 [xyz] 一个字符集合。匹配方括号的中任意字符，包括转义序列。你可以使用破折号（-）来指定一个字符范围。对于点（.）和星号（*）这样的特殊符号在一个字符集中没有特殊的意义。他们不必进行转义，不过转义也是起作用的。例如，[abcd] 和[a-d]是一样的。他们都匹配”brisket”中得‘b’,也都匹配“city”中的‘c’。/[a-z.]+/ 和/[\\w.]+/都匹配“test.i.ng”中得所有字符。 [^xyz] 一个反向字符集。也就是说， 它匹配任何没有包含在方括号中的字符。你可以使用破折号（-）来指定一个字符范围。任何普通字符在这里都是起作用的。例如，[^abc] 和 [^a-c] 是一样的。他们匹配”brisket”中得‘r’，也匹配“chop”中的‘h’。 [\\b] 匹配一个退格(U+0008)。（不要和\\b混淆了。） \\b 匹配一个词的边界。一个词的边界就是一个词不被另外一个词跟随的位置或者不是另一个词汇字符前边的位置。注意，一个匹配的词的边界并不包含在匹配的内容中。换句话说，一个匹配的词的边界的内容的长度是0。（不要和[\\b]混淆了）例子：/\\bm/匹配“moon”中得‘m’；/oo\\b/并不匹配”moon”中得’oo’，因为’oo’被一个词汇字符’n’紧跟着。/oon\\b/匹配”moon”中得’oon’，因为’oon’是这个字符串的结束部分。这样他没有被一个词汇字符紧跟着。/\\w\\b\\w/将不能匹配任何字符串，因为一个单词中的字符永远也不可能被一个非词汇字符和一个词汇字符同时紧跟着。注意: JavaScript的正则表达式引擎将特定的字符集定义为“字”字符。不在该集合中的任何字符都被认为是一个断词。这组字符相当有限：它只包括大写和小写的罗马字母，小数位数和下划线字符。不幸的是，重要的字符，例如“é”或“ü”，被视为断词。 \\B 匹配一个非单词边界。他匹配一个前后字符都是相同类型的位置：都是单词或者都不是单词。一个字符串的开始和结尾都被认为是非单词。例如，/\\B../匹配”noonday”中得’oo’, 而/y\\B./匹配”possibly yesterday”中得’ye‘ \\cX 当X是处于A到Z之间的字符的时候，匹配字符串中的一个控制符。例如，/\\cM/ 匹配字符串中的 control-M (U+000D)。 \\d 匹配一个数字。等价于[0-9]。例如， /\\d/ 或者 /[0-9]/ 匹配”B2 is the suite number.”中的’2’。 \\D 匹配一个非数字字符。等价于[^0-9]。例如， /\\D/ 或者 /[^0-9]/ 匹配”B2 is the suite number.”中的’B’ 。 \\f 匹配一个换页符 (U+000C)。 \\n 匹配一个换行符 (U+000A)。 \\r 匹配一个回车符 (U+000D)。 \\s 匹配一个空白字符，包括空格、制表符、换页符和换行符。等价于[ \\f\\n\\r\\t\\v\\u00a0\\u1680\\u180e\\u2000-\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff]。例如, /\\s\\w*/ 匹配”foo bar.”中的’ bar’。 \\S 匹配一个非空白字符。等价于[^ \\f\\n\\r\\t\\v\\u00a0\\u1680\\u180e\\u2000-\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff]。例如， /\\S\\w*/ 匹配”foo bar.”中的’foo’。 \\t 匹配一个水平制表符 (U+0009)。 \\v 匹配一个垂直制表符 (U+000B)。 \\w 匹配一个单字字符（字母、数字或者下划线）。等价于[A-Za-z0-9_]。例如, /\\w/ 匹配 “apple,” 中的 ‘a’，”$5.28,”中的 ‘5’ 和 “3D.” 中的 ‘3’。 \\W 匹配一个非单字字符。等价于[^A-Za-z0-9_]。例如, /\\W/ 或者 /[^A-Za-z0-9_]/ 匹配 “50%.” 中的 ‘%’。 \\n 当 n 是一个正整数，一个返回引用到最后一个与有n插入的正则表达式(counting left parentheses)匹配的副字符串。比如 /apple(,)\\sorange\\1/ 匹配”apple, orange, cherry, peach.”中的’apple, orange,’ 。 \\0 匹配 NULL (U+0000) 字符， 不要在这后面跟其它小数，因为 \\0 是一个八进制转义序列。 \\xhh 与代码 hh 匹配字符（两个十六进制数字） \\uhhhh 与代码 hhhh 匹配字符（四个十六进制数字）。 参考 常用的JS正则表达式 | Github","tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://yoursite.com/tags/正则表达式/"},{"name":"javascript","slug":"javascript","permalink":"http://yoursite.com/tags/javascript/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"front-end","slug":"CS/web/front-end","permalink":"http://yoursite.com/categories/CS/web/front-end/"},{"name":"js","slug":"CS/web/front-end/js","permalink":"http://yoursite.com/categories/CS/web/front-end/js/"}]},{"title":"开源密码管理工具对比","date":"2018-03-19T16:00:00.000Z","path":"wiki/CS/tools/密码管理/summary/","text":"KeepPass KeepPassX LessPass clipperz Encryptr 备注 简介 keepass的山寨版，很弱 github-fork 代码由sourceforget-svn托管。老顽固拒绝github 535 106 121 121 submoduel的contributor是否算在主仓库中？ github-star 3613 2618 569 1480 github-contributor 29 10 9 7 github近期更新 ☆ ☆☆ ☆☆☆ ☆☆ ☆☆ 主仓库 主仓库即所有代码，C++ Qt客户端 shell backend python-django frontend vuejs + html cli nodejs desktop node + js 编译成windos、linux、max客户端 webextension 无 移动客户端 由第三方提供，并非开源。种类繁多，良莠不齐 同步 借助dropbox等第三方 主推功能 synchronize，多设备同步 模块化/组件化 也有很多plugin 基于nodejs，模块化很好 优点 比keepassx好用 1. C++看着吃力，python看着爽，nodejs也比较火 2. 多设备同步很重要3. 模块化很赞 老顽固拒绝githubhttps://sourceforge.net/p/keepass/discussion/329221/thread/97110c29/ 其他 LastPass（最大的优势是跨浏览器平台","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"密码管理","slug":"CS/tools/密码管理","permalink":"http://yoursite.com/categories/CS/tools/密码管理/"}]},{"title":"【读图识政治】图解中国官员级别--2013","date":"2018-03-19T16:00:00.000Z","path":"wiki/others/politics/china/2013中国官员级别/","text":"图来自政见网貌似被墙了 2005年4月27日通过的《公务员法》第十六条规定： 公务员职务分为领导职务和非领导职务。 领导职务层次分为：国家级正职、国家级副职、省部级正职、省部级副职、厅局级正职、厅局级副职、县处级正职、县处级副职、乡科级正职、乡科级副职。 国家副主席是国家级正职吧？No 2013年，中共十二届全国人大第一次会议上，李源潮顺利“当选”国家副主席，这使得李源潮成为中国政府约20年来首位非政治局常委的国家副主席，前一“非常”副主席是王震。令人们十分好奇的内容之一是，他在随后的5年时间里，更准确地说是他在2017年秋季召开中共十九大之前的这段时间里，到底会享受和7名政治局常委一样的“正国级”待遇，还是继续享受十八届中央领导集体内和他党内身份相同的其他政治局委员们共同享受的“副国级”待遇。 中共此前有明文规定，以下职位：中共中央总书记、中央政治局常委、国家主席、国务院总理、全国人大常委会委员长、全国政协主席、中央军委主席、国家副主席为正国家级别。因此，有观点认为，延续原来的惯例，现在在职的正国家领导有八位，7大常委 和国家副主席李源潮。 但也有观点认为，中国的国家主席一般是中央总书记，行政级别是是国家级，在这届李源潮之前近20年间，国家副主席均是政治局常委，属于党和国家领导人，其行政级别是国家级，但从今年开始，国家副主席不是政治局常委，而是政治局委员，因此，他的行政级别是副国级。 参考参考 “高级检察院” “中级检察院” 笑尿了","tags":[{"name":"官员级别","slug":"官员级别","permalink":"http://yoursite.com/tags/官员级别/"},{"name":"国家领导","slug":"国家领导","permalink":"http://yoursite.com/tags/国家领导/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"利用travis自动构建Gitbook静态页面，并自动部署到Github Page","date":"2018-03-19T16:00:00.000Z","path":"wiki/CS/tools/CI-持续集成/Travis CI/deploy-gitbook-with-travis-ci/","text":"目的实现 Gitbook - Github仓库 - Github Pages 三方同步。 修改Gitbook，实现 Github自动同步 + 自动部署静态页面到Github Pages 修改Github仓库，实现Gitbook自动同步 + 自动部署静态页面到Github Pages Gitbook自身已经实现了与Github仓库的同步，现在的问题是，如何实现自动部署静态页面到Github Pages。 当然有很多实现方式，这里我们介绍利用Travis CI自动部署Github Pages。 Travis CITravis CI原理就是当你每次提交commit到在github后，它会自动检测你的提交，同时根据的配置文件，生成一个Linux虚拟机来运行你的命令，通常这些命令用于测试，构建等。在我们的要求下，就可以用它运行一些hexo g d之类的命令来自动生成、部署我静态网页。 博客提交修改后push到github github通知travis ci项目需要构建 这里需要配置： travis ci立马安排构建 这里需要.travis.yml 构建完成后将结果push到github的gh-pages分支 这里需要github访问权限。即personal access token 把token设置到.travis.yml环境变量中，安全起见，最好加密 travis环境变量的定义与加密 vps利用git钩子将结果部署到web容器 123456$ npm install travis-encrypt -g$ travis-encrypt -r username/repository GH_TOKEN=[the token you created before] -a$ travis-encrypt -r ESbook/TCP-IP GH_TOKEN=6ad73f4597162bf335caaeef3e1138b77645dd5c -a# GH_TOKENXpJ36JE64TJCwGQ5ZxxWosn64Rhwq3OGOqNJhjKUyeGPlj9B+fNPAqBmP+YTLxB5nRpoLv5UsK62Qw15Of02iZcoO50H8qBrb2cWNEW3z2+Ih12JoeN5qJi4MTShT6ePbwH7Tvid27wosswuYH2+O4hvSQR13WwsHqCPDmzno6Zni+Unt8tya0etSkRqS81hKbHTItL0fOQiDpVIK2GrUioqPAbDV2TNBZfas8EENmSfZMRjHV6BYaOY/ZQg8qx3UuPSnGLU6pmiv9pcaiths4LNBoHb71+Rm87E+FffI6sHtmqrKn9NoW5sEsiiIAUusYQE5woQsn46+uc8lgjlx+1DGBxPstQwvTQNcu8HWzoN0lxlnIYMTWTj/aoUBmc90/Do1GPlpSP9/vONrU2ljfyfKlxxwbUdvHg8pvfU09QsWtTRAqfSjrH305nHOCPKWQgeYv0zbgTqRq/zKh5xTS+iaU6R+VscxFTCnktQaCG1oB6VMSBsU6YjvG5KcY7UZHiyF/fPTRFIH/LtT6iX9DpGlvc3NBb/mA4ERcEvMp/1Bgs7rqHVML+luhwKBwqeivilz0VRajK5JQxBmMeuJ4cDVt/yJuwGjf72chKa8Y909/iwAKm5wJ/FAEKvv7wl1aZJyOFdWEW6n/6u63+6VQy1YF/6aSodbkQcvO/o8qw=$ git remote add origin 'https://f6884617cab7ada45740e5034604e3e82e4ac722@github.com/ESbook/TCP-IP.git' 博客：http://blog.csdn.net/qq8427003/article/details/64921201 应用实例 https://github.com/8427003/book/blob/master/deploy-to-github.sh 实例&amp;博客：https://github.com/steveklabnik/automatically_update_github_pages_with_travis_example 博客：https://shawnho.me/2017/11/23/deploy-hexo-blog-with-travis-ci/ 疑问为什么要采用personal access token？为什么不采用ssh验证？HTTPS URLs和SSH URLs对应的是两套完全独立的权限校验方式，主要的区别就是HTTPS URLs采用账号密码进行校验，SSH URLs采用SSH秘钥对进行校验。 采用personal access token的方式来访问gitub，目的是代替密码输入。 如果要采用ssh，需要把travis主机的ssh key加入到github中。这样确实能够方便部署，免密码验证，但是存在风险。因为travis主机是很多人共用的，同一个主机加很多github的ssh会存在多账户权限风险。（我猜的）。即使每个github账号对应一个虚机或者docker，不方便多主机CDN。 为什么要travis encrypt？因为公开personal access token，就基本等同于公开github密码。任何人可以通过用户名+token获得github的相应权限，github中的项目有被恶意篡改，删除的风险。 travis encrypt对token进行加密，该密文仅travis能够识别。 ##","tags":[{"name":"travis","slug":"travis","permalink":"http://yoursite.com/tags/travis/"},{"name":"gitbook","slug":"gitbook","permalink":"http://yoursite.com/tags/gitbook/"},{"name":"自动化部署","slug":"自动化部署","permalink":"http://yoursite.com/tags/自动化部署/"},{"name":"持续集成","slug":"持续集成","permalink":"http://yoursite.com/tags/持续集成/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"CI-持续集成","slug":"CS/tools/CI-持续集成","permalink":"http://yoursite.com/categories/CS/tools/CI-持续集成/"},{"name":"Travis CI","slug":"CS/tools/CI-持续集成/Travis-CI","permalink":"http://yoursite.com/categories/CS/tools/CI-持续集成/Travis-CI/"}]},{"title":"Gitbook自动化部署到Github Pages的方案汇总","date":"2018-03-19T16:00:00.000Z","path":"wiki/CS/tools/formatting/gitbook/auto-deploy-to-GithubPages/","text":"采用shell命令 参考一：http://sangsoonam.github.io/2016/08/02/publish-gitbook-to-your-github-pages.html 参考二：https://tonydeng.github.io/gitbook-zh/gitbook-howtouse/publish/gitpages.html 参考三：http://yangjh.oschina.io/gitbook/UsingPages.html 封装成node module借鉴 hexo deploy命令 采用web hook这是 Github 提供的一种机制，使应用能与 Github 通讯。这种机制实际上就是 Pub/Sub，当 Github 监测到资源（如仓库）有变化就往预先设定的 URL 发送一个 POST 请求（Pub），告知变化情况，而后接收变化的服务器（Sub）即可做一些额外的事情。 这个思路需要有一个服务器并启动一个服务来接收 Github 的请求。这里又有种不同的策略，这两种策略都是基于源码放置在 Github 的前提。第一个是源码将最终文档直接部署在这台服务器上（如使用 Nginx），当接收到 Github 通知直接编译更新到服务器指定的文件夹下即可。另一种策略是当服务器接收到通知后编译更新，而后将编译后的版本提交到 Github 仓库的 gh-pages 分支，让 Github 做 Host。 采用git hook貌似必须要自己搭建git server。 CI工具持续集成（英语：Continuous integration，缩写CI）是一种软件工程流程，是将所有软件工程师对于软件的工作副本持续集成到共用主线（mainline）的一种举措。持续集成的提出主要是为解决软件进行系统集成时面临的各项问题，极限编程称这些问题为集成地狱（integration hell）。 常用工具 travis-ci Jenkins Jenkins是一个持续集成工具，相当于一个构建调度平台，围绕着scm，ssh, ant,maven插件，进行构建操作。理论上来讲，有合适的插件，大部分自动化行为都可以在jenkins平台上展开。使用Jenkins 来触发和调度，在Jenkins构建执行shell脚本来进行分发和安装，测试，可以部署成流水线的方式，依次运行 已实现","tags":[{"name":"gitbook","slug":"gitbook","permalink":"http://yoursite.com/tags/gitbook/"},{"name":"自动化部署","slug":"自动化部署","permalink":"http://yoursite.com/tags/自动化部署/"},{"name":"持续集成","slug":"持续集成","permalink":"http://yoursite.com/tags/持续集成/"},{"name":"travis-ci","slug":"travis-ci","permalink":"http://yoursite.com/tags/travis-ci/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"gitbook","slug":"CS/tools/formatting/gitbook","permalink":"http://yoursite.com/categories/CS/tools/formatting/gitbook/"}]},{"title":"OCR引擎-Tesseract-OCR简介","date":"2018-03-16T16:00:00.000Z","path":"wiki/ML/app/vision/app/OCR/Tesseract-OCR/Tesseract-ocr/","text":"Tesseract简介&amp;历史Tesseract(/‘tesərækt/) 意思是四维超正方体（英语：tesseract）或正八胞体。下图来自维基百科，是一个正八胞体绕着两个四维空间中互相正交的平面进行双旋转时的透视投影。 Tesseract was originally developed at Hewlett-Packard Laboratories Bristol and at Hewlett-Packard Co, Greeley Colorado between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. Since 2006 it is developed by Google.来自 github官方 Tesseract-OCR是一个开源的OCR引擎，具有悠久的历史。惠普公司的布里斯托尔实验室在1985-1994年开发完成。起初作为惠普的平板扫描仪的文字识别引擎。Tesseract在1995年UNLV OCR字符识别准确性测试中拔得头筹，受到广泛关注。后来HP放弃了OCR市场。在1994年以后，Tesseract的开发就停止了。 在2005年，HP将Tesseract贡献给开源社区。美国内华达州信息技术研究所获得该源码，同时，Google开始对Tesseract进行功能扩展及优化。目前，Tesseract作为开源项目发布在Google Project上，重获新生。Tesseract的最新版本是3.02，它支持60种以上的语言，提供一个引擎和一个命令行工具。 github-官网 官方文档-wiki 安装sudo apt-get install tesseract-ocr sudo apt-get install tesseract-ocr-eng tesseract-ocr-chi-sim Tesseract:安装与命令行使用 使用12# 查看可用的 \"语言\"$ tesseract --list-langs Tesseract识别图片12# from a TIFF image with Tesseract OCR$ tesseract test.png test Tesseract识别tiff12345# 识别tiff文档，默认是英语$ tesseract test.tiff test# 识别非英语文档tesseract test.tiff -l [lan] test.txt Tesseract识别pdf步骤:123# 1. 转换pdf到tiff(或其他格式)# 2. 12345$ tesseract test.pdf testTesseract Open Source OCR Engine v3.02 with LeptonicaError in pixReadStream: Unknown format: no pix returnedError in pixRead: pix not readUnsupported image type. tesseract不能直接识别pdf，一般需要借助工具转化成tiff，然后再识别。 12345678$ convert test.pdf test.tiff$ tesseract test.tiff testTesseract Open Source OCR Engine v3.02 with LeptonicaError in pixReadFromTiffStream: can't handle bpp &gt; 32Error in pixReadStreamTiff: pix not readError in pixReadStream: tiff: no pix returnedError in pixRead: pix not readUnsupported image type. tesseract不能够读取bpp &gt; 32的tiff文件。因此我们转为8bit的tiff文件。 12$ convert test.pdf -depth 8 test.tiff$ tesseract test.tiff output 现在能够正常识别了。 训练参考 https://www.jianshu.com/p/31afd7fc5813 准备训练集评价 图像预处理Tesseract目的不是作为OCR软件，而仅仅是OCR engine。Tesseract在图像预处理方面很弱，如果想得到比较好的识别效果，需要使用者自己做图片预处理。然而一般多数OCR软件都会集成图片预处理模块，比如Nuance。 估计怕做的太好，让商业软件 #","tags":[{"name":"OCR","slug":"OCR","permalink":"http://yoursite.com/tags/OCR/"},{"name":"Tesseract","slug":"Tesseract","permalink":"http://yoursite.com/tags/Tesseract/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"OCR","slug":"ML/app/vision/app/OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/"},{"name":"Tesseract-OCR","slug":"ML/app/vision/app/OCR/Tesseract-OCR","permalink":"http://yoursite.com/categories/ML/app/vision/app/OCR/Tesseract-OCR/"}]},{"title":"单播，组播(多播)，广播以及任播","date":"2018-03-12T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/5. 第三层 网络层/单播，组播(多播)，广播以及任播/","text":"路由形式 单播（原文：unicast）是指数据包在计算机网络的传输中，目的地址为单一目标的一种传输方式。它是现今网络应用最为广泛，通常所使用的网络协议或服务大多采用单播传输，例如一切基于TCP的协议。 任播（英语：anycast）是一种网络定址和路由的策略，使得资料可以根据路由拓扑来决定送到“最近”或“最好”的目的地。 路由形式 任播 广播 多播 单播 geocast bgp anycast就是利用一个（多个） as号码在不同的地区广播相同的一个ip段。利用bgp的寻路原则，短的as path 会选成最优路径（bgp寻路原则之n），从而优化了访问速度。其实bgp anycast是不同服务器用了相同的ip地址。 阿里的DNS 就是使用了BGP AnyCast“其实bgp anycast是不同服务器用了相同的ip地址。” BGP Anycast 和 IP Anycast 有区别吗？BGP Anycast相较于IP Anycast多了BGP AS，也就是说宣告的这段IP拥有独立的AS号，属于独立的自治域。 不同服务器用相同地址，不会冲突吗？参考http://colobu.com/2014/10/21/udp-and-unicast-multicast-broadcast-anycast/ 问题广播，是面向什么范围的广播？局域网？世界所有计算机？ ARP广播，比特币中的广播，","tags":[{"name":"单播","slug":"单播","permalink":"http://yoursite.com/tags/单播/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"5. 第三层 网络层","slug":"CS/network/网络协议-OSI七层模型/5-第三层-网络层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/5-第三层-网络层/"}]},{"title":"如何托管你的网站 - 托管服务器","date":"2018-03-07T16:00:00.000Z","path":"wiki/CS/web/建站/host/host-your-website/","text":"Host - 网站托管web hosting (service)可以被翻译为：网站托管。这里的host，类似于“主持、主办、提供”的含义。 大体分Iaas和PaaS两种 IaaS：云主机(或虚拟机) - 权限大，费用贵 阿里云主机、Google云主机(GCE)、腾讯云主机等 PaaS：云平台(运行软件的平台) - 权限小，便宜或免费 动态网站托管平台：SAE、GAE等 静态网站托管平台：github pages服务、coding pages服务 注意区分：github的仓库(repo)是版本控制软件，是github提供的SaaS服务。github的Pages服务用于网站托管，是github提供的PaaS服务。 鉴于免费，很多人采用Pages服务来托管自己的网站(个人博客等）。 关于静态网站 动态网站纯静态网站静态网站 + 自己搭建后台应用例如 wordpress的方式。 需要自己租用服务器，自己搭建应用 免费静态网站 + 免费动态服务平台福利: 全免费 静态网站建站现在有很多快速的技术和平台。静态网站简单，但是存在很多局限性。 很多网站提供了常用的动态服务，比如评论、流量统计、实时聊天。我们只需要调用其接口，而不用自己租服务器搭建后台应用。 常用的免费动态服务有： 评论: 多说、畅言、disqus、gitment 等， 流量统计: 百度统计、google统计、不蒜子 实时聊天: 云主机 - 贵GAE - 限额免费Google App Engine是Google提供的基于Google数据中心的开发、托管网络应用程序的平台，每个 Google App Engine 应用程序都可使用1GB存储空间和每天1G的流量，GAE对于使用资源有各种限制，跑动态网站往往会配置不够用，但如果网站使用纯粹的静态HTML建立，那么这种网站还是可以支持较大的访问量。 GAE网站的免费额度限制主要是：文件总容量小于1G，文件数量少于1万个，每天流量小于1G，由于静态网站对于CPU消耗很少，因此CPU的运算限制可以忽略，通常来说，这样的配额对于普通中小型网站已经足够了。 Pages服务 - 免费 - 适合纯静态网站 - 简单图片服务器图片服务器的优势总得来说，部署图片服务器有以下几点好处： 分担 Web 服务器的 I/O 负载 - 将耗费资源的图片服务分离出来，提高服务器的性能和稳定性 能够专门对图片服务器进行优化 - 为图片服务设置有针对性的缓存方案，减少带宽成本，提高访问速度 提高网站的可扩展性 - 通过增加图片服务器，提高图片吞吐能力 案例案例：又拍云存储又拍云是通用的大规模存储服务，主要为用户提供静态文件存储以及 CDN 加速的服务。 又拍云在静态文件存储方面有多年的技术经验，一直专注于静态文件存储处理领域。 又拍云存储在全国各地有 26 个 CDN 节点 ， 300 多台服务器以及电信、联通、移动和教育网四线带宽，能够让用户以极低的价格获得可靠、安全和快速的基础存储服务。","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"建站","slug":"建站","permalink":"http://yoursite.com/tags/建站/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"}]},{"title":"将Hexo博客到同时部署到Github和Coding实现全球快速访问。","date":"2018-03-05T16:00:00.000Z","path":"wiki/CS/web/建站/host/双线部署/","text":"coding.net采用httpsgithub pages怎样采用https呢？ 简介多线，指多条解析线路(isp)。 如果访问量特别大，可以多线部署，比如分别部署电信、网通等多条线路，或者不同省份的线路。这里我们仅采用国内线路、海外线路两种。 一个主机头可以分别解析不同的线路、不同IP，当用户访问网站的时候，智能DNS会判断出他们的线路并解析给他们对应线路的IP，以达到最快的访问速度 配置hexo的_config文件这样在执行hexo deploy命令时就会同时部署到github和coding，由于之前已经配置了ssh，所以这里并不需要输密码 非常方便。 DNS解析的配置 主要配置:123记录类型 解析线路(isp) 记录值CNAME 世界 xu-song.github.io # 海外线路采用github pageCNAME 默认 xu-song.coding.me # 国内线路采用coding page 在coding和github绑定自己的域名如何测试方式一：http://tool.chinaz.com/dns/可测试 DNS 服务器的可用性和响应时间 美国、香港、台湾已经是解析的github的地址，国内的dns解析的是coding的地址。 方式二：http://ce.cloud.360.cn/ 方式三：1234567chrome://dns/查看DNS解析的地址chrome://net-internals/#dns更多功能请参考chrome://chrome-urls/ 问题以上方式，github的 双线部署方案方案列表： Github + Coding + DNS双线解析。简单，但github不能对独立域名配置HTTPS Github + CloudFlare + Coding + DNS双线解析。实现双线部署，双线HTTPS 如何对js image等资源设置多线CDN？比如有些google的js国内访问不到，需要采用国内的镜像CDN资源。 另外，图片、js、css等静态文件可以使用CDN加速，一些公共的js、css可以使用一些公共CDN，比如百度CDN，其余资源可以上传到七牛云来加速。 如何在html页面动态显示连接线路？根据访问的路线，动态显示Hosted by Coding Pages 或者 Github Pages。 dns解析过程在页面解析之前。。前端无法获取到这个信息。 Update为了双线部署，且启用 SSL 。当前版本采用了 国内线路：万网NDS + Coding_Pages(提供Lets’ Encrypt免费SSL证书) 境外线路：万网DNS + CloudFlare_Name_Server(提供CDN+CloudFlare免费SSL证书) + Github_Pages","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"建站","slug":"建站","permalink":"http://yoursite.com/tags/建站/"},{"name":"pages","slug":"pages","permalink":"http://yoursite.com/tags/pages/"},{"name":"https","slug":"https","permalink":"http://yoursite.com/tags/https/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"}]},{"title":"DNS解析实例之 Github Pages","date":"2018-03-05T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/DNS/-DNS解析实例-github-pages/","text":"","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"dns","slug":"dns","permalink":"http://yoursite.com/tags/dns/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"DNS","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS/"}]},{"title":"DNS解析实例之 Coding Pages","date":"2018-03-05T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/DNS/DNS解析实例-coding-pages/","text":"coding page跳转至首页DNS配置 coding.net域名配置 首选域名，一次到达 12345678$ wget https://blog.eson.org# 这个不需要重定向--2018-03-02 18:51:26-- https://blog.eson.org/Resolving blog.eson.org (blog.eson.org)... 107.150.121.91, 107.150.121.231, 103.72.147.89, ...Connecting to blog.eson.org (blog.eson.org)|107.150.121.91|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 72536 (71K) [text/html]Saving to: ‘index.html.1’ 跳转至首页的域名，采用301跳转 123456789101112131415161718192021$ wget xusong.vip--2018-03-02 17:35:28-- http://xusong.vip/# dns解析xusong.vip，根据CNAME记录得到xu-song.coding.me。# 然后解析xu-song.coding.me对应的服务器IP。# 返回“301跳转到 http://blog.eson.org/”Resolving xusong.vip (xusong.vip)... 103.72.145.7, 23.91.101.50, 103.218.240.147, ...Connecting to xusong.vip (xusong.vip)|103.72.145.7|:80... connected.HTTP request sent, awaiting response... 301 Moved PermanentlyLocation: http://blog.eson.org/ [following]# DNS解析http站点，返回“301跳转至https页面”--2018-03-02 17:35:29-- http://blog.eson.org/Resolving blog.eson.org (blog.eson.org)... 103.72.147.211, 103.72.145.7, 23.91.101.50, ...Reusing existing connection to xusong.vip:80.HTTP request sent, awaiting response... 301 Moved PermanentlyLocation: https://blog.eson.org/ [following]# DNS解析https站点，返回页面内容--2018-03-02 17:35:31-- https://blog.eson.org/Connecting to blog.eson.org (blog.eson.org)|103.72.147.211|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 72536 (71K) [text/html]Saving to: ‘index.html’ 不加https协议，会首先301跳转到https站点。 12345678910111213$ wget blog.eson.org# 默认是访问 http://blog.eson.org，返回301重定向 https://blog.eson.org/--2018-03-02 18:50:27-- http://blog.eson.org/Resolving blog.eson.org (blog.eson.org)... 36.255.221.66, 107.150.121.91, 107.150.121.231, ...Connecting to blog.eson.org (blog.eson.org)|36.255.221.66|:80... connected.HTTP request sent, awaiting response... 301 Moved PermanentlyLocation: https://blog.eson.org/ [following]#--2018-03-02 18:50:28-- https://blog.eson.org/Connecting to blog.eson.org (blog.eson.org)|36.255.221.66|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 72536 (71K) [text/html]Saving to: ‘index.html’ 直接访问coding pages页面，要跳转2次，一次302，一次30112345678910111213141516171819$ wget xu-song.coding.me#--2018-03-02 18:58:45-- http://xu-song.coding.me/Resolving xu-song.coding.me (xu-song.coding.me)... 23.91.97.251, 103.218.241.74, 103.72.147.211, ...Connecting to xu-song.coding.me (xu-song.coding.me)|23.91.97.251|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://blog.eson.org/ [following]#--2018-03-02 18:58:46-- http://blog.eson.org/Resolving blog.eson.org (blog.eson.org)... 103.72.147.211, 103.72.145.7, 23.91.101.50, ...Reusing existing connection to xu-song.coding.me:80.HTTP request sent, awaiting response... 301 Moved PermanentlyLocation: https://blog.eson.org/ [following]#--2018-03-02 18:58:46-- https://blog.eson.org/Connecting to blog.eson.org (blog.eson.org)|103.72.147.211|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 72536 (71K) [text/html]Saving to: ‘index.html.3’","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"dns","slug":"dns","permalink":"http://yoursite.com/tags/dns/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"DNS","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS/"}]},{"title":"metric 距离度量","date":"2018-03-04T16:00:00.000Z","path":"wiki/ML/ml 传统方法/metric/","text":"什么时候采用均方差，什么时候采用cross entropy？ 连个任意向量的距离L1 L2 L2距离，更改坐标系，距离不变。L1距离，更改坐标系，距离会变。coordinate dependency 有特殊意义的，可以用L1. 没有特殊意义的向量，最好用L2。 http://vision.stanford.edu/teaching/cs231n-demos/knn/ 两个概率的距离 cross entropy kl divergence word mover distance WMD for document distance Wasserstein GAN (W-GAN)-","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"【机器学习系列】特征工程","date":"2018-03-03T16:00:00.000Z","path":"wiki/ML/ml 传统方法/特征工程/","text":"简介there’re now hundreds or perhaps thousands of researchers who’ve spent years of theirlives slowly and laboriously hand-engineering vision, audio or text features. While much of this feature-engineering work is extremely clever, one has to wonder if we can do better. Certainly this labor-intensive hand-engineering approach does not scale well to new problems; further, ideally we’d like to have algorithms that can automatically learn even better feature representations than the hand-engineered ones. – 来自ufldl 特征类别离散特征连续特征 (continuous features)Bucketization turns a continuous column into a categorical column. This transformation lets you use continuous features in feature crosses, or learn cases where specific value ranges have particular importance. Bucketization12age_buckets = tf.feature_column.bucketized_column( age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65]) 为什么要Bucketization? 类别特征 Categorical features 文本中的word 图像中的像素点，不是。因为具有大小有意义。 通常被转化为稀疏向量。(比如FM中对user_id的处理，NLP中的one-hot表达，) 比如 ‘eye_color’的’brown’表示为[1, 0, 0], ‘blue’ 表示为[0, 1, 0] and ‘green’表示为[0, 0, 1]. 称之为稀疏向量，因为多数情况下向量维度高，仅只有一个非零值。 为什么不用一个点表示？比如表示成 1 2 3？这样只占用一个维度。 典型的特征处理方法 one-hot处理 还有hash-bucket处理 挑战 未知的类别 可采用categorical_column_with_hash_bucket() ss 特征工程Base Feature Column 通常原始特征表达能力不够，通常大家会在原始特征的基础上人工设计一些特征。特征设计的好坏对整个系统至关重要。设计的好，效果好，外接简单的分类器或其他模型就能够取得较好的效果。因此工业界很青睐这种方法。 Feature Crosses组合特征，这仅仅适用于sparser特征.产生的依然是sparsor特征 12sport_x_city = tf.feature_column.crossed_column( [&quot;sport&quot;, &quot;city&quot;], hash_bucket_size=int(1e4)) ### 挑战 &amp; 缺陷 特征工程 特征选择参考 Wide &amp; Deep Learning Tutorial | TensorFlow | code 浅层模型(比如LR)要提高效果，一般会提前大量的人工特征，即wide模型 DNN一般采用end-to-end的模型，建立原始特征--&gt;label的映射。 wide &amp; deep则是结合两者的有点。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"Hexo中的SEO技巧","date":"2018-03-03T16:00:00.000Z","path":"wiki/CS/web/建站/seo/seo-in-hexo/","text":"关于keywords为每个post添加tag，因为tag会被放入页面的keywords 12345&#123;% if page.keywords %&#125; &lt;meta name=\"keywords\" content=\"&#123;&#123; page.keywords &#125;&#125;\" /&gt;&#123;% elif page.tags and page.tags.length %&#125; &lt;meta name=\"keywords\" content=\"&#123;% for tag in page.tags %&#125;&#123;&#123; tag.name &#125;&#125;,&#123;% endfor %&#125;\" /&gt; 每个页面 keywords 的选择顺序，是按照如下优先顺序进行 page 中定义的 keywords page 中定义的 tags _config.yml 中定义的 keywords (hexo中定义的keyword，不是theme的config) 源码https://github.com/hexojs/hexo/blob/master/lib/plugins/helper/open_graph.js https://github.com/theme-next/hexo-theme-next/blob/master/layout/_partials/head/head-unique.swig 建议tags标签和keywords标签都加。由于keywords在页面不会展示，因此添加更自由，添加面向SEO的标签。 关于robots.txt 和 sitemap.xml参考http://www.restran.net/2017/05/02/hexo-custom-html-meta-keywords/","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"domain","slug":"domain","permalink":"http://yoursite.com/tags/domain/"},{"name":"SEO","slug":"SEO","permalink":"http://yoursite.com/tags/SEO/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"seo","slug":"CS/web/建站/seo","permalink":"http://yoursite.com/categories/CS/web/建站/seo/"}]},{"title":"广义线性模型","date":"2018-03-02T16:00:00.000Z","path":"wiki/ML/ml 传统方法/广义线性模型/","text":"logistic regression逻辑回归 = 最小二乘法。 最小二乘法(Least squares)的线性回归中，我们的目标方程 ridge regression岭回归 二范数 L2正则相当于对参数加高斯先验 L1正则相当于对参数加拉普拉斯先验。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"ml 传统方法","slug":"ML/ml-传统方法","permalink":"http://yoursite.com/categories/ML/ml-传统方法/"}]},{"title":"SSL证书","date":"2018-03-02T16:00:00.000Z","path":"wiki/CS/web/建站/SSL证书/ssl-certificate/","text":"为什么要用HTTPS？HTTP 协议是不加密传输数据的，也就是用户跟你的网站之间传递数据有可能在途中被截获，破解传递的真实内容，所以使用不加密的 HTTP 的网站是不太安全的。所以， Google 的 Chrome 浏览器将在 2017 年 1 月开始，标记使用不加密的 HTTP 协议的网站为 Not Secure，不安全。 HTTPS 会为您的网站建立加密的信息安全通道，保证数据传输的安全，防止传输内容被第三方冒充或篡改。 部署 HTTPS 网站的时候需要证书，证书由 CA 机构签发，大部分传统 CA 机构签发证书是需要收费的，这不利于推动 HTTPS 协议的使用。 证书的类型SSL证书没有所谓的“品质”和“等级”之分，只有三种不同的类型。SSL证书需要向国际公认的证书证书认证机构（简称CA，Certificate Authority）申请。CA机构颁发的证书有3种类型： 域名型SSL证书（DV SSL）：信任等级普通，只需验证网站的真实性便可颁发证书保护网站； 企业型SSL证书（OV SSL）：信任等级强，须要验证企业的身份，审核严格，安全性更高； 增强型SSL证书（EV SSL）：信任等级最高，一般用于银行证券等金融机构，审核严格，安全性最高，同时可以激活绿色网址栏。 SSL证书的颁发机构 - CA机构 Let’s Encrypt: Let’s Encrypt 是目前使用范围最为广泛的免费 SSL 证书，而且官方博客宣布，自 2018 年开始提供通配符 SSL 证书，也就是 wildcard certificates。 在线申请网址1（中文）：https://freessl.org/ 在线申请网址2（英文）：https://www.sslforfree.com/ Symantec GeoTrust TrustAsia 亚信 AlwaysOnSSL Comodo Cloudflare: Cloudflare 很早就开始提供免费 SSL 证书，前提是你的域名要放在 Cloudflare 解析，注册为 Free Plan 就可以。 自从 Let’s encrypt 开始提供免费DV SSL后，SSL 证书市场就已经开始洗牌了。 12Issued by: Encryption Everywhere DV TLS CA - G1Issued by: Let&apos;s Encrypt Authority X3 第三方机构 - 辅助申请证书阿里云阿里云提供免费DV SSL证书 Symantec 免费版 单域名证书 - 免费 GeoTrust 通配符DV SSL证书 - 收费 又拍云 免费提供 Let’s Encrypt 和 Symantec 签发的两款 DV SSL 证书，也是业内唯一一家提供两种。立即签署颁发，并实现了Let’s Encrypt 自动续期功能。 腾讯的就是方便，不过时间只有一年。 cloudflare 免费版并不是很快。而且他强制你 nameserver 指过去(可把域名解析都托管过去，也可只托管指定主机） coding.net coding pages会自动给证书续期 注意：申请 SSL/TLS 证书需要通过 Let’s Encrypt 的 HTTP 方式验证域名所有权。如果您的域名在境外无法访问 Coding Pages 的服务器，将导致 SSL/TLS 证书申请失败。 Let’s Encrypt证书SSL 证书服务，大家用哪家的？ Let’s Encrypt：免费，快捷，支持多域名，三条命令即时签署+导出证书。缺点是暂时 2018年3月14日，Let’s Encrypt 对外宣布 ACME v2 已正式支持通配符证书。 Let’s encrypt 的免费证书默认有效期为 90 天，到期后如果要续期可以执行：1certbot-auto renew 操作流程要使用 HTTPS，你需要安全机构颁发的安全证书，然后配置服务器，去使用这个证书。下面介绍一下在阿里云免费申请安全证书，还有配置一般的 NGINX 服务器支持 HTTPS 的方法。 申请证书、绑定域名 下载证书 使用证书: 配置 相应的Web服务器 github pages如何使用SSL证书？虽然 Github 早在2016年就已经为 *.github.io 添加了 HTTPS 支持，但自定义域名开启 HTTPS 却是一件令人头疼的事情。大家只能使用 Cloudflare 之类的支持 SSL 的 CDN 曲线支持 HTTPS 。 好消息: 2018年5月1日，GitHub 宣布与 Let’s Encrypt 合作，为 Github Pages 自定义域名提供官方的HTTPS 支持。如果在 Github Pages 绑定了域名，现在可以使用 Let’s Encrypt 签发的 SSL 证书为绑定的域名开启 HTTPS 访问。 如果 enforce HTTPS 不可勾选，并且提示 Not yet available for your site because the certificate has not finished being issued ，说明证书尚未申请完成，等待一天即可。 github pages采用的github的服务器，不能直接设置https，但可以通过CDN来设置SSL。 github_pages + cloudflare（cdn+https） gitpage + 又拍云(cdn,https) 又拍云需要域名备案 cloudflare配置CDN流程 进入万网控制台 修改dns服务器，默认dns服务器 dns1.hichina.com,dns2.hichina.com，修改成cloudflare的dns服务器 To use Cloudflare, you need to change your domain’s authoritative DNS servers, which are also referred to as nameservers. 用 cloudflare,但是他要我更换 dns 服务器，更换后貌似导致域名访问不了 coding pages 的服务器了。原因是cloudflare接管DNS解析后，不支持双线部署。 设置https 在CF的Crypto页中，SSL设置为Flexible。这将允许CDN到github pages之间的访问为http。 现在，通过https://你的域名已经可以访问站点首页了。 强制httpsCF提供Page Rules功能，可设置路由规则。通过规则中的Always use https选项，可以将用户强制跳转到https 参考 https://blog.chionlab.moe/2016/01/28/github-pages-with-https/ 证书信息12网站: blog.eson.org颁发给: sni90514.cloudflaressl.com # 这个是 原理它的原理是当访客使用 HTTPS 访问站点的时候， 从访客到 Cloudflare 然后从 Cloudflare 到站点这段是明文的 s 虽然不是全程加密，假设从 Cloudflare 到站点的信道相对可靠的话，也能很大程度上解决中间人劫持的问题。 更改DNS服务器。这样万网域名eson.org中的所有配置失效，转由cloudflare提供DNS解析服务。 但是cloudflare没有线路配置，也就没必要双线部署了 DNS导向到github page之前，进行了缓存。 扩展阅读 关于免费SSL证书的那些事儿 | 知乎浏览器->Cloudflare: 加密数据 Cloudflare-->web服务器: 明文{\"theme\":\"simple\",\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"sequence-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"sequence-0-options\").value)); var diagram = Diagram.parse(code); diagram.drawSVG(\"sequence-0\", options);","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"SSL证书","slug":"CS/web/建站/SSL证书","permalink":"http://yoursite.com/categories/CS/web/建站/SSL证书/"}]},{"title":"【深度学习】深度学习框架总结","date":"2018-03-02T16:00:00.000Z","path":"wiki/ML/deep learning/toolbox/-summary/","text":"基本介绍 库名 主语言 从语言 速度 灵活性 文档 适合模型 平台 上手难易 开发者 模式 Tensorflo C++ cuda/python/Matlab/Ruby/R 中等 好 中等 CNN/RNN Linux,OSX 难 Google 分布式/声明式 Caffe C++ cuda/python/Matlab 快 一般 全面 CNN 所有系统 中等 贾杨清，后入坑Facebook 声明式 PyTorch python C/C++ 中等 好 中等 - – 中等 FaceBook MXNet c++ cuda/R/julia 快 好 全面 CNN 所有系统 中等 李沐和陈天奇等，后来入坑Amazon 分布式/声明式/命令式 Torch lua C/cuda 快 好 全面 CNN/RNN Linux,OSX 中等 Facebook 命令式 Theano python c++/cuda 中等 好 中等 CNN/RNN Linux, OSX 易 蒙特利尔理工学院 命令式 Caffe2代码全部并入PyTorch：深度学习框架格局剧震 ss tool year download feature example code pretrained_model state of art 备注 caffe theano tensorflow torch DL4j 容易与Kafka、Hadoop和Spark集成 api 对比tensorflowpytorchpytorch 0.4theanokerasMXNet核心类是 autograd.VariableVariables并入Tensor，核心类是torch.Tensor数据data类型torch.FloatTensor, torch.DoubleTensor等类型torch.Tensor创建torch.from_numpy(a) 等torch.ones(1)输入数据x类型tf.placeholder (占位符)torch.autograd.variable.Variabletorch.Tensor创建torch.autograd.Variable(value)torch.ones(1)简介运行时赋值(Session.run 的 feed_dict)声明时赋值。variable是tensor的容器，增加了自动求梯度的功能。variables wrap tensors, and construct a chain of operations between the tensors, so that the gradients can flow back.它的创建与data相同。是否加入graph取决于运算中是否有requires_grad=True节点变量variable类型tf.variabletorch.autograd.variable.Variabletorch.Tensor创建torch.autograd.Variable(value, requires_grad=True)x = torch.ones(2, 2, requires_grad=True)简介模型参数。 声明时须提供初始值.训练时值会改变评价placeholder的必要性？优势：data与variable分离。缺陷，tensor和variable不能直接计算。因为前者非graph，后者要加到graph。默认优化器查看变量值sess = tf.InteractiveSession() &lt;br&gt;raw_data.eval()tf.scan可用普通的imperative flow controltf.constant放哪torch.tensor放哪？这些都是符号包含数据的变量 核心: tensor variable tensor 不能改变的tensor，tf.constant不能被assign 能够改变的tensor， variable tensorflow新版，推荐不采用tf.Variable，而是采用tf.get_Variable. 我觉得是一个挺合理的变化。因为tf.Variable自身是operation，容易与tf.variable的tensor混淆。 FAQ pytorch中tensor和variable为什么要合并？tf中为什么不合并？ 什么情况下维度用？表示？只有符号编程需要这样做吗？ tf.Variable(0.0, trainable=False)与tf.constant的区别？前者的应用场景是什么？ PyTorch 0.4：年度最大更新！完全改变APICombine Variable and Tensor APIs (Perform autograd directly on torch.Tensor) | github 12Q: 新的pytorch没有了variable类，以前的很多code是不是都不能用了A: 不用，只有用户显示调用的variable会不能用了，之前很多采用的是内置参数，比如 nn.Embedding nn.GRU 0.4以前，tf.Tensor是数据，tf.Variable是变量。数据不能够进行计算，需要转化成variable。variable是对tensor的封装，额外包含了梯度、graph信息。比如 requires_grad=True 是variable的专利。0.4之后，合并tensor与variable，可在tensor中设置requires_grad=True。 取消所有对variable的变量名，统统改称为tensor tensor to numpyArray tensorflow tf.eval 或 session.run。需要依赖 pytorch torch.from_numpy(a) 方便 类似的东东tf - tf.variable是tf.tensor的封装pytorch - autograd.Variable是tensor的封装 ONNX 性能Caffe&gt; TensorFlow和Torch 上升趋势：MXNet(Amazon主推) &gt; PyTorch(Facebook主推) &gt; TF &amp; Keras 速度：pytorch想要写的快也需要了解自动求导等原理，没写好一定慢。tf没写好也会慢PyTorch多清爽 (tf的session，graph很烦)MXNet多快。底层都是C++，为什么tf的python这么丑？ 为什么keras不支持MXNet？不支持PyTorch？ TFpros 与Theano类似的计算图抽象化 编译时间快于Theano 用TensorBoard进行可视化 (pytorch和MXNet也有可视化了，这个不算优势了) 同时支持数据并行和模型并行 生态好，分布式，serving， cons control dependency反人类（不理解） 写动态结构麻烦(不理解) 目前TensorFlow还不支持所谓的“内联（inline）”矩阵运算，必须要复制矩阵才能对其进行运算。复制非常大的矩阵会导致成本全面偏高。TF运行所需的时间是最新深度学习工具的四倍。谷歌表示正在解决这一问题。 速度慢（例如：CNTK 和 MxNet）. 为什么？？？ TensorFlow不提供商业支持。而谷歌也不太可能会从事支持开源企业软件的业务。谷歌的角色是为研究者提供一种新工具。 和Theano一样，TensforFlow会生成计算图（如一系列矩阵运算，例如z = sigmoid(x)，其中x和z均为矩阵），自动求导。自动求导很重要，否则每尝试一种新的神经网络设计就要手动编写新的反向传播算法，没人愿意这样做。在谷歌的生态系统中，这些计算图会被谷歌大脑用于高强度计算，但谷歌还没有开放相关工具的源代码。TensorFlow可以算是谷歌内部深度学习解决方案的一半。 加载每个新的训练批次时都要跳至Python 动态类型在大型软件项目中容易出错 速度慢,有争议 比Torch笨重许多；更难理解 tensorflow是符号式编程方式，继承了theano一大堆缺点，不仅写法麻烦，而且bug难调； 作为静态图框架，调试困难。有个tfdbg的工具可以调试。 tensorflow_Fold的“动态”是指dynamic batching，并非pytorch的“动态” 疑问 按道理静态图适宜部署，运行应该比动态图快啊。比pytorch快吗？为什么比MXNet慢呢？ caffe – deprecated适合前馈网络和图像处理 pros 适合前馈网络和图像处理 适合微调已有的网络 无需编写任何代码即可训练模型 Python接口相当有用 cons 需要用C++ / CUDA编写新的GPU层 不适合循环网络，不适用于文本、声音或时间序列数据等其他类型的深度学习应用 用于大型网络（GoogLeNet、ResNet）时过于繁琐 不可扩展，有些不够精简 不提供商业支持 更新缓慢，以后不再更新 caffe2 – 没文档 by 贾扬清Caffe2将接替原版Caffe，与Caffe和PyTorch一样，Caffe2提供一个在C++引擎上运行的Python API。 不提供商业支持 pytorch 命令式编程的方式，随时能够运行结果，容易定位bug 支持动态图，非常灵活，能够随意取出其中的tensor进行操作和查看； 最新的cs231n都推出了PyTorch版本的作业 其实PyTorch也是仿照Chainer开发的，其后端也是调用的torch的运算，定位比keras低，但是又比tensorflow高。 PyTorch定位于科研，在Facebook内部使用Caffe2作为产品的部署和应用 pytorch更容易重构函数，但是如果需要部署的话就还是得像TF或者其他一些框架一样老老实实做dirty work。 CNTKChainerDyNetDyNet亦称动态神经网络工具包，由卡纳基梅隆大学推出，过去曾被称为cnn。它最值得一提的功能就是动态计算图，能够处理可变长度的输入，很适合自然语言分析。PyTorch和Chainer也提供同样的功能。 动态计算图 用户群较小、 kerasKeras 是一个基于Theano和TensorFlow的深度学习库，具有一个受Torch启发、较为直观的API。这可能是目前最好的Python API。Deeplearning4j可以导入Keras模型。Keras是由谷歌软件工程师Francois Chollet开发的。 受Torch启发的直观API 可使用Theano、TensorFlow和Deeplearning4j后端（即将推出CNTK后端） 该框架正快速成长 有可能成为用于开发神经网络的标准Python API 不用keras的原因主要是不能像TensorFlow一样自己定义输入输出，只能add layer，不太好构造结构独特的网络。MxNet 结合了神经网络几何的象征性声明与张量操作的命令性编程 允许混合符号和命令式编程风格。 MXNet平台是建立在一个动态依赖调度器上的，它可以自动并行化符号和命令式操作 在许多方面MXNet类似于TensorFlow，但增加了嵌入命令张量操作的能力。 MXnet速度快，省显存，并行效率高，分布式简单 动态图接口Gluon。MXNet正是看到了以PyTorch为首的命令式编程框架的潜力，对于新用户特别友好，易于上手，所以他们决定模仿PyTorch开发一个动态图接口Gluon Gluon也可以看作一个接口，调用底层的MXNet，但是前端使用符号式编程的方式。 Gluon不仅定位于科研，同时也可用于产品 PyTorch只有动态图的模式，有的时候我们的网络结构其实是一个静态图，但是通过PyTorch每次都会重新构建动态图，而Gluon提供了一个静态图和动态图之间切换的方式 使用者可以先用imperatvie的方式写网络，debug，最后跑通网络之后，如果网络是一个静态图结构，就可以用net.hybridize()的方式将其转换成静态图，众所周知静态图的运算会比动态图快， Paddle如何评价余凯在朋友圈发表呼吁大家用caffe, mxnet等框架，避免tf 假设有一天Google为了卖它的TPU，决定渐渐放弃GPU支持，你说nVidia会不会慌？ 假设Google说要把放弃x86和Xeon Phi支持，你说Intel慌不慌？ Google拒绝针对以太网（AWS和Windows Azure都是万兆以太网）做任何优化，而且不愿意merge任何与此相关的PR，你说Amazon和Microsoft慌不慌？ 假设有一家做TPU(比如寒武纪)，或者做无人车的公司，对Google造成了严重威胁，那么他们发的PR，能不能保证得到Google的公正对待？ NVidia笑了。这几个框架跑分全靠cuDNN，就算不用cuDNN，也是要用CUDA的。深度学习就是NVidia的私家花园。TensorFlow能垄断啥？ NVIDIA 搞生态(？？？)，是指支持很多框架吗？ 发展史 段子 我曾经做过一段时间的图像算法工程师，主要工作就是看论文、实践论文中的各种算法以及优化算法以适应自己的工程问题。当时的主要工程问题就是做人脸检测、图像识别和图像搜索等等，其中比较考验水平和依赖经验的部分是选择Feature和优化Feature以适应具体的工程问题。对于当时的一些通用的Feature，比如SURF/SIFT（这两个基本是划时代的）、LBP或者MSER等等，不仅是需要了解其使用场景及各种局限，而且最好能够很清楚其理论基础和推导过程，这样才能便于优化和适应。大概在2013年左右，了解到Deep Learning崛起的趋势，然后阅读了相关教程。当时的第一个反应就是WTF，难怪有人将DL列为“知其然而不知其所以然”的科学技术之前几名。第二个反应就是，选择和优化Feature这一步岂不是被完全替代了。紧接着Caffe、TensorFlow以及各种DL的Library接踵而出，搞DL的门槛被拉得越来越低。这不得不让人想起来在OpenCV中实现人脸检测就只需要一两行代码，使用的人完全不用考虑Adaboost以及Haar等数学问题。 我大概13年的时候听说有深度学习这回事，然后跟着UFLDL学习了如何推导矩阵导数，练习了一些常见层的推导和代码编写。后来出了caffe，因为当时在外地出差，搬砖之余就看了不少caffe的代码，慢慢地就开始在caffe上写layer，前向cpu、后向cpu、前向gpu、后向gpu，一共4份代码。为了写一个layer，需要学会推导矩阵求导的公式（我研究生时期才学到相关知识），要会写c++，会使用BLAS（一个矩阵运算的库，参数非常繁复，每次都要看半天文档才能写出一个函数），还要会写GPU上运行的CUDA代码。如果是一名编程基础不是很好的研究生，可能到了研二结束都写不出一个layer。还好，当时我是个编程基础还不错的研究生，上手还不算很困难。然而当我刚刚能够熟练写layer的时候，深度学习的各种library如雨后春笋般一个个冒出来了，各个都有自动求导、cpu gpu代码自动转换的功能！这意味着不需要推导公式，不需要会BLAS，不需要会CUDA，只需要写1份前向代码，而其他所有工作都由library自动完成！一开始我并没有在意，后来实现neural style（就是之前很火的Prisma用的方法：免费摄影APP“Prisma”将照片变成名画）的时候我花了2天时间写了个gram layer并完成测试后，赫然看到别人用torch几行就写出来了，顿时目瞪口呆：function gram(input) local k = input:size(2) local flat = input:view(k, -1) local gram = torch.mm(flat, flat:t()) return gramend它简洁而优雅，简洁到根本不需要测试就知道它是对的，优雅得像“神说要有光，于是便有了光”。而这是我的代码：caffe-windows/gram_layer.cpp at master · happynear/caffe-windows · GitHubcaffe-windows/gram_layer.cu at master · happynear/caffe-windows · GitHub两个文件，一个cpu版一个gpu版。理所当然的，我的代码除了我自己根本没人使用。如果不保持学习，就算你在从事尖端的人工智能研究，一样说淘汰就淘汰。作者：王峰链接：https://www.zhihu.com/question/50144455/answer/119655526来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://yoursite.com/tags/tensorflow/"},{"name":"pytorch","slug":"pytorch","permalink":"http://yoursite.com/tags/pytorch/"},{"name":"theano","slug":"theano","permalink":"http://yoursite.com/tags/theano/"},{"name":"keras","slug":"keras","permalink":"http://yoursite.com/tags/keras/"},{"name":"mxnet","slug":"mxnet","permalink":"http://yoursite.com/tags/mxnet/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"toolbox","slug":"ML/deep-learning/toolbox","permalink":"http://yoursite.com/categories/ML/deep-learning/toolbox/"}]},{"title":"Coding Pages托管静态博客-原理浅析","date":"2018-03-01T16:00:00.000Z","path":"wiki/CS/web/建站/host/coding-pages/coding-pages/","text":"参考 DNS解析实例-ESON github page不支持多个域名，因此不存在重定向 301，302 区别对于用户301，302对用户来说没有区别，他们看到效果只是一个跳转，浏览器中旧的URL变成了新的URL。页面跳到了这个新的url指向的地方。 对于引擎及站长302 redirect: 302 代表暂时性转移(Temporarily Moved ) 临时跳转302转向可能会有URL规范化及网址劫持的问题。可能被搜索引擎判为可疑转向，甚至认为是作弊。 302重定向和网址劫持（URL hijacking）有什么关系呢？这要从搜索引擎如何处理302转向说起。从定义来说，从网址A做一个302重定向到网址B时，主机服务器的隐含意思是网址A随时有可能改主意，重新显示本身的内容或转向其他的地方。大部分的搜索引擎在大部分情况下，当收到302重定向时，一般只要去抓取目标网址就可以了，也就是说网址B。 实际上如果搜索引擎在遇到302转向时，百分之百的都抓取目标网址B的话，就不用担心网址URL劫持了。问题就在于，有的时候搜索引擎，尤其是Google，并不能总是抓取目标网址。为什么呢？比如说，有的时候A网址很短，但是它做了一个302重定向到B网址，而B网址是一个很长的乱七八糟的URL网址，甚至还有可能包含一些问号之类的参数。很自然的，A网址更加用户友好，而B网址既难看，又不用户友好。这时Google很有可能会仍然显示网址A。 由于搜索引擎排名算法只是程序而不是人，在遇到302重定向的时候，并不能像人一样的去准确判定哪一个网址更适当，这就造成了网址URL劫持的可能性。也就是说，一个不道德的人在他自己的网址A做一个302重定向到你的网址B，出于某种原因， Google搜索结果所显示的仍然是网址A，但是所用的网页内容却是你的网址B上的内容，这种情况就叫做网址URL劫持。你辛辛苦苦所写的内容就这样被别人偷走了。 DNS解析有一条 显性URL-将域名302重定向到另外一个地址。 301 redirect: 301 代表永久性转移(Permanently Moved)，当网页A用301重定向转到网页B时，搜索引擎可以肯定网页A永久的改变位置，或者说实际上不存在了，搜索引擎就会把网页B当作唯一有效目标。301的好处是: 第一， 没有网址规范化问题。 第二， 也很重要的，网页A的PR网页级别会传到网页B。 变更网站域名建议直接做301重定向，UEL跳转不利于SEO蜘蛛本身不喜欢，运气不好还会被判作弊当网页A用301重定向到网页B时，搜索引擎可以肯定网页A永久的改变位置，或者说实际上不存在了，搜索引擎就会把网页B当作唯一有效目标。好处是，第一没有网址规划问题；第二，网页A的PR网页级别会传到网页B。 大家常用的301 302301t.cn知乎跳转dns解析跳转coding page跳转主页 如何实现转发 DNS可配置 302转发 apache / nginx 配置文件中写转发规则，rewrite xxx yyy 301 写一个 index.html 文件，里面写 meta refresh 跳转规则","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"},{"name":"coding-pages","slug":"CS/web/建站/host/coding-pages","permalink":"http://yoursite.com/categories/CS/web/建站/host/coding-pages/"}]},{"title":"修宪 - 2018","date":"2018-02-26T16:00:00.000Z","path":"wiki/others/politics/china/2018宪法修正案/","text":"中华人民共和国宪法 (1982-12-04) 中华人民共和国宪法 (2004-03-14) 2018年修宪全名：《中华人民共和国宪法修正案》（2018年）) 2017年9月29日 - 成立宪法修改小组 2018年1月30日 - 由人大常委会提请申报成功，全票通过《中华人民共和国宪法修正案（草案）》 2018年2月25日 - 由新华社和新闻联播于公布 《中国共产党中央委员会关于修改宪法部分内容的建议》 划重点 12345678910第七十九条- 中华人民共和国主席、副主席每届任期同全国人民代表大会每届任期相同，连续任职不得超过两届。+ 中华人民共和国主席、副主席每届任期同全国人民代表大会每届任期相同。- 在马克思列宁主义、毛泽东思想、邓小平理论和“三个代表”重要思想指引下+ 在马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观、习近平新时代中国特色社会主义思想指引下第六十三条 全国人民代表大会有权罢免下列人员： 主席、副主席、国务院总理、副总理、军事委员会主席、最高人民法院院长、最高人民检察院检察长+ （四）国家监察委员会主任； 宪法第七十九条第三款，删除“国家主席、副主席连续任职不得超过两届”，而引起国际关注。外界普遍将之视为邓小平时代提出的“废除干部领导职务终身制”的结束。 宪法序言增写“科学发展观”、“习近平新时代中国特色社会主义思想”及“富强民主文明和谐美丽的社会主义现代化强国”字样 关于 监察机关 国家监察委员会123456+ 第一百二十三条 中华人民共和国各级监察委员会是国家的监察机关。+ 第一百二十四条 中华人民共和国设立国家监察委员会和地方各级监察委员会。监察委员会由下列人员组成+ 主任，+ 副主任若干人，+ 委员若干人。+ 监察委员会主任每届任期同本级人民代表大会每届任期相同。国家监察委员会主任连续任职不得超过两届。 关于修宪历史中国现行宪法制定于1982年。当时，为废除实际存在的领导职务终身制，吸取文革个人崇拜的教训，宪法规定了国家主席连续任职不得超过两届，在客观上限定了中国国家元首任职不能超过十年。 中共于1988年、1993年、1999年、2004年对现行宪法进行了四次修改 1988年修宪：为“私营经济”正名1993年修宪1993年，中共总书记、中央军委主席江泽民接替杨尚昆出任国家主席，定下了总书记、国家主席、中央军委主席“三位一体”的最高领导模式。 国家的奋斗目标，则由建设“高度文明、高度民主的社会主义国家”变为建设“富强、民主、文明的社会主义国家”。两个字的增加、两个词顺序的变化，看似微小，却深意可见。 “市场经济”一词的入宪、“计划经济”一词的淡出。 1999年修宪：为“法治”鼓与呼“依法治国”。 2004- 第四次修改，关于连任 根据邓小平在1980年提倡的“废除干部领导职务终身制”，重新设立的国家主席和副主席任期为五年一届，连任不能超过两届。 党总书记、军委主席是中国政治体系中拥有最大权力的两个职务，没有连任次数的限制。 扩展阅读 修宪前后完整对比 为什么美国的 1787 宪法可以至今沿用?","tags":[{"name":"宪法","slug":"宪法","permalink":"http://yoursite.com/tags/宪法/"},{"name":"国家监察委员会","slug":"国家监察委员会","permalink":"http://yoursite.com/tags/国家监察委员会/"}],"categories":[{"name":"others","slug":"others","permalink":"http://yoursite.com/categories/others/"},{"name":"politics","slug":"others/politics","permalink":"http://yoursite.com/categories/others/politics/"},{"name":"china","slug":"others/politics/china","permalink":"http://yoursite.com/categories/others/politics/china/"}]},{"title":"如何解决百度爬虫无法爬取搭建在Github上的个人博客的问题","date":"2018-02-26T16:00:00.000Z","path":"wiki/CS/web/建站/seo/baiduspider-blocked-by-github/","text":"现状 &amp; 原因github做了什么。 robots.txt 中屏蔽了baidu 即使百度爬虫无视robots协议强抓github，github也会通过检查UA，返回403 forbidden，即拒绝访问。(当然如果要想强抓是拦不住的，伪装一下UA即可) 造成的现状 robots.txt 失效 sitemap 失效 原因：github在robots.txt中屏蔽了百度，百度默认不抓取github的内容。 主动提交失效 自动提交失效 手动提交失效 Github是通过 UA 来判定百度爬虫并返回 403 Forbidden 的 而百度爬虫的UA一般固定为 Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html) 即使向百度提交了页面，github服务器一看UA是百度爬虫，就直接拒绝访问 如何解决 换其他host服务器，比如coding.net CDN 百度爬虫不要直接向 Github 的服务器发送请求，而是通过 CDN 边缘服务器的缓存来抓取网站的内容。边缘服务器本身是不会关心 UA 的，所以问题就迎刃而解了。 也不靠谱 https://www.dozer.cc/2015/06/github-pages-and-cdn.html https://www.zhihu.com/question/30898326","tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"},{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://yoursite.com/tags/搜索引擎/"},{"name":"robots协议","slug":"robots协议","permalink":"http://yoursite.com/tags/robots协议/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"seo","slug":"CS/web/建站/seo","permalink":"http://yoursite.com/categories/CS/web/建站/seo/"}]},{"title":"禁止搜索引擎收录的方法","date":"2018-02-26T16:00:00.000Z","path":"wiki/CS/web/建站/seo/how-to-block-spider/","text":"什么是robots协议Robots协议（也称为爬虫协议、机器人协议等）的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。搜索引擎抓取网站内容前会先抓取robots.txt，据此“自觉地”抓取或者不抓取该网页内容，其目的是保护网站数据和敏感信息、确保用户个人信息和隐私不被侵犯。 需要注意的是robots协议并非是规范，只是行业内一个约定俗成的协议。什么意思呢?Robots协议不是什么技术壁垒，而只是一种互相尊重的协议，好比私家花园的门口挂着“闲人免进”，尊重者绕道而行，不尊重者依然可以推门而入，比如说360。 如果网站有数据需要保密，必需采取技术措施，比如说：用户验证，加密，ip拦截，访问频率控制等。 为什么要禁止搜索引擎收录 某些路径下是个人隐私或者网站管理使用，不想被搜索引擎抓取 不喜欢某个搜索引擎，不愿意被他抓取，最有名的就是之前淘宝不希望被百度抓取 流量有限或者需要付费，希望搜索引擎抓的温柔点。 阻止竞争抓取自己的网站内容，比如搜索引擎之间相互屏蔽，360 robots的屏蔽恩怨历史汇总 百度 google bing 备注 淘宝 × √ √ 不屏蔽google，因为google不做淘宝的竞价排名。另外还能作为淘宝流量入口 京东 √ √ √ 微信公众平台 社交网络–开放空间 weibo facebook twitter 社交网络–隐私空间 qq空间 微信朋友圈 baidu、google × × × 搜索引擎，屏蔽一切搜索引擎爬虫 github - 屏蔽百度、搜狗、360等为什么屏蔽百度 We are currently blocking the Baidu user agent from crawling GitHub Pages sites in response to this user agent being responsible for an excessive amount of requests, which was causing availability issues for other GitHub customers. This is unlikely to change any time soon, so if you need the Baidu user agent to be able to crawl your site you will need to host it elsewhere. – by Github Support Jerry’s blog 即百度爬虫爬得太猛烈，已经对很多 Github 用户造成了可用性的问题了，而禁用百度爬虫这一举措可能会一直持续下去。 白名单中竟然有 EtaoSpider。why？为什么百度中搜索site:github.io有结果？ www.github.com中的robots.txt1234567User-agent: Googlebot # google yandex等都在白名单。Allow: /*/*/tree/masterAllow: /*/*/blob/masterUser-agent: * Allow: /humans.txtDisallow: / # 百度不在白名单，即整个站点屏蔽百度 除设置了robots.txt之外，github后台服务器还会检查HTTP请求的UA，如果是百度就返回403 forbidden。 电商淘宝 - 屏蔽百度 争夺流量入口- . 2008年淘宝屏蔽了百度搜索引擎，自此用户再也无法从百度直接搜索到关于淘宝的信息。 淘宝网站曾经屏蔽百度搜索爬虫，禁止百度搜索引擎抓取淘宝网站的网页内容，淘宝官方的解释是“杜绝不良商家欺诈”。 首先，在08年9月淘宝先屏蔽了百度搜索，使得当我们在百度搜索淘宝产品名时，百度返回不到有效信息。导致普通网民在进行网上购物行为时，会直接选择登陆淘宝网，用站内搜索进行，从上网入口上讲，淘宝这样就让网民一步到位了，而不是单单记住百度这个工具，淘宝的流量肯定会水涨船高，带来的好处也不言而明。 如果当初淘宝没有屏蔽百度，不多说：最起码30%的购物搜索会来自百度。淘宝屏蔽百度以后，淘宝真正的成为了购物的第一入口。 淘宝主页www.taobao.com的robots.txt123456789101112131415User-agent: BaiduspiderAllow: /articleAllow: /oshtmlDisallow: /product/ # 禁止百度抓取www.taobao.com/product/Disallow: / # 屏蔽网站其他路径User-Agent: GooglebotAllow: /articleAllow: /oshtmlAllow: /product # 对google很宽松，即开放google入口，Allow: /spuAllow: /dianpuAllow: /overseaAllow: /listDisallow: / 淘宝商品页面item.taobao.com的robot.txt 12345678User-agent: Baiduspider # 百度，你被完全屏蔽了Disallow: /User-Agent: Googlebot # 对google和bing开放Allow: /item.htmUser-agent: BingbotAllow: /item.htm 搜索示例： 关键词搜索 - 百度 洗面奶 淘宝 搜不到淘宝的商品。 洗面奶 京东 能搜到京东的商品。 站点搜索 - 百度 site:www.taobao.com 洗面奶 竟然能搜索www.taobao.com/product/中的页面，点进去是无效商品链接 site:www.jd.com 洗面奶 能搜到京东的商品 京东 - 屏蔽一淘(阿里) 惠惠(网易)京东和阿里向来水火不容，京东不准用户使用支付宝支付，也因为新浪和阿里的关系不准用户用新浪微博登录。2011年10月，京东和当年淘宝屏蔽百度一样，毅然屏蔽了一淘搜索。失去京东这么大的一个电商平台，一淘可谓流年不顺。 12345678910User-agent: *Disallow: /?*Disallow: /pop/*.htmlDisallow: /pinpai/*.html?*User-agent: EtaoSpider # 屏蔽一淘Disallow: /User-agent: HuihuiSpider # 屏蔽惠惠购物助手Disallow: / 阿里旗下自家的比价产品一淘网曾因抓取京东的商品数据而被京东通过代码进行干扰，刘强东亦亲自出来抨击一淘网，但是嘴仗一时痛快，最终的结果却是一淘至今仍然可以索引京东，而京东的抗争只能是停止与支付宝的合作。 为什么taobao不屏蔽惠惠购物助手？ 这是阿里抛出的交易筹码，即如果比价软件想要全年抓取天猫淘宝等站的数据，作为与我这边发放通行证的交换，比价软件需要遵从的是在“双十一”期间主动阉割，否则就会尝到终身制的闭门羹。 参考–如何看待惠惠购物助手被迫在双十一期间停止比价功能？ amazon社交网络/媒体QQ空间QQ空间自05年诞生时就没有开放给百度与谷歌，和Facebook一样封闭。QQ的逻辑是要将QQ空间打造成一个巨大的闭环，唯一的搜索只能是旗下的搜搜。 2012年的时候，QQ空间也终于向百度与谷歌开放。 现在网友多数将自己的空间设置的为加密空间、非好友不能访问，所以里面的日志是没办法搜索； 新浪微博微信公众平台 - 屏蔽所有微信做了公众账号后，积累了大量高质量的作者和文章。为了对这种优质数据进行独家保护，微信利用robot协议，不允许所有搜索引擎进行内容抓取。 1234567User-Agent: *Allow: /$Allow: /debug/ # 微信公众平台接口调试工具Allow: /qa/ Allow: /wiki/Allow: /cgi-bin/loginpageDisallow: / # 公众号文章 后来，腾讯投资搜狗，开放微信数据供搜狗搜索独家使用，搜狗 微信搜素，将微信的公众号文章嵌入了搜狗搜索中。 Facebook - 屏蔽谷歌搜索Facebook屏蔽谷歌的原因也很简单，用户在Facebook上产生的内容势必会有能够带来商业价值的数据并且同时也涉及到用户隐私，所以Facebook也同样不会将这些数据轻易交付给第三方的。facebook至今仍然屏蔽谷歌搜索。 新闻站点默多克旗下新闻 - 屏蔽谷歌搜索，后来又开放从传统媒体起家的默多克，对于搜索引擎的态度相当不友善，默多克曾说搜索引擎是“网络寄生虫”。 默多克原话“他们是Google,他们是微软,他们是Ask.com,他们不应该免费获得内容,我想我们一直睡着了.”而默多克在09年开始展开计划，对谷歌等搜索引擎展开行动，对旗下多家新闻网站屏蔽搜索爬虫。 谷歌的回应也很简单明了”如果贵站不想在谷歌上出现，请修改贵站的robots文件即可“。不过到了2012年，默多克就投降了，默多克向谷歌认输，重新允许搜索抓取报纸网站。其实默多克的想法还是停留在传统的付费阅读的思维上，缺少对网络的深刻洞察。 搜索引擎 - 互相屏蔽 - 偷抓sogou、baidu、360、google 百度诉360违反Robots协议 一审判360赔偿70万360方面认为，Robots协议并不具有任何法律效力，而是百度利用了Robots协议自设白名单，谷歌、微软必应、雅虎、搜狗、SOSO等搜索引擎均可以抓取这些内容，唯独禁止360搜索抓取，属于打压竞争对手，涉嫌违反《反垄断法》。 网曝百度不顾robots协议擅自抓取微信内容 baidu通过大量抓取搜狗中的微信数据，将其放入搜索结果中，用于提升自己的搜索体验。 百度违反 Robots 协议抓搜狗数据，有图有真相有撕逼 - 知乎 搜狗与360曾互诉对方不正当竞争，并提出千万级别的索赔。 sogou偷爬baidu，baidu偷爬搜狗 http://weixin.sogou.com 2013年，百度诉奇虎360违反“Robots协议”抓取、复制其网站内容的不正当竞争行为一案，索赔金额高达一亿元 参考虎嗅-盘点那些robots的屏蔽恩怨历史 如果搜索引擎不遵守robot协议呢？搜索引擎不遵守robot协议，对网站都抓，会违法吗？ robot协议是规定还是法律，不遵守robot协议是道德问题还是法律问题？robots.txt 协议不是法律法规，也不是行业规范。但是一个搜索引擎声称自己遵守 robots.txt 协议那就有道德责任遵守。 ss如何在技术上反爬虫检查UA s","tags":[{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"},{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://yoursite.com/tags/搜索引擎/"},{"name":"域名","slug":"域名","permalink":"http://yoursite.com/tags/域名/"},{"name":"robot协议","slug":"robot协议","permalink":"http://yoursite.com/tags/robot协议/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"seo","slug":"CS/web/建站/seo","permalink":"http://yoursite.com/categories/CS/web/建站/seo/"}]},{"title":"【建站】汇总","date":"2018-02-24T16:00:00.000Z","path":"wiki/CS/web/建站/汇总/","text":"建站流程 购买域名 网站的托管服务器 完整案例 利用Github Pages搭建独立域名的个人博客 优化 SEO: Hexo中的SEO技巧 双线部署 CDN加速 背景 &amp; 原理 DNS解析之“记录类型” Github Pages托管静态博客-原理浅析 Coding Pages托管静态博客-原理浅析","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"}]},{"title":"网络分层","date":"2018-02-22T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/网络分层/","text":"Overview基本概念&nbsp;数据单元/格式TCP/IP层OSI层功能TCP/IP协议族典型设备主机层Dagta(数据)应用层7. 应用层网络进程到应用程序。针对特定应用规定各层协议、时序、表示等，进行封装。在端系统中用软件来实现，如HTTP等DHCP、Telnet、FTP、HTTP、SNMP、DNS网关6. 表示层数据表示形式，加密和解密，把机器相关的数据转换成独立于机器的数据。规定数据的格式化表示，数据格式的转换等&nbsp;&nbsp;5. 会话层主机间通讯，管理应用程序之间的会话。规定通信时序；数据交换的定界、同步，创建检查点等&nbsp;&nbsp;Segments(数据段)传输层4. 传输层在网络的各个节点之间可靠的分发数据包。所有传输遗留问题；复用；流量控制；可靠TCP UDP TLS/SSL&nbsp;媒介层&nbsp;网络层 Internet3. 网络层负责IP地址。在网络的各个节点之间进行地址分配、路由和(不一定可靠的)分发报文。路由(IP寻址)；拥塞控制分割和重新组合数据包IP ICMP BGP RIP路由器Bit/Frame数据帧链路层2. 数据链路层负责MAC地址。一个可靠的点对点数据直链。检错与纠错(CRC码)；多路访问；寻址WiFi ARP交换机、网桥、网卡Bit 比特流1.物理层一个(不一定可靠的)点对点数据直链。定义机械特性；电气特性；功能特性；过程特性&nbsp;调制解调器、中继器、集线器、同轴电缆、双绞线 https://en.wikipedia.org/wiki/Internet_protocol_suite Overview of TCP/IP Protocol Architectural Overview of the TCP/IP Protocol Suite Overview of TCP/IP protocols,摘自《Unix网络编程 chapter2》 七层 应用层应用层（Application Layer）提供为应用软件而设的界面，以设置与另一应用软件之间的通信。针对某个特定的用户应用程序（FTP、Telnet等）比如 HTTP Client与HTTP Server通信。 DNS client与DNS Server通信。 六层 表示层表示层（Presentation Layer）把数据转换为能与接收者的系统格式兼容并适合传输的格式。 五层 会话层会话层（Session Layer）负责在数据传输中设置和维护电脑网络中两台电脑之间的通信连接。 四层 传输层传输层（Transport Layer）把传输表头（TH）加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。例如:传输控制协议（TCP）等。 TCP使用不可靠的IP服务，但是它提供一种可靠的运输层服务；UDP为应用程序接收和发送数据报。但是UDP是不可靠的，它不保证数据报能安全无误的到达目的地。 三层 网络层在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。网络层将解封数据链路层收到的帧，提取数据包，包中封装有网络层包头，其中含有逻辑地址信息- -源站点和目的站点地址的网络地址。 IP是网际层的主要协议，同时被TCP和UDP使用；ICMP是IP的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要的信息；IGMP是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。 数据的路径选择(分组的选路)、转发，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络数据。例如:互联网协议（IP）等。 寻址路由器根据IP地址进行寻址，通过路由表路由协议产生 对网络层而言使用IP地址来唯一标识互联网上的设备，网络层依靠IP地址进行相互通信。 路由/转发在同一个网络中的内部通信并不需要网络层设备，仅仅靠数据链路层就可以完成相互通信，对于不同的网络之间相互通信则必须借助路由器等三层设备。 数据包的转发，不在同一个局域网，他们彼此之间是不认识的，那么就不得不通过其他媒介，寻找到适当的方式才可以传输数据。 二层 链路层二层交换，只能解决同一个局域网(彼此认识，mac地址)内的数据交换。 物理地址寻址、数据的成帧、流量控制、数据的检错、重发等 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络数据。例如:互联网协议（IP）等。 设备驱动程序及接口卡 ARP（地址解析协议）和RARP（逆地址解析协议）是某些网络接口使用的特殊协议，用来转换IP层和网络接口层使用的地址。 交换机根据MAC地址寻址，通过站表选择路由，站表的建立和维护由交换机自动进行 一层 物理层物理层（Physical Layer）在局部局域网上传送帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机适配器等 疑问为什么要平行层通信？因为其它层看不懂该协议。(其他协议看不懂) 我觉得，也可以理解成相邻层之间的协议。比如 web中的后台与前台协定的数据格式，是不同层之间的协议。因为后台数据是给前台用的，前台http。 网络协议中，相邻层之间的 VPN算在哪个层？算网路协议吗？按道理应该算协议，客户端和服务端都要遵守的约定。应该算在应用层吧。–by xs vpn在IP层工作，而ss在TCP层工作 proxy算在哪个层？应用层吧，至少socket之上 html5提出的websocket协议属于应用层 待看/其他参考 OSI-7层模型-wiki 网络传输协议-四层模型-wiki 所有的网络请求底层协议是不是都是TCP/IP？ ss","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"}]},{"title":"路由器","date":"2018-02-22T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/5. 第三层 网络层/路由器/","text":"路由器是怎样做到连接不同网络的？用到的关键技术有什么？路由器的好处是为不同类型的物理网络提供连接：以太网、令牌环网、点对点的链接和FDDI（光纤分布式数据接口）等等。 现在网关这个术语只用来表示应用层网关：一个连接两种不同协议族的进程（例如，TCP/IP和IBM的SNA），它为某个特定的应用程序服务（常常是电子邮件或文件传输）。 不在同一 应用层和运输层使用端到端（End-to-end）协议。在图中，只有端系统需要这两层协议。但是，网络层提供的却是逐跳（ Hop-by-hop）协议，两个端系统和每个中间系统都要使用它。","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"5. 第三层 网络层","slug":"CS/network/网络协议-OSI七层模型/5-第三层-网络层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/5-第三层-网络层/"}]},{"title":"经典的web编辑器--CKEditor","date":"2018-02-22T16:00:00.000Z","path":"wiki/CS/tools/formatting/html-富文本编辑器/CKEditor/","text":"快速搭建CKEditorCKEditor CDN 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;CKEditor&lt;/title&gt; &lt;script src=\"https://cdn.ckeditor.com/4.8.0/standard/ckeditor.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;textarea name=\"editor1\"&gt;&lt;/textarea&gt; &lt;script&gt; CKEDITOR.replace( 'editor1' ); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 保存为html，双击打开即可。Online Demo 源码https://github.com/ckeditor/ckeditor-dev CKFinder没有CKFinder，CKEditor作为一个编辑器，也是可以正常使用的，但是无法在编辑器里浏览服务器上的用户上传文件。所以要整合CKFinder。 需要后台服务器。(用于文件上传、存储)。支持java php .net等语言 其他编辑器 Tinymce 为知笔记也不错，但不开源 参考https://www.ibm.com/developerworks/cn/web/1012_moying_ckeditor/index.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"html-富文本编辑器","slug":"CS/tools/formatting/html-富文本编辑器","permalink":"http://yoursite.com/categories/CS/tools/formatting/html-富文本编辑器/"}]},{"title":"抓包原理","date":"2018-02-08T16:00:00.000Z","path":"wiki/CS/network/tools/-抓包原理/","text":"wireshark原理，见wireshark目录","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"}]},{"title":"wireshark常见问题","date":"2018-02-08T16:00:00.000Z","path":"wiki/CS/network/tools/wireshark/-wireshark常见问题/","text":"抓不到http包wireshark抓取的http协议包在数据传输过程中显示的是TCP协议，只有建立连接和断开连接那几个包才显示为http filter采用http，有时会出现没有包。why？ 如何抓取手机包？","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"}]},{"title":"wireshark原理","date":"2018-02-08T16:00:00.000Z","path":"wiki/CS/network/tools/wireshark/-wireshark原理/","text":"wireshark是开源的。 ##","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"tools","slug":"CS/network/tools","permalink":"http://yoursite.com/categories/CS/network/tools/"},{"name":"wireshark","slug":"CS/network/tools/wireshark","permalink":"http://yoursite.com/categories/CS/network/tools/wireshark/"}]},{"title":"反演 百度DNS解析规则","date":"2018-02-08T16:00:00.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/DNS/DNS解析实例-baidu/","text":"Overview域名系统（DNS）是一种用于 TCP/IP应用程序的分布式数据库，它提供主机名字和IP地址之间的转换及有关电子邮件的选路信息。 通常情况下，我们是先设定DNS解析规则，然后ISP(供应商)依据指定的解析规则进行DNS解析。同样，我们通过测试解析结果，也可以反推DNS解析规则。本文以百度首页为例，分析其DNS解析规则。 DNS地址解析器的核心功能能 gethostbyname 主机名–&gt;ip gethostbyaddr ip–主机名 分析方式一：通过抓包，分析DNS查询和响应报文。每个响应报文对应一条DNS解析规则，通过一条或者多条记录才能完成DNS解析。 分析方式二：一堆命令，见参考博客。 参考 https://aslibra.com/blog/post/use_dig_dns_check.php通过dig命令理解DNSdig挖出DNS的秘密 百度DNS解析规则 编号 主机记录 记录类型 解析线路(isp) 记录值 TTL值(不定) 备注 1 www.baidu.com CNAME – www.a.shifen.com 268 2 www.a.shifen.com CNAME – www.wshifen.com 271 3 www.wshifen.com A 新加坡 百度 45.113.192.101 160 “1-2-[3 4]” 4 www.wshifen.com A 北京电信 220.181.111.188 160 wshifen.com NS – ns1.wshifen.com 163 很多name server baidu.com A 北京移动 111.13.101.208 见解析方式二 baidu.com A 北京联通… 123.125.114.144 baidu.com SOA – dns.baidu.com 900 见解析方式四 baidu.com NS – ns1.baidu.com baidu.com NS – ns2.baidu.com dns.baidu.com A 202.108.22.220 67498 这里只有一个A记录吗？为什么TTL这么高？ ns1.baidu.com A 202.108.22.220 27780 为什么和上个记录同IP？ ns2.baidu.com A 61.135.165.235 86400 shifen.com. NS ns1.baidu.com shifen.com. A 202.108.250.218 shifen.com SOA dns.shifen.com dig shifen.com soa dns.shifen.com A 202.108.250.228 dig dns.shifen.com a.shifen.com NS – ns1.a.shifen.com 397 见解析方式五 ns1.a.shifen.com A 61.135.165.224 600 注：所有解析路线由ip.cn提供。 www.wshifen.com 没有NS记录，没有SOA记录。dig www.wshifen.com ns。没有answer，即没有ns记录dig wshifen.com ns，有answer 解析方式一: 1–&gt;2 （www.baidu.com，查询类型A，即查询IPv4地址）123456789101112131415161718192021# 一会功夫变成102了# DNS响应一般为多个ip，后续连接只用一个ip$ ping www.baidu.comPING www.wshifen.com (45.113.192.102) 56(84) bytes of data.64 bytes from 45.113.192.102: icmp_seq=1 ttl=43 time=87.3 ms$ wget www.baidu.com--2018-03-08 11:30:32-- http://www.baidu.com/Resolving www.baidu.com (www.baidu.com)... 45.113.192.102, 45.113.192.101Connecting to www.baidu.com (www.baidu.com)|45.113.192.102|:80... connected.HTTP request sent, awaiting response... 200 OK$ dig www.baidu.com;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 337 IN CNAME www.a.shifen.com.www.a.shifen.com. 191 IN CNAME www.wshifen.com.www.wshifen.com. 110 IN A 45.113.192.102www.wshifen.com. 110 IN A 45.113.192.101 解析方式二：9 （baidu.com，查询类型A） 123456789101112131415161718192021# 这种域名一般情况下是不能做cname解析的，只能用A记录$ ping baidu.comPING baidu.com (111.13.101.208) 56(84) bytes of data.64 bytes from 111.13.101.208: icmp_seq=1 ttl=45 time=13.8 ms# DNS中没有对baidu.com做CNAME记录，貌似。# 为什么浏览器重定向到http://www.baidu.com/？ 后面章节会介绍$ wget baidu.com--2018-03-08 11:32:10-- http://baidu.com/Resolving baidu.com (baidu.com)... 111.13.101.208, 220.181.57.216Connecting to baidu.com (baidu.com)|111.13.101.208|:80... connected.HTTP request sent, awaiting response... 200 OK#$ dig baidu.com;; QUESTION SECTION:;baidu.com. IN A;; ANSWER SECTION:baidu.com. 345 IN A 111.13.101.208baidu.com. 345 IN A 220.181.57.216 解析方式三: 1–&gt;5–&gt;8 （www.baidu.com，查询类型AAAA，即查询IPv6地址） 请求路线： www.baidu.com 未找到AAAA记录，走CNAME记录1 www.a.shifen.com 未找到AAAA记录，走CNAME记录5 www.wshifen.com 找到NS记录，返回 抓包内容123456789101112131415161718192021222324252627# 目前使用IPv6的还是极少数，所以得不到AAAA记录的。# DNS响应报文中的资源记录部分：回答字段、授权字段和附加信息字段，均采用一种称为资源记录RR（ Resource Record）的相同格式。#Domain Name System (response) Questions: 1 Answer RRs: 2 Authority RRs: 1 Additional RRs: 0 Queries www.baidu.com: type AAAA, class IN Answers # 回答字段 www.baidu.com: type CNAME, class IN, cname www.a.shifen.com Name: www.baidu.com Type: CNAME (Canonical NAME for an alias) (5) CNAME: www.a.shifen.com www.a.shifen.com: type CNAME, class IN, cname www.wshifen.com Name: www.a.shifen.com Type: CNAME (Canonical NAME for an alias) (5) Class: IN (0x0001) Time to live: 271 Data length: 14 CNAME: www.wshifen.com Authoritative nameservers # 授权字段 wshifen.com: type SOA, class IN, mname ns1.wshifen.com Name: wshifen.com Type: SOA (Start Of a zone of Authority) (6) Primary name server: ns1.wshifen.com baidu_dns_master.baidu.com dig 内容12345678910$ dig www.baidu.com AAAA;; QUESTION SECTION:;www.baidu.com. IN AAAA;; ANSWER SECTION:www.baidu.com. 4 IN CNAME www.a.shifen.com.www.a.shifen.com. 174 IN CNAME www.wshifen.com.;; AUTHORITY SECTION:wshifen.com. 250 IN SOA ns1.wshifen.com. baidu_dns_master.baidu.com. 1803080001 60 30 2592000 3600 解析方式四：11 （baidu.com，查询类型AAAA）1234567891011Domain Name System (response) Questions: 1 Answer RRs: 0 Authority RRs: 1 Queries baidu.com: type AAAA, class IN Authoritative nameservers baidu.com: type SOA, class IN, mname dns.baidu.com Name: baidu.com Type: SOA (Start Of a zone of Authority) (6) Primary name server: dns.baidu.com 123456$ dig baidu.com AAAA;; QUESTION SECTION:;baidu.com. IN AAAA;; AUTHORITY SECTION:baidu.com. 4581 IN SOA dns.baidu.com. sa.baidu.com. 2012138564 300 300 2592000 7200 解析方式五: 12 （www.a.shifen.com，查询类型AAAA）123456789$ dig www.a.shifen.com AAAA;; QUESTION SECTION:;www.a.shifen.com. IN AAAA;; ANSWER SECTION:www.a.shifen.com. 34 IN CNAME www.wshifen.com.;; AUTHORITY SECTION:wshifen.com. 235 IN SOA ns1.wshifen.com. baidu_dns_master.baidu.com. 1803080001 60 30 2592000 3600 疑问 &amp; 剖析编号1中，别名www.a.shifen.com的作用觉得没啥用啊。看看网上的说法： 使用CNAME有个好处就是，我IP地址去做改动的时候不需要去DNS运营商上面做改动，只需要自己的服务器做改动就好，方便自己的域名与实际IP地址做对应。 –觉得没什么道理啊 百度弄的一个域名保护壳。？ CDN加速节点？ 逆向思维吧。如果没什么用，为什么要保留呢？是不是还有点作用？ 编号2,3中，多条A记录的作用 可用于多线智能解析，为了每条线路（电信、联通/网通、移动等）上的用户都能最快访问站点 可用于简单的负载均衡(dns轮询) 可HA(高可用) 关于返回主机(IP)的策略考虑的因素有： 智能解析线路 用户所在网络的网络运行商类型、区域 距离–跳数 当我一个IP到DNS上面请求DNS域名解析的时候，DNS系统会根据你的IP地址所到达的域名对应的IP地址中路由跳数最小的那个IP地址作为访问的IP地址，具体你可以用LINUX的NSLOOKUP来查看域名所对应的IP地址，然后用PC的TRACERT的功能把所有DNS解析出来的IP地址进行跳数记录，然后在访问该域名，查看具体是哪个地址解析给你的PC。 为什么无法直接访问www.a.shifen.com 流程： [1,2,3,4] - DNS解析 [5,6,7] - 三次握手，建立TCP连接 [8] - 发送HTTP Get请求 [9] - 服务器返回RST复位信号，强制关闭TCP连接 服务器成功收到了HTTP Get请求，后台逻辑认为这个连接不符合规范()。所谓baidu定义的规范那应该就是服务器检查host，非baidu.com或s就拒绝访问。 抓包貌似看不到整个路由，是吗？如何分析整个路由？。。 为什么访问 baidu.com 会跳转到 www.baidu.com ？baidu.com返回的页面如下：123&lt;html&gt;&lt;meta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"&gt;&lt;/html&gt; 表示0秒之后跳转到www.baidu.com主页。这种叫做HTML redirections。并非30X 重定向。参考 参考https://www.zhihu.com/question/36891472/answer/69455356 http://skyrover.me/2017/02/19/BAIDU%E7%9A%84DNS%E8%A7%A3%E6%9E%90/","tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"},{"name":"dns","slug":"dns","permalink":"http://yoursite.com/tags/dns/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"DNS","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS/"}]},{"title":"矢量图的制作","date":"2018-02-06T13:08:53.000Z","path":"wiki/CS/tools/绘图工具/矢量图制作/","text":"矢量图制作入门级(并不低级)： powerpoint: 首先group元素，然后save as png/emf。如需要svg，可再用Inkscape转化。 visio: Inkscape 功能貌似很强大，但我用过它的格式转化功能。实例图片 专业级： Adobe Illustrator Corel Draw TeX and PGF/TikZ 示例 流程图visioiGrafx（流程图） online工具: http://picresize.com/ Google Drawings – web-based diagramming https://tool.lu/favicon/ 1616 3232 转化 ico制作","tags":[{"name":"矢量图","slug":"矢量图","permalink":"http://yoursite.com/tags/矢量图/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"绘图工具","slug":"CS/tools/绘图工具","permalink":"http://yoursite.com/categories/CS/tools/绘图工具/"}]},{"title":"DL next","date":"2018-02-06T13:08:53.000Z","path":"wiki/ML/deep learning/next/-DL Next/","text":"DL future底层 nvidia-cda AMD microsoft中层高层 google带记忆的网络 新思路 发现复用的pattern， 第四种分形复用， deep-fusion-network 通用人工智能 超大网络，大部分神经元休眠。！！！！！！！！未来神经网络是可演化，优胜劣汰，遗传变异。","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"next","slug":"ML/deep-learning/next","permalink":"http://yoursite.com/categories/ML/deep-learning/next/"}]},{"title":"【神经网络] Going Deeper","date":"2018-02-06T13:08:53.000Z","path":"wiki/ML/deep learning/next/-very-deep/","text":"residual &amp; highway 发展历程Highway Networks既然LSTM gate 也是为了解决 Information flow，有没有其他方式去解决？更直观一点的，不通过 gradient 的？既然 information 像被阻隔了一样，我们就“暴力”让它通过一下，给它们来个特权——在某些 gate 上，你就不用接受“审查”（transform）了，直接通过吧。这像高速公路一样——于是就有了这个名字，Highway Networks（HW-Nets）。 （gate直接等于1吗？） Deep Residual Learning for Image RecognitionIdentity Mappings in Deep Residual Networks分析了 ResNet 中 Identity mapping 为什么比较好，为何能让梯度在网络中顺畅的传递而不会爆炸或消失 Residual Net 核心思想是，去拟合残差函数 F （F = y - h（x）），选 h(x)=x 时效果最好。 code torch (lua) resnet-1k-layers by Kaiming He fb.resnet.torch 待看blog","tags":[],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"next","slug":"ML/deep-learning/next","permalink":"http://yoursite.com/categories/ML/deep-learning/next/"}]},{"title":"【深度学习-RNN系列】GRU简介 & 源码实现","date":"2018-02-06T11:08:53.000Z","path":"wiki/ML/deep learning/model-basic/RNN/-lightRNN-GRU/","text":"简介 LSTM 计算较为复杂，参数也非常多，难以训练。GRU（Gated Recurrent Units）应运而生。 在 GRU 中，大幅简化了 LSTM 结构 背后的逻辑 新增 reset gate，即图中的 r 开关； 将输入门和遗忘门合并为“update gate”，即图中的 z 开关； 将细胞状态 C 和隐藏状态 m 合并为 h； 省掉了输出门； 应用实例 百度的Deep speech2 GRU的实现源码GRU-tensorflow1234567891011121314151617181920def call(self, inputs, state): \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\" gate_inputs = math_ops.matmul( array_ops.concat([inputs, state], 1), self._gate_kernel) gate_inputs = nn_ops.bias_add(gate_inputs, self._gate_bias) value = math_ops.sigmoid(gate_inputs) r, u = array_ops.split(value=value, num_or_size_splits=2, axis=1) r_state = r * state candidate = math_ops.matmul( array_ops.concat([inputs, r_state], 1), self._candidate_kernel) candidate = nn_ops.bias_add(candidate, self._candidate_bias) c = self._activation(candidate) new_h = u * state + (1 - u) * c return new_h, new_h pytorch缺陷参考 Understanding LSTM Networks | colah Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling Evolution: from vanilla RNN to GRU &amp; LSTMs","tags":[{"name":"gru","slug":"gru","permalink":"http://yoursite.com/tags/gru/"},{"name":"rnn","slug":"rnn","permalink":"http://yoursite.com/tags/rnn/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"【深度学习-RNN系列】递归神经网络 RNN (从HMM到RNN)","date":"2018-02-06T11:08:53.000Z","path":"wiki/ML/deep learning/model-basic/RNN/0. RNN-basic/","text":"简介 递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。时间递归神经网络的神经元间连接构成矩阵，而结构递归神经网络利用相似的神经网络结构递归构造更为复杂的深度网络。RNN一般指代时间递归神经网络。单纯递归神经网络因为无法处理随着递归，权重指数级爆炸或消失的问题（Vanishing gradient problem），难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。—— 维基百科 其他翻译 recurrent：“循环神经网络” recursive 递归神经网络 feedforward 总结 RNN解决了HMM的 双向RNN解决了上下文依赖问题 LSTM解决了RNN训练中梯度消失和梯度爆炸的问题 GRU取消了LSTM中的cell，结构上更加简单，在性能上，训练时间更短，epoch更小的情况下可以收敛。 序列建模的发展史 Memoryless models for sequences Markov: bi-gram, tri-gram, n-gram 严格的独立性假设条件，无法建模任意长度的上下文信息。 n-gram矩阵太大，太稀疏，(2-gram也很大很稀疏)。怎样解决？词典大小$V$， 详见HMM博客 HMM RNN HMM转移概率矩阵太大，这里可以认为是对其降维。 LSTM RNN与HMM 基本结构上是挺像的，都是通过hidden state 的演化来刻画 序列间的依赖关系 RNN与HMM的本质区别是RNN没有马尔科夫假设，可以考虑很长的历史信息。 隐状态的表示: hmm是onehot, RNN是分布表示，RNN的表示能力强很多，或者说在面对高维度时，表示效率更高。类似nlp里，对单个token的表示，一种是onehot, 一种是word vector 。 隐状态的演化方式: hmm是线性的，RNN是高度非线性。 在垂直方向上，实际中的lstm还会增加depth, 来增加不同层面的抽象表示，也会使得表示能力指数增加，随着depth 增加。 RNN也是基于马尔可夫假设的，当前的隐状态仅依赖前一个时刻的隐状态。在有马尔可夫假设的模型中，不代表距离超过1的两个状态是无依赖的。 印象中有paper证明， 在HMM中两个状态的依赖关系随距离指数衰减，而在RNN中是power law decay. 也就是大家通常说的 rnn可以略好的刻画 long term dependency. 另，SLAM中还有种算法跟hmm类似，kalman filter. https://www.zhihu.com/question/57396443/answer/263019702 RNN Overview 狭义上的RNN，指vanilla RNN。 广义上的RNN，lstm gru等都属于RNN框架。 该文章针对广义上的RNN。 RNN的核心思想就是利用当前时刻的输入$X_t$和上一时刻的隐状态$h_{t-1}$来计算$h_t$:1out, hidden = lstm(input, hidden) # 来自pytorch的抽象 $$ h_t = f(x_t, h_{t-1}) $$ 针对不同的任务又有不同的RNN形式 大部分应用都可归入该框架。具体的应用可参考karpathy 名词解释: hidden 也叫cell, hidden_state, cell_state。它是forget的关键 out 也叫 output， hidden cell output在stack RNN中也叫hidden output = new_state = Most basic RNN:1output = new_state = act(W * input + U * state + B) https://www.quora.com/How-is-the-hidden-state-h-different-from-the-memory-c-in-an-LSTM-cell vanilla RNN中没有cell，所以hidden=cell=outLSTM中 RNN的高层抽象 抽象不是实现，是API。由整体到局部，可把RNN当做一个黑盒子，有需求的情况下再细看其具体实现。 keras的RNN抽象123keras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)# return_sequences: 是否返回整个序列out# return_state: 是否返回整个序列的hidden 应用示例–lstm用于二分类： 1234model = Sequential()model.add(Embedding(num_words, 128)) # 输入整个sequencemodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) # 输出最后一个cell的outputmodel.add(Dense(1, activation='sigmoid')) # 二分类 这是上图中的many to one模式。 关于 关于静态图：sequence的数目固定为80 应用示例–基于lstm的seq2seq 1234567891011121314151617# Define an input sequence and process it.encoder_inputs = Input(shape=(None, num_encoder_tokens))encoder = LSTM(latent_dim, return_state=True)encoder_outputs, state_h, state_c = encoder(encoder_inputs)# We discard `encoder_outputs` and only keep the states.encoder_states = [state_h, state_c]# Set up the decoder, using `encoder_states` as initial state.decoder_inputs = Input(shape=(None, num_decoder_tokens))# We set up our decoder to return full output sequences,# and to return internal states as well. We don't use the# return states in the training model, but we will use them in inference.decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)decoder_dense = Dense(num_decoder_tokens, activation='softmax')decoder_outputs = decoder_dense(decoder_outputs) 应用示例–基于lstm的attention-seq2seq keras是对整个sequence做的抽象。因为keras是面向tensorflow和theano的静态图做的封装。 pytorch的RNN抽象应用示例–基于lstm的1234# for a sequence inputsfor input in inputs: # Step through the sequence one element at a time out, hidden = lstm(input, hidden) 1output, (h_n, c_n) = lstm(input, (h_0, c_0)) pytorch是动态图，会随着inputsequence 源码实现 tensorflow的抽象示例–基于lstm的语言模型 12lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)output, state = lstm(words, state) # 这里的输入和输出都是符号，类型是tf.placeholder，lstm参数是tf.variable BasicLSTMCell源码 基于RNN的变形（mainstream variation）cellcascade rnnchar-rnn + word rnn (Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation)char-cnn + word rnn (Exploring the Limits of Language Modeling) sequence labelingPart-of-speech Tagging attentionrnn new trends未分类recurrent highway network 框架 总结Sequence Modeling按照架构一般分为： Encoder 架构 Sequence Classification Sequence Labeling/Prediction Deep Encoder 架构 Encoder – Decoder 架构其中input和output都是sequence的架构，又叫seq2seq encoder: CNN：图片一般采用CNN，文本也可以采用CNN RNN: decoder: simple decoder: 通常是LSTM作为解码器[^seq2seq-NN][^seq2seq-MT][^seq2seq-Conversation]. encodes the “meaning” of the input sequence into a single vector of a fixed dimensionality. Then another deep LSTM to decode the target sequence from the vector. (only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence.map the input sequence)缺陷：只用了一个vector(context vector)表征输入序列压力太大(it carries the burden of encoding the entire sentence).解决: 整个序列都用 1. 一个简单的方式是对序列vector取均值，高大上点叫mean pooling 2. 对序列vector线性加权。难点：加权系数怎么来？因为这是不定长序列，不能像DNN那样放一个全连接参数W让模型去学。于是就出现了attention，以及self-attention。 attention decoder: LSTM+attention The decoder decides parts of the source sentence to pay attention to. It relieves the encoder from the burden of having to encode all information in the source sentence into a fixedlength vector.Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of attention weights. 列个表，input和output 参考[^RNN]: The Unreasonable Effectiveness of Recurrent Neural Networks[^seq2seq-NN]: Sequence to Sequence Learning with Neural Networks | nips 2014[^seq2seq-MT]: Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation | EMNLP 2014[^seq2seq-Conversation]: A Neural Conversational Model[]: 吴恩达《序列模型》精炼笔记 – 循环神经网络（RNN）","tags":[{"name":"rnn","slug":"rnn","permalink":"http://yoursite.com/tags/rnn/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"【深度学习-RNN系列】长短期记忆 LSTM （从RNN到LSTM）","date":"2018-02-06T11:08:53.000Z","path":"wiki/ML/deep learning/model-basic/RNN/LSTM/","text":"传统方法 Historyerror signals “flowing backwards in time” tend to either blow up or vanish。 bp算法中为什么会产生梯度消失？ | 知乎 LSTMLSTM网络是RNN的一种，专门设计用于解决long-term dependency/memory问题，1997年由 Hochreiter &amp; Schmidhuber提出。由于独特的设计结构，LSTM适合于处理和预测时间序列中间隔和延迟非常长的重要事件。 名字：long short-term memory意思是vanilla RNN是short-term memory，sequence太长， LSTM只能避免RNN的梯度消失（gradient vanishing）； 梯度膨胀(gradient explosion)不是个严重的问题，一般靠裁剪后的优化算法即可解决，比如gradient clipping（如果梯度的范数大于某个给定值，将梯度同比收缩）。下面简单说说LSTM如何避免梯度消失. 梯度弥散是什么鬼？ cell: memory_cell 关于梯度消失问题梯度消失问题–直观解释 传统RNN中存在的梯度消失。 梯度消失 – 产生的原因本质原因就是因为矩阵高次幂导致的 在多层网络中，影响梯度大小的因素主要有两个：权重和激活函数的偏导。 深层的梯度是多个激活函数偏导乘积的形式来计算，如果这些激活函数的偏导比较小（小于1）或者为0，那么梯度随时间很容易vanishing；相反，如果这些激活函数的偏导比较大（大于1），那么梯度很有可能就会exploding。因而，梯度的计算和更新非常困难。 https://www.zhihu.com/question/34878706 参考: BP Through Time and Vanishing Gradients Chapter 4: LSTM | Supervised Sequence Labelling with Recurrent Neural Networks 关于valve的比喻 梯度消失问题 – 解决方案见后续的gate 梯度消失问题 – LSTM是如何避免的1、当gate是关闭的，那么就会阻止对当前信息的改变，这样以前的依赖信息就会被学到。2、当gate是打开的时候，并不是完全替换之前的信息，而是在之前信息和现在信息之间做加权平均。所以，无论网络的深度有多深，输入序列有多长，只要gate是打开的，网络都会记住这些信息。 上面这个例子中，数据从实心1向后传递。通过gate的配合，成功在节点4和6输出该数据。数据流(梯度)不会因long-term传输而消失，有效解决RNN的梯度消失问题。即梯度保持 用数学来表达，就是f=1,i=0，那么就状态保持(完整)。f=0，i=1就状态遗忘(后面也LSTM的变种，采用i=1-f)。 当gate是关闭的，那么就会阻止对当前信息的改变，这样以前的依赖信息就会被学到。 当gate是打开的时候，并不是完全替换之前的信息，而是在之前信息和现在信息之间做加权平均。所以，无论网络的深度有多深，输入序列有多长，只要gate是打开的，网络都会记住这些信息。 参考 LSTM | Sepp Hochreiter 1997 LSTM的设计思想LSTM的核心：cell + gate。用于解决传统RNN中的梯度消失问题 (Gradient Vanish) 关于gate gate，即阀门、开关。取值范围[0,1]，0表示关闭，1表示通行 使用一个合适激活函数，它的梯度在一个合理的范围。LSTM使用gate function，有选择的让一部分信息通过。gate是由一个sigmoid单元和一个逐点乘积操作组成，sigmoid单元输出1或0，用来判断通过还是阻止，然后训练这些gate的组合。所以，当gate是打开的（梯度接近于1），梯度就不会vanish。并且sigmoid不超过1，那么梯度也不会explode。 LSTM信息流 包括：input gate, output gate, forget gate Gates are a way to optionally let information through. 待看 An Empirical Exploration of Recurrent Network Architectures. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. 关于cell的设计$h_t$在RNN中承担两个角色: 作为当前时刻的output，用于prediction 作为当前时刻的hidden state，用于时序信息的传递 LSTM将这两个角色拆分为 $h_t$和$C$，这样LSTM中的隐状态实际上就是$C$了，$h_t$作为output。通过这样的设计，输出层只利用$h_t$的信息，而不直接利用内部cell的值 $C$。 x和h_t-1做一个拼接，过sigmoide得到forget-gate。forget-gate作用在c_t-1上。 为什么要设计cell？这样抽象的意义？ LSTM中c和h的区别: 仅仅是一个输出门的区别(c没过输出门，h_t-1作为上一时刻的输出，要过输出门)。 c与x拼接送入forget gate呢？ forget作用在h上呢？ https://zhuanlan.zhihu.com/p/28919765 GRU中合并了cell state和和hidden state 关于激活函数sigmoidsigmoid之类的大量用在rnn的门也并非是概率解释的问题。而是理想门函数是阶跃函数，但其本身不可导，所以soft成sigmoid是一种折中。而且rnn中sigmoid陷入饱和区本身也是一件无所谓的事儿，因为门的作用本身就是通过与不通过，他希望的就是激活值大量集中在0/1附近而不是其他的连续值。 为什么rnn中sigmoid陷入饱和区本身也是一件无所谓的事儿？不影响梯度消失？ tanh为什么用tanh不用ReLU？ 在CNN等结构中将原先的sigmoid、tanh换成ReLU可以取得比较好的效果。为什么在RNN中，将tanh换成ReLU不能取得类似的效果？ 从信号处理的方式说，要保证系统稳定。类似线性系统极点要在单位圆里，非线性直接加个激活卡住。所以简而言之：Relu不行，越界了；sigmoid差一半平面；只有tanh刚好。tanh还有个好处是零点梯度为1，这个性质比sigmoid好，relu在右半平面也是1，但越界不稳定，然并卵了。 参考：https://www.zhihu.com/question/61265076/answer/239987704 接口设计12output, (h_n, c_n) = lstm(input, (h_0, c_0)) # pytorch的接口new_h, (new_c, new_h) = lstm(inputs, (c, h)) # tensorflow的接口，其中state=(c, h) LSTM可以看做有两个隐状态h和c，对应的隐层就是一个Tuple。这里可以对比RNN的接口。 在RNN中 $output = c_t = h_t$，即$h$既是hidden state又是output 为什么lstm代码里和有些图里，习惯吧output称作h(hidden)？ 前面已经解释了 这里为什么要用 tuple 呢？直接把它们拼成一个 Tensor 不行吗，tuple 还得一个一个遍历，这多麻烦？ 不行。因为多层 RNN 并不需要每一层都一样大，例如有可能最底层维度比较高，隐层单元数较大，越往上则隐层维度越小。这样一来，每一层的状态维度都不一样，没法 concat 成一个 Tensor 啊！）；而这个大的 RNN 单元的输出则只有原先的最上层 RNN 的输出，即整体的 接口(对LSTM的封装)要具有良好的扩展性(水平扩展-sequence，垂直扩展-stack)。在stack lstm中，下一层的out对接上一层的input，在深度模型的概念里这就是隐含层hidden的作用，所以命名为hidden。 但是呢，作为一个cell，我还是觉得叫output比较好。追根溯源，谁第一个采用hidden命名的？ 为什么lstm代码里要把(c, h)封装成一个tuple？ 为什么不拼成一个tensor？ 为什么不用2个独立元素？ 这样设计的目的是为了兼容RNN的接口(毕竟LSTM属于RNN的一种)。另外 pytorch 源码 - LSTM tensorflow源码 - BasicLSTMCell example 应用示例应用示例–基于lstm的语言模型 12345lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)# current_batch_of_words不是sequence，只是for current_batch_of_words in words: # 这里的输入和输出都是符号，类型是tf.placeholder，lstm参数是tf.variable output, state = lstm(current_batch_of_words, state) LSTM: 实现In order to make the learning process tractable, it is common practice to create an “unrolled” version of the network, which contains a fixed number (num_steps) of LSTM inputs and outputs. The model is then trained on this finite approximation of the RNN. This can be implemented by feeding inputs of length num_steps at a time and performing a backward pass after each such input block. 为什么要限定长度?对于任意长度的序列，BP算法计算复杂，因此采用固定长度的序列。 LSTM: tensorflow实现 tensorflow源码 - BasicLSTMCell 12345678910111213141516171819202122232425# 源码精简版def call(self, inputs, state): \"\"\"Run one step of LSTM. Args: inputs: `2-D` tensor with shape `[batch_size, input_size]`. 是单个时间节点的batch样本 state: Returns: hidden state, new state (). \"\"\" c, h = state gate_inputs = math_ops.matmul( array_ops.concat([inputs, h], 1), self._kernel) gate_inputs = nn_ops.bias_add(gate_inputs, self._bias) # i = input_gate, j = new_input, f = forget_gate, o = output_gate i, j, f, o = array_ops.split( value=gate_inputs, num_or_size_splits=4, axis=one) forget_bias_tensor = constant_op.constant(self._forget_bias, dtype=f.dtype) # update new_c = add(multiply(c, sigmoid(add(f, forget_bias_tensor))), multiply(sigmoid(i), self._activation(j))) new_h = multiply(self._activation(new_c), sigmoid(o)) new_state = LSTMStateTuple(new_c, new_h) return new_h, new_state pytorch包装的好复杂，参考 https://blog.ddlee.cn/2017/05/29/LSTM-Pytorch%E5%AE%9E%E7%8E%B0/ 缺陷 难并行 计算量大 low rank approximation之类的参数控制，运算量会是对应RNN的四倍以上。所以Gating其实是一种代价很高的方法。 FAQ 汇总关于静态图和动态图？ LSTM为什么要设置cell？ cell state 和 hidden state的关系、区别？为什么lstm代码里和有些图里，习惯吧output称作h(hidden)？ 为什么要引入gate？ gate是点，还是向量？ 向量， decides what parts of the cell state we’re going to output LSTM为什么不用ReLU？ 其他参考 通俗经典之作–Understanding LSTM Networks BasicLSTMCell对应的paper–Recurrent Neural Network Regularization Supervised Sequence Labelling with Recurrent Neural Networks 地平线语音战略与研究 其他黄畅：我补充一点。关于 LSTM，不管你是单向的、双向的、摞一起的、不摞一起的，其实都有一个问题：信息传导的约束很强。换句话说，不管是做前向预测还是后向 BP（反向传播），一个信息从左边到右边，或者从开始到结束，都要经过很长的路径。而且在整个过程中，会有很多非线性的变化，尤其是 LSTM 这种典型的、很容易进入自我限制状态的模型。经过很多次这样的事情，就导致整个优化变得异常困难。这个结构天生就使得优化变得非常困难。 这是 LSTM 的弊病，它的结构设计有很大限制性。你可以类比一些其他结构，比如 ResNet，它通过建立 free-way 的方式，人为地架了很多 short-pass（短路径），使得本来在网络上距离很远的两个单元之间建立一些高速的快速通道。直观的理解就是可以让它们之间的信息沟通更加顺畅，减轻我前面说的那个问题。 更进一步，你会发现在语音识别中有人用完整的 CNN 替代 LSTM，包括讯飞、微软、百度。刚开始的时候 CNN 用得很浅，只是作为基本的局部表达，后来发现可以用 CNN 不断堆积，而且堆的很有技巧。在计算量不显著增加的情况下，这样就可以用 CNN 覆盖很大的语境。 就是说优化算法本身也许没有很好的进步，但是通过网络结构的设计可以规避目前主要基于 SGD 的优化算法难以解决的 LSTM 问题，直接构造一个更适合目前优化算法去优化的网络结构。所以本质上很难说哪个结构更好，你只能说这个结构更适合现在主流的这种优化方法。 其实论文出来时我稍微看了一点，它本质上好像和 attention model 很像。attention model 的概念是不管语境是怎么传过来的，总是有选择的看所有东西，做决策（比如生成一个词）的时候有选择的去做。这时候会产生一个 attention mask，这可以理解成一个 gate，封住一些不想看的东西，保留想看的。 这个在图像和 NLP 里面已经得到很好的验证。NLP、语音、图像其实都是相通的，你会发现很多思想、结构、设计理念会越来越相似。这也给了我们信心，让我们可以实现语音图像识别一体化交互，用一套统一的专用架构去做解决各种各样的问题。 FAQ","tags":[{"name":"gradient vanish","slug":"gradient-vanish","permalink":"http://yoursite.com/tags/gradient-vanish/"},{"name":"rnn","slug":"rnn","permalink":"http://yoursite.com/tags/rnn/"},{"name":"lstm","slug":"lstm","permalink":"http://yoursite.com/tags/lstm/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"deep learning","slug":"ML/deep-learning","permalink":"http://yoursite.com/categories/ML/deep-learning/"},{"name":"model-basic","slug":"ML/deep-learning/model-basic","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/"},{"name":"RNN","slug":"ML/deep-learning/model-basic/RNN","permalink":"http://yoursite.com/categories/ML/deep-learning/model-basic/RNN/"}]},{"title":"关于websocket","date":"2018-02-05T11:08:53.000Z","path":"wiki/CS/web/服务器推送/websocket/","text":"websocket属于服务器推送技术的一种。HTML5定义了 WebSocket 协议，以及相关的编程API，能更好的实现双向通信且节省服务器资源和带宽。 WebSocket 实际上指的是一种协议，与我们熟知的 Http 协议是同等的一个网络协议。用网络模型结构来解释的话， WebSocket 和 Http 协议都属于 应用层协议，两者都基于传输层协议 TCP。 http协议 http://ftp协议 ftp://websocket协议 ws:// Websocket是基于HTTP协议的，或者说借用了HTTP的协议来完成一部分握手。在握手阶段是一样的 背景以前的网站为了实现推送功能，使用的方法都是轮询。所谓的轮询就是在特定的时间间隔（例如1秒），由浏览器向服务器发出一个 Http request，然后服务器返回最新的数据给客户端浏览器，从而给出一种服务端实时推送的假象。由于Http Request的Header（请求头）很长,而传输的数据可能很短就只占一点点，每次请求消耗的带宽大部分都消耗在 Header上。从网上资料得知后来还有改进的轮询方法叫做 Comet，使用 Ajax。但这种技术虽然可达到双向通信，但依然需要发出请求，而且在Comet中，普遍采用了长链接，这也会大量消耗服务器带宽和资源。 流程 首先WebSocket 服务器启动，并监听端口 客户端new websocket(dfd)，建立连接 客户端的API (js)不同浏览器有不同的实现，但都提供的javascript API，所以客户端API都类似，或者可以统一API。 服务端的实现websocket服务器则因语言不同而提供不同的调用方式。 是叫实现，还是应该叫封装？ 基于java的实现 tomcat的websocket实现 jetty的websocket实现 基于nodejs的实现 服务器端的socket.io，搭配客户端js库socket.io-client 基于python的实现 基于shell的实现 WebSocketd 原理12345678GET /chat HTTP/1.1Host: server.example.comUpgrade: websocket ## 这个就是Websocket的核心了，告诉Apache、Nginx等服务器：注意啦，窝发起的是Websocket协议，快点帮我找到对应的助理处理~不是那个老土的HTTP。Connection: Upgrade ##Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==Sec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13Origin: http://example.com 参考 http://www.ruanyifeng.com/blog/2017/05/websocket.html https://en.wikipedia.org/wiki/Comparison_of_WebSocket_implementations 学习WebSocket协议—从顶层到底层的实现原理 WebSocket 是什么原理？为什么可以实现持久连接？ —很赞 理论联系实际：从零理解WebSocket的通信原理、协议格式、安全性 疑问 websocket是依赖TCP吗？ 如何debug websocket？方式一：在chrome inspect中查看websocket连接 network下的WS选项可以查看websocket连接。能看到Request连接:wss://echo.websocket.org/在frame中能看到明文数据，wss竟然也是明文传输 超详细教程 方式二：通过chrome console中命令查看12var webSocket = new WebSocket(&apos;ws://address:port&apos;);webSocket.onmessage = function(data) &#123; console.log(data); &#125; 方式三：在chrome internal里查看 chrome://net-internals/#sockets 方式四：通过抓包查看 见network/tools/wireshark/抓包 如何查看websocket发送的数据？浏览器inspect能看到websocket连接，为什么没看到发送的数据包？那么通过抓包总能够看到吧。 websocket的实现原理是什么？在TCP的基础上做了什么？加了header？ online demo socket.io的在线聊天室 webSocket.org Echo demo ## ##","tags":[{"name":"html5","slug":"html5","permalink":"http://yoursite.com/tags/html5/"},{"name":"websocket","slug":"websocket","permalink":"http://yoursite.com/tags/websocket/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"服务器推送","slug":"CS/web/服务器推送","permalink":"http://yoursite.com/categories/CS/web/服务器推送/"}]},{"title":"微信网页版 聊天原理","date":"2018-02-05T11:08:53.000Z","path":"wiki/CS/web/服务器推送/非websocket的例子/微信网页版--聊天原理/","text":"Overview微信网页版聊天，未采用websocket，而是基于long polling(长轮询)。 客户端消息发送客户端消息接收（伪服务端推送） 客户端间隔性发送http请求sync（每隔）源码; beauty后的源码 服务端对该请求延时返回，强制建立长连接 当服务端有需要推送的消息，即时在已建立的长连接中返回http response 客户端收到response后，立即发送一个新的http request goto 2 客户端发送http request客户端间隔性发送ajax请求 1234567891011Request URL: https://webpush.wx.qq.com/cgi-bin/mmwebwx-bin/synccheck?Referrer Policy: no-referrer-when-downgrade# Query String Parametersr: 151**skey: @crypt_d8e**sid: a5ne**uin: 1709**deviceid: e2387***synckey: 1_677803136|2_677803**_: 1517** 这是一个服务器端强制保持的长连接。 待看 网页微信的封装，直接在 Electron 里加载微信的网页版，并向其中注入一些代码 网页版微信抓包+注入实现表情贴纸显示 微信网页版的 JavaScript 实现，兼容Node和浏览器，微信机器人 微信网页版的 Python 实现，包含终端版微信及微信机器人 微信抢红包插件–基于安卓 微信聊天功能使用了什么协议？ 原理 教程 基于TLS1.3的微信安全通信协议mmtls介绍.—by 微信员工 疑问为什么不采用websocket?websocket占用资源多？不安全？socket连接数限制？低端浏览器不支持？手机浏览器不支持？知乎说，是因为懒","tags":[{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"},{"name":"推送","slug":"推送","permalink":"http://yoursite.com/tags/推送/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"服务器推送","slug":"CS/web/服务器推送","permalink":"http://yoursite.com/categories/CS/web/服务器推送/"},{"name":"非websocket的例子","slug":"CS/web/服务器推送/非websocket的例子","permalink":"http://yoursite.com/categories/CS/web/服务器推送/非websocket的例子/"}]},{"title":"【Markdown系列】marked渲染器","date":"2018-02-03T16:00:00.000Z","path":"wiki/CS/tools/formatting/markdown/render-marked/","text":"hexo博客默认采用marked引擎进行markdown解析。 online demo","tags":[{"name":"markdown","slug":"markdown","permalink":"http://yoursite.com/tags/markdown/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"markdown","slug":"CS/tools/formatting/markdown","permalink":"http://yoursite.com/categories/CS/tools/formatting/markdown/"}]},{"title":"【Markdown系列】语法进阶 (Advanced Markdown Tips)","date":"2018-02-03T16:00:00.000Z","path":"wiki/CS/tools/formatting/markdown/advanced-markdown-tips/","text":"Overview markdown语法简单方便，但要实现复杂的样式仍然要借助html标签。本文介绍常用的html标签，用于对markdown原生格式的增强。 常用的标签折叠块 &lt;summary&gt;你和猪，打一种动物 点击展开答案 象 源码：1234&lt;details&gt; &lt;summary&gt;点击展开答案&lt;/summary&gt; &lt;p&gt; 象&lt;/p&gt;&lt;/details&gt; 通常用于FAQ页面。 图片 &lt;img&gt;markdown的语法不支持图片大小，位置等样式。1![Alt text](图片链接 \"optional title\") 所以可采用&lt;img&gt;标签 1&lt;img align=\"middle\" alt=\"=&amp;quot;alternate_text&amp;quot;\" src=\"http://img5.2345.com/duoteimg/zixunImg/local/2016/03/18/14582940693488.gif\" title=\"hover\" width=\"20%\" /&gt; 对齐 (align) 学而不思则罔，思而不学则殆 —— 《论语》 1&lt;div style=\"text-align:right\" &gt;-- 《论语》&lt;/div&gt; 注释 (comment)不在页面显示，一般写给自己看，或者写给编辑者看(比如提交issue的模板中附带的注释) 方式一: 采用html注释标签 &lt;!-- 这里不会显示 --&gt; 方式二: 直接采用&lt;标签 &lt;这里不会显示&gt; 推荐方式一 代码块 (code block)个性化设置code block的样式1&lt;pre&gt;sample &lt;b&gt;sample&lt;/b&gt; sample&lt;/pre&gt; sample sample sample 123&lt;pre&gt;&lt;i&gt;&lt;a href=&quot;http://manpages.ubuntu.com/manpages/dapper/man1/prename.1.html&quot;&gt;rename&lt;/a&gt;&lt;/i&gt; sfds&lt;/pre&gt; rename sfds &lt;pre&gt;标签更灵活。但是，不能显示行号，需要自定义每个元素的格式。 code block不常用的语言diff样式用的不多，但比较实用。12345678public class Hello1&#123; public static void Main() &#123;- System.Console.WriteLine(\"Hello, World!\");+ System.Console.WriteLine(\"Rock all night long!\"); &#125;&#125; 动态链接 (link)这部分属于需要动态link，需要借助javascript。因此需要markdown render支持（比如MultiMarkdown），或者利用插件（比如hexo-reference） 链接的集中管理对link的集中管理，方便复用。 1234这是[链接一][1]，这是[链接二][2]。多次引用更方便、更简洁，[链接一][1]。 [1]: http://url1 [2]: http://url2 &quot;这是2的标题，可以试着把指针移到链接二上&quot; 这是链接一，这是链接二。多次引用更方便、更简洁，链接一。 脚注 (footnote) 马克飞象支持footnote，它采用的MultiMarkdown，已经停止开发了。 https://github.com/kchen0x/hexo-reference 123basic footnote[^demo][^demo]: basic footnote content [title](http://link) link总结集中link和脚注link最好都放在文档末尾。区别是，前者只提供link，后者明文显示参考文献。我更倾向于后者。 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— 维基百科 问题是否支持嵌入js？是否支持Markdown Inside HTML Blocks? Markdown in HTML does not work very well –来自官方文档 部分支持 &lt;div&gt; *Emphasized* text. &lt;/div&gt; &lt;div&gt; ## dfd &lt;/div&gt; 参考 Github-Markdown | 官方文档 Hexo-Markdown | 官方文档","tags":[{"name":"markdown","slug":"markdown","permalink":"http://yoursite.com/tags/markdown/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"markdown","slug":"CS/tools/formatting/markdown","permalink":"http://yoursite.com/categories/CS/tools/formatting/markdown/"}]},{"title":"tex 简介与编译流程","date":"2018-01-25T19:08:53.000Z","path":"wiki/CS/tools/formatting/-tex/-tex简介与编译流程/","text":"编译器PdfLaTexLaTexXeLaTex 我的简历在sharelatex上要用这个编译器XuaLaTex 区别是什么？ 编译流程问题为什么编译软件那么大，而js版编译工具却很小？(因为js要调用远程服务吗？)","tags":[{"name":"tex","slug":"tex","permalink":"http://yoursite.com/tags/tex/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"-tex","slug":"CS/tools/formatting/tex","permalink":"http://yoursite.com/categories/CS/tools/formatting/tex/"}]},{"title":"tex 在线编译工具","date":"2018-01-25T19:08:53.000Z","path":"wiki/CS/tools/formatting/-tex/-tex在线编译工具/","text":"工具首推 sharelatex已开源，很赞，可以自己架个服务跑https://github.com/sharelatex/sharelatex 是否支持gbk？ 用到了什么backend接口，可否全部前端？ SageMathCloud这个是Sage（一个志在超越MATLAB、Mathematica、Maple的数学软件）在线使用站点，同时也支持LaTeX文档的书写、编译、预览及查看，最方便的是原生提供了SageTeX的支持，绘制函数图像更方便，数学运算在文档内直接完成。 shareLatex对中文的支持 MathJax开源 支持tex吗？ 其他：js驱动的: MathQuill - WYSIWYG math using only HTML and CSS (开源)MathJax (开源)LaTeX4Web: a simple LATEX TO HTML converter (javascript) (开源)http://manuels.github.io/texlive.js/website/ (开源) 疑问cjk* 和cjk的区别","tags":[{"name":"tex","slug":"tex","permalink":"http://yoursite.com/tags/tex/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"formatting","slug":"CS/tools/formatting","permalink":"http://yoursite.com/categories/CS/tools/formatting/"},{"name":"-tex","slug":"CS/tools/formatting/tex","permalink":"http://yoursite.com/categories/CS/tools/formatting/tex/"}]},{"title":"一图知git","date":"2018-01-25T19:08:53.000Z","path":"wiki/CS/tools/同步与版本管理/git/一图知git/","text":"简介首先，这不是一个git命令教程，这是一个用于快速理解git命令的辅助文档。 用了git几年了，每次遇到疑难杂症都要现查，归其原因，是不了解git命令背后到底做了什么。 于是决定整理一下思路。 术语存储位置 工作区：working_directory，working_tree，workspace 暂存区：stage, index (加入到暂存区的更改：staged/indexed changes, add changes to stage/index) 本地仓库： local_repository, local_commit_history，history 远程仓库：remote_repository 快照：snapshot Blobs: 即files 文件状态 Untrack file：新文件，从未被add的文件。下一步操作往往是git add或者加入.gitignore中- changes Changes to be committed Changes not staged for commit 操作stage操作：git addcommit操作：git commit 指针指针指向实体 HEAD指针 正常状态: 指向一个 (确切说是named branch) Detached HEAD: 指向了anonymous branch，即 null: 不可能出现这个状态 master HEAD指针状态 实体hash 、、、什么区别？能写master~吗？能写 jkjdka~吗？ 参考 https://stackoverflow.com/questions/23303549/what-are-commit-ish-and-tree-ish-in-git 上图 有点紧凑，建议放大看 看图说话入门：git add : 读取工作区文件，写入暂存区 (1个箭头代表1个写操作) 进阶： git checkout \\&lt;branch>: 移动本地仓库中的HEAD指针到指定branch，更新index，更新工作区文件 (3个箭头) git reset –soft：撤销指定commit，移动HEAD (不涉及工作区、暂存区、远程仓库的操作) soft mixed hard三个参数的区别也一目了然… 所有涉及更改index区域的操作 git add git rm by listing files as arguments to the commit command (without –interactive or –patch switch), in which case the commit will ignore changes staged in the index, and instead record the current content of the listed files (which must already be known to Git); by using the -a switch with the commit command to automatically “add” changes from all known files (i.e. all files that are already listed in the index) and to automatically “rm” files in the index that have been removed from the working tree, and then perform the actual commit; by using the –interactive or –patch switches with the commit command to decide one by one which files or hunks should be part of the commit in addition to contents in the index, before finalizing the operation. See the “Interactive Mode” section of git-add[1] to learn how to operate these modes. 逆向操作(undo)12345678910111213141516171819202122232425git add # 加入indexgit reset –mixed HEAD # 撤销index 对不，是checkout吗？git commit #git reset –soft HEAD~ # 撤销尚未push的commitgit add + git commit #git push push不支持撤销操作 # 如何撤销已经push的commit？git push –force # 覆盖远程仓库提交历史(太狠) # 参考 https://www.borfast.com/blog/2014/10/19/how-to-undo-a-git-push---force-and-undelete-things/git rm file # 删除文件和indexgit checkout HEAD file # 恢复文件和index (index中已经没有该文件的信息，只能从仓库的HEAD中恢复文件)git rm -r dir # 删除整个目录及相应indexgit checkout HEAD dir # 恢复git add −pgit reset −pgit stashgit stash pop 两个git add 会怎样？会merge为一个吧？git add + rm 前面的add的changes就完全丢了吧？ If you don’t have uncommited changes for removed files, the 如何撤销已经push的commit？ 如何撤销已经force push的commit？ https://www.borfast.com/blog/2014/10/19/how-to-undo-a-git-push---force-and-undelete-things/ Reset 关于该图的改进 捡重要的命令放 (init clone不要放) 布局，整体，有点丑 待看https://github.com/geeeeeeeeek/git-recipes/blob/master/sources/%E6%A3%80%E5%87%BA%E4%BB%A5%E5%89%8D%E7%9A%84%E6%8F%90%E4%BA%A4.md 代码合并：Merge、Rebase 的选择重写项目历史常见工作流比较 参考 https://stackoverflow.com/questions/292357/what-is-the-difference-between-git-pull-and-git-fetch/292359 官方doc 图解git 待续","tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"}]},{"title":"Gist 从入门到精通到放弃","date":"2018-01-25T19:08:53.000Z","path":"wiki/CS/tools/同步与版本管理/git/github/gist/","text":"gist简介官方描述 Gists are a great way to share your work. You can share single files, parts of files, or full applications. 关键词: share, single, parts。gist的定位就在这几个词里。 详解 为了强调single和parts，gist对git进行阉割，禁用了directory功能。(貌似还禁用了pull功能) 为了强调share，在原来Clone的基础上，额外引入了Embed和Share两个功能。其中Embed(嵌入)实现了仅通过一行JS就能分享到网站(share your work in your website) 既然要share，那就不能没有feedback，这就像作presentation有问答环节一样。于是加入了comments功能。 Gist背后的Git库创建的每一个Gist的背后都对应着一个Git版本库 gist 推荐用法推荐用法 不宜用Gist 含图片等文件的项目 因为Gist不支持directory，file&amp;image最好放在其他地方。 最省事的方法：1. 在comment里upload image 2. 在gist doc中引用 3. 删除1中的comment 多个文件的项目 先在comments里写好doc 主doc不支持markdown preview 主doc有提交慢。因为主doc具有版本管理功能，comments不需要。所以频繁改动状态的doc也最好在comments里写，成形后再放入repo。 用embed js的方式发布gist 解决了多个blog的同步问题 节省blog服务器存储空间 host站点不支持嵌入js怎么办？ 知乎、博客、github.io都不支持js 存放ipynb文件 ipynb一般也是单文件程序(教程)，很适合用gist来管理 禁忌用法两个终端同时修改同一个comment，会已最后提交的为准，有内容丢失的风险（不可逆）。 gist 代码片段用法片段的优势体现在： embed。比如一篇博客里面，要贴个代码片段，可直接引用gist。 据说搜索也有优势 gistBox / cacher 用法技巧文件排序： 根据文件名的ascii排序，数字&gt; 大写&gt; 小写快捷键：用Ctrl或者Cmd按着鼠标多处点击进行多选!用中键或者alt进行拖动实现拉选! 缺陷 主doc不能preview gist embed方式嵌入页面，样式固定，不能自适应网站主题。另外背景是白色，不能融入网站的主题背景。- 疑问为什么要偏要对gist设置private和anonymous？git和wiki却没有，设计初衷是什么？ 为什么gist不开放directory？阉割了这个功能，图片等raw文件就不适宜放在gist了 gist不提供Pull Request功能？ 类似组件bitbucket的Snippets。 不提供embed嵌入方式 reference http://www.worldhello.net/gotgithub/06-side-projects/gist.html","tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"},{"name":"github","slug":"CS/tools/同步与版本管理/git/github","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/github/"}]},{"title":"利用Github Pages搭建独立域名的个人博客","date":"2018-01-25T19:08:53.000Z","path":"wiki/CS/web/建站/host/github-pages/利用Github-Pages搭建独立域名的个人博客/","text":"购买域名阿里云-万网 或其他供应商 了解更多域名 域名解析 (xusong.vip –&gt; xu-song.github.io)域名注册完成后首先需要做域名解析，域名解析就是把域名指向网站所在服务器的IP，让人们通过注册的域名可以访问到网站。 配置DNS解析进入你的阿里云DNS解析，选择你想要解析的域名，点击后面的解析。如下图所示： We recommend you change this to a CNAME record pointing at [YOUR USERNAME].github.io.– Github Help Github建议采用CNAME记录，为什么？ 因为IP有可能会变动，导致A记录失效吗？不是，是因为所有Github Pages共用ip，Github后台是根据host定位www目录的。详见Github Pages原理 阿里云建议采用A记录 因为A记录限制最少，最灵活，多条不会冲突 参考DNS解析-解析记录 重定向(xu-song.github.io –&gt; xusong.vip)配置github pages的custom domain进入你的github pages的仓库，然后在设置里面将的你的域名的地址，添加到custom domain中，然后保存即可。如下图所示： 这里是对github.io做了重定向，会重定向到所配置的站点。也可以随便填写一个站点，比如www.baidu.com，也会重定向过去 细心的同学会发现，配置custom domain后github仓库的根目录多了一个CNAME文件，里面正式刚刚配置的域名地址。 重新deploy，你会发现github page的domain设置又被改回去了，肿么办？原因是，hexo deploy时会采用git push --force。如果deploy版本没有CNAME文件，则会强制删除3.1中添加的CNAME文件，导致custom domain失效。 因此，最佳的方式是我们手动添加CNAME文件来设置domain。在source目录下新建CNAME文件，内容是xusong.vip。这样每次deploy会自动完成步骤3.1。 思考 为什么还要再github仓库中设置？dns解析不是已经做了重定向了吗。指向ip:80端口还不够吗？ 每个账号的gitpage都是独立的IP吗？github怎么这么多独立外网IP？还是不同账号共用IP？ 不同github page共享ip 正因为如此，才需要步骤3的设置。 配置github pages的custom domain，其作用仅仅是xu-song.github.io --&gt; xusong.vip (重定向)吗？ 思考题 - 答疑","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"domain","slug":"domain","permalink":"http://yoursite.com/tags/domain/"},{"name":"建站","slug":"建站","permalink":"http://yoursite.com/tags/建站/"},{"name":"pages","slug":"pages","permalink":"http://yoursite.com/tags/pages/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"},{"name":"github-pages","slug":"CS/web/建站/host/github-pages","permalink":"http://yoursite.com/categories/CS/web/建站/host/github-pages/"}]},{"title":"DNS解析之“记录类型”","date":"2018-01-25T19:08:53.000Z","path":"wiki/CS/network/网络协议-OSI七层模型/1. 第七层 应用层/DNS/DNS解析-资源记录/","text":"简介域名与IP之间的对应关系，称为”记录”（record）。根据使用场景，”记录”可以分成不同的类型（type）。 资源记录(RR: Resource Record)： 域名服务器记录类型列表 - 维基百科 常见的DNS记录类型参考1234567891011A: 将域名指向一个IPV4地址 #CNAME: 将域名指向另外一个域名 # 将域名指向另一个域名，再由另一个域名提供IP地址AAAA: 将域名指向一个IPV6地址 # 当您希望访问者通过IPv6地址访问您的域名时，可以使用AAAA记录。NS: 将子域名指向其他DNS服务器解析 # 如果需要把子域名交给其他DNS服务商解析，就需要添加NS记录。MX: 将域名指向邮件服务器地址 # 如果需要设置邮箱，让邮箱能收到邮件，就需要添加MX记录。SRV: 记录提供特定服务的服务器显性URL: 将域名302重定向到另外一个地址隐性URL: 与显性URL类似，但是会隐藏真实目标地址SOA记录: Start of Authority，始授权机构记录。NS用于标识多台域名解析服务器，SOA记录用于在众多NS记录中那一台是主服务器。SOA 资源记录表明此 DNS 名称服务器是为该 DNS 域中的数据的信息的最佳来源。PTR: 逆向查询记录（Pointer Record），只用于从IP地址查询域名，... 万网域名解析为什么没有301重定向？URL 重定向服务实际并非DNS 服务，它们在 HTTP 级别运行，而非 DNS 级别。使用URL转发的客户基本都是免费DNS的用户，当前业务暂不会投入支持。 优先级 单独设置的域名解析优先级高于泛域名解析 NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。 A记录优先于CNAME记录。即如果一个主机地址同时存在A记录和CNAME记录，则CNAME记录不生效 MX记录可以通过设置优先级实现主辅服务器设置，“优先级”中的数字越小表示级别越高。也可以使用相同优先级达到负载均衡的目的 主机记录主机记录就是域名前缀，常见用法有：1234567www: 解析后的域名为www.aliyun.com。@: 直接解析主域名 aliyun.com。*: 泛解析，匹配其他所有域名 *.aliyun.com。mail: 将域名解析为mail.aliyun.com，通常用于解析邮箱服务器。二级域名: 如：abc.aliyun.com，填写abc。手机网站: 如：m.aliyun.com，填写m。显性URL: 不支持泛解析（泛解析：将所有子域名解析到同一地址） @和WWW是两个主机名，可以指向不同的IP(A记录)或域名(CNAME记录) 可以为一个主机添加多个A记录 (1. 实现负载均衡，2. 可配合解析路线进行智能解析) 一个主机配置了CNAME记录，就不能再为该主机配置其他任何记录 (为啥呢？) 见 记录冲突判断规则 负载均衡的实现：负载均衡(Server Load Balancing，SLB)是指在一系列资源上面动态地分布网络负载。负载均衡可以减少网络拥塞，提高整体网络性能，提高自愈性， 并确保企业关键性应用的可用性。当相同子域名有多个目标地址时，表示轮循，可以达到负载均衡的目的，但需要虚拟主机服务商支持。 解析路线如果多个IP，搜索引擎线路 如果只有一个IP地址或CNAME域名，请务必选择【默认】。123默认: 必填！未匹配到智能解析线路时，返回【默认】线路设置结果。世界: 向除中国大陆以外的其他国家和地区，返回设置的记录值。 # 可用于双线部署，搜索引擎: 向搜索引擎爬虫的DNS，返回设置的记录值。 TTL（Time to live 的缩写 TTL为缓存时间，数值越小，修改记录各地生效时间越快。万网DNS的默认值为600，表示600秒之内不用重新查询。 查看解析是否生效怎样查看解析是否生效？ Windows 用户测试修改域名解析，实际上是在域名解析服务商处修改域名解析记录。修改的解析记录是否在用户端生效，既受运营商递归 DNS 服务器的直接影响，也受域名解析服务商提供的权威 DNS 服务器的间接影响。 测试本地运营商递归 DNS 服务器是否生效123$ nslookup eson.org服务器: ... # 一般返回的是最近的DNS服务器，Address: ... 测试域名解析服务商的权威 DNS 服务器是否生效。测试方法如下: 1$ nslookup eson.org dns25.hichina.com Linux测试dig 要检测的域名 @dns服务器地址 12345678910111213141516171819$ dig eson.org; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.17-Ubuntu &lt;&lt;&gt;&gt; eson.org;; global options: +cmd;; Got answer: # 为什么0个answer？;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 8309;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;eson.org. IN A;; AUTHORITY SECTION: # 不应该啊，我已经改回阿里的name server了eson.org. 3592 IN SOA hugh.ns.cloudflare.com. dns.cloudflare.com. 2027227883 10000 2400 604800 3600;; Query time: 112 msec;; SERVER: 9.0.146.50#53(9.0.146.50);; WHEN: Sun Mar 11 18:04:06 CST 2018;; MSG SIZE rcvd: 99 以上部分是不是延迟问题，明天再试试。 (Update: 第二天测试，果然解析到了xu-song.coding.me. ANSWER: 15, AUTHORITY: 0,) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758$ dig eson.org vip1.alidns.com; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.17-Ubuntu &lt;&lt;&gt;&gt; eson.org vip1.alidns.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 23319;; flags: qr rd ra; QUERY: 1, ANSWER: 15, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;eson.org. IN A;; ANSWER SECTION: # 这个就对了。我采用的双线部署。国内走coding.neteson.org. 600 IN CNAME xu-song.coding.me.xu-song.coding.me. 60 IN A 103.72.147.211xu-song.coding.me. 60 IN A 103.72.145.7xu-song.coding.me. 60 IN A 23.91.101.50xu-song.coding.me. 60 IN A 103.218.240.147xu-song.coding.me. 60 IN A 36.255.221.66xu-song.coding.me. 60 IN A 107.150.121.91xu-song.coding.me. 60 IN A 107.150.121.231xu-song.coding.me. 60 IN A 103.72.147.89xu-song.coding.me. 60 IN A 103.14.35.185xu-song.coding.me. 60 IN A 103.72.146.177xu-song.coding.me. 60 IN A 36.255.220.102xu-song.coding.me. 60 IN A 23.91.96.142xu-song.coding.me. 60 IN A 23.91.97.251xu-song.coding.me. 60 IN A 103.218.241.74;; Query time: 682 msec;; SERVER: 9.0.146.50#53(9.0.146.50);; WHEN: Sun Mar 11 18:05:55 CST 2018;; MSG SIZE rcvd: 292;; Got answer: # 为什么又有一个query &amp; answer？;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 52301;; flags: qr rd ra; QUERY: 1, ANSWER: 9, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;vip1.alidns.com. IN A;; ANSWER SECTION: # 这是什么鬼？vip1.alidns.com. 600 IN A 14.1.112.11vip1.alidns.com. 600 IN A 140.205.29.113vip1.alidns.com. 600 IN A 106.11.30.113vip1.alidns.com. 600 IN A 116.211.173.151vip1.alidns.com. 600 IN A 106.11.41.151vip1.alidns.com. 600 IN A 140.205.1.1vip1.alidns.com. 600 IN A 121.29.51.151vip1.alidns.com. 600 IN A 140.205.228.51vip1.alidns.com. 600 IN A 47.88.44.151;; Query time: 389 msec;; SERVER: 9.0.146.50#53(9.0.146.50);; WHEN: Sun Mar 11 18:05:56 CST 2018;; MSG SIZE rcvd: 188 以上命令，第二天竟然变回了cloudflare的name server。why？ 1234;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1...AUTHORITY SECTION:eson.org. 3600 IN SOA hugh.ns.cloudflare.com. dns.cloudflare.com. 过几天又变回来了。 12345678910111213141516171819202122232425262728293031323334353637383940414243$ dig eson.org dns25.hichina.com; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.17-Ubuntu &lt;&lt;&gt;&gt; eson.org dns25.hichina.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 18683;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;eson.org. IN A;; AUTHORITY SECTION: # 这个也有延迟啊。什么情况？dns25.hichina.com与vip1.alidns.com什么区别？是不是有个根节点?eson.org. 3404 IN SOA hugh.ns.cloudflare.com. dns.cloudflare.com. 2027227883 10000 2400 604800 3600;; Query time: 115 msec;; SERVER: 9.0.146.50#53(9.0.146.50);; WHEN: Sun Mar 11 18:07:14 CST 2018;; MSG SIZE rcvd: 99;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 31080;; flags: qr rd ra; QUERY: 1, ANSWER: 8, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;dns25.hichina.com. IN A;; ANSWER SECTION:dns25.hichina.com. 496 IN A 106.11.211.69dns25.hichina.com. 496 IN A 106.11.211.59dns25.hichina.com. 496 IN A 106.11.141.129dns25.hichina.com. 496 IN A 106.11.141.119dns25.hichina.com. 496 IN A 140.205.41.29dns25.hichina.com. 496 IN A 140.205.41.19dns25.hichina.com. 496 IN A 140.205.81.29dns25.hichina.com. 496 IN A 140.205.81.19;; Query time: 114 msec;; SERVER: 9.0.146.50#53(9.0.146.50);; WHEN: Sun Mar 11 18:07:14 CST 2018;; MSG SIZE rcvd: 174 以上这个部分，第二天测试竟然不变。为什么会采用cloudflare的DNS服务器呢？ 过几天又变回了coding.me线路。 测试结果分析如果递归 DNS 服务器和权威 DNS 服务器都未生效，表明域名确实没有添加成功。 如果递归 DNS 服务器未生效，权威 DNS 服务器已生效，表明域名刚添加不久，全球的递归 DNS 服务器未完全同步，需要等待域名配置的 TTL 时间后再次检测是否生效。如果某些个别的运营商递归 DNS 服务器依然未生效，很可能是你遇到了域名劫持或者 DNS 缓存投毒事件。 参考: https://www.alibabacloud.com/help/zh/doc-detail/58458.html 修改过 DNS 服务器，多长时间解析可以生效？ 多长时间解析可以生效要全球解析生效，得等上一会了，也可以先ping一下自己的设置对不对。阿里云域名服务的工作原理是，在你更新了域名解析之后，首先是阿里的万网云解析，然后传播到各大运营商的DNS服务器，刷新DNS缓存，至此你的域名可以被访问。","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"domain","slug":"domain","permalink":"http://yoursite.com/tags/domain/"},{"name":"建站","slug":"建站","permalink":"http://yoursite.com/tags/建站/"},{"name":"pages","slug":"pages","permalink":"http://yoursite.com/tags/pages/"},{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"DNS","slug":"DNS","permalink":"http://yoursite.com/tags/DNS/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"network","slug":"CS/network","permalink":"http://yoursite.com/categories/CS/network/"},{"name":"网络协议-OSI七层模型","slug":"CS/network/网络协议-OSI七层模型","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/"},{"name":"1. 第七层 应用层","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/"},{"name":"DNS","slug":"CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS","permalink":"http://yoursite.com/categories/CS/network/网络协议-OSI七层模型/1-第七层-应用层/DNS/"}]},{"title":"github中的git gist wiki区别","date":"2018-01-25T16:00:00.000Z","path":"wiki/CS/tools/同步与版本管理/git/github/git gist wiki 区别/","text":"git gist wiki 区别 git: 这里指 github.com中的repo gist: gist.github.com wiki: github.com/ wiki 三者都是repo，都记录历史。详细对比如下 github repo gist wiki 注解 markup支持 .md .textile .org .rst .wiki … 同上 同上 previw_所见即所得 √ × √ 可在gist的comment中preview MathJax × × × gitpage支持 private space 收费 √ gist的private repo不能设置密码。不知道搜索引擎能不能搜到 anonymous × √ × Gist提供匿名发布，有时候被用来议论政府，政府害怕所以给墙掉了(DNS污染) directory √ × √ gist是平行文档(一般只一个page)，不支持子目录 fork &amp; clone √ √ √ comments × √ × issue可视为git和wiki的comments， 多人协作 √ √ √ 直接用途、设计思想 代码版本管理、协作 分享代码片断 写文档 snippet什么用？ 博客 github.io gist的embed方式很适合博客，但是多数网站不支持嵌入js 搜索引擎友好性 gist 在google搜索的 rank较高(据说) 缺点 不易归类 其他特征 gist_comment ≈ git_issue (issue多支持了几种附件类型而已) GitHub Pages. 这个除了展示静态的网页(网站)之外并没有什么神奇的功能。它对各种文本文档的渲染支持, 比如 .md, .rst, .org 等. gitpage官方定义： GitHub Pages is deeply integrated with Jekyll, a popular static site generator designed for blogging and software documentation, but used for much more. github markdown 不支持动态js。 gitpages 不支持动态语言，什么意思？不支持js？还是不支持restapi，数据库，不支持UGC(评论，在线写博客) 注意区别这俩。markdown是连js都不支持。gitpage支持了js，但不支持backend","tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"tools","slug":"CS/tools","permalink":"http://yoursite.com/categories/CS/tools/"},{"name":"同步与版本管理","slug":"CS/tools/同步与版本管理","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/"},{"name":"git","slug":"CS/tools/同步与版本管理/git","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/"},{"name":"github","slug":"CS/tools/同步与版本管理/git/github","permalink":"http://yoursite.com/categories/CS/tools/同步与版本管理/git/github/"}]},{"title":"Github Pages托管静态博客-原理浅析","date":"2018-01-25T16:00:00.000Z","path":"wiki/CS/web/建站/host/github-pages/github-pages原理/","text":"关于github提供的http serverping 几个不同账号的gitpage(比如colah.github.io,xu-song.github.io)，发现对应的是同一个ip。为什么返回的页面不同呢？github pages 的 CNAME 是绑定 pages.github.io，不是${username}.github.io coding.net 的 CNAME 是绑定 pages.coding.me 显然，Github肯定在后台做了处理。即github自身会维护一个映射，host_name --&gt; www_path，这样就可以根据不同的host信息返回不同的html了。 这样，在访问xu-song.github.io时github就找到了该返回的html。 关于custom domain现在我们改用custom domain的方式访问gitpage主页。假设已经配置好了dns的A记录映射。访问xusong.vip，dns解析得到ip地址。然而这次github服务器得到的host是xusong.vip。懵逼了，github不认识xusong.vip(host数据里没有该记录)，返回404页面 怎么办呢？ 那就让github认识一下xusong.vip，也就是在github page里设置一下custom domain，或者添加CNAME文件，详见用Github Pages搭建独立域名的个人博客 如果DNS设置CNAME记录，是不是github page不用设置就能work？ 那么上一篇中的重重疑点也就解开了 每个账号的gitpage都是独立的IP吗？github怎么这么多独立外网IP？还是不同账号共用IP？ 很多账号是同一个ip。 不同github page共享ip 正因为如此，才需要步骤3的设置。 配置github pages的custom domain，其作用仅仅是xu-song.github.io --&gt; xusong.vip (重定向)吗？ 不是。1. 查dns解析是否通过 2. 部署到github服务器的相应目录（因为） 3. github page到domain的重定向 关于https为什么Github Pages不支持为自定义域名添加SSL证书？https://steffan.cn/2017/03/22/use-cloudflare-to-implement-HTTPS-for-GithubPages-with-custom-domain-names/ 多个域名能否指向同一个 GitHub Pages？GitHub Pages 的官方文档，一个 username.github.io 只能支持一个域名。 coding page支持多个域名。 一个账号能否见多个github page？可以建立多个， 个人账户page只能有一个， 项目page可以有多个 比如你的账号名为 username, 项目叫 project1 那你可以通过 username.github.io/project1 访问， 如果配置了个人域名就可以用自己的域名访问了 但是CNAME不能指向username.github.io/project1，怎么办？ todo 如何解决md同步问题？ git-repo源，gist源，git issue源，gitpage源。最优的方式就是同源 + 自动deploy。 方式一：以issue作源，要自己利用github api，读取issue，然后写到source目录(貌似也挺简单)。 方式二：以git-repo作源，貌似不错哎。单独把source目录单独作为repo 方式三：以gist作源：易集成(一行js即可)，但不易管理(不支持directory，文档多了很麻烦) 如何实现在线写blog，像wordpress那样 用js调用github api，或者其他后台api即可","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"pages","slug":"pages","permalink":"http://yoursite.com/tags/pages/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"host","slug":"CS/web/建站/host","permalink":"http://yoursite.com/categories/CS/web/建站/host/"},{"name":"github-pages","slug":"CS/web/建站/host/github-pages","permalink":"http://yoursite.com/categories/CS/web/建站/host/github-pages/"}]},{"title":"google云主机---GCE","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/cloud/google/google云主机--GCE/","text":"简介GCP 免费方案送您 $300 赠金和 12 个月免费试用期，帮助您顺利上手。更有“始终免费”产品助您一路前行。 随时可能更改 只要绑定信用卡就送300刀，能免费用一年 GCP控制台 开通google云只支持以下几种信用卡。不支持中国银联2: masterCard3: 美国运通或JCB4:: visa5:mastercard 开通后，消费1美元，是什么意思？ (先消费1美元，再撤销1美元) 价格&amp; 配置综述：GCE是主机部分按时间计费的，网络部分是按流量计费的，跟AWZ一样（与cpu和内存使用率无关，那就可劲用吧）(时间是使用时间，还是申请时间？关机算时间吗？关机不收费，那可以多开几个vm)(流量是怎么算？下载conda，软件包也算流量？) GCE 的价格比较亲民，最低配 1 共享核-0.6 GB 内存-10GB HDD 每月只需要不到 5 美元，而且由于 CPU、内存大小和磁盘大小都是可调的，所以可以根据自己的需要去购买最适合的，能省去不必要的开销。 GCE服务内容 估算费用 折扣 总计 备注 1 个共享 vCPU + 0.6 GB 内存 $5.55/月 - $1.66/月 $4.28/月 内存小了点 1 个共享 vCPU + 1.7 GB 内存 $19.71/月 - $5.91/月 $14.20/月 1 个 vCPU + 3.75 GB 内存 $34.67/月 - $10.40/月 $24.67/月 2 个 vCPU + 7.5 GB 内存 $69.35/月 - $20.81/月 $48.95/月 .. 10 GB 标准永久性磁盘 $0.40/月 1 个 GPU NVIDIA Tesla K80 $328.50/月 - $108.95/月 $254.62/月 1. 共享 vCPU 不支持 GPU 1 个 GPU NVIDIA Tesla P100 $1,065.80/月 - $330.14/月 $770.73/月 2. 简直敲诈，不如自己买。另外仅特定区域才有GPU支持 不同地区价格有差异，美国服务器价格最便宜，亚洲欧洲比美国本土贵点。 可用性策略 抢占：该模式能够获得更低廉的价格，但是不能用做需要长期保持在线的服务（比如 Web 服务），它最长的使用期限是 24 小时，然而在我的使用中，它有时候不到 1 小时就会被终止使用。它只适合短时间去计算一些东西，计算完后中止它，平常的一般使用不要开启此功能。 自动重启：推荐开启，以获得在云端的好处，以及更好的 Uptime 主机维护期间：推荐选择 “迁移”，原因同上 IP 转发：建议关闭，几乎不会用得着此功能，关闭有助于提高安全性 SSH：这可能不同于其他一些 VPS，它默认不自动生成用户密码，所以为了远程登录必须配置好公钥私钥。而且所填写的公钥末尾的用户名是有作用的，所填写的用户名就是所需要登录的用户名，默认不支持 root 登陆，除非你将用户名设置成了 root。 流量流量的话对于所有的可用区，连中国大陆 $0.23/Gbyte、美欧地区 $0.12/Gbyte，流量的价格有些小贵，但是如果是连接 Google 自己的服务的话（包括但不限于 Gmail、YouTube），流量不计费（但是流量是双向的，所以是本地通过 GCE 上传完全免费，下载还是原价）。流量另算钱，起步50g，因此最低配只要不超流量就可以用上一年。 GCE 还有一点比较特殊的是它是按分钟计费的，当服务处于终止状态（相当于关机，磁盘数据保留）时，不收取费用（除了少量的磁盘使用费用）。每次计算 Uptime 时，如果不到 10 分钟则一律按十分钟算，超过 10 分钟后才是真正的按分钟计费，不过还是很划算了 ssh 登录首先在浏览器窗口中打开ssh 创建实例后设置当前用户的新密码 12$ sudo passwd $&#123;whoami&#125; // 下面以 user 代替 $&#123;whoami&#125;# 输入新密码 设置下 root 的新密码12$ sudo passwd root# 输入新密码 在本地生成私钥和公钥 复制公钥 导入公钥到google VM方法一：12进入谷歌云平台页面 -&gt; 计算引擎 -&gt; 元数据 -&gt; SSH 密钥，粘贴保存 谷歌就会把上面这段 public key 写入到 ~/.ssh/authorized_keys 1$ cat ~/.ssh/authorized_keys cat ~/.ssh/authorized_keys文件，检查是否已经存在了刚刚的公钥 如果不work。就手动生成这个文件，然后拷贝public key 本地通过 SSH 密码验证登录 用途VPS 代理 web应用主机 GCE 云主机google computer engine Compute Engine 可让您使用在 Google 基础架构上运行的虚拟机。从微型 VM 到运行 Debian、Windows 或其他标准映像的大型虚拟机一应俱全。创建您的第一个 VM 实例并通过 CloudEndure 迁移服务导入该实例，或通过快速入门指南构建示例应用。 据说GCE 在国内经常不稳定 GCE 的后台配置页面虽不能在中国访问，但是其 GCE 实例是可以在中国访问的。(什么意思？) 评价速度超快，下载tensorflow 116MB/s referencehttps://guozeyu.com/2016/10/asia-google-compute-engine/SSH 连接配置 app engine 云应用谷歌云平台","tags":[{"name":"cloud","slug":"cloud","permalink":"http://yoursite.com/tags/cloud/"},{"name":"google","slug":"google","permalink":"http://yoursite.com/tags/google/"},{"name":"GPU","slug":"GPU","permalink":"http://yoursite.com/tags/GPU/"},{"name":"computer engine","slug":"computer-engine","permalink":"http://yoursite.com/tags/computer-engine/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"cloud","slug":"CS/cloud","permalink":"http://yoursite.com/categories/CS/cloud/"},{"name":"google","slug":"CS/cloud/google","permalink":"http://yoursite.com/categories/CS/cloud/google/"}]},{"title":"静态博客框架比较","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/-blog framework比较/","text":"overview比较流行的一些静态博客框架，比较流行的有Jekyll，Hexo，Simple，Octopress，Pelican以及Lo·gecho等等. Hexo（Node.js写的，编译速度比前两者快）优势：轻量静态博客，与以上相比速度更快，适合博客内容很多的用户。可以从多个平台（比如wp，joomla）移植博客。可以使用绝大多数octopress插件缺点：需要在本地更新博客 安装：较简单 Jekyll 更活跃，github官方指定。像黑客一样写作。可以通过http://prose.io直接写博客。缺点： 模板基于liquid template engine，更改较复杂，安装稍复杂 Jekyll的一个最大优势 ：Github自动构建和部署，用户基本只需维护md文件；而hexo等博客需要本地编译成html，然后再上传到Github。 Github原文 Jekyll’s simplified build process with GitHub Pages is one of the biggest advantages of using Jekyll instead of other static site generators. GitHub Pages manages your site’s build process with a single push to your site’s publishing branch.– 来自 Github官网 https://help.github.com/articles/about-github-pages-and-jekyll/ Hakyll Haskell 示例： http://colah.github.io 为什么都喜欢ll结尾？ Octopress Jekyll的再开发 jekyll hexo contributor 751 115 star 32983 20441 搜索 hexo 迁移 jekll，搜到的都是从Jekyll迁移到Hexo， why？ https://acris.me/ 的title字体 参考 https://www.zhihu.com/question/21981094 https://www.slant.co/topics/329/~best-solutions-for-a-personal-blog","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"},{"name":"framework","slug":"framework","permalink":"http://yoursite.com/tags/framework/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"}]},{"title":"【hexo系列】hexo的正确打开方式","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/Hexo使用建议/","text":"背景核心思想 利用submodule管理blog 先fork再add submodule 利用branch管理自己的project和需要PR的project 实现细节 主仓库 blog themes/next/ 每个theme是一个子仓库 source/post/ 作为一个子仓库 source/image/ 作为一个子仓库 模块搭建&amp;整合流程 1234567891011121314151617181920212223# 1. fork hexo-starter 作为blog主仓库$ git clone --recursive git@github.com:esblog/hexo-starter.git blog# 2. 添加 submodule# 2.1 fork theme &amp; add submodule$ cd blog/themes/$ git submodule add git@github.com:esblog/hexo-theme-next.git next# 2.2 fork _post &amp; add submodule$ git submodule add git@github.com:esblog/_posts.git# 2.3 fork project-u-like &amp; add submodule$ mkdir blog/source/games/ &amp;&amp; cd blog/source/games/$ git submodule add git@github.com:esblog/2048.git# 检查是否添加成功$ vi .gitmodules# 3. push到blog主仓库 (整合)cd blog/git commit -m \"add submodules hexo-theme-next source/_post games/2048\"git push -u origin master Note: 如果你嫌fork太多，那么可以开一个github小号，管理这些fork。github主账号只放deploy版本。 实例： Dev Repository Main project for all submodules Deployed Repository is deployed by Hexo from Dev Repository Demo Site hosts the Deployed Repository 常用操作push 每个module独立push 1234567# 1. commit changes from all submodules (e.g. _posts)$ cd _posts$ commit &amp; push# 2. commit changes from esblog.github.io$ cd blog$ commit &amp; push pull &amp; merge1$ git pull &amp;&amp; git submodule init &amp;&amp; git submodule update &amp;&amp; git submodule status clone &amp; setup1234567# master用于Gitpage的部署$ git clone -b dev --recursive git@github.com:esblog/esblog.github.io.git blog-dev$ cd blog-dev$ git branch # 确认已经切换到dev分支$ npm install hexo --save # install node_modules dependency$ hexo s$ hexo d 其他操作从官方更新模块（操作较少）比如，theme-next有些新功能 如何更新到自己的博客中？ 12$ git pull https://github.com/theme-next/hexo-theme-next.git# 如果有冲突，需要人工merge 也可在theme的github界面pull &amp; merge 其他操作建议 每个post都加date，不然每次编辑文档，时间都会变动 draft 可以放在_draft目录下，当然我更习惯放在_post/中，文件名_开头即可，或者整个目录_开头。 文件名不要经常变动(因为会改变url)，title和path可以随时改动 非法操作 在Deployed Repository人工提交。(除非你不用hexo d命令，或不用hexo)-","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"Hexo简介","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/Hexo简介/","text":"Hexo剖析中文文档：https://hexo.io/zh-cn/docs/官方主题库：https://hexo.io/themes/next主题：https://github.com/theme-next Hexo原理综述markdown到html的旅程 模板渲染 模板渲染 hexo文件结构1234567891011121314151617181920├── _config.yml # 站点配置文件├── db.json # database，缓存文件├── node_modules # 安装的插件以及hexo所需的一些node.js模块├── package.json # 应用程序信息，配置hexo运行需要的js包├── public # deploy时生成，最终所见网页的所有内容├── scaffolds # 模板文件夹，hexo默认包含以下三种布局(layout) https://hexo.io/zh-cn/docs/writing.html│ ├──draft.md # hexo new draft &lt;title&gt; 会在source/_drafts目录下生成md文件│ ├──page.md # hexo new page &lt;title&gt; 在source目录下│ └──post.md # hexo new post &lt;title&gt; 在source/_posts目录下生成md文件├── source # 资源文件夹。除 posts 文件夹之外，开头命名为 (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。│ ├── _draft # 除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略│ └── _posts #│ └── hello-world.md└── themes #主题文件夹 ├── └──next ├── ├── ├── ├── 详解clean1234$ hexo clean --debugINFO Deleted database. # 清空 db.jsonINFO Deleted public folder. # 删除public目录 详解hexo g每次运行 hexo g 命令，hexo(node.js程序)会遍历你的 source 目录，建立索引，根据你 theme 文件夹的主题生成页面到 public 文件夹。这时 public 文件夹就是一个纯由 html javascript css 等内容制作的博客，而这些恰好能在 git pages 识别 详解deploy最后 hexo d 将 public 文件夹的内容复制到临时目录，以 git 方式 push 到 github 的指定项目的指定分支，由 github 进行显示 首次deploy1234567891011121314151617181920212223242526272829303132333435$ hexo d --debug# 1. 首先加载plugin和themeDEBUG Config loaded: ~/xs/blog/_config.ymlDEBUG Plugin loaded: hexo-generator-category# 2. 开始转化htmlINFO Start processing# 2.1 处理404页面DEBUG Processed: source/404.html # 404不需要themeDEBUG Processed: 404.html# 2.2 加载主题，处理source目录下的.md .htmlDEBUG Theme config loaded.DEBUG Processed: _config.yml # 这个也需要处理？DEBUG Processed: source/css/main.styl # 处理source目录下所有文件，包括js image mdDEBUG Processed: layout/archive.swig # 处理layout languages等DEBUG Generator: page # 还包括post category archive index tag# 3. 生成html，存储在public目录INFO Files loaded in 796 ms #DEBUG Rendering page: 404.htmlDEBUG Rendering post: 2018/01/25/hello-world/index.htmlDEBUG Rendering archive: archives/index.htmlDEBUG Rendering index: index.html# 4. deploy: 创建git repo，在public中拷贝文件，并pushINFO Deploying: gitInitialized empty Git repository # git initINFO Copying files from public folder... # 从public复制到.deploy_git目录INFO Copying files from extend dirs...INFO Deploy done: git # commit &amp; push 已完成DEBUG Database saved 详解hexo serverhexo s –debug hexo的模板引擎,Rendering HTML模板引擎的作用，就是将界面与数据分离。最简单的原理是将模板内容中指定的地方替换成数据，实现业务代码与逻辑代码分离。 source 文件夹理解为数据库，而theme文件夹相当于 界面。 hexo g 就将我们的数据和界面相结合生成静态文件 public。 Hexo 的模板引擎是默认使用 ejs 编写的，同类型的东西还有很多，比如jade，swig。 next选用的swig 比较赞的设计 文件名与博客名分离，即title不直接采用文件名。(这样保证了不会因为title的变动引起url的变动) url路径与实际路径分离 () referencehttp://coderunthings.com/2017/08/20/howhexoworks/","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"【hexo源码系列】 入门","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/Hexo源码浅析/","text":"首先为什么要看源码呢？因为想自己更便捷高效的管理博客，比如 如何更新Hexo。(需要看hexo init的源码，因为该命令隐藏了hexo-starter项目) 如何更新theme。某些bug-fix&amp;新功能。(需要借助git的submodule来高效管理) 如何自己实现一个新功能(比如添加edit button，添加URL哈希。需要了解模板原理) 源码不用细看，看个大概能满足自己的需求就够了。 本文仅介绍Hexo基础包，扩展包可参考【Hexo插件系列】博客。 查看Hexo和Plugin版本首先看一下自己的Hexo和Plugin版本，因为不同的版本是不同的实现。版本号是次要的，主要看是不是同一种包。比如hexo-deployer-git和hexo-deployer-rsync在执行hexo d命令时方式就不同。详见官方文档 查看package.json文件的依赖项。1234567891011\"dependencies\": &#123; \"hexo\": \"^3.7.0\", # https://github.com/hexojs/hexo/ hexo仅仅是一个module而已，用于... \"hexo-generator-archive\": \"^0.1.5\", # generator最复杂 \"hexo-generator-category\": \"^0.1.3\", \"hexo-generator-index\": \"^0.2.1\", \"hexo-generator-tag\": \"^0.2.0\", # nodejs的模板引擎，有EJS、Jade、Swig、Haml。theme-next采用的swig \"hexo-renderer-ejs\": \"^0.3.1\", \"hexo-renderer-stylus\": \"^0.3.3\", \"hexo-renderer-marked\": \"^0.3.2\", # markdown的render engine，即`.md`转`html` \"hexo-server\": \"^0.3.1\"&#125; 也可用以下命令查看版本：1$ npm ls --depth 0 更新各个模块，命令 npm update hexo-cli， 提供hexo init、hexo help、hexo version命令 hexo hexo new hexo generate hexo plugin，即node依赖 hexo server hexo deploy 其他命令 回顾Hexo搭建流程以下来自官方文档 123456789101112131415# 1. Installation$ npm install hexo-cli -g# 2. Setup your blog$ hexo init blog$ cd blog# 3. Start the server$ hexo server# 4. Create a new post$ hexo new \"Hello Hexo\"# 5. Generate static files$ hexo generate 流程详解1. npm installnpm是nodejs的包管理器，管理javascript libhexo-cli是nodejs的一个包，用于运行hexo命令。(有cli难道还有server？) npm list -g 能够看到安装路径。一般在/usr/lib/node_modules/ 或者/usr/local/lib/node_modules/ 2. hexo inithexo init命令做了什么？ 答案hexo init等价于以下两行shell命令。1234# 1. Cloning hexo-starter to blog$ git clone --recursive https://github.com/hexojs/hexo-starter.git blog# 2. Install dependencies$ npm install --production 看到这里，就够用。如果自己的hexo项目是老版本的，可以在这个仓库pull更新(虽然更新很少)。如果对追寻答案的过程感兴趣，可以继续往下看。 追寻答案的旅程 - optional首先看一下hexo 1234567$ which hexo/usr/bin/hexo$ cat /usr/bin/hexo#!/usr/bin/env node'use strict';require('../lib/hexo')(); 这里你会发现，hexo命令是nodejs脚本。 ../lib/hexo对应的是usr/lib/hexo，然而没有path。 12$ ls -l /usr/bin/hexo /usr/bin/hexo -&gt; ../lib/node_modules/hexo-cli/bin/hexo 原来/usr/bin/hexo是个符号链接，链接到nodejs的modules目录里。 1234$ cat /usr/lib/node_modules/hexo-cli/bin/hexo#!/usr/bin/env node'use strict';require('../lib/hexo')(); 即hexo命令对应的是/usr/lib/node_modules/hexo-cli/lib/hexo.js文件。 hexo找到了，init命令呢？讲道理应该是个package.json下的script。 原生hexo-cli提供了4个命令，都在hexo-cli/lib/console路径下。 123$ hexo help$ hexo init$ hexo version 扩展命令通过hexo-cli/lib/extends.console.js实现。 hexo init 命令 init.js核心代码 路径hexo-cli/lib/console/init.js 123456789var GIT_REPO_URL = 'https://github.com/hexojs/hexo-starter.git';// 1. git clone --recursive https://github.com/hexojs/hexo-starter.git bloglog.info('Cloning hexo-starter to'spawn('git', ['clone', '--recursive', GIT_REPO_URL, target]);removeGitDir(target);removeGitModules(target);// 2. npm install --productionlog.info('Install dependencies');spawn(npmCommand, ['install', '--production']); 实际上吧，如果hexo的log打印出来GIT_REPO_URL就更清晰，非要藏起来等人挖掘。 参考 hexo-starter项目 hexo.js源码 | hexo-cli 项目 hexo init 命令源码 | hexo-cli 项目 3. hexo server这个不属于hexo-cli了。hexo server命令源码 暂没兴趣，应该就是启了个nodejs HttpServer。待看 额外的逻辑是，如果没generate，先调一下 hexo g 但是偶尔出现的bug来源于hexo s，这里的逻辑还需要看一下。 4. hexo new5. hexo generate生成器（Generator）官方文档 这个好麻烦，看不动了。这么多generator和render。 放个链接 https://github.com/hexojs/hexo-generator-index ，貌似主要先看这个。 generatorgenerates static files 这一步最慢。常用的有hexo-renderer-markedhexo-renderer-pandoc render 模板引擎官方文档 https://hexo.io/zh-cn/api/rendering.html 模板引擎的作用，就是将界面与数据分离。最简单的原理是将模板内容中指定的地方替换成数据，实现业务代码与逻辑代码分离。 生成静态文件。将我们的数据和界面相结合生成静态文件的过程。会遍历主题文件中的 source 文件夹（js、css、img 等静态资源），然后建立索引，然后根据索引生成 pubild 文件夹中，此时的 publid 文件是由 html、 js、css、img 建立的纯静态文件可以通过 index.html 作为入口访问你的博客。 其中 _layout.swig 是通用模板，里面引入了 head、footer 等公共组件，然后在其他的模板中会引入这个 _layout.swig 通用模板，比如 post.swig 模板 .md解析成html .swig渲染为html 数据的填充数据的填充主要是 hexo -g 的时候将数据传递给 swig 模板，然后再由 swig 模板填充到 HTML 中。 6. hexo deploydeploy到底干了什么？执行了git push？ deploy配置123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:- type: git repo: git@github.com:xu-song/xu-song.github.io.git branch: master 部署主要是根据在 _config.yml 中配置的 git 仓库或者 coding 的地址，将 public 文件上传至 github 或者 coding 中。然后再根据上面的 github 提供的 pages 服务呈现出页面。当然你也可以直接将你生成的 public 文件上传至你自己的服务器上。 deploy.js核心源码：https://github.com/hexojs/hexo-deployer-git/blob/master/lib/deployer.js#L83123git('add', '-A'); // 对publc目录中执行add操作。git('commit', '-m', message);git('push', '-u', repo.url, 'HEAD:' + repo.branch, '--force'); 即等价于以下几个命令(通常情况下)1234567$ rm -rf .deploy_git # log.info('Clearing .deploy_git folder...');$ cp -rf public .deploy_git # log.info('Copying files from public folder...');$ cd .deploy_git$ git add -A$ git commit -m \"Site updated: 2018-01-30 *:*:*\" #某时间$ git push -u origin HEAD:master --force 上面命令使用–force选项，强制push到远程主机，会使远程主机更新的版本被覆盖。所以不要在deploy之后的仓库做提交，要在dev仓库提交。 实例： Dev Repository Main project for all submodules Deployed Repository is deployed by Hexo from Dev Repository Demo Site hosts the Deployed Repository 参考 hexo deploy官方文档 hexo deploy.js源码 http://cherryblog.site/hexo-4.html 深入理解 Hexo hexo是怎么工作的7. Hexo 的模板引擎这个render讲道理应该是在hexo g的时候调用的。 待看 如何debug hexo调试hexo，实质就是调试nodejs","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"源码","slug":"源码","permalink":"http://yoursite.com/tags/源码/"},{"name":"原理","slug":"原理","permalink":"http://yoursite.com/tags/原理/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"}]},{"title":"关于theme-next","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/theme/-关于theme-next/","text":"简介目录结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980├── _config.yml // 主题配置项文件├── languages // 语言文件├── layout // 布局（模板）文件夹├── scripts // └── source // layout 子目录├── layout│ ├── _custom│ │ ├── head.swig│ │ ├── header.swig│ │ └── sidebar.swig│ ├── _layout.swig│ ├── _macro // 宏，所有页面都包含的部分│ │ ├── menu // 菜单│ │ ├── post-collapse.swig│ │ ├── post-copyright.swig│ │ ├── post-related.swig│ │ ├── post.swig│ │ ├── reward.swig│ │ ├── sidebar.swig // 比如在sidebar添加│ │ └── wechat-subscriber.swig│ ├── _partials│ │ ├── breadcrumb.swig│ │ ├── comments.swig│ │ ├── footer.swig│ │ ├── head│ │ ├── header│ │ ├── page-header.swig│ │ ├── pagination.swig│ │ ├── search│ │ └── share│ ├── _scripts│ │ ├── boostrap.swig│ │ ├── commons.swig│ │ ├── noscript.swig│ │ ├── pages│ │ ├── schemes│ │ └── vendors.swig│ ├── _third-party│ │ ├── analytics│ │ ├── bookmark.swig│ │ ├── comments│ │ ├── copy-code.swig│ │ ├── exturl.swig│ │ ├── github-banner.swig│ │ ├── math│ │ ├── needsharebutton.swig│ │ ├── pangu.swig│ │ ├── rating.swig│ │ ├── schedule.swig│ │ ├── scroll-cookie.swig│ │ ├── search│ │ └── seo│ ├── archive.swig│ ├── category.swig│ ├── index.swig│ ├── page.swig│ ├── post.swig│ ├── schedule.swig│ └── tag.swig// scripts├── scripts│ ├── helpers.js│ ├── merge-configs.js│ ├── merge.js│ └── tags// source子目录├── source│ ├── css│ ├── fonts│ ├── images│ ├── js│ └── lib 如果想改主题，最关心的是layout目录，另外配套改一改对应的source/css search疑问hexo-theme-next的owner到底是ivan-nginx还是iissnan？ 貌似iissnan是老owner，后来移交给了俄罗斯的ivan-nginx。 Main repo was rebased from iissnan’s profile to theme-next organization. 见https://github.com/theme-next/hexo-theme-next/blob/master/docs/UPDATE-FROM-5.1.X.md","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"theme","slug":"CS/web/blog-framework/nodejs-hexo/theme","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/theme/"}]},{"title":"【hexo源码系列】 入门","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/src/Hexo源码浅析/","text":"为什么要看源码能够更便捷高效的管理博客，比如 更新Hexo: 需要了解hexo init的源码，因为该命令隐藏了hexo-starter项目 () 更新theme: 某些bug-fix以及new feature。可借助git的submodule来高效管理 定制博客(个性化): (比如添加edit button，添加URL哈希，个性化主题。需要了解模板原理 源码不用细看，看个大概能满足自己的需求就够了。 本文仅介绍Hexo基础包，扩展包可参考【Hexo插件系列】博客。 查看Hexo和Plugin版本首先看一下自己的Hexo和Plugin版本，因为不同的版本是不同的实现。版本号是次要的，主要看是不是同一种包。比如hexo-deployer-git和hexo-deployer-rsync在执行hexo d命令时方式就不同。详见官方文档 查看package.json文件的依赖项。1234567891011\"dependencies\": &#123; \"hexo\": \"^3.7.0\", # https://github.com/hexojs/hexo/ hexo仅仅是一个module而已，用于... \"hexo-generator-archive\": \"^0.1.5\", # generator最复杂 \"hexo-generator-category\": \"^0.1.3\", \"hexo-generator-index\": \"^0.2.1\", \"hexo-generator-tag\": \"^0.2.0\", # nodejs的模板引擎，有EJS、Jade、Swig、Haml。theme-next采用的swig \"hexo-renderer-ejs\": \"^0.3.1\", \"hexo-renderer-stylus\": \"^0.3.3\", \"hexo-renderer-marked\": \"^0.3.2\", # markdown的render engine，即`.md`转`html` \"hexo-server\": \"^0.3.1\"&#125; 也可用以下命令查看版本：1$ npm ls --depth 0 更新各个模块，命令 npm update 回顾Hexo搭建流程以下来自官方文档 123456789101112131415# 1. Installation$ npm install hexo-cli -g# 2. Setup your blog$ hexo init blog$ cd blog# 3. Start the server$ hexo server# 4. Create a new post$ hexo new \"Hello Hexo\"# 5. Generate static files$ hexo generate 流程详解1. npm installnpm是nodejs的包管理器，管理javascript libhexo-cli是nodejs的一个包，用于运行hexo命令。(有cli难道还有server？) npm list -g 能够看到安装路径。一般在/usr/lib/node_modules/ 或者/usr/local/lib/node_modules/ 2. hexo inithexo init命令做了什么？ 答案hexo init等价于以下两行shell命令。1234# 1. Cloning hexo-starter to blog$ git clone --recursive https://github.com/hexojs/hexo-starter.git blog# 2. Install dependencies$ npm install --production 看到这里，就够用。如果自己的hexo项目是老版本的，可以在这个仓库pull更新(虽然更新很少)。如果对追寻答案的过程感兴趣，可以继续往下看。 追寻答案的旅程 - optional首先看一下hexo 1234567$ which hexo/usr/bin/hexo$ cat /usr/bin/hexo#!/usr/bin/env node'use strict';require('../lib/hexo')(); 这里你会发现，hexo命令是nodejs脚本。 ../lib/hexo对应的是usr/lib/hexo，然而没有path。 12$ ls -l /usr/bin/hexo /usr/bin/hexo -&gt; ../lib/node_modules/hexo-cli/bin/hexo 原来/usr/bin/hexo是个符号链接，链接到nodejs的modules目录里。 1234$ cat /usr/lib/node_modules/hexo-cli/bin/hexo#!/usr/bin/env node'use strict';require('../lib/hexo')(); 即hexo命令对应的是/usr/lib/node_modules/hexo-cli/lib/hexo.js文件。 hexo找到了，init命令呢？讲道理应该是个package.json下的script。 原生hexo-cli提供了4个命令，都在hexo-cli/lib/console路径下。 123$ hexo help$ hexo init$ hexo version 扩展命令通过hexo-cli/lib/extends.console.js实现。 hexo init 命令 init.js核心代码 路径hexo-cli/lib/console/init.js 123456789var GIT_REPO_URL = 'https://github.com/hexojs/hexo-starter.git';// 1. git clone --recursive https://github.com/hexojs/hexo-starter.git bloglog.info('Cloning hexo-starter to'spawn('git', ['clone', '--recursive', GIT_REPO_URL, target]);removeGitDir(target);removeGitModules(target);// 2. npm install --productionlog.info('Install dependencies');spawn(npmCommand, ['install', '--production']); 实际上吧，如果hexo的log打印出来GIT_REPO_URL就更清晰，非要藏起来等人挖掘。 参考 hexo-starter项目 hexo.js源码 | hexo-cli 项目 hexo init 命令源码 | hexo-cli 项目 3. hexo server这个不属于hexo-cli了。hexo server命令源码 暂没兴趣，应该就是启了个nodejs HttpServer。待看 额外的逻辑是，如果没generate，先调一下 hexo g 但是偶尔出现的bug来源于hexo s，这里的逻辑还需要看一下。 4. hexo new5. hexo generate生成器（Generator）官方文档 这个好麻烦，看不动了。这么多generator和render。 放个链接 https://github.com/hexojs/hexo-generator-index ，貌似主要先看这个。 generatorgenerates static files 这一步最慢。常用的有hexo-renderer-markedhexo-renderer-pandoc render 模板引擎官方文档 https://hexo.io/zh-cn/api/rendering.html 模板引擎的作用，就是将界面与数据分离。最简单的原理是将模板内容中指定的地方替换成数据，实现业务代码与逻辑代码分离。 生成静态文件。将我们的数据和界面相结合生成静态文件的过程。会遍历主题文件中的 source 文件夹（js、css、img 等静态资源），然后建立索引，然后根据索引生成 pubild 文件夹中，此时的 publid 文件是由 html、 js、css、img 建立的纯静态文件可以通过 index.html 作为入口访问你的博客。 其中 _layout.swig 是通用模板，里面引入了 head、footer 等公共组件，然后在其他的模板中会引入这个 _layout.swig 通用模板，比如 post.swig 模板 .md解析成html .swig渲染为html 数据的填充数据的填充主要是 hexo -g 的时候将数据传递给 swig 模板，然后再由 swig 模板填充到 HTML 中。 6. hexo deploydeploy到底干了什么？执行了git push？ deploy配置123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:- type: git repo: git@github.com:xu-song/xu-song.github.io.git branch: master 部署主要是根据在 _config.yml 中配置的 git 仓库或者 coding 的地址，将 public 文件上传至 github 或者 coding 中。然后再根据上面的 github 提供的 pages 服务呈现出页面。当然你也可以直接将你生成的 public 文件上传至你自己的服务器上。 deploy.js核心源码：https://github.com/hexojs/hexo-deployer-git/blob/master/lib/deployer.js#L83123git('add', '-A'); // 对publc目录中执行add操作。git('commit', '-m', message);git('push', '-u', repo.url, 'HEAD:' + repo.branch, '--force'); 即等价于以下几个命令(通常情况下)1234567$ rm -rf .deploy_git # log.info('Clearing .deploy_git folder...');$ cp -rf public .deploy_git # log.info('Copying files from public folder...');$ cd .deploy_git$ git add -A$ git commit -m \"Site updated: 2018-01-30 *:*:*\" #某时间$ git push -u origin HEAD:master --force 上面命令使用–force选项，强制push到远程主机，会使远程主机更新的版本被覆盖。所以不要在deploy之后的仓库做提交，要在dev仓库提交。 实例： Dev Repository Main project for all submodules Deployed Repository is deployed by Hexo from Dev Repository Demo Site hosts the Deployed Repository 参考 hexo deploy官方文档 hexo deploy.js源码 http://cherryblog.site/hexo-4.html 深入理解 Hexo hexo是怎么工作的7. Hexo 的模板引擎这个render讲道理应该是在hexo g的时候调用的。 待看","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"源码","slug":"源码","permalink":"http://yoursite.com/tags/源码/"},{"name":"原理","slug":"原理","permalink":"http://yoursite.com/tags/原理/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"src","slug":"CS/web/blog-framework/nodejs-hexo/src","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/src/"}]},{"title":"渣渣中的渣渣 之 DaoVoice","date":"2018-01-24T19:08:53.000Z","path":"wiki/CS/web/blog-framework/nodejs-hexo/plugin/2/Hexo博客添加在线联系功能--DaoVoice分析/","text":"垃圾中的垃圾 之 DaoVoice特点：高延迟 你如果用过DaoVoice的话，肯定知道它延迟很长。但是为什么延迟这么长呢，下面来看看。 通常web-chat都采用websocket。html–server–html就是一堆的websocket连接 反应特别慢，消息的发送和接收，在websocket中并未看到。 消息的发送https://im.daovoice.io/v1/conversations/b1fba959-a843-43ca-9538-928a1cdfd62d/reply的request payload参数进行明文传输的。 消息的接收https://im.daovoice.io/v1/conversations/b1fba959-a843-43ca-9538-928a1cdfd62d/read 消息接收并非是服务器推送的，而是每次客户端主动发送消息时才会触发消息接收。(DaoVoice的设计也太挫了吧，这可不是一般的延迟啊，根本不能叫instant message) 开了个websocket，什么事都不干，发一些没用的数据。 dao voice原理基于websocket Request123Request URL:wss://rtm.daovoice.io/socket.io/?EIO=3&amp;transport=websocket&amp;sid=-ezTav4AxWfvgBszAjuIRequest Method:GETStatus Code:101 Switching Protocols Response header123456Connection: upgradeDate: Tue, 06 Feb 2018 01:52:13 GMTSec-WebSocket-Accept: +vrxS3Tw4HDKi3JDS5wRL7vIqKc=Sec-WebSocket-Extensions: permessage-deflateServer: nginx/1.9.13Upgrade: websocket Frames 首先发送http请求https://rtm.daovoice.io/socket.io/?EIO=3&amp;transport=polling&amp;t=M5ZWKps&amp;sid=JtjO6wXdOoHH7RXWFqhw https://im.daovoice.io/v1/conversations/02010594-d7b8-4f3a-896a-4f82e2cc9198/fetchhttps://im.daovoice.io/v1/conversations/02010594-d7b8-4f3a-896a-4f82e2cc9198/readhttps://im.daovoice.io/v1/conversations/02010594-d7b8-4f3a-896a-4f82e2cc9198/reply 如何自己实现在线联系利用websocket利用微信api参考利用dao voice","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"plugin","slug":"plugin","permalink":"http://yoursite.com/tags/plugin/"},{"name":"instant-message","slug":"instant-message","permalink":"http://yoursite.com/tags/instant-message/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"blog-framework","slug":"CS/web/blog-framework","permalink":"http://yoursite.com/categories/CS/web/blog-framework/"},{"name":"nodejs-hexo","slug":"CS/web/blog-framework/nodejs-hexo","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/"},{"name":"plugin","slug":"CS/web/blog-framework/nodejs-hexo/plugin","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/"},{"name":"2","slug":"CS/web/blog-framework/nodejs-hexo/plugin/2","permalink":"http://yoursite.com/categories/CS/web/blog-framework/nodejs-hexo/plugin/2/"}]},{"title":"关于域名","date":"2018-01-24T16:00:00.000Z","path":"wiki/CS/web/建站/domain/","text":"顶级域名比较互联网顶级域列表 简介 google页面数(million) 域名数目 域名饱和度 开放时间 价格 审核 星级 备注 .com 原用于商业组织，现无限制 25,270 13290万 4字母的基本饱和 1985-01-01 ☆☆☆☆☆ .net 原用于网络服务，现无限制 2,790 1437万 大批量4字母 1985-01-01 ☆☆☆☆ .org 原用于非营利组织，现无限制 5,040 1040万 大批量4字母 1985-01-01 ☆☆☆☆ 国内不能实名认证，不能备案 .info 适用于提供信息服务的企业 738 656万 2001-06-26 .cn 中国 425 1134万 1990-11-28 需提供政府颁发的有效身份证件。 ☆☆☆☆ .us 美国 420 205万 1985-02-15 美国的网站很喜欢使用.com的域名。因此.us网站相对较少 .io 新秀，“Indian Ocean”为英属印度洋领地的缩写 193 33万 1997-09-16 贵 ☆☆☆☆ 该顶级域十分受初创公司和IT公司欢迎 .biz 104 200万 2001-06-26 取意来自英文单词 “business” ，代表着商业领域，在 .com 资源日渐枯竭的情况下， .biz 必将代替 .com 成为企业注册域名的首选。 .cc 91 96万 1997-10-13 .ai 英国海外属地安圭拉国家及地区顶级域 25 3万 1995-02-16 贵 ☆☆☆☆ 由于近来人工智能的大热，.ai域名热度极度攀升 .xyz 24 184万 2014-02-06 贵 .top 1 168万 2014-07-24 便宜 .vip 0.6 74万 2015-07-30 便宜 特殊用途域名 .gov 政府部门 1,170 0.5万 1985-01-01 需提供相关证件资料 ☆☆☆☆☆☆ 域名少，页面丰富 .edu 教育机构 601 0.7万 1985-01-01 需提供相关证件资料 ☆☆☆☆☆☆ 中文域名比如 域名.com，有点贵 溢价域名溢价域名，是注册局根据ICANN相关规定，在开放注册后可以保留一定时间后再开放的。通常情况下，溢价域名是注册局保留的精品优质域名。 域名实名认证.org .cc .me的域名不能实名认证，不在阿里云实名认证列表里。会有一下提示： 根据工信部和域名注册局新的实名认证要求，该后缀域名暂时停止实名认证，具体开放时间等待进一步通知 阿里云实名认证文档: 为贯彻国家工信部对域名持有者实名制审核管理的相关规范，阿里云将全面推行域名实名认证。域名实名认证包括域名命名审核（指域名将由国家监管部门认定是否含有政策不允许注册的字符）和域名持有人信息资料实名认证。 须完成实名认证或命名审核的域名 按照工信部 2017 年全面域名实名认证的要求，目前阿里云已接到相关注册局通知：若域名在规定时间内未通过实名审核，会被注册局暂停解析（Serverhold），无法正常访问，待实名认证通过后方可恢复正常使用。涉及的域名后缀包括：.cn/.中国/.公司/.网络/.xin/.com/.net/.top/.xyz/.vip/.club/.shop/.wang/.ren/.site/.我爱你/.集团/.biz/.red/.kim/.pro/.info/.mobi/.ltd/.group/.link/.ink/.在线/.中文网/.网址/.work/.online/ .tech/.fun/.store/.网店/.live/.social/.pub/.video。 没有实名认证的域名可以备案吗？ 不能，因为备案需要域名证书 没有办法 转国外了 我想问 你们域名都在国外，NS有没在国内？比如cloudxns？有啊，我就是namesilo域名，cloudxns解析，没啥问题 备案 2018年1月1日起，工信部要求备案域名必须完成域名实名认证，未完成实名认证、实名信息与备案信息不一致等会被管局驳回。 备案订单有效期为45天(自提交当天开始计算)，订单超期后自动失效，请您尽快提交并完成备案。为避免影响网站备案及访问，请注意服务器的服务期限及时续费。 网站备案域名核验 提示域名不支持备案怎么办？市面上流通的域名后缀并非都可以备案。只有工信部收录的域名后缀才允许开放备案，目前工信部暂未收录 .pub/.rocks/.band/.market/software/.social/.lawyer/.engineer/.link/.click/.help/.gift/.pics/.photo/.news/.video/.win/.party/.date/.trade/.science/.online/.tech/.website/.space/.press/.wiki/.design/.live/.studio/.red/.loan/.bid/.mom/.lol/.work/.game/.store/.ltd 等后缀的域名，故无法进行网站备案。 您可以访问 工信部备案管理系统 （www.miitbeian.gov.cn），进入 公共查询 &gt; 域名类型 查看域名后缀是否已收录。如果您购买的域名后缀无法进行备案，您可将域名指向中国大陆以外免备案服务器。中国大陆以外节点服务器无需进行备案。 此外，部分省市管局对可备案域名有特殊要求，请查看各省管局 备案规则。 认可度，信任程度，稳定性，正式度，流行度排名。国内域名 .cn 要使用您的域名，您必须提供政府颁发的有效身份证件。 .com.cn 要使用您的域名，您必须提供政府颁发的有效身份证件。 .org.cn 其他 .song 神奇的亚马逊还有这个域名 特殊功能域名 .shoes .map .data .game .x 等 last.fm del.icio.us flic.kr .blog… 适宜个人：.me .name .blog .site（换个说法就是不适宜商用，） 锤子花高价买t.tt所以不流行的域名里，配合好的二级域名也是有投资价值的 预测 无商业投资价值的域名不会火，规律，商人、组织、企业们看中哪个域名，哪个域名就火。像个人主义的域名，再名字再好，在商业投资价值下，也变得逊色。比如.me 收费 &amp; 续费[万网-阿里云价格]https://wanwang.aliyun.com/help/price.html 续费小技巧：先将域名转到国内，续费个好几年，等 2 个月后转出到国外。比如 shuaige.me 已续费到 2023 年， 13 年 37 一年续到了 22 年，今天转到了 gandi 花了 99 排名注册量总排名全球十大域名后缀，.cn仅次于.com 实时查询 | 国别域名 注册量排名.cn域名总量达2140万，国别域名中位居全球第一截至2017年3月31日，国别域名的注册总量为1.431亿个，环比增长03.%，同比增长1.7%。其中排名前十的分别是.cn（中国）、.tk（托克劳）、.de（德国）、.uk（英国）、.ru（俄罗斯）、.nl（荷兰）、.br（巴西）、.eu（欧盟）、.au（澳大利亚）和.it（意大利）。 目前(2018-02-27)，.tk 第一，.de第二，.cn第三 神奇的 .tk.tk 托克劳是一个太平洋上的蕞尔小岛国，却无疑是互联网世界中的真正霸主。它力压所有国家成为了域名最多的国家。 托克劳使用了一种目前在互联网上极为流行的“免费增值”商业模式，以.tk注册的网站只享有免费的使用权。若想完全拥有这个域名仍需要支付一笔费用。这些费用占了托克劳年收入的六分之一。 域名免费提供给任何人。 新域名排名新顶级域名总量达2540万，.xyz、.top、.loan位居前三 .xyz注册量这么大，不可思议。也许因为便宜，8元一个。另外还免费送，在中国备案也助长注册量吧。目前已经在走下坡路了 知乎一切不能在中国备案的域名后缀球都不值 (什么意思？) 域名对SEO的影响域名对网页搜索没有影响。 百度说 google说 reference wikipedia https://www.quora.com/What-is-a-better-alternative-for-a-startup-when-the-com-is-taken-co-io-net-or-org http://www.ctoutiao.com/239698.html 域名注册机构变化注册商whois是用来查询互联网中域名的IP以及所有者等信息的传输协议。早期的WHOIS查询多以命令行接口（Command Line）存在，但是现在出现了一些基于网页接口的简化在线查询工具，甚至可以一次向不同的数据库查询。网页接口的查询工具仍然依赖WHOIS协议向服务器发送查询请求，命令行接口的工具仍然被系统管理员广泛使用。WHOIS通常使用TCP协议43端口。每个域名或IP的WHOIS信息由对应的管理机构保存，例如，以.com结尾的域名的WHOIS信息由.com域名运营商VeriSign管理，中国国家顶级域名.cn域名由CNNIC管理。 通常情况下，域名或IP的信息可以由公众自由查询获得，具体的查询方法是登陆由管理机构提供的WHOIS服务器，输入待查询的域名进行查询。 whois.ai的变化ai-domain也在这次升级中变为注册商，代号ai-domain。可惜的是，新用户已经无法在whois.ai创建账户，这意味着，新用户只能通过注册商进行注册了。而且注册局的用户的域名只出不进，即只提供转出功能，不提供转入功能。whois.ai已经变成一个遗留系统，趋势上会慢慢退出历史的舞台。前后模式的变化如下图： 参考：https://www.zhihu.com/question/57642499/answer/154856435 域名转让/交易 带价push，是直接Push到对方账户里，他要付款接收。（自己找买家，随意商议价格） 一口价域名发布,一口价需要他找域名批量或逐个购买（阿里平台给你找买家，当然要手续费） 烂域名就一口价甩出去 线上议价域名发布 （） 竞价域名发布 一口价挂出来，有被其他人秒走的可能(好域名可以线上议价) 交易手续费 手续费为 1%平台支持的一口价、线上议价会收取手续费，带价 push 免费。 交易费由谁承担？由卖家承担，对于域名买家不受影响。 根据ICANN域名转移政策调整要求，为了确保交易的顺利进行，请所有卖家选择关闭“60天内禁止转出阿里云”限制，否则不能发布域名交易，且在2017年1月10日24点前未完成确认的已发布交易域名将全部下架处理，点击确认 域名发展史","tags":[{"name":"domain","slug":"domain","permalink":"http://yoursite.com/tags/domain/"},{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"},{"name":"建站","slug":"建站","permalink":"http://yoursite.com/tags/建站/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"}]},{"title":"关于SEO","date":"2018-01-24T16:00:00.000Z","path":"wiki/CS/web/建站/seo/seo-for-spider/","text":"简介如何检查自己网站是否被baidu google检索site:xu-song.top gitsite:xu-song.github.io git 提交百度检索https://ziyuan.baidu.com/linksubmit/url 百度搜索资源平台为站长提供链接提交通道，您可以提交想被百度收录的链接，百度搜索引擎会按照标准处理，但不保证一定能够收录您提交的链接。 Hexo 博客添加百度sitemap hexo部署在github，用百度的站长收录sitemap，抓取失败怎么办？Github屏蔽了百度爬虫。除了sitemap还有其他提交方法，还可以采用主动推送和自动推送， 为什么我的博客始终无法被百度收录我在GoDaddy购买了域名，完成了在谷歌搜录，百度完成自动推送的设置后在sitemap一栏中填入我的域名始终显示sitemap抓取失败，请问这是什么问题我该如何解决呢 – 知乎 github 禁止了百度的爬虫，你可以在 国内的 coding.net 上放一份，然后修改域名服务商的 CNAME 让国内的指向 coding.net ，国外的依然指向 github。具体你自己查下吧 就算放开了，肯定也没有国内的vps收录快。还有就是并不是所有的ip地址的权重都一样。爬虫有自己喜欢和不喜欢的ip群 如果完全没有外链，也不向百度提交，相当于孤岛，是不可能被收录的。除非有人替你提交，或者本身百度数据库有你域名的记录。 没外链不代表孤岛，没外链你DNS修改时候百度等也有可能会知道，参考dnspod和百度合作的某文章…… 有多个域名，怎么做最符合 SEO?把其他域名都转发到主域名。很多人把不同的域名都解析到同一个网站，这样导致的结果是其他的域名没有对主域名起到任何作用，反而可能导致负面影响，如：让搜索引擎分不清到底哪一个是主域名。 搜索引擎对同一ip下的域名有互相推广的作用，给的比重越来越小了，多个域名同时解析到一个主机上，对SEO是有影响的，比如说：排名不好、PR值低、收录量少等问题。 对于多域名绑定建议从下面入手： 1.使用301重定向功能。关于301重定向的操作需要注意的是：不要将次要网站中的所有网页的流量都重定向到主站上，这样做虽然节省了很多工作量，但是如果用户从搜索引擎上找过来，访问到的网页并不是他想要的内容，就会损失流量。尽可能做到页对页的重定向，保证用户从搜索引擎找过来的网页即使不是绝对匹配也是相关的内容。 2.给次要的网站首页做一个导航,把流量指引到主站上； 3.给次要的域名做URL转发； 一定要这样做：实现301重定向把次域名重定向到主域名去，避免权重分散，甚至被K，或者影响SEO排名。 301 redirect:：301代表永久性转移。301重定向是网页更改地址后对搜索引擎最友好的方法，只要不是暂时搬移的情况，都建议使用301来做转址。 302 redirect:：302代表暂时性转移。在前些年，不少Black Hat SEO曾广泛应用这项技术作弊。各大主要搜索引擎均加强了打击力度。(怎么作弊？) 当网页A用301重定向转到网页B时，搜索引擎可以肯定网页A永久的改变位置，或者说实际上不存在了，搜索引擎就会把网页B当作唯一有效目标。好处是，第一，没有网址规范化问题，第二，也很重要的，网页A的PR网页级别会传到网页B。 SEO与跳转(重定向)301 vs 302 vs meta-refresh tag 参考 URL 重定向服务实际并非DNS 服务，它们在 HTTP 级别运行，而非 DNS 级别。使用URL转发的客户基本都是免费DNS的用户，当前业务暂不会投入支持。 301重定向301 重定向，是指当用户通过浏览器访问某个 URL 时，Web 服务器被设置自动跳转到另外一个 URL，此时给客户端的返回码是 301。 应用场景301 重定向一般用于两个 URL 之间的跳转。由于 301 重定向可以实现 URL 跳转后的权重转移，实现 SEO 优化，所以常用于如下场景： 网站有多个域名，但有一个主域名作为 SEO 推广对象，所有其他域名可以做 301 重定向到主域名，实现权重转移。 网站更换过域名，希望用新的域名作为 SEO 推广对象，当网站的用户访问旧域名时就会被 301 重定向到新的域名，实现权重转移。 迁移后，访问统计归零。 301重定向之后是不会承继老网站的关键词排名，只不过老网站的排名依然在而已，用户点击你的老域名会直接指向新域名 网站部分内容做过调整，URL 已经无法访问，可以做 301 重定向实现权重转移。 参考： http://www.360doc.com/content/14/0212/15/13780192_351920352.shtml http://www.hurencai.com/archives/453 服务器ip迁移比如从gitpage迁移到coding page。 https://www.zhihu.com/question/19987112 ### URL设计 与 SEO 静态URL 尽量英文，中文用拼音。(现在搜索引擎也对中文优化了，貌似中文url也不错，例如wikipedia的中文页面就采用的中文url) 字母全部小写 URL中包含关键词 url要短 单词之间一般建议使用短横线（-）分隔，不要使用下划线或者其他符号 robots.txtrobots.txt位置固定，sitemap.xml需要在robots.txt中指定路径 必要性 提交链接的几种方式Sitemap提交：在配置sitemap文件时，无论是txt格式的文本文档还是还是xml格式的文件。都不建议将其sitemap的文件名命名为sitemap.txt或sitemap.xml这么大众化且谁都能够知道的文件名。如果你这样设置，你的竞争对手或需要你网站内容的人很容易就能拿到你所有的页面url。出于保险起见还是使用一些自己定义的较复杂的文件名。每一个url都必须包含http://，文件中包含的url不得超过5万条，单文件大小不得超过10MB，一个站点最多提交5万个sitemap文件，超出5万个不再处理并会提示“链接数超”。如果是通过子域名的形式验证的站点。那么主域名下的sitemap文件是可以包含该域名下的所有域名的url的。 主动推送： 对比sitemap而言在及时抓取上推送更快、发现更快、抓取更及时。如果是时效性文章不排除其收录速度达到一瞬间的效率，这里特别建议一下，最好是主动推送我们网站第一时间产生的新内容给百度其效果更佳；主动推送是有推送数量的限制，尽可能的不要推送重复的内容给百度。这样会大大浪费自己的可推送资源。 自动推送：在页面被访问时，页面URL将立即被推送给百度。 sitemap爬虫会通过网页内部的链接发现新的网页。但是如果没有连接指向的网页怎么办?或者用户输入条件生成的动态网页怎么办?能否让网站管理员通知搜索引擎他们网站上有哪些可供抓取的网页?这就是sitemap，最简单的 Sitepmap 形式就是XML文件，在其中列出网站中的网址以及关于每个网址的其他数据(上次更新的时间、更改的频率以及相对于网站上其他网址的重要程度等等)，利用这些信息搜索引擎可以更加智能地抓取网站内容。 新的问题来了，爬虫怎么知道这个网站有没有提供sitemap文件，或者说网站管理员生成了sitemap，(可能是多个文件)，爬虫怎么知道放在哪里呢? 由于robots.txt的位置是固定的，于是大家就想到了把sitemap的位置信息放在robots.txt里。这就成为robots.txt里的新成员了。 站点地图对于百度失效。可以用主动推送和自动推送， 对于主域名下有多个2级域名的问题，应该是每一个二级域名都有自己独立的robots文件和sitemap。 必要性：不做也能收录。最好做，为蜘蛛提供一个引导，有利于收录 知乎没有sitemap.xml，或许自定义了文件名 https://blog.eson.org/2018/03/04/web/site-dev/seo-in-hexo/ 主动推送调用接口http://data.zz.baidu.com/urls?site=https://blog.eson.org&amp;token=hOraXsrU6jl6Pifg&quot; 应用实例hexo的baidu主动推送hexo-baidu-url-submit 新链接的产生，hexo generate会产生一个文本文件，里面包含最新的链接新链接的提交，hexo deploy会从上述文件中读取链接，提交至百度搜索引擎。 自动推送页面每次被访问时，页面URL将立即被推送给百度。借助用户的浏览行为来触发推送动作，无需站长汇总URL再进行主动推送操作，省去了站长人工操作的时间。 源码需要将这段js代码部署到我们的每一个网页中1234567891011121314&lt;script&gt;(function()&#123; var bp = document.createElement('script'); var curProtocol = window.location.protocol.split(':')[0]; if (curProtocol === 'https') &#123; bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'; &#125; else &#123; bp.src = 'http://push.zhanzhang.baidu.com/push.js'; &#125; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(bp, s); //&#125;)();&lt;/script&gt; 每当用户进行访问时，就会触发了这段代码，这段代码自动将当前页面的url推送给了百度。具体推送代码如下： push.js123456789101112!function() &#123; var e = /([http|https]:\\/\\/[a-zA-Z0-9\\_\\.]+\\.baidu\\.com)/gi , r = window.location.href , t = document.referrer; if (!e.test(r)) &#123; var o = \"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif\"; t ? (o += \"?r=\" + encodeURIComponent(document.referrer), r &amp;&amp; (o += \"&amp;l=\" + r)) : r &amp;&amp; (o += \"?l=\" + r); var i = new Image; i.src = o &#125;&#125;(window); 比如每次访问页面https://blog.eson.org时，都会触发一个http请求https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif?l=https://blog.eson.org/。这就是自动推送。 应用实例：hexo-theme-next中的baidu自动推送， baidu-push.swig 总结建议同时配置这三种方式，并让三者协同工作，将抓取和收录价值最大化。 怎样判断网站有网址规范化问题？1) 查一下这些URL是否都有差不多的PR值和网页快照： http://domainname.comhttp://www.domainname.com/index.htmlhttp://domainname.com/index.htmlhttp://www.domainname.com 2)搜一下site:domain.com看是否结果中有多个主页版本。 3)你的网站是否在Google有大量网页被标为“ 补充材料”(Supplemental Result)。一般认为被归为“ 补充材料”是网址规范化问题的征兆。 reference： https://www.seozac.com/seo/301-redirect/ site:.top tips edu和gov后缀的域名天生权重更高。有些域名天生反链高，比如xxx sex 之类的等等！ 百度说：使用何种形式的域名后缀对百度网页搜索没有影响 注册时间越早的域名，越有利于排名。 到期时间越晚的域名，越有利于排名。 不同的子域名是会被当作独立网站处理的，不能继承主域名的权重。 不同国家的域名，在本国会越有利于排名，比如http://abc.cn在中国会排名更好，而http://abc.us在美国会排名更好。 一个网站有多个域名没问题，请做好301跳转，别每个域名都可以访问。 gov和edu对排名有利，但对大多数人没什么指导意义，因为你根本弄不到这种后缀的域名。 域名买卖历史，（不涉及到违规行业越好） 惩罚 &amp; 奖励 关键词堆砌 频繁的修改网页title、description和keywords 网站加上黑链 短时间内频繁的增加外链，或者短时间内大量的删除外链 服务器不稳定，网站经常打不开活域名解析错误。 全站 HTTPS，谷歌对 HTTPS 有加分 响应式设计，谷歌对提供友好移动端友好页面有加分 AMP，谷歌对提供 AMP 支持的网站有加分 PWA，谷歌对 PWA 有加分 加载优化，谷歌对 Pageseed 测试 90 分以上的网站有加分 页面内容持续不断更新，迎合了搜索引擎喜新厌旧的特性。 关键词密度要提升，但不是堆积 高质量内容出现在代码更靠前的位置，方便搜索引擎识别抓取。 内容很少的页面搜索引擎肯定不喜欢 tricks有很多大学生在他们大学的个人网站上出卖链接。搜索引擎怎样去辨别哪些来自.edu的链接是自然的？哪些又是买卖的呢？ seo诊断bing站长有SEO Analyzer。 title长度诊断我的主页，title太短，因为只有四个字母ESON。 Recommended Action:Change the length of the title to be between 5 and 100 characters SEO Explanation:If the title is too short, it may not provide us and users with enough information to understand the relevancy of your page. If the title is too long, we may need to shorten it in the search results and your keywords may not appear on the search results page. You should try to keep the length of the title somewhere between at least 5 characters and 100 characters. description长度 Recommended Action:Change the description in the tag in the page source to be between 25 and 160 characters in length. SEO Explanation:Search engine crawlers only show the first 150-160 characters of the description in the search results page, so if a description is too long, searchers may not see all of the text. If a description is too short, the search engines may add text found elsewhere on the page. Note that search engines may show a different description from the one you have authored if they feel it may be more relevant to a user’s search. tag数量太多https://blog.eson.org/2018/01/25/web/site-dev/seo/seo-for-spider/ There are multiple tags on the page.Recommended Action:Remove redundant tags from the page source, so that only one tag exists. tag 的 ALT属性 Recommended Action:Use the attribute to write descriptive content for the image: &lt;img source=”pic.gif” alt=”Accurate and descriptive keyword text that represents the image.”. SEO Explanation:As a general rule, search engines do not interpret the content of image files. The text provided in the attribute enables the site owner to provide relevant information to the search engine and to the end user. Alt text is helpful to end users if they have images disabled or if the image does not properly load. In addition, the Alt text is utilized by screen readers. Make sure that your Alt text is descriptive and accurately reflects what the image represents and supports the content on the page. referencehttps://www.webmasterworld.com/forum25/3716.htmhttp://www.ehcoo.com/seo.html百度站长平台关于SEO的建议自动推送Hexo博客文章至百度 待看知乎是怎么把 SEO 做起来的？ https建议 新站如何被百度快速收录待续 常见疑问http站点转为https后，对站点原本的评价权重得分是否有影响？无影响，后续会有正向收益，认为https更安全，在排序上会有倾斜。 转https后，需要做301跳转，在这个过程中，http已有的排名是否会有变动？快照是否有变动？301需要永久存在吗？快照和排名不会有变化，建议301永久存在，不管是对搜索引挚还是对用户来说都更好一些。 针对https的站点，百度在抓取技术层面上有哪些建议？如果以前有http站点，建议永久保留跳转行为。之后注意通过百度站长平台的抓取诊断工具和抓取异常工具关注抓取结果。 百度索引量增加收录量反而下降是什么原因？百度索引量是指被百度收集的数量，百度收录量是指被百度放出的数量 索引量指可以被搜索用户搜索到的网站数据库，索引量工具同时支持站点自定义想要关注的目录，查看某一目录规则下的索引量；索引量不等于流量，索引量会有定期数据波动，属于正常现象。 百度索引数据最快每天更新一次，最迟一周更新一次，不同站点的更新日期可能不同。 您可以查询到近一年中每天的索引量数据，一年前的索引量数据为每月索引量数据。 如果已有流量数据查询不到，请隔日再查，最长间隔一周可查询到数据。来自百度 https://ziyuan.baidu.com 百度索引是指你的网页已被百度蜘蛛爬取到百度索引库里了，但这不表示你的网页被百度收录了，所以你是检索不到的。 百度收录是指，在百度索引库的网页经一定检查符合百度标准的，百度“转移到”（这个词是我自己说的，方便理解，实际百度未必这样处理）收录库里，予以放出，也就是被百度收录了这时你才能检索到自己的网页，但此时你的网页如果不符合标准仍然有从百度收录库被删的可能，比如文章是复制的重复率太高等等，百度检查也不是完美的。 索引增加说明，百度蜘蛛还会定期到你的网站爬取网页，所以你的索引会增加。收录减少很可能是因为你的网页在百度的价值不够，又被百度收录删了。 为什么百度索引量和收录量一直不增加呢?新站开始收录比较慢比较正常，当然有些新站收录也会比较好。这个也是有一些偶性的，看下抓取频次和日志里面的蜘蛛爬行情况，都是正常即可。 提交链接后，都会被百度抓取并收录吗？百度对已提交的数据，不保证一定会抓取及收录所有网址。是否收录与页面质量相关。 实例电商比较重视排名，SEO一定要好 总结麻蛋，百度不行啊。seo设置麻烦，收录又慢。google都不用设置，收录又新又好。","tags":[{"name":"domain","slug":"domain","permalink":"http://yoursite.com/tags/domain/"},{"name":"SEO","slug":"SEO","permalink":"http://yoursite.com/tags/SEO/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"web","slug":"CS/web","permalink":"http://yoursite.com/categories/CS/web/"},{"name":"建站","slug":"CS/web/建站","permalink":"http://yoursite.com/categories/CS/web/建站/"},{"name":"seo","slug":"CS/web/建站/seo","permalink":"http://yoursite.com/categories/CS/web/建站/seo/"}]},{"title":"【Hexo插件系列】 常用tag","date":"2017-12-31T16:00:00.000Z","path":"wiki/demo/hexo/hexo-tag/","text":"buttion标签1&#123;% btn #, Text %&#125; Text Text Text & Title Text & Icon (fixed width) 为什么要采用 #, ,, &amp; 作为分隔符? title的作用是什么？hover text吗？貌似没这功能 相关issue &amp; 更多用法: https://github.com/iissnan/hexo-theme-next/pull/1328 note标签123456&#123;% note success %&#125;success **欢迎**[note](.)&#123;% endnote %&#125;&#123;% note danger %&#125;danger **欢迎**[note](.)&#123;% endnote %&#125; success 欢迎note danger 欢迎note 评价note标签在theme-next中集成。它是是blockquote的强化版。额外增加了:主题: simple, modern, flat色系+图标: default(灰色), primary(紫色), info(蓝色), success(绿色), warning(黄色), danger(红色)注意: 不要写在一行，避免渲染错误 建议采用更优雅的方式，比如&gt;danger的方式，继承markdown的blockquote label标签1Lorem &#123;% label default@ipsum %&#125; &#123;% label primary@dolor sit %&#125;. Lorem ipsum dolor sit. theme-next中集成 相关issue &amp; usage: https://github.com/iissnan/hexo-theme-next/pull/1697 色系: 与note相同 只是添加了颜色而已吧，搞这么复杂。 tab标签12 solution 2First unique name 3This is Tab 1.b = 1c = 2b + cb + c = 3This is Tab 3. theme-next中集成 能不能采用更简洁的用法？为什么要采用html注释的方式？ tab内貌似不能放code block 相关issue: https://github.com/iissnan/hexo-theme-next/pull/1697 extrul标签1&#123;% exturl Hexo Theme Next https://github.com/iissnan/hexo-theme-next/ %&#125; Hexo Theme Next 评价: 不如直接写html，比如下面的例子12&lt;i class=\"fa fa-external-link\"&gt;&lt;/i&gt;[&lt;i class=\"fa fa-external-link\"&gt;link to &lt;/i&gt;](ss) 类似的bootstrap标签 http://www.hahack.com/hexo-theme-wixo/Docs/tag-plugins-cn/ 挺赞 https://github.com/wzpan/hexo-tag-bootstrap chat标签hexo-tag-chat，under construction. 文字狱是清朝哪位皇帝兴起的; 康熙 拼音中四声起于; 元 TODO: 用icon还是用头像？icon可以用foneawesome，头像限制比较多 丰富头像库 instagram标签hexo-tag-instagram 将 Instagram元素嵌入Hexo博客 12345678# 1. 默认配置 width:100%, captioned:true&#123;% instagram url:https://www.instagram.com/p/Bg71nq4HuAU/ %&#125;# 或&#123;% instagram Bg71nq4HuAU %&#125;# 2. 无标题 + 调整尺寸&#123;% instagram false Bg71nq4HuAU 60% %&#125;# 或&#123;% instagram captioned:false id:Bg71nq4HuAU width:60% %&#125;","tags":[],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]},{"title":"Docker镜像的构建","date":"2017-12-31T16:00:00.000Z","path":"wiki/docker/tutorial/images/-build/","text":"如何创建docker镜像直接pull从Docker Hub下拉 现在docker官方共有仓库里面有大量的镜像，所以最基础的镜像，我们可以在共有仓库直接拉取，因为这些镜像都是原厂维护，可以得到即使的更新和修护。 Dockerfile：我们如果想去定制这些镜像，我们可以去编写Dockerfile，然后重新bulid，最后把它打包成一个镜像，这种方式是最为推荐的方式包括我们以后去企业当中去实践应用的时候也是推荐这种方式。 Commit当然还有另外一种方式，就是通过镜像启动一个容器，然后进行操作，最终通过commit这个命令commit一个镜像，但是不推荐这种方式，虽然说通过commit这个命令像是操作虚拟机的模式，但是容器毕竟是容器，它不是虚拟机，所以大家还是要去适应用Dockerfile去定制这些镜像这种习惯。 镜像的概念主要就是把把运行环境和业务代码进行镜像的打包，我们这个课重点是了解镜像的分层技术，我们先来看一个Ubuntu系统的镜像。 build images从文件进行build1docker build -f Dockerfile . -t bitspeech/tensor2tensor:1.9.0-gpu 构建小容量Docker镜像的技巧 使用较小的基础镜像 centos:7的大小就比ubuntu:14.04要大，而ubuntu:14.04比debian:jessie要大。 安装完成后进行清理 apt 安装，编译，remove 要一气呵成。docker 镜像是 git 的机制，安装和移除必须写在一行。 你可以通过移除软件包和清理垃圾文件来减小镜像的大小。例如使用apt包管理器的系统可以通过apt-get purge，apt-get autoremove，及apt-get clean命令移除软件包，使用rm -rf /var/lib/apt/lists/*及rm -rf /tmp清除一些临时文件。这里需要注意的是，因为Docker的层次系统，Dockerfile中的每一个RUN命令都会创建一个新的copy-on-write层，从而增加了最终镜像的大小，即使是通过RUN指令运行移除文件的命令。所以上面的这些命令如果都单独地以Dockerfile中的RUN指令执行，最终的镜像大小不会减小，反而会增加。这就需要我们下面的对Dockerfile的进一步改进。 1.系统级镜像:如Ubuntu镜像，CentOS镜像以及Debian容器等； 2.工具栈镜像:如Golang镜像，Flask镜像，Tomcat镜像等； 3.服务级镜像:如MySQL镜像，MongoDB镜像，RabbitMQ镜像等； 4.应用级镜像:如WordPress镜像，DockerRegistry镜像等。 参考 Docker镜像分层技术 | 麦子学院 深刻理解Docker镜像大小 构建小容量Docker镜像的技巧","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"},{"name":"images","slug":"docker/tutorial/images","permalink":"http://yoursite.com/categories/docker/tutorial/images/"}]},{"title":"Docker镜像分层技术","date":"2017-12-31T16:00:00.000Z","path":"wiki/docker/tutorial/images/-images/","text":"简介采用的sha256对每层编码。对image进行编码。 Docker对于镜像的维护类似于git对于repository的维护，都是只记录增量的。原有镜像是静态文件，基于这个静态文件可以创建的一个动态容器，在这个动态的容器中做任何你希望做的修改，然后退出容器后使用commit生成新的镜像，这个新的镜像就保留了你做的改动，从而生成新的一层。 未改变的文件还是使用原有镜像的文件， 被改动的文件作为新的layer被保存。基于同一个base image构建的两个不同的镜像，就类似于 基于同一个repository创建的两个不同的branch， 未修改的文件由两个镜像公用，每个镜像又独自保留他们特定的修改内容的增量。 从命令行上来说： 一个commit指令对应一个新的layer 一条RUN语句对应一个新的layer Ubuntu系统的镜像参考-","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"},{"name":"tutorial","slug":"docker/tutorial","permalink":"http://yoursite.com/categories/docker/tutorial/"},{"name":"images","slug":"docker/tutorial/images","permalink":"http://yoursite.com/categories/docker/tutorial/images/"}]},{"title":"图像分类--模型汇总","date":"2017-12-31T16:00:00.000Z","path":"wiki/ML/app/vision/app/Object Recognition/image-classification/image classification/","text":"image classificationImageNet分类模型 model 简介 conv_padding conv_activation pooling code 备注 LeNet5 3个卷积层+2个pooling层 valid sigmoid AlexNet 8层 same ReLU Overlapping Pooling VGG-19 19层 same ReLU keras GoogLeNet 22层 ResNet 152层 keras padding=same，是采用zero-padding的方式，使得input和output的维度一致。 google.charts.load(“current”,{packages:[‘corechart’]}); google.charts.setOnLoadCallback(drawChart); function drawChart(){var data=google.visualization.arrayToDataTable([ [“Year”, “Accruacy”], [“2010\\nLin”, 28.2], [“2011\\nSanchez”, 25.8], [“2012\\nAlexNet”, 16.4], [“2013\\nZeiler”, 11.7], [“2014\\nVGG”, 7.3], [“2014\\nGoogLeNet”, 6.7], [“2015\\nResNet”, 3.6], [“2016\\nShao”, 3.0], [“2017\\nSENet”, 2.3], [“Human\\nRussak..”, 5.1],]); var view=new google.visualization.DataView(data); view.setColumns([0, 1,{calc: “stringify”, sourceColumn: 1, type: “string”, role: “annotation”}]); var options={title: “ImageNet”, titlePosition: ‘none’, width: 800, height: 400, ‘chartArea’:{‘width’: ‘95%’}, vAxis:{maxValue: 32, ticks: [0, 10, 20, 30]}, hAxis:{textStyle:{fontSize:12.4}}, bar:{groupWidth: “50%”}, legend:{position: “none”}, annotations:{alwaysOutside: ‘true’, textStyle:{color: “black”, bold:true}},}; var chart=new google.visualization.ColumnChart(document.getElementById(“columnchart_values”)); chart.draw(view, options);} 上图来自cs231n,","tags":[{"name":"cv","slug":"cv","permalink":"http://yoursite.com/tags/cv/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"},{"name":"image classification","slug":"image-classification","permalink":"http://yoursite.com/tags/image-classification/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"app","slug":"ML/app/vision/app","permalink":"http://yoursite.com/categories/ML/app/vision/app/"},{"name":"Object Recognition","slug":"ML/app/vision/app/Object-Recognition","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/"},{"name":"image-classification","slug":"ML/app/vision/app/Object-Recognition/image-classification","permalink":"http://yoursite.com/categories/ML/app/vision/app/Object-Recognition/image-classification/"}]},{"title":"计算机视觉--常用数据库","date":"2017-12-11T16:00:00.000Z","path":"wiki/ML/app/vision/dataset/dataset/","text":"summary dataset im_size class*num download task example code pretrained_model state of art 实例图片 备注 mnist 28*28 70000 CIFAR-10 32x32x3 10*6000 Alex,Hinton发布，超小图片 CIFAR-100 32x32 170M 100*600 Pascal VOC (05-12) 2GB voc2012 coco 40GB imagenet2012 尺寸不固定，但多数比较清晰 1000类，训练集1.2m，验证集50k,测试集100k 层级标签。 评价指标，top5的label包含正确label就算正确 AlexNet imagenet2016 1400多万幅图片，涵盖2万多个类别 1TB places 12306 约80*80 12306图片比cifar数据库大多了 分类结果汇总 task_code: 图像分类（image classification） 目标检测（object detection） 目标识别（object recognition） 语义分割（semantic segmentation） 实例分割（instance segmentation） 来自pytorch vision的data LSUN http://lsun.cs.princeton.edu`_ dataset Local Image Descriptors Data http://phototour.cs.washington.edu/patches/default.htm`_ Dataset. SEMEION http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit`_ Dataset. STL10 https://cs.stanford.edu/~acoates/stl10/`_ Dataset. SVHN http://ufldl.stanford.edu/housenumbers/`_ Dataset. 来自tensorflow的data##","tags":[{"name":"dataset","slug":"dataset","permalink":"http://yoursite.com/tags/dataset/"},{"name":"cv","slug":"cv","permalink":"http://yoursite.com/tags/cv/"}],"categories":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/categories/ML/"},{"name":"app","slug":"ML/app","permalink":"http://yoursite.com/categories/ML/app/"},{"name":"vision","slug":"ML/app/vision","permalink":"http://yoursite.com/categories/ML/app/vision/"},{"name":"dataset","slug":"ML/app/vision/dataset","permalink":"http://yoursite.com/categories/ML/app/vision/dataset/"}]},{"title":"java系列 - Error & Exception","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/Error-and-Exception/","text":"definition catch an error at compile time: before you even try to run the program (think in java)-java framework 123456789101112131415161718192021Throwable─┬─Exception─┬─RuntimeException─┬─IndexOutOfBoundsException │ │ ├─NullPointerException │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └─ │ │ │ ├─ ReflectiveOperationException─┬─NoSuchMethodException │ │ ├─ClassNotFoundException │ │ └─IllegalAccessException │ │ │ │ │ │ │ ├─IOException─┬─FileNotFoundException │ │ ├─EOFException │ └─Error─┬─ RuntimeException non-RuntimeException checked × √ occur in runtime runtime must catch × √ caused by programmer,such as NullPointerException, IndexOutOfBoundsException external, such as FileNotFoundException thrown during the normal operation of JVM Compile-Time Checking of Exceptions 设计思想RuntimeException一般情况下，不要捕获或声明RuntimeException。因为问题在于你的程序逻辑本身有问题，如果你用异常流程处理了，反而让正常流程问题一直存在。程序应该从逻辑角度尽可能避免这类异常的发生； non-RuntimeExceptionRuntimeException之外的异常我们统称为非运行时异常。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。 非运行时异常，编译期要做语法检查，即检查是否处理了catch。程序报Exception还是要运行期才能知道的。 An Exception is checked, and a RuntimeException is unchecked. A checked exception must be handled explicitly by the code (catch or throw) An un-checked exception does not need to be explicitly handled. ambiguous, common errors, common misconceptionsIs non-RuntimeException CompiletimeException in java framework?No, non-RuntimeException would be checked in compile time. But the Exception occurs in run time. where did RuntimeException comes fromsince JDK1.0 new/reasonable frameworkIn my view, the RuntimeException should be renamed as CheckedException RuntimeException CheckedException UncheckedException CompiletimeException .. reference 《The Java™ Language Specification》11.2 Compile-Time Checking of Exceptions other framework Some programming languages and their implementations react to such errorsby peremptorily terminating the program; other programming languages allow animplementation to react in an arbitrary or unpredictable way. Neither of theseapproaches is compatible with the design goals of the Java SE platform: to provideportability and robustness. Instead, the Java programming language specifies that an exception will be thrownwhen semantic constraints are violated and will cause a non-local transfer of controlfrom the point where the exception occurred to a point that can be specified by theprogrammer. 2. python frameworkreference: http://www.cnblogs.com/rubylouvre/archive/2011/06/22/2086644.html c++ framework","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"}]},{"title":"java系列 - byte code","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/-JavaBytecodes/","text":"查看byte code javap -c java.lang.Object eclipse插件ASM 常用byte code","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"}]},{"title":"【java源码系列】 - String","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/String/","text":"ssString s = “abc”,并没有在堆上生成对象Object o = new Object() 对应字节码为: 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: astore_1 String s = “abc” 对应字节码为: 0: ldc #2 // String abc 2: astore_1 String s = new String() 对应字节码为: 0: new #2 // class java/lang/String 3: dup 4: invokespecial #3 // Method java/lang/String.&quot;&lt;init&gt;&quot;:()V 7: astore_1","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"string","slug":"string","permalink":"http://yoursite.com/tags/string/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"}]},{"title":"java系列 - class文件","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/jvm/classFile/","text":"introduction目的：完整分析class文件。 java源码package MyTest; public class SimpleClass { void dfd() { int i; for (i = 0; i &lt; 100; i++) { ; // Loop body is empty } } } class文件 16进制编译得到MyTest.class cafe babe | 0000 0033 000c magic num | minor0 major51 常量池计数器11+1=12 //////////// 常量池 ///////////// #1 07 0002 class #2 #2 01 0012 4d79 5465 7374 2f53 696d 706c 6543 6c61 7373 utf8 length=18 MyTest/SimpleClass | | #3 07 0004 class #4 // java/lang/Object #4 01 0010 6a61 7661 2f6c 616e 672f 4f62 6a65 6374 | utf8 lengh16 java/lang/Object | #5 01 0006 3c 696e 6974 3e utf8 length=6 &lt;init&gt; #6 01 0003 2829 56 utf8 length=3 ()V #7 01 0004 436f 6465 utf8 length=3 Code #8 0a 000300 09 md_ref #3. #9 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #9 0c 0005 0006 nam&amp;ty #5 #6 // &quot;&lt;init&gt;&quot;:()V #10 01 0003 64 6664 utf8 length=3 dfd #11 01 000d 53 7461 636b 4d61 7054 6162 6c65 utf8 length=13 StackMapTable //////////// 常量池 ///////////// 0021 0001 0003 可能是public #1 类索引 #3 父类索引 // 0x0021=0x0001|0x0020 也即ACC_PUBLIC 和 ACC_SUPER为真，其中ACC_PUBLIC大家好理解，ACC_SUPER是jdk1.2之后编译的类都会带有的标志。 0000 接口计数器 接口表 0000 fields_count 0002 methods_count //////////////// 第一个method void &lt;init&gt; /////////// 0001 0005 0006 public #5&lt;init&gt; #6()V 其值为()V，表示&lt;init&gt;方法没有参数和返回值, 其实这是编译器自动生成 的实例构造器方法 0001 attrib_count 0007 00000011 0001 0001 00000005 2ab70008b1 0000 0000 #7Code属性 attrib_len max_stack max_locals code_length code[] exception_table_length attribute_count // 代码是存储在Class文件中的method的code属性的code[]数组中 //////////////// 第二个method dfd() /////////// 0000 000a 0006 没写access_flag #10,dfd ()V 0001 attrib_count 0007 00000028 0002 0002 0000000f 033ca700068401011b1064a1fffab1 #7Code属性 属性表的长度 max_stack max_locals code_length=15 code[]，解析见《jvm spec》41页 0000 exception_table_length 0001 attribute_count 000b 00000007 0002 fc00 0501 0200 00 #11:StackMapTable length num_of_entries 7个length的stack_map_frame 疑问.和：是怎么区分的？ 其他阅读http://coolshell.cn/articles/9229.html","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"jvm","slug":"CS/programing/lan/java/jdk/jvm","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/"}]},{"title":"【java源码系列】Atomic","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/Atomic/","text":"简介 原子量和普通变量相比，主要体现在读写的线程安全上。对原子量的是原子的(比如多线程下的共享变量i++就不是原子的)，由CAS操作保证原子性。对原子量的读可以读到最新值，由volatile关键字来保证可见性。 原子量多用于数据统计(如接口调用次数)、一些序列生成(多线程环境下)以及一些同步数据结构中 atomic是基于底层硬件的CAS做的 区别于HashTable等线程安全类，这里面没有锁 以AtomicLong为例java源码// 1. from AtomicLong.java (rt.jar:java.util.concurrent.atomic.AtomicLong) public final boolean compareAndSet(long expect, long update) { return unsafe.compareAndSwapLong(this, valueOffset, expect, update); } // 2. from Unsafe.java (rt.jar:sun.misc.Unsafe) public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x); native方法的C++实现// 3. from hotspot/src/share/vm/prims/unsafe.cpp (openjdk) static JNINativeMethod methods[] = { {CC&quot;compareAndSwapLong&quot;, CC&quot;(&quot;OBJ&quot;J&quot;&quot;J&quot;&quot;J&quot;&quot;)Z&quot;, FN_PTR(Unsafe_CompareAndSwapLong)}, ... } ... UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapLong(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jlong e, jlong x)) UnsafeWrapper(&quot;Unsafe_CompareAndSwapLong&quot;); Handle p (THREAD, JNIHandles::resolve(obj)); jlong* addr = (jlong*)(index_oop_from_field_offset_long(p(), offset)); if (VM_Version::supports_cx8()) return (jlong)(Atomic::cmpxchg(x, addr, e)) == e; // 主要实现 else { // 如果不支持cx8，那么就需要用到ObjectLocker锁 jboolean success = false; ObjectLocker ol(p, THREAD); if (*addr == e) { *addr = x; success = true; } return success; } UNSAFE_END It is a JNI wrapper for the CAS API, with memory barriers for IA64 architecture. It is an atomic operation which means no other processor can change the value of dest whilst the operation executes. Atomic::cmpxchg(x, addr, e)CAS需要三个参数 address,old_value, new_value.modern CPU is required for this process. CAS has its weakness as ABA problem, so memory barrier is necessary here to ensure the CAS is still correct in multithread environment. native的实现 Atomic::cmpxchg方法的分支依赖于OS &amp; CPU &amp; 32bit/64bit. 所以JVM在这里产生了分支 // 4. from hotspot/src/share/vm/runtime/atomic.cpp # include &quot;atomic_windows_x86.inline.hpp&quot; # include &quot;atomic_linux_x86.inline.hpp&quot; // x86生产商有Intel, AMD, IBM等 # include &quot;atomic_solaris_sparc.inline.hpp&quot; // Solaris系统，sparc处理器(都是sun的) # include &quot;atomic_linux_sparc.inline.hpp&quot; // linux系统，sparc处理器 ... linux_x86中： // from openjdk/hotspot/os_cpu/linux_x86/vm/atomic_linux_x86.inline.hpp #ifdef AMD64 inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) { bool mp = os::is_MP(); __asm__ __volatile__ (LOCK_IF_MP(%4) &quot;cmpxchgq %1,(%3)&quot; : &quot;=a&quot; (exchange_value) : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp) : &quot;cc&quot;, &quot;memory&quot;); return exchange_value; } #else // !AMD64 inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) { return _Atomic_cmpxchg_long(exchange_value, dest, compare_value, os::is_MP()); } #endif // AMD64 windows_x86中 // from openjdk\\hotspot\\src\\os_cpu\\windows_x86\\vm #ifdef AMD64 inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) { return (*os::atomic_cmpxchg_long_func)(exchange_value, dest, compare_value); } #else // !AMD64 inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) { int mp = os::is_MP(); jint ex_lo = (jint)exchange_value; jint ex_hi = *( ((jint*)&amp;exchange_value) + 1 ); jint cmp_lo = (jint)compare_value; jint cmp_hi = *( ((jint*)&amp;compare_value) + 1 ); __asm { push ebx push edi mov eax, cmp_lo mov edx, cmp_hi mov edi, dest mov ebx, ex_lo mov ecx, ex_hi LOCK_IF_MP(mp) cmpxchg8b qword ptr [edi] pop edi pop ebx } } #endif // AMD64 其他平台… 可以看出，当CPU支持时，最终确实是直接用cmpxchg相关指令实现的。 ObjectLocker锁这是synchronized锁吗？ Why would you use a CAS function?名词解释 Solaris：原是太阳微系统公司研制的类Unix操作系统，在Sun公司被Oracle并购后，称作Oracle Solaris。早期的Solaris主要用于Sun工作站上 saparc: sun公司开发的处理器，用于Sun工作站等上。Solaris在SPARC上拥有强大的处理能力和硬件支持(相对Intel x86平台) cx8: ObjectLocker: 疑问 i = i + 1不是原子操作吗？为什么AtomicLong.incrementAndGet()的实现要这么复杂?直接用i = i + 1实现不行吗？(见《java并发编程实战》18页) #include &lt;atomic> C++自带的实现与atomic_linux_x86.inline.hpp有什么区别？应该前者是后者的进一步封装吧？ 这个native方法的实现为什么在JVM层而不在jdk层？JVM是用来run byte code的。这里的JVM代码是用来run哪个byte code呢？ 这里生成的byte code是啥样的？ 再挖掘参考 (http://stackoverflow.com/questions/7169961/can-anyone-interpret-this-c-code-from-openjdk6-into-plain-english)","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"}]},{"title":"【java源码系列】- Thread","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/Thread/","text":"疑问Java的线程是如何创建的，是直接调用OS的API，还是有自己的“抽象线程”？java线程是映射到操作系统的内核线程上的 跟踪Thread.start()java // Thread.java public synchronized void start() { group.add(this); ... start0(); ... } private native void start0(); native方法hotspot源码 // openjdk\\jdk\\src\\share\\native\\java\\lang\\Thread.c static JNINativeMethod methods[] = { {&quot;start0&quot;, &quot;()V&quot;, (void *)&amp;JVM_StartThread}, ... }; // openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cpp JVM_ENTRY(void, JVM_StartThread(JNIEnv* env, jobject jthread)) JVMWrapper(&quot;JVM_StartThread&quot;); JavaThread *native_thread = NULL; ... native_thread = new JavaThread(&amp;thread_entry, sz); // 重点 ... Thread::start(native_thread); // 重点 JVM_END // openjdk\\hotspot\\src\\share\\vm\\runtime\\thread.cpp JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) : Thread() { ... os::create_thread(this, thr_type, stack_sz); // 可以看出java线程是映射到操作系统的内核线程上的 ... } void Thread::start(Thread* thread) { ... os::start_thread(thread); } } // 在hotspot\\src\\os目录下可以看到windows, linux, solaris和posix的实现，先检查linux\\vm\\os_linux.cpp bool os::create_thread(Thread* thread, ThreadType thr_type, size_t stack_size) { ... int ret = pthread_create(&amp;tid, &amp;attr, (void* (*)(void*)) java_start, thread); // linux中调用的pthread，POSIX中的api ... }","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"}]},{"title":"java hotspot虚拟机 - SocketOutputStream","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/jvm/HotSpot/SocketOutputStream/","text":"SocketOutputStream.java就只有这一个native方法 123456789/*** Writes to the socket.* @param fd the FileDescriptor* @param b the data to be written* @param off the start offset in the data* @param len the number of bytes that are written* @exception IOException If an I/O error has occurred.*/private native void socketWrite0(FileDescriptor fd, byte[] b, int off, int len) throws IOException; SocketOutputStream.c路径: openjdk\\jdk\\src\\windows\\native\\java\\net\\SocketOutputStream.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143#include &lt;windows.h&gt;#include &lt;winsock2.h&gt;#include &lt;ctype.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;malloc.h&gt;#include &lt;sys/types.h&gt;#include \"java_net_SocketOutputStream.h\"#include \"net_util.h\"#include \"jni_util.h\"/************************************************************************ * SocketOutputStream */static jfieldID IO_fd_fdID;/* * Class: java_net_SocketOutputStream * Method: init * Signature: ()V */JNIEXPORT void JNICALLJava_java_net_SocketOutputStream_init(JNIEnv *env, jclass cls) &#123; IO_fd_fdID = NET_GetFileDescriptorID(env);&#125;/* * Class: java_net_SocketOutputStream * Method: socketWrite * Signature: (Ljava/io/FileDescriptor;[BII)V */JNIEXPORT void JNICALLJava_java_net_SocketOutputStream_socketWrite0(JNIEnv *env, jobject this, jobject fdObj, jbyteArray data, jint off, jint len) &#123; char *bufP; char BUF[MAX_BUFFER_LEN]; int buflen; int fd; if (IS_NULL(fdObj)) &#123; JNU_ThrowByName(env, JNU_JAVANETPKG \"SocketException\", \"Socket closed\"); return; &#125; else &#123; fd = (*env)-&gt;GetIntField(env, fdObj, IO_fd_fdID); &#125; if (IS_NULL(data)) &#123; JNU_ThrowNullPointerException(env, \"data argument\"); return; &#125; /* * Use stack allocate buffer if possible. For large sizes we allocate * an intermediate buffer from the heap (up to a maximum). If heap is * unavailable just use our stack buffer. */ if (len &lt;= MAX_BUFFER_LEN) &#123; bufP = BUF; buflen = MAX_BUFFER_LEN; &#125; else &#123; buflen = min(MAX_HEAP_BUFFER_LEN, len); bufP = (char *)malloc((size_t)buflen); if (bufP == NULL) &#123; bufP = BUF; buflen = MAX_BUFFER_LEN; &#125; &#125; while(len &gt; 0) &#123; int loff = 0; int chunkLen = min(buflen, len); int llen = chunkLen; int retry = 0; (*env)-&gt;GetByteArrayRegion(env, data, off, chunkLen, (jbyte *)bufP); while(llen &gt; 0) &#123; int n = send(fd, bufP + loff, llen, 0); if (n &gt; 0) &#123; llen -= n; loff += n; continue; &#125; /* * Due to a bug in Windows Sockets (observed on NT and Windows * 2000) it may be necessary to retry the send. The issue is that * on blocking sockets send/WSASend is supposed to block if there * is insufficient buffer space available. If there are a large * number of threads blocked on write due to congestion then it's * possile to hit the NT/2000 bug whereby send returns WSAENOBUFS. * The workaround we use is to retry the send. If we have a * large buffer to send (&gt;2k) then we retry with a maximum of * 2k buffer. If we hit the issue with &lt;=2k buffer then we backoff * for 1 second and retry again. We repeat this up to a reasonable * limit before bailing out and throwing an exception. In load * conditions we've observed that the send will succeed after 2-3 * attempts but this depends on network buffers associated with * other sockets draining. */ if (WSAGetLastError() == WSAENOBUFS) &#123; if (llen &gt; MAX_BUFFER_LEN) &#123; buflen = MAX_BUFFER_LEN; chunkLen = MAX_BUFFER_LEN; llen = MAX_BUFFER_LEN; continue; &#125; if (retry &gt;= 30) &#123; JNU_ThrowByName(env, JNU_JAVANETPKG \"SocketException\", \"No buffer space available - exhausted attempts to queue buffer\"); if (bufP != BUF) &#123; free(bufP); &#125; return; &#125; Sleep(1000); retry++; continue; &#125; /* * Send failed - can be caused by close or write error. */ if (WSAGetLastError() == WSAENOTSOCK) &#123; JNU_ThrowByName(env, JNU_JAVANETPKG \"SocketException\", \"Socket closed\"); &#125; else &#123; NET_ThrowCurrent(env, \"socket write error\"); &#125; if (bufP != BUF) &#123; free(bufP); &#125; return; &#125; len -= chunkLen; off += chunkLen; &#125; if (bufP != BUF) &#123; free(bufP); &#125;&#125;","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"jvm","slug":"CS/programing/lan/java/jdk/jvm","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/"},{"name":"HotSpot","slug":"CS/programing/lan/java/jdk/jvm/HotSpot","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/HotSpot/"}]},{"title":"java hotspot虚拟机 - init方法","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/jvm/HotSpot/init/","text":"初始化方法在编译生成class文件时，会自动产生两个方法，一个是类的初始化方法, 另一个是实例的初始化方法 ：在jvm第一次加载class文件时调用，包括静态变量初始化语句和静态块的执行 :在实例创建出来的时候调用，包括调用new操作符；调用Class或java.lang.reflect.Constructor对象的newInstance()方法；调用任何现有对象的clone()方法；通过java.io.ObjectInputStream类的getObject()方法反序列化。 init的实现是由jvm实现的，以下是hotspot jvm实现的版本 openjdk\\hotspot\\src\\share\\vm\\oops\\instanceKlass.cppopenjdk\\hotspot\\src\\share\\vm\\oops\\instanceKlassKlass.cpp 为什么叫 名词解释 oops原来不是Object Oriented Programming，实际指的是 Ordinary Object Pointer（普通对象指针）。它用来表示对象的实例信息，看起来像个指针实际上是藏在指针里的对象。而klass则包含 元数据和方法信息，用来描述Java类。 Klass KlassKlass 参考(见JVM规范8中的2.9节)","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"jvm","slug":"CS/programing/lan/java/jdk/jvm","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/"},{"name":"HotSpot","slug":"CS/programing/lan/java/jdk/jvm/HotSpot","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/HotSpot/"}]},{"title":"java hotspot虚拟机 - class文件","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/jvm/HotSpot/klass/","text":"oop-klass model概述HotSpot JVM并没有根据Java实例对象直接通过虚拟机映射到新建的C++对象，而是设计了一个oop-klass model。 当我们在写Java代码的时候，我们会面对着无数个接口，类，对象和方法。但我们有木有想过，Java中的这些对象、类和方法，在HotSpot JVM中的结构又是怎么样呢？HotSpot JVM底层都是C++实现的，那么Java的对象模型与C++对象模型之间又有什么关系呢？今天就来分析一下HotSpot JVM中的对象模型：oop-klass model，它们的源码位于openjdk-8/openjdk/hotspot/src/share/vm/oops文件夹内。 那么为何要设计这样一个一分为二的对象模型呢？这是因为HotSopt JVM的设计者不想让每个对象中都含有一个vtable（虚函数表），所以就把对象模型拆成klass和oop，其中oop中不含有任何虚函数，而klass就含有虚函数表，可以进行method dispatch。这个模型其实是参照的 Strongtalk VM 底层的对象模型。 jdk版本：openjdk-7-fcs-src-b147-27_jun_2011源码路径：openjdk\\hotspot\\src\\share\\vm\\oops\\ 在oopsHierarchy.hpp里定义了oop和klass各自的体系。这是oop的体系： typedef class oopDesc* oop; typedef class instanceOopDesc* instanceOop; typedef class methodOopDesc* methodOop; typedef class constMethodOopDesc* constMethodOop; typedef class methodDataOopDesc* methodDataOop; typedef class arrayOopDesc* arrayOop; typedef class objArrayOopDesc* objArrayOop; typedef class typeArrayOopDesc* typeArrayOop; typedef class constantPoolOopDesc* constantPoolOop; typedef class constantPoolCacheOopDesc* constantPoolCacheOop; typedef class klassOopDesc* klassOop; typedef class markOopDesc* markOop; typedef class compiledICHolderOopDesc* compiledICHolderOop; 概述，代码架构123456789101112131415161718klass.cppoop.cpparrayKlass.cpparrayOop.cppinstanceKlass.cppinstanceOop.cpp // #include &quot;oops/oop.hpp&quot;methodKlass.cpp// A methodOop represents a Java method.// #include &quot;oops/constantPoolOop.hpp&quot;#include &quot;oops/instanceKlass.hpp&quot; #include &quot;oops/oop.hpp&quot;methodOop.cpp methodDataKlass.cppmethodDataOop.cppobjArrayKlass.cppobjArrayOop.cppsymbol.cpp 名词解释 oop：Ordinary Object Pointer（普通对象指针），oop.h中定义了oopDesc类(没有oop这个类) oop* 有这个而东东啊 Desc：即Describe， {name}Desc classes describe the format of Java objects so the fields can be accessed from C++ oopDesc:oop对象的类型其实是oopDesc*。在Java程序运行的过程中，每创建一个新的对象，在JVM内部就会相应地创建一个对应类型的oop对象。各种oop类的共同基类为oopDesc类。 oop-klass model： Klass一个Klass对象代表一个类的元数据（相当于java.lang.Class对象）。它提供：language level class object (method dictionary etc.)provide vm dispatch behavior for the object 所有的函数都被整合到一个C++类中。Klass对象的继承关系：xxxKlass &lt;:&lt; Klass &lt;:&lt; Metadata &lt;:&lt; MetaspaceObj klass对象的布局如下：来自klass.hpp // A Klass is the part of the klassOop that provides: // 1: language level class object (method dictionary etc.) // 2: provide vm dispatch behavior for the object // Both functions are combined into one C++ class. The toplevel class &quot;Klass&quot; // implements purpose 1 whereas all subclasses provide extra virtual functions // for purpose 2. // One reason for the oop/klass dichotomy in the implementation is // that we don&apos;t want a C++ vtbl pointer in every object. Thus, // normal oops don&apos;t have any virtual functions. Instead, they // forward all &quot;virtual&quot; functions to their klass, which does have // a vtbl and does the C++ dispatch depending on the object&apos;s // actual type. (See oop.inline.hpp for some of the forwarding code.) // ALL FUNCTIONS IMPLEMENTING THIS DISPATCH ARE PREFIXED WITH &quot;oop_&quot;! // Klass layout: // [header ] klassOop // [klass pointer ] klassOop // [C++ vtbl ptr ] (contained in Klass_vtbl) // [layout_helper ] // [super_check_offset ] for fast subtype checks // [secondary_super_cache] for fast subtype checks // [secondary_supers ] array of 2ndary supertypes // [primary_supers 0] // [primary_supers 1] // [primary_supers 2] // ... // [primary_supers 7] // [java_mirror ] // [super ] // [name ] // [first subklass] // [next_sibling ] link to chain additional subklasses // [modifier_flags] // [access_flags ] // [verify_count ] - not in product // [alloc_count ] // [last_biased_lock_bulk_revocation_time] (64 bits) // [prototype_header] // [biased_lock_revocation_count] oopoop类型其实是oopDesc*。在Java程序运行的过程中，每创建一个新的对象，在JVM内部就会相应地创建一个对应类型的oop对象。各种oop类的共同基类为oopDesc类。 JVM内部，一个Java对象在内存中的布局可以连续分成两部分：instanceOopDesc和实例数据。instanceOopDesc和arrayOopDesc又称为对象头。 instanceOopDesc对象头包含两部分信息：Mark Word 和 元数据指针(Klass*)： // from oop.hpp // oopDesc is abstract. // (see oopHierarchy for complete oop class hierarchy) class oopDesc { friend class VMStructs; private: volatile markOop _mark; // mark word union _metadata { // metadata wideKlassOop _klass; narrowOop _compressed_klass; } _metadata; ... Mark word: // 存储对象的hashCode或锁信息等。 Klass* // 存储到对象类型数据的指针 基础知识：C++ vtbl pointer：虚函数ss 参考深入探究JVM | klass-oop对象模型研究","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"hotspot","slug":"hotspot","permalink":"http://yoursite.com/tags/hotspot/"},{"name":"class","slug":"class","permalink":"http://yoursite.com/tags/class/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"jvm","slug":"CS/programing/lan/java/jdk/jvm","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/"},{"name":"HotSpot","slug":"CS/programing/lan/java/jdk/jvm/HotSpot","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/jvm/HotSpot/"}]},{"title":"【java源码系列】 - System","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/system/System/","text":"简介java.lang.System.java 跟踪arraycopypublic static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); System.c// jdk/src/share/native/java/lang/System.c /* Only register the performance-critical methods */ static JNINativeMethod methods[] = { {&quot;currentTimeMillis&quot;, &quot;()J&quot;, (void *)&amp;JVM_CurrentTimeMillis}, {&quot;nanoTime&quot;, &quot;()J&quot;, (void *)&amp;JVM_NanoTime}, {&quot;arraycopy&quot;, &quot;(&quot; OBJ &quot;I&quot; OBJ &quot;II)V&quot;, (void *)&amp;JVM_ArrayCopy}, }; jvm.cpp// src/share/vm/prims/jvm.cpp JVM_ENTRY(void, JVM_ArrayCopy(JNIEnv *env, jclass ignored, jobject src, jint src_pos, jobject dst, jint dst_pos, jint length)) JVMWrapper(&quot;JVM_ArrayCopy&quot;); // Check if we have null pointers if (src == NULL || dst == NULL) { THROW(vmSymbols::java_lang_NullPointerException()); } arrayOop s = arrayOop(JNIHandles::resolve_non_null(src)); arrayOop d = arrayOop(JNIHandles::resolve_non_null(dst)); assert(s-&gt;is_oop(), &quot;JVM_ArrayCopy: src not an oop&quot;); assert(d-&gt;is_oop(), &quot;JVM_ArrayCopy: dst not an oop&quot;); // Do copy Klass::cast(s-&gt;klass())-&gt;copy_array(s, src_pos, d, dst_pos, length, thread); JVM_END","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"system","slug":"CS/programing/lan/java/jdk/rt/system","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/system/"}]},{"title":"【java源码系列】Collection Framework","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/util/Collection/","text":"Hierarchy12345678910111213Collection├List│├ArrayList│├LinkedList│└Vector│ └Stack # 实现了栈的基本操作，由于涉及不够规范，目前极少使用。使用queue接口的相关实现可以完全取代它├PriorityQueue├Set│├EnumSet │├HashSet│├LinkedHashSet│├TreeSet└ArrayDeque http://www.cnblogs.com/skywang12345/p/3308498.html compare 类 同步(线程安全) 随机访问 快速增删 存储空间 复杂度：增删改查，containsValue 其他语言 Array .. Yes O() 最小 ArrayList .. Yes O() 小 . LinkedList .. No O() 大 . redis中的list采用双向链表实现 Vector .. Stack Queue class Stack extends Vectorinterface Queue extends Collection 实例场景排队：秒杀。FIFO，消息队列：频繁插入：采用linkedList","tags":[{"name":"java源码","slug":"java源码","permalink":"http://yoursite.com/tags/java源码/"},{"name":"collection","slug":"collection","permalink":"http://yoursite.com/tags/collection/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"util","slug":"CS/programing/lan/java/jdk/rt/util","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/util/"}]},{"title":"【java源码系列】Map","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/util/Map/","text":"diagram，java设计架构来自网络 http://www.cnblogs.com/skywang12345/p/3308931.html Map 接口提供三种collection 视图，允许以键集、值集或键-值映射关系集的形式查看某个映射的内容。 summary 类 同步(线程安全) order null key null value implementation 增删查改(按key) 查(按value) containsValue C C++(STL) python HashMap × 无序 √ √ hash table （采用seperate chaining解决键冲突）java8采用了哈希表与红黑树结合的方法 O(1) 顺序查找 O(n) 比如redis的实现 LinkedHashmap × 按插入顺序排序 √ √ 同上 Hashtable √ 无序 × × 同上 TreeMap 按key自定义排序 红黑树 O(log n) 无 WeakHashMap EnumMap HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。 HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。 sychronized意味着在一次仅有一个线程能够更改Hashtable。就是说任何线程要更新Hashtable时要首先获得同步锁，其它线程要等到同步锁被释放之后才能再次获得同步锁更新Hashtable。Fail-safe和iterator迭代器相关。如果某个集合对象创建了Iterator或者ListIterator，然后其它的线程试图“结构上”更改集合对象，将会抛出ConcurrentModificationException异常。但其它线程可以通过set()方法更改集合对象是允许的，因为这并没有从“结构上”更改集合。但是假如已经从结构上进行了更改，再调用set()方法，将会抛出IllegalArgumentException异常。 结构上的更改指的是删除或者插入一个元素，这样会影响到map的结构。 有没有既linked，又线程安全的Map，答案没有。因为多个线程同时操作，不同的执行顺序会产生不同的结果。所以linked的东东都应该不存在线程安全性。不能加锁吗？ –by xs 底层实现HashTable使用Enumeration，HashMap使用Iterator。HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。 6.哈希值的使用不同，HashTable直接使用对象的hashCode，代码是这样的：int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length;而HashMap重新计算hash值，而且用与代替求模：int hash = hash(k);int i = indexFor(hash, table.length); static int hash(Object x) { int h = x.hashCode(); h += ~(h &lt;&lt; 9); h ^= (h &gt;&gt;&gt; 14); h += (h &lt;&lt; 4); h ^= (h &gt;&gt;&gt; 10); return h;}static int indexFor(int h, int length) { return h &amp; (length-1);}以上只是一些比较突出的区别，当然他们的实现上还是有很多不同的，比如HashMap对null的操作 哈希冲突","tags":[{"name":"java源码","slug":"java源码","permalink":"http://yoursite.com/tags/java源码/"},{"name":"map","slug":"map","permalink":"http://yoursite.com/tags/map/"}],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"util","slug":"CS/programing/lan/java/jdk/rt/util","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/util/"}]},{"title":"【java源码系列】 - Object","date":"2017-02-01T16:00:00.000Z","path":"wiki/CS/programing/lan/java/jdk/rt/-lang/Object/","text":"架构 Object.java(rt.jar) 调用 jdk的native方法(Object.c)。 native方法 调用hotspot jvm的方法(jvm.cpp)。 Object.java java source版本：oracle 1.7 Object 还有隐形的构造函数. 12new Object();new Object[int]; // 在ArrayList的构造函数中用到了 疑问： 为什么Object.java中看不到构造函数编译器为它生成了构造函数 为什么在stack trace中看不到调用Object.有7个native方法。 private static native void registerNatives(); protected native Object clone() throws CloneNotSupportedException; public final native Class&lt;?&gt; getClass(); public native int hashCode(); public final native void notify(); public final native void notifyAll(); public final native void wait(long timeout) throws InterruptedException; 但是构造函数是怎样实现的呢？(见jvm目录的init.md) 由于Object类中有JNI方法调用，按照JNI的规则，应当生成JNI 的头文件。在此目录下执行javah -jni java.lang.Object 指令，将生成一个java_lang_Object.h头文件(自动生成的header，没什么意义) Object.c source版本：openjdk-7-fcs-src-b147-27_jun_2011 路径: openjdk\\jdk\\src\\share\\native\\java\\lang\\Object.c 没有Object.h Object.c 123456789101112131415161718192021222324252627282930313233343536373839404142/*- * Implementation of class Object * * former threadruntime.c, Sun Sep 22 12:09:39 1991 */#include &lt;stdio.h&gt;#include &lt;signal.h&gt;#include &lt;limits.h&gt;#include \"jni.h\"#include \"jni_util.h\"#include \"jvm.h\"#include \"java_lang_Object.h\"// JVM_这些函数是在jvm.c中实现的static JNINativeMethod methods[] = &#123; &#123;\"hashCode\", \"()I\", (void *)&amp;JVM_IHashCode&#125;, // 返回int &#123;\"wait\", \"(J)V\", (void *)&amp;JVM_MonitorWait&#125;, // 返回void，参数是long &#123;\"notify\", \"()V\", (void *)&amp;JVM_MonitorNotify&#125;, // 返回void &#123;\"notifyAll\", \"()V\", (void *)&amp;JVM_MonitorNotifyAll&#125;, // 返回void &#123;\"clone\", \"()Ljava/lang/Object;\", (void *)&amp;JVM_Clone&#125;, // 返回Ojbect&#125;;JNIEXPORT void JNICALLJava_java_lang_Object_registerNatives(JNIEnv *env, jclass cls)&#123; (*env)-&gt;RegisterNatives(env, cls, methods, sizeof(methods)/sizeof(methods[0]));&#125;JNIEXPORT jclass JNICALLJava_java_lang_Object_getClass(JNIEnv *env, jobject this)&#123; if (this == NULL) &#123; JNU_ThrowNullPointerException(env, NULL); return 0; &#125; else &#123; return (*env)-&gt;GetObjectClass(env, this); &#125;&#125; 其中JNINativeMethod的结构体如下: 12345typedef struct &#123; char *name; // Java中函数的名字 char *signature; // signature 方法签名，描述了函数的参数和返回值 void *fnPtr; // native实现的函数指针，指向C函数&#125; JNINativeMethod; 跟踪 hashcode1234567891011// jvm.h 路径: openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.hJNIEXPORT jint JNICALLJVM_IHashCode(JNIEnv *env, jobject obj);// jvm.cpp 路径: openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cppJVM_ENTRY(jint, JVM_IHashCode(JNIEnv* env, jobject handle)) JVMWrapper(\"JVM_IHashCode\"); // as implemented in the classic virtual machine; return 0 if object is NULL return handle == NULL ? 0 : ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)) ;JVM_END FastHashCode才是真正计算hashcode的代码 FastHashCode这是hashCode()的具体实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105// 路径: openjdk\\hotspot\\src\\share\\vm\\runtime\\synchronizer.cppintptr_t ObjectSynchronizer::FastHashCode (Thread * Self, oop obj) &#123; if (UseBiasedLocking) &#123; // NOTE: many places throughout the JVM do not expect a safepoint // to be taken here, in particular most operations on perm gen // objects. However, we only ever bias Java instances and all of // the call sites of identity_hash that might revoke biases have // been checked to make sure they can handle a safepoint. The // added check of the bias pattern is to avoid useless calls to // thread-local storage. if (obj-&gt;mark()-&gt;has_bias_pattern()) &#123; // Box and unbox the raw reference just in case we cause a STW safepoint. Handle hobj (Self, obj) ; // Relaxing assertion for bug 6320749. assert (Universe::verify_in_progress() || !SafepointSynchronize::is_at_safepoint(), \"biases should not be seen by VM thread here\"); BiasedLocking::revoke_and_rebias(hobj, false, JavaThread::current()); obj = hobj() ; assert(!obj-&gt;mark()-&gt;has_bias_pattern(), \"biases should be revoked by now\"); &#125; &#125; // hashCode() is a heap mutator ... // Relaxing assertion for bug 6320749. assert (Universe::verify_in_progress() || !SafepointSynchronize::is_at_safepoint(), \"invariant\") ; assert (Universe::verify_in_progress() || Self-&gt;is_Java_thread() , \"invariant\") ; assert (Universe::verify_in_progress() || ((JavaThread *)Self)-&gt;thread_state() != _thread_blocked, \"invariant\") ; ObjectMonitor* monitor = NULL; markOop temp, test; intptr_t hash; markOop mark = ReadStableMark (obj); // object should remain ineligible for biased locking assert (!mark-&gt;has_bias_pattern(), \"invariant\") ; if (mark-&gt;is_neutral()) &#123; hash = mark-&gt;hash(); // this is a normal header 对象的hashcode存储在对象头里 if (hash) &#123; // if it has hash, just return it 注意这里有个cache，对于同一个Ojbect，第一次调用Object.hashCode将会执行实际的计算并记入cache，以后直接从cache中取出。 return hash; &#125; hash = get_next_hash(Self, obj); // allocate a new hash code temp = mark-&gt;copy_set_hash(hash); // merge the hash code into header // use (machine word version) atomic operation to install the hash test = (markOop) Atomic::cmpxchg_ptr(temp, obj-&gt;mark_addr(), mark); if (test == mark) &#123; return hash; &#125; // If atomic operation failed, we must inflate the header // into heavy weight monitor. We could add more code here // for fast path, but it does not worth the complexity. &#125; else if (mark-&gt;has_monitor()) &#123; monitor = mark-&gt;monitor(); temp = monitor-&gt;header(); assert (temp-&gt;is_neutral(), \"invariant\") ; hash = temp-&gt;hash(); if (hash) &#123; return hash; &#125; // Skip to the following code to reduce code size &#125; else if (Self-&gt;is_lock_owned((address)mark-&gt;locker())) &#123; temp = mark-&gt;displaced_mark_helper(); // this is a lightweight monitor owned assert (temp-&gt;is_neutral(), \"invariant\") ; hash = temp-&gt;hash(); // by current thread, check if the displaced if (hash) &#123; // header contains hash code return hash; &#125; // WARNING: // The displaced header is strictly immutable. // It can NOT be changed in ANY cases. So we have // to inflate the header into heavyweight monitor // even the current thread owns the lock. The reason // is the BasicLock (stack slot) will be asynchronously // read by other threads during the inflate() function. // Any change to stack may not propagate to other threads // correctly. &#125; // Inflate the monitor to set hash code monitor = ObjectSynchronizer::inflate(Self, obj); // Load displaced header and check it has hash code mark = monitor-&gt;header(); assert (mark-&gt;is_neutral(), \"invariant\") ; hash = mark-&gt;hash(); // 取出缓存 if (hash == 0) &#123; hash = get_next_hash(Self, obj); // 实际计算 temp = mark-&gt;copy_set_hash(hash); // merge hash code into header assert (temp-&gt;is_neutral(), \"invariant\") ; test = (markOop) Atomic::cmpxchg_ptr(temp, monitor, mark); if (test != mark) &#123; // The only update to the header in the monitor (outside GC) // is install the hash code. If someone add new usage of // displaced header, please update this code hash = test-&gt;hash(); assert (test-&gt;is_neutral(), \"invariant\") ; assert (hash != 0, \"Trivial unexpected object/monitor header usage.\"); &#125; &#125; // We finally get the hash return hash;&#125; get_next_hash这才是核心代码 又调用的get_next_hash() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 路径: openjdk\\hotspot\\src\\share\\vm\\runtime\\synchronizer.cppstatic inline intptr_t get_next_hash(Thread * Self, oop obj) &#123; intptr_t value = 0 ; if (hashCode == 0) &#123; // This form uses an unguarded global Park-Miller RNG, // so it's possible for two threads to race and generate the same RNG. // On MP system we'll have lots of RW access to a global, so the // mechanism induces lots of coherency traffic. value = os::random() ; &#125; else if (hashCode == 1) &#123; // This variation has the property of being stable (idempotent) // between STW operations. This can be useful in some of the 1-0 // synchronization schemes. intptr_t addrBits = intptr_t(obj) &gt;&gt; 3 ; value = addrBits ^ (addrBits &gt;&gt; 5) ^ GVars.stwRandom ; &#125; else if (hashCode == 2) &#123; value = 1 ; // for sensitivity testing &#125; else if (hashCode == 3) &#123; value = ++GVars.hcSequence ; &#125; else if (hashCode == 4) &#123; value = intptr_t(obj) ; &#125; else &#123; // Marsaglia's xor-shift scheme with thread-specific state // This is probably the best overall implementation -- we'll // likely make this the default in future releases. unsigned t = Self-&gt;_hashStateX ; t ^= (t &lt;&lt; 11) ; Self-&gt;_hashStateX = Self-&gt;_hashStateY ; Self-&gt;_hashStateY = Self-&gt;_hashStateZ ; Self-&gt;_hashStateZ = Self-&gt;_hashStateW ; unsigned v = Self-&gt;_hashStateW ; v = (v ^ (v &gt;&gt; 19)) ^ (t ^ (t &gt;&gt; 8)) ; Self-&gt;_hashStateW = v ; value = v ; &#125; value &amp;= markOopDesc::hash_mask; if (value == 0) value = 0xBAD ; assert (value != markOopDesc::no_hash, \"invariant\") ; TEVENT (hashCode: GENERATE) ; return value;&#125; hashCode()并不是简单的返回内存地址。OpenJDK一共实现了5中不同的计算hash值的方法，通过这段代码中hashCode进行切换。其中hashCode == 4的是直接使用地址的（前面的实验说明OpenJDK默认情况下并没有使用这种方式，或许可以通过运行/编译时参数进行选择）。 ### 结论前面通过JNI验证已经能够得到很显然的结论，hashCode返回的并不一定是对象的（虚拟）内存地址，具体取决于运行时库和JVM的具体实现。 跟踪wait123456789101112131415JNIEXPORT void JNICALLJVM_MonitorWait(JNIEnv *env, jobject obj, jlong ms);// 路径: openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cppJVM_ENTRY(void, JVM_MonitorWait(JNIEnv* env, jobject handle, jlong ms)) JVMWrapper(\"JVM_MonitorWait\"); Handle obj(THREAD, JNIHandles::resolve_non_null(handle)); assert(obj-&gt;is_instance() || obj-&gt;is_array(), \"JVM_MonitorWait must apply to an object\"); JavaThreadInObjectWaitState jtiows(thread, ms != 0); if (JvmtiExport::should_post_monitor_wait()) &#123; JvmtiExport::post_monitor_wait((JavaThread *)THREAD, (oop)obj(), ms); &#125; ObjectSynchronizer::wait(obj, ms, CHECK);JVM_END 跟踪notify1234567891011JNIEXPORT void JNICALLJVM_MonitorNotify(JNIEnv *env, jobject obj);// 路径: openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cppJVM_ENTRY(void, JVM_MonitorNotify(JNIEnv* env, jobject handle)) JVMWrapper(\"JVM_MonitorNotify\"); Handle obj(THREAD, JNIHandles::resolve_non_null(handle)); assert(obj-&gt;is_instance() || obj-&gt;is_array(), \"JVM_MonitorNotify must apply to an object\"); ObjectSynchronizer::notify(obj, CHECK);JVM_END 跟踪clone12345678910JNIEXPORT jobject JNICALLJVM_Clone(JNIEnv *env, jobject obj);// 路径: openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cppJVM_ENTRY(jobject, JVM_Clone(JNIEnv* env, jobject handle)) JVMWrapper(&quot;JVM_Clone&quot;); Handle obj(THREAD, JNIHandles::resolve_non_null(handle)); const KlassHandle klass (THREAD, obj-&gt;klass()); JvmtiVMObjectAllocEventCollector oam; 跟踪 getClass跟踪参考http://blog.csdn.net/xusiwei1236/article/details/45152201 byte code 通过编译后的jar包(即class文件)，查看byte code. 运行 javap -c java.lang.Object &gt; a.txt，得到以下的byte code 如果执行不成功，看看是否把jdk的lib加入到了classpath: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101Compiled from &quot;Object.java&quot;public class java.lang.Object &#123; public java.lang.Object(); // 什么都不干？不需要调用&lt;init&gt;吗？ Code: 0: return public final native java.lang.Class&lt;?&gt; getClass(); public native int hashCode(); public boolean equals(java.lang.Object); Code: 0: aload_0 1: aload_1 2: if_acmpne 9 5: iconst_1 6: goto 10 9: iconst_0 10: ireturn protected native java.lang.Object clone() throws java.lang.CloneNotSupportedException; public java.lang.String toString(); Code: 0: new #1 // class java/lang/StringBuilder 3: dup 4: invokespecial #2 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V // 注意这里，调用了&lt;init&gt; 7: aload_0 8: invokevirtual #3 // Method getClass:()Ljava/lang/Class; 11: invokevirtual #4 // Method java/lang/Class.getName:()Ljava/lang/String; 14: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 17: ldc #6 // String @ 19: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 22: aload_0 23: invokevirtual #7 // Method hashCode:()I 26: invokestatic #8 // Method java/lang/Integer.toHexString:(I)Ljava/lang/String; 29: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 32: invokevirtual #9 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 35: areturn public final native void notify(); public final native void notifyAll(); public final native void wait(long) throws java.lang.InterruptedException; public final void wait(long, int) throws java.lang.InterruptedException; Code: 0: lload_1 1: lconst_0 2: lcmp 3: ifge 16 6: new #10 // class java/lang/IllegalArgumentException 9: dup 10: ldc #11 // String timeout value is negative 12: invokespecial #12 // Method java/lang/IllegalArgumentException.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V 15: athrow 16: iload_3 17: iflt 26 20: iload_3 21: ldc #13 // int 999999 23: if_icmple 36 26: new #10 // class java/lang/IllegalArgumentException 29: dup 30: ldc #14 // String nanosecond timeout value out of range 32: invokespecial #12 // Method java/lang/IllegalArgumentException.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V 35: athrow 36: iload_3 37: ldc #15 // int 500000 39: if_icmpge 52 42: iload_3 43: ifeq 56 46: lload_1 47: lconst_0 48: lcmp 49: ifne 56 52: lload_1 53: lconst_1 54: ladd 55: lstore_1 56: aload_0 57: lload_1 58: invokevirtual #16 // Method wait:(J)V 61: return public final void wait() throws java.lang.InterruptedException; Code: 0: aload_0 1: lconst_0 2: invokevirtual #16 // Method wait:(J)V 5: return protected void finalize() throws java.lang.Throwable; Code: 0: return static &#123;&#125;; Code: 0: invokestatic #17 // Method registerNatives:()V 3: return &#125; C:\\Program Files\\java\\jdk1.7.0_67\\jre\\lib\\rt&gt; 其他 object header: it’s JVM dependent， 具体参考JVM 扩展阅读 Object.hashCode()的返回值到底是不是对象内存地址","tags":[],"categories":[{"name":"CS","slug":"CS","permalink":"http://yoursite.com/categories/CS/"},{"name":"programing","slug":"CS/programing","permalink":"http://yoursite.com/categories/CS/programing/"},{"name":"lan","slug":"CS/programing/lan","permalink":"http://yoursite.com/categories/CS/programing/lan/"},{"name":"java","slug":"CS/programing/lan/java","permalink":"http://yoursite.com/categories/CS/programing/lan/java/"},{"name":"jdk","slug":"CS/programing/lan/java/jdk","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/"},{"name":"rt","slug":"CS/programing/lan/java/jdk/rt","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/"},{"name":"-lang","slug":"CS/programing/lan/java/jdk/rt/lang","permalink":"http://yoursite.com/categories/CS/programing/lan/java/jdk/rt/lang/"}]},{"title":"陈云霁报告 - 听课笔记","date":"2015-05-17T16:00:00.000Z","path":"wiki/电子/芯片/厂商/寒武纪/","text":"陈云霁陈云霁 14岁上大学 24岁博士毕业 科大少年班。青年千人。 寒武纪AI+芯片 寒武纪作为背靠中科院计算所和中科曙光的AI芯片独角兽公司，在芯片开发实力上处于国内领先地位。目前1A芯片通过IP授权形式进入华为手机，并与中科曙光进行产业链互补。 2013 研发全球首个深度学习处理器架构DianNao，是智能芯片领域全球被引次数最多的论文 2014 研发全球首个多核深度学习处理器架构DaDianNao，是智能芯片全球被引次数第二的论文 2015 成功研制深度学习专用芯片寒武纪 2016 发布商用深度学习深度学习处理器IP产品 寒武纪1A，以及人工智能专用指令集Cambricon ISA 2017 寒武纪1A授权华为海思使用在Kiring 970手机芯片中 2017 发布低功耗场景视觉应用处理器1H8，通用性更高的1H16和智能驾驶新片1M 2018 发布针对服务器推理和训练的机器学习处理器 MLU100 从2017年起获得了中科院为期18个月的共计1000万元的专项资金支持。 目前寒武纪主要有三条产品线： IP授权，智能IP指令集可授权集成到手机、安防、可穿戴设备等终端芯片中，2016年全年拿到1亿元订单 在智能云服务器芯片领域，作为PCIe加速卡插在云服务器上，希望能布局进入人工智能训练和推理市场 开发面向家用智能服务机器人、智能驾驶、智能安防等领域的应用芯片 深度学习处理器寒武纪做的是终端芯片？还是服务器芯片？貌似 智能计算和普通计算的区别是什么？符号主义不再流行符号逻辑表示问题，求解逻辑表达式 行为主义联结主义 - 人工神经网络把神经细胞抽象成数字，把突出抽象成数字。 轴突 - 输出 树突 - 输入 交接地方叫 - 人工神经网络一千亿个突触，人脑有百万亿突触。数量级的差距。 人工神经元与生物神经元细胞的区别。 逐层抽象处理 ## 现有硬件的缺陷，cpu gpu高能耗，低性能。alpha go 几千台。耗电几千瓦，李世乭只需要吃碗饭。 ai算法不错，落地困难，有硬件原因。cpu/gpu构建大规模神经网络，消耗很大。因此， 华为，阿里，曙光等手机都集成了寒武纪芯片。 拍照时识别东西。自动调节光圈， 本地机器翻译，不需要联网。牛逼，模型多大啊？很消耗内存吧。本地实时翻译。 存在的问题传统的ASIC(将给定算法硬件化)的思路无法解决深度学习处理的需求。(并不难，比如把C的程序编程virlog程序) 有限规模的硬件 VS 任意规模的算法 电路做神经元 突触。芯片流片后都是固定的，多少神经元。 寒武纪采用的思路是：硬件神经元的虚拟化。通过时分复用，把有限规模的硬件虚拟成任意大规模的硬件 缺陷是，数据搬运 结构固定的硬件 VS 千变万化的算法 任务不同(下棋，语音，图像)，结构差异(卷积、全连接等)。每天有大量新算法 VS 芯片研发周期长 寒武纪解决方案：抽象各种网络的通用算子，找不同算法，最耗时的部分。 主要运算：向量内积、向量距离、计数、非线性函数、排序 三个柱子：所有变量可概括为三类。 新算法来了，我们只需要对现有算子的组合 能耗受限的硬件 VS 精度优先的算法 手机上不要超过1w，不然手机发烫，电池续航也不行 服务器不超过300w，散热问题 google大脑不考虑能耗，只考虑精度 做硬件和做算法的人就存在矛盾 寒武纪解决方案：稀疏神经网络处理器 很好。跳过90%的神经元。问题是多小能够稀疏化，比如0.01导致用户体验下降，那么就调高点。通过运行时，动态调节稀疏度。 华为mate10的深度学习处理器，比iphone10高效。牛逼呀 google大脑采用了1.6万个cpu核，如果提高1万倍，就可以融入手机。寒武纪目标提高性能1万倍。 寒武纪 是通用机器学习处理器，大部分机器学习算法都支持。 牛逼 7nm，流片成本1亿人民币。没有百万量就不能回本。 距离通用的gpu，tpu距离多远？往电脑上一插就能用的。 应用面没gpu广，比如gpu能处理图片，寒武纪不擅长图片。 性能功耗比: 寒武纪 &gt; tpu &gt; gpu tpu做cnn效率高，做lstm效率低。 云端PCA加速卡，曙光出了单机20卡，基于寒武纪。 寒武纪芯片是否支持caffe tf pytorch？支持 陈天霁：华为芯片最领先，展讯、比特大陆(挖矿芯片，异军突起) # 北大公开课 - 陈云霁","tags":[],"categories":[{"name":"电子","slug":"电子","permalink":"http://yoursite.com/categories/电子/"},{"name":"芯片","slug":"电子/芯片","permalink":"http://yoursite.com/categories/电子/芯片/"},{"name":"厂商","slug":"电子/芯片/厂商","permalink":"http://yoursite.com/categories/电子/芯片/厂商/"}]},{"title":"","date":"1999-12-31T16:00:00.000Z","path":"wiki/demo/hexo/hexo-abbrlink/","text":"Demo: No-TitleThis is a post, which has no title. Typically, we can locate this file by URL with default hexo settings. 1permalink: :year/:month/:day/:title/ e.g. URL is as follows:1https://blog.eson.org/2000/01/01/demo/hexo/no-title/ It shows the full path of this post _post/demo/hexo/no-title.md. Trouble in hexo-abbrlinkhexo-abbrlink is a great plugin for hexo users. I setup hexo-abbrlink in my post. In this case, url becomes1https://blog.eson.org/pub/0/ God, I want to locate this post and add a title. But, how can I locate my error-post? Solutionwith hexo-abbrlink logIt would be better if hexo-abbrlink log the post with no title. Give me a warning. with hexo-auto-categoryIn this post, you may notice that the category is demo, hexo.Actually, the full path of this post is _post/demo/hexo/no-title.md. It really helps. hexo-auto-category binds folder structure to category. It is also a good way to locate your post. Summaryhexo-abbrlink and hexo-auto-category","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"plugin","slug":"plugin","permalink":"http://yoursite.com/tags/plugin/"},{"name":"hexo-abbrlink","slug":"hexo-abbrlink","permalink":"http://yoursite.com/tags/hexo-abbrlink/"}],"categories":[{"name":"demo","slug":"demo","permalink":"http://yoursite.com/categories/demo/"},{"name":"hexo","slug":"demo/hexo","permalink":"http://yoursite.com/categories/demo/hexo/"}]}]}